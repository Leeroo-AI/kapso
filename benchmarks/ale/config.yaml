# ALE-Bench Configuration
# Configuration for AtCoder Heuristic Contest algorithmic problems
#
# Coding agents are configured in: src/agents/coding_agents/agents.yaml
# Just specify the agent type here - defaults come from agents.yaml
#
# Available agents: aider, gemini, claude_code, openhands
# Use --list-agents to see details
#
# Knowledge search backends are pluggable via KnowledgeSearchFactory.
# Available: kg_llm_navigation (more can be added via @register_knowledge_search decorator)

# Default mode to use
default_mode: ALE_CONFIGS

# Available configuration modes
modes:
  # ===========================================
  # Production Modes
  # ===========================================
  
  # Production configuration for ALE-Bench
  ALE_CONFIGS:
    # Search strategy configuration
    search_strategy:
      type: "llm_tree_search"
      params:
        reasoning_effort: "high"
        code_debug_tries: 5
        node_expansion_limit: 2
        node_expansion_new_childs_count: 8
        idea_generation_steps: 2
        first_experiment_factor: 1
        experimentation_per_run: 1
        per_step_maximum_solution_count: 10
        exploration_budget_percent: 40
        idea_generation_model: "o3"
        idea_generation_ensemble_models:
          - "o3"
          - "o3"
          - "gemini/gemini-2.5-pro"
    
    # Coding agent configuration
    coding_agent:
      type: "aider"
      model: "o3"
      debug_model: "gpt-4.1-mini"
    
    # Context manager configuration
    context_manager:
      type: "kg_enriched"
      params:
        max_experiment_history_count: 5
        max_recent_experiment_count: 5
    
    # Knowledge search configuration
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: true
      params:
        search_top_k: 1
        navigation_steps: 3
        expansion_limit: 3
        search_node_type: "specialization"
    
    # ALE uses C++, no HuggingFace models needed
    fetch_huggingface_models: false

  # Heavy thinking - deeper reasoning per solution
  HEAVY_THINKING:
    search_strategy:
      type: "llm_tree_search"
      params:
        reasoning_effort: "high"
        code_debug_tries: 5
        node_expansion_limit: 2
        node_expansion_new_childs_count: 10
        idea_generation_steps: 1
        first_experiment_factor: 1
        experimentation_per_run: 1
        per_step_maximum_solution_count: 10
        exploration_budget_percent: 50
        idea_generation_model: "o3"
        idea_generation_ensemble_models:
          - "o3"
          - "o3"
          - "o3"
    
    coding_agent:
      type: "aider"
      model: "gpt-4.1-mini"
      debug_model: "gpt-4.1-mini"
    
    context_manager:
      type: "kg_enriched"
      params:
        max_experiment_history_count: 5
        max_recent_experiment_count: 5
    
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: true
      params:
        search_top_k: 1
        navigation_steps: 3
        expansion_limit: 3
        search_node_type: "specialization"
    
    fetch_huggingface_models: false

  # ===========================================
  # Testing Modes
  # ===========================================
  
  # Minimal configuration for quick testing
  MINIMAL:
    search_strategy:
      type: "llm_tree_search"
      params:
        reasoning_effort: "medium"
        code_debug_tries: 2
        node_expansion_limit: 2
        node_expansion_new_childs_count: 3
        idea_generation_steps: 1
        first_experiment_factor: 1
        experimentation_per_run: 1
        per_step_maximum_solution_count: 3
        exploration_budget_percent: 50
        idea_generation_model: "gpt-5-mini"
        idea_generation_ensemble_models:
          - "gpt-5-mini"
    
    coding_agent:
      type: "aider"
      model: "gpt-5-mini"
      debug_model: "gpt-5-mini"
    
    context_manager:
      type: "kg_enriched"
      params:
        max_experiment_history_count: 3
        max_recent_experiment_count: 3
    
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: false
    
    fetch_huggingface_models: false
