# Excavation + Synthesis Phase: Implementation-Principle Pairs

You are a knowledge extraction agent. Your task is to:
1. **Trace APIs** from Workflows to source code â†’ create Implementation-Principle pairs
2. **Fill gaps** by creating Principle pages for ALL concepts referenced in workflows

**âš ï¸ CRITICAL GOAL: Every `[[step::Principle:X]]` reference in workflows MUST have a corresponding Principle page by the end of this phase.**

## High-Level Task Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: EXCAVATION + SYNTHESIS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Step 1: Read workflows, collect ALL APIs and Principle references      â”‚
â”‚  Step 2: For each API â†’ Create Implementation + Principle PAIR          â”‚
â”‚  Step 3: Update indexes after each pair                                 â”‚
â”‚  Step 4: Handle shared principles (multiple implementations)            â”‚
â”‚  Step 5: GAP FILL - Create concept-only Principles for remaining refs   â”‚
â”‚  Step 6: Write execution report                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  END STATE: 100% of workflow Principle references have pages            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Context

- Repository: {repo_name}
- Repository Path: {repo_path}
- Wiki Output Directory: {wiki_dir}
- **Repository Map (Index):** {repo_map_path}
- **File Details:** {wiki_dir}/_files/
- Workflow Pages Written: {wiki_dir}/workflows/

## IMPORTANT: Read Previous Phase Reports

**FIRST**, read the previous phase reports:
- `{wiki_dir}/_reports/phase0_repo_understanding.md` - Repository structure insights
- `{wiki_dir}/_reports/phase1_anchoring.md` - Workflows created, APIs to trace

These reports tell you what workflows exist and which APIs need documentation.

## IMPORTANT: Use the Repository Map

**THEN**, read the Repository Map index at `{repo_map_path}`.

The index contains:
- **Purpose column:** What each file does
- **Coverage column:** Which files are already covered

For detailed info on any file, read its detail page in `_files/`.

## Wiki Structure Definitions

### Implementation Structure
{implementation_structure}

### Principle Structure
{principle_structure}

## Your Task: Write Implementation-Principle Pairs

### Core Process (REPEAT FOR EACH API)

For **each** significant class/function in the workflows:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FOR EACH API (e.g., FastLanguageModel, get_peft_model, etc.)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Read the source code                                         â”‚
â”‚  2. Write Implementation page (HOW it works)                     â”‚
â”‚  3. Write Principle page (WHY/WHAT concept)                      â”‚
â”‚  4. Link them bidirectionally                                    â”‚
â”‚  5. Update all indexes                                           â”‚
â”‚  6. Move to next API                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DO NOT** write all Implementations first then all Principles. Write them as **pairs**.

---

## Step 1: Identify APIs AND Referenced Principles from Workflows

Read Workflow pages in `{wiki_dir}/workflows/` and identify:

### 1A: APIs Used (for Implementation-Principle pairs)
- Classes (e.g., `FastLanguageModel`)
- Methods (e.g., `get_peft_model()`, `save_pretrained_merged()`)
- Functions (e.g., `get_chat_template()`, `train_on_responses_only()`)

### 1B: Principles Referenced in Related Pages (CRITICAL!)

**âš ï¸ CHECK EVERY WORKFLOW'S `== Related Pages ==` SECTION!**

Each workflow contains links like:
```
* [[step::Principle:{repo_name}_CLI_Configuration]]
* [[step::Principle:{repo_name}_Training_Monitoring]]
```

**You MUST create ALL referenced Principle pages.** These include:
- **API-backed Principles**: Have a corresponding Implementation (e.g., `LoRA_Configuration` â†’ `get_peft_model`)
- **Concept-only Principles**: No direct Implementation, but still need documentation (e.g., `Training_Monitoring`, `Hub_Upload`)

**Create a tracking checklist** of ALL unique `Principle:{repo_name}_X` references:

```
Example Checklist (from reading all workflow Related Pages):
â˜ Principle:unslothai_unsloth_CLI_Configuration
â˜ Principle:unslothai_unsloth_LoRA_Configuration
â˜ Principle:unslothai_unsloth_Training_Configuration
â˜ Principle:unslothai_unsloth_Training_Monitoring
â˜ Principle:unslothai_unsloth_Model_Export
â˜ Principle:unslothai_unsloth_GGUF_Conversion
â˜ Principle:unslothai_unsloth_Hub_Upload
... (continue for all unique references)
```

**Mark each as âœ… when you create the page.** At end of phase, ALL must be âœ….

## Step 2: For Each API, Write the Implementation-Principle Pair

This step handles **API-backed Principles** that have Implementation pages.

### 2A: Write the Implementation Page

Create `{wiki_dir}/implementations/{repo_name}_APIName.md`

**Required Sections:**
1. Metadata block (sources, domains, last_updated)
2. `== Overview ==` - "Concrete tool for X provided by Y library"
3. `=== Description ===` - What this code does
4. `=== Usage ===` - When to import/use this
5. `== Code Reference ==` - Source location, signature, import statement
6. `== I/O Contract ==` - Inputs/outputs as tables
7. `== Usage Examples ==` - Complete, runnable code
8. `== Related Pages ==` - Link to the Principle page you're about to create

**Code Reference Format:**
```mediawiki
== Code Reference ==

=== Source Location ===
* '''Repository:''' [{repo_url} {repo_name}]
* '''File:''' [{repo_url}/blob/main/path/to/file.py#L50-L150 path/to/file.py]
* '''Lines:''' 50-150

=== Signature ===
<syntaxhighlight lang="python">
class FastLanguageModel:
    @staticmethod
    def from_pretrained(...) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:
</syntaxhighlight>

=== Import ===
<syntaxhighlight lang="python">
from unsloth import FastLanguageModel
</syntaxhighlight>
```

**Related Pages Format:**
```mediawiki
== Related Pages ==

=== Implements Principle ===
* [[implements::Principle:{repo_name}_Model_Loading]]
```

### 2B: Identify the Underlying Concept

Before writing the Principle, ask:
- **"What theoretical/algorithmic concept does this code execute?"**
- **"What problem does this technique solve?"**
- **"Is there academic literature about this?"**

Be SPECIFIC - avoid generic names:
- âŒ "Loading" â†’ âœ… "4-bit NormalFloat (NF4) Quantization"
- âŒ "Training" â†’ âœ… "Response-Only Loss Masking for SFT"
- âŒ "Saving" â†’ âœ… "LoRA Weight Merging"

### 2C: Write the Principle Page

Create `{wiki_dir}/principles/{repo_name}_ConceptName.md`

**Required Sections:**
1. Metadata block (include academic papers!, domains, last_updated)
2. `== Overview ==` - One sentence defining the concept (library-agnostic)
3. `=== Description ===` - What it is, what problem it solves
4. `=== Usage ===` - When to use this technique
5. `== Theoretical Basis ==` - Math, pseudocode, diagrams explaining the mechanism
6. `== Related Pages ==` - **With Implementation Mapping if multiple implementations**

---

## âš ï¸ CRITICAL: Implementation Mapping for Multi-Implementation Principles

When a Principle is implemented by **multiple** Implementation pages, you MUST include an **Implementation Mapping** that explicitly shows which part of the concept each implementation handles.

### Single Implementation (Simple Case)
```mediawiki
== Related Pages ==

=== Implemented By ===
* [[implemented_by::Implementation:{repo_name}_FastLanguageModel]]
```

### Multiple Implementations (MUST ADD MAPPING)
```mediawiki
== Related Pages ==

=== Implemented By ===
* [[implemented_by::Implementation:{repo_name}_save_pretrained_merged]]
* [[implemented_by::Implementation:{repo_name}_save_pretrained_gguf]]

=== Implementation Mapping ===

This principle is implemented across multiple APIs. Here's what each handles:

{{| class="wikitable"
|-
! Concept Component !! Implementation !! What It Does
|-
| LoRA weight fusion (W = Wâ‚€ + Î±BA) || [[Implementation:{repo_name}_save_pretrained_merged]] || Merges adapters into base weights, saves as HuggingFace safetensors
|-
| LoRA merge + GGUF quantization || [[Implementation:{repo_name}_save_pretrained_gguf]] || Merges adapters, then converts to GGUF format with quantization
|}}

'''When to use each:'''
* Use `save_pretrained_merged` when deploying to vLLM, SGLang, or HuggingFace Hub
* Use `save_pretrained_gguf` when deploying to Ollama or llama.cpp
```

### Another Multi-Implementation Example (GRPO)
```mediawiki
== Related Pages ==

=== Implemented By ===
* [[implemented_by::Implementation:{repo_name}_FastLanguageModel]]
* [[implemented_by::Implementation:{repo_name}_get_peft_model]]

=== Implementation Mapping ===

GRPO training requires multiple components working together:

{{| class="wikitable"
|-
! GRPO Component !! Implementation !! Role
|-
| Model loading with vLLM || [[Implementation:{repo_name}_FastLanguageModel]] || Load model with `fast_inference=True` for fast generation during RL
|-
| LoRA adapter setup || [[Implementation:{repo_name}_get_peft_model]] || Apply LoRA with high rank (r=64+) for RL capacity
|-
| Training loop || External: `GRPOTrainer` from TRL || Orchestrates generation, reward, and optimization (not Unsloth-specific)
|}}

'''Complete GRPO Setup:'''
<syntaxhighlight lang="python">
# Step 1: Load with vLLM (FastLanguageModel)
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="...", fast_inference=True, max_lora_rank=64
)

# Step 2: Apply LoRA (get_peft_model)
model = FastLanguageModel.get_peft_model(model, r=64, ...)

# Step 3: Train with GRPOTrainer (external)
from trl import GRPOTrainer, GRPOConfig
trainer = GRPOTrainer(model=model, reward_funcs=[...], ...)
trainer.train()
</syntaxhighlight>
```

---

## Step 3: Update All Indexes (After Each Pair)

After writing each Implementation-Principle pair:

### 3A: Update Implementation Index
Add row to `{wiki_dir}/_ImplementationIndex.md`:
```
| {repo_name}_FastLanguageModel | [â†’](./implementations/...) | âœ…Principle:{repo_name}_Model_Loading, â¬œEnv:{repo_name}_CUDA | loader.py:L120-620 |
```

### 3B: Update Principle Index
Add row to `{wiki_dir}/_PrincipleIndex.md`:
```
| {repo_name}_Model_Loading | [â†’](./principles/...) | âœ…Impl:{repo_name}_FastLanguageModel | 4-bit NF4 quantization for model loading |
```

### 3C: Update Workflow Index
Change `â¬œImpl:X` to `âœ…Impl:X` and `â¬œPrinciple:X` to `âœ…Principle:X`

### 3D: Update Repository Map Coverage
```
| âœ… | `unsloth/models/loader.py` | 620 | Model loader | Impl: FastLanguageModel; Principle: Model_Loading | [â†’](...) |
```

---

## Step 4: Handle Shared Principles

Sometimes multiple implementations share the same principle. In this case:
1. Write the first Implementation
2. Write the Principle with Implementation Mapping
3. Write additional Implementations
4. Update the Principle to add more rows to the mapping table

---

## Step 5: Create Concept-Only Principles (GAP FILLING)

**âš ï¸ CRITICAL: Don't skip this step!**

After creating all Implementation-Principle pairs, check your checklist from Step 1B.

For any Principle referenced in workflows that you **haven't created yet**, create a **concept-only Principle page**.

### When to Create Concept-Only Principles

These are principles that:
- Are referenced in workflow steps (e.g., `[[step::Principle:X]]`)
- Don't have a single API implementation (they're process/concept descriptions)
- Examples: `Training_Monitoring`, `Hub_Upload`, `CLI_Configuration`, `Data_Preparation`

### Concept-Only Principle Format

Create `{wiki_dir}/principles/{repo_name}_ConceptName.md`

**Required Sections:**
1. Metadata block (sources, domains, last_updated)
2. `== Overview ==` - One sentence defining the concept
3. `=== Description ===` - What it is, what problem it solves
4. `=== Usage ===` - When to apply this concept
5. `== Practical Guide ==` - How to do this (since there's no single API)
6. `== Related Pages ==` - Link to relevant workflows and any related implementations

**Example: Training_Monitoring (concept-only)**
```mediawiki
== Overview ==

Training monitoring involves tracking metrics, detecting issues, and ensuring model convergence during fine-tuning.

=== Description ===

Effective training monitoring helps identify problems early...

=== Usage ===

Monitor training when: running long training jobs, fine-tuning for production...

== Practical Guide ==

=== Key Metrics to Track ===
* '''Loss curves''': Training and validation loss should decrease
* '''Learning rate''': Track LR schedule progression
* '''GPU memory''': Monitor for OOM risks

=== Tools ===
* '''Weights & Biases''': `pip install wandb`, pass `report_to="wandb"` to trainer
* '''TensorBoard''': Built-in with HuggingFace Trainer
* '''Console output''': `logging_steps=1` for real-time loss

== Related Pages ==

=== Used In Workflows ===
* [[used_by::Workflow:{repo_name}_QLoRA_Finetuning]]
* [[used_by::Workflow:{repo_name}_CLI_Finetuning]]
```

### Gap-Filling Checklist

Before finishing, verify:
```
â˜‘ All [[step::Principle:X]] references in workflows have pages
â˜‘ All concept-only Principles have Practical Guide sections
â˜‘ Principle Index includes ALL principles (with and without implementations)
```

---

## Step 6: Final Verification (BEFORE WRITING REPORT)

**âš ï¸ DO NOT SKIP THIS STEP!**

Before writing the execution report:

### 6A: Re-read All Workflow Related Pages
Go through each workflow file in `{wiki_dir}/workflows/` and check its `== Related Pages ==` section.

### 6B: Verify Every Reference Has a Page
For each `[[step::Principle:{repo_name}_X]]` link:
1. Check if `{wiki_dir}/principles/{repo_name}_X.md` exists
2. If NOT â†’ **Create it now** (use concept-only format if no API)

### 6C: Count and Report
```
Total Principle references in workflows: ___
Principle pages created: ___
Coverage: ___% (MUST be 100%)
```

**If coverage is not 100%, go back and create the missing pages before proceeding.**

---

## Output Instructions

Write files to:
- `{wiki_dir}/implementations/` - Implementation pages
- `{wiki_dir}/principles/` - Principle pages

**Filename formats:**
- Implementation: `{repo_name}_ClassName.md` or `{repo_name}_function_name.md`
- Principle: `{repo_name}_Concept_Name.md`

**âš ï¸ IMPORTANT: Principle filenames MUST match workflow references!**

If a workflow has:
```
* [[step::Principle:{repo_name}_CLI_Configuration]]
```

Then the file MUST be named:
```
{wiki_dir}/principles/{repo_name}_CLI_Configuration.md
```

**NOT** `{repo_name}_CLI_Config.md` or `{repo_name}_CLIConfiguration.md` â€” must match EXACTLY.

## Repo Scoping Rule (CRITICAL)

Only create/update pages whose filenames start with `{repo_name}_`.

## âš ï¸ File Editing Tip

When updating index files (`_RepoMap.md`, `_ImplementationIndex.md`, `_PrincipleIndex.md`):
- **Use Write tool** (read entire file â†’ modify â†’ write back)
- **Avoid Edit tool** â€” it often fails on markdown tables

## ğŸ“ Execution Report (REQUIRED)

When finished, write a summary report to `{wiki_dir}/_reports/phase2_excavation_synthesis.md`:

```markdown
# Phase 2: Excavation + Synthesis Report

## Implementation-Principle Pairs Created

| Implementation | Principle | Source File | Concept |
|----------------|-----------|-------------|---------|
| FastLanguageModel | Model_Loading | loader.py:L120-620 | 4-bit NF4 quantization |
| get_peft_model | LoRA_Configuration | llama.py:L2578-2800 | Low-rank adaptation |
| save_pretrained_merged | LoRA_Merging | save.py:L228-506 | Adapter weight fusion |
| save_pretrained_gguf | GGUF_Conversion | save.py:L1776-2000 | GGUF quantization |

## Multi-Implementation Principles

| Principle | Implementations | Mapping Documented |
|-----------|-----------------|-------------------|
| LoRA_Merging | save_pretrained_merged, save_pretrained_gguf | âœ… Yes |
| GRPO_Training | FastLanguageModel, get_peft_model | âœ… Yes |

## Concept-Only Principles (Gap Filling)

| Principle | Referenced By Workflows | Description |
|-----------|------------------------|-------------|
| Training_Monitoring | QLoRA_Finetuning, CLI_Finetuning | Tracking metrics and convergence |
| Hub_Upload | Model_Export, CLI_Finetuning | HuggingFace Hub deployment |
| CLI_Configuration | CLI_Finetuning | Command-line argument handling |

## Coverage Summary
- Implementation pages: X
- Principle pages (with impl): X
- Principle pages (concept-only): X
- Total Principle pages: X
- Source files covered: X
- Multi-impl principles with mapping: X

## Gap Check
- Workflow principle references: X
- Principles created: X
- **Coverage: X%** (should be 100%)

## Notes for Enrichment Phase
- [Files with environment requirements to document]
- [Code with heuristics/tribal knowledge]
```

