# Excavation Phase: Trace Imports to Source Code

You are a knowledge extraction agent. Your task is to trace the imports from the Workflow pages to find the actual implementation code, then create Implementation wiki pages.

## Context

- Repository: {repo_name}
- Repository Path: {repo_path}
- Wiki Output Directory: {wiki_dir}
- **Repository Map (Index):** {repo_map_path}
- **File Details:** {wiki_dir}/_files/
- Workflow Pages Written: {wiki_dir}/workflows/

## IMPORTANT: Read Previous Phase Reports

**FIRST**, read the previous phase reports:
- `{wiki_dir}/_reports/phase0_repo_understanding.md` - Repository structure insights
- `{wiki_dir}/_reports/phase1_anchoring.md` - Workflows created, APIs to trace

These reports tell you what workflows exist and which APIs need Implementation pages.

## IMPORTANT: Use the Repository Map

**THEN**, read the Repository Map index at `{repo_map_path}`.

The index contains:
- **Purpose column:** What each file does (helps identify which files contain the code you need)
- **Coverage column:** Which files are already covered (avoid duplicate work)
- Classes and functions listed in each file

For detailed info on any file, read its detail page in `_files/`.

## IMPORTANT: Check the Page Indexes

**Also read** `{wiki_dir}/_WorkflowIndex.md` to see what Workflows exist.

**How to read the Connections column:**
- `‚úÖImpl:{repo_name}_FastLanguageModel` = Implementation page EXISTS (don't create duplicate)
- `‚¨úImpl:{repo_name}_SFTTrainer` = Implementation page MISSING (you should create it)

**Your job:** Create pages for all `‚¨úImpl:{repo_name}_X` references you see.

## Wiki Structure Definition

{implementation_structure}

## Your Task

### Step 1: Read the Index and Workflow Pages

1. Read `{repo_map_path}` to see file purposes and find relevant source files
2. Read the Workflow pages in `{wiki_dir}/workflows/`
3. Identify which classes/functions from the index are used in the workflows

### Step 2: Match Imports to Source Files

Use the Repository Map to locate source files. The **Purpose** column tells you what each file does.

Example: If a workflow imports `FastLanguageModel`:
- Look in index for files with Purpose like "Main model loader"
- Check the detail page for that file to confirm it has `FastLanguageModel` class

### Step 3: Write Implementation Pages

For EACH significant class/function you find, create an Implementation wiki page.

**Required Sections:**
1. Metadata block (wikitable with sources, domains, last_updated)
   - ‚ö†Ô∏è **Sources must be HIGH-LEVEL only:** repo URLs, docs, papers
   - ‚ùå WRONG: `[[source::Repo|Loader|unsloth/models/loader.py]]`
   - ‚úÖ RIGHT: `[[source::Repo|Unsloth|https://github.com/unslothai/unsloth]]`
2. `== Overview ==` - One sentence: "Concrete tool for X provided by Y library"
3. `=== Description ===` - What this code does, its role in the stack
4. `=== Usage ===` - When to import/use this
5. `== Code Reference ==` - **Source location, signature, and import** (file paths go HERE)
6. `== I/O Contract ==` - Inputs/outputs as structured tables
7. `== Usage Examples ==` - **Complete, runnable code examples**
8. `== Related Pages ==` - Context & Requirements, Tips and Tricks

#### Code Reference Format (CRITICAL)

```mediawiki
== Code Reference ==

=== Source Location ===
* '''Repository:''' [{repo_url} {repo_name}]
* '''File:''' [{repo_url}/blob/main/path/to/file.py#L50-L150 path/to/file.py]
* '''Lines:''' 50-150

=== Signature ===
<syntaxhighlight lang="python">
class FastLanguageModel:
    @staticmethod
    def from_pretrained(
        model_name: str,
        max_seq_length: int = 2048,
        dtype: Optional[torch.dtype] = None,
        load_in_4bit: bool = True,
        ...
    ) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:
        """Load and optimize a language model."""
</syntaxhighlight>

=== Import ===
<syntaxhighlight lang="python">
from unsloth import FastLanguageModel
</syntaxhighlight>
```

#### Usage Examples Format (CRITICAL)

```mediawiki
== Usage Examples ==

=== Basic Usage ===
<syntaxhighlight lang="python">
from unsloth import FastLanguageModel

# Load model with 4-bit quantization
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/llama-3-8b-bnb-4bit",
    max_seq_length=2048,
    load_in_4bit=True,
)

# Use model for generation
inputs = tokenizer("Hello, ", return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0]))
</syntaxhighlight>
```

**Important:**
- Include the ACTUAL code signature from the source file
- Use REAL GitHub URLs with line numbers: `{repo_url}/blob/main/file.py#L50-L150`
- Provide COMPLETE, RUNNABLE examples
- Do NOT add `[[requires_env::...]]` or `[[uses_heuristic::...]]` links yet

### Step 4: Update Coverage in Repository Map

After creating Implementation pages, **update the index** at `{repo_map_path}`:

For each source file your Implementation covers, update its **Coverage column**:

```markdown
| ‚úÖ | `unsloth/models/loader.py` | 320 | Main model loader | Impl: FastLanguageModel | [‚Üí](...) |
```

If a file is covered by multiple pages:
```markdown
| ‚úÖ | `unsloth/save.py` | 450 | Model saving utilities | Impl: save_pretrained, save_gguf | [‚Üí](...) |
```

If a file already has Workflow coverage, append to it:
```markdown
| ‚úÖ | `examples/qlora.py` | 150 | QLoRA example | Workflow: QLoRA_Finetuning; Impl: ‚Äî | [‚Üí](...) |
```

### Step 5: Update the Implementation Index (IMMEDIATELY)

**‚ö†Ô∏è CRITICAL:** Update `{wiki_dir}/_ImplementationIndex.md` **IMMEDIATELY after creating each Implementation page**.

| Column | Content |
|--------|---------|
| Page | Implementation page name (without .md) |
| File | Link: `[‚Üí](./implementations/{repo_name}_X.md)` |
| Connections | All links with **per-reference status** (see format below) |
| Notes | Brief description + source location |

**Connections Format (use FULL page names with `{repo_name}_` prefix):**
- `‚¨úPrinciple:{repo_name}_LoRA` = Principle not created yet (filled in Synthesis phase)
- `‚¨úEnv:{repo_name}_CUDA_11` = Environment not created yet
- `‚úÖWorkflow:{repo_name}_QLoRA_Finetuning` = Workflow exists

**Example row:**
```
| {repo_name}_FastLanguageModel | [‚Üí](./implementations/...) | ‚¨úPrinciple:{repo_name}_LoRA, ‚¨úEnv:{repo_name}_CUDA, ‚úÖWorkflow:{repo_name}_QLoRA_Finetuning | loader.py:L50-200 |
```

This shows which referenced pages exist (‚úÖ) and which need creation (‚¨ú).

### Step 6: Update Other Indexes (Bi-directional)

When you create an Implementation (e.g., `{repo_name}_FastLanguageModel`):

1. **Search for references:** Look in `_WorkflowIndex.md` for `‚¨úImpl:{repo_name}_FastLanguageModel`
2. **Update to ‚úÖ:** Change `‚¨úImpl:{repo_name}_FastLanguageModel` to `‚úÖImpl:{repo_name}_FastLanguageModel`

**Example:**
```markdown
# BEFORE (in _WorkflowIndex.md):
| {repo_name}_QLoRA_Finetuning | [‚Üí](...) | ‚¨úImpl:{repo_name}_FastLanguageModel, ‚¨úImpl:{repo_name}_SFTTrainer | ... |

# AFTER (you created FastLanguageModel):
| {repo_name}_QLoRA_Finetuning | [‚Üí](...) | ‚úÖImpl:{repo_name}_FastLanguageModel, ‚¨úImpl:{repo_name}_SFTTrainer | ... |
```

**How to find references:**
- Read each index file (`_WorkflowIndex.md`, `_PrincipleIndex.md`, etc.)
- Search for `‚¨úImpl:{repo_name}_YourPageName`
- Update all occurrences to `‚úÖImpl:{repo_name}_YourPageName`

## Output Instructions

Write .md files to: `{wiki_dir}/implementations/`

**Filename format:** `{repo_name}_ClassName.md` or `{repo_name}_function_name.md`

**Examples:**
- `{repo_name}_FastLanguageModel.md`
- `{repo_name}_get_peft_model.md`
- `{repo_name}_save_pretrained_gguf.md`

Focus on the most important user-facing APIs (the ones used in the workflow examples).

## Repo Scoping Rule (CRITICAL)

Only read Workflow pages whose filenames start with `{repo_name}_`.
Only create/update Implementation pages whose filenames start with `{repo_name}_`.

## Provenance Hook (IMPORTANT)

In each Implementation page, include the *exact* source evidence:
- The repo-relative file path(s) where the class/function is defined
- The line range(s) if you can determine them

Use this exact text pattern somewhere in the Implementation page (for later automation):
`Source Files: path/to/file.py:L10-L120; other/file.py:L5-L40`

## ‚ö†Ô∏è File Editing Tip

When updating index files (`_RepoMap.md`, `_ImplementationIndex.md`):
- **Use Write tool** (read entire file ‚Üí modify ‚Üí write back)
- **Avoid Edit tool** ‚Äî it often fails on markdown tables

## üìù Execution Report (REQUIRED)

When finished, write a summary report to `{wiki_dir}/_reports/phase2_excavation.md`:

```markdown
# Phase 2: Excavation Report

## Implementations Created
| Implementation | Source File | Lines |
|----------------|-------------|-------|
| [Name] | [file:L#-#] | [count] |

## API Coverage
- Classes documented: X
- Functions documented: X
- Total source files covered: X

## Notes for Synthesis Phase
- [Concepts that need Principle pages]
- [Patterns observed across implementations]
```
