---
title: "Installation"
description: "Complete installation guide for Praxium and benchmarks"
---

## Core Installation

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone <repository-url>
    cd mle_expert_coding
    ```
  </Step>
  <Step title="Install core dependencies">
    ```bash
    pip install -r requirements.txt
    ```
  </Step>
  <Step title="Configure API keys">
    Create `.env` in project root:
    ```bash
    # Required
    OPENAI_API_KEY=your-openai-api-key
    GOOGLE_API_KEY=your-google-api-key

    # Optional
    ANTHROPIC_API_KEY=your-anthropic-api-key
    ```
  </Step>
</Steps>

## Benchmark Installation

<Tabs>
  <Tab title="MLE-Bench">
    MLE-Bench provides Kaggle competition problems.

    **Prerequisites:**
    - Git LFS (`sudo apt-get install git-lfs` or `brew install git-lfs`)

    **Installation:**
    ```bash
    # Clone and install MLE-Bench
    git clone https://github.com/openai/mle-bench.git
    cd mle-bench
    git lfs install
    git lfs fetch --all
    git lfs pull
    pip install -e .
    cd ..

    # Install MLE-specific dependencies
    pip install -r benchmarks/mle/requirements.txt
    ```

    **Verify:**
    ```bash
    PYTHONPATH=. python -m benchmarks.mle.runner --list
    ```
  </Tab>
  <Tab title="ALE-Bench">
    ALE-Bench provides AtCoder algorithmic optimization problems.

    **Prerequisites:**
    - Docker
    - libcairo2-dev (`sudo apt-get install -y libcairo2-dev`)

    **Installation:**
    ```bash
    # Clone and install ALE-Bench
    git clone https://github.com/SakanaAI/ALE-Bench.git
    cd ALE-Bench
    pip install .
    pip install ".[eval]"

    # Build Docker container for evaluation
    bash ./scripts/docker_build_202301.sh $(id -u) $(id -g)
    cd ..
    ```

    **Verify:**
    ```bash
    PYTHONPATH=. python -m benchmarks.ale.runner --list
    ```
  </Tab>
</Tabs>

## Optional: Knowledge Search

The knowledge search provides ML domain expertise using semantic search (Weaviate) and graph structure (Neo4j).

<Tabs>
  <Tab title="KG Graph Search (Recommended)">
    Uses Weaviate for embeddings + Neo4j for graph connections.

    <Steps>
      <Step title="Start Weaviate">
        ```bash
        docker run -d --name weaviate \
            -p 8081:8080 -p 50051:50051 \
            -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \
            -e PERSISTENCE_DATA_PATH='/var/lib/weaviate' \
            semitechnologies/weaviate:latest
        ```
      </Step>
      <Step title="Start Neo4j">
        ```bash
        docker run -d --name neo4j \
            --restart unless-stopped \
            -p 7474:7474 -p 7687:7687 \
            -e NEO4J_AUTH=neo4j/password123 \
            neo4j:latest
        ```
      </Step>
      <Step title="Configure connection">
        Add to `.env`:
        ```bash
        # Required for embeddings
        OPENAI_API_KEY=your-openai-api-key

        # Neo4j (graph structure)
        NEO4J_URI=bolt://localhost:7687
        NEO4J_USER=neo4j
        NEO4J_PASSWORD=password123

        # Weaviate (embeddings)
        WEAVIATE_URL=http://localhost:8081
        ```
      </Step>
      <Step title="Index wiki pages">
        ```bash
        PYTHONPATH=. python -c "
        from src.knowledge.search import KnowledgeSearchFactory, KGIndexInput
        search = KnowledgeSearchFactory.create('kg_graph_search', enabled=True)
        search.index(KGIndexInput(
            wiki_dir='data/wikis',
            persist_path='data/indexes/wikis.json',
        ))
        print('Wiki pages indexed')
        "
        ```
      </Step>
    </Steps>
  </Tab>
  <Tab title="KG LLM Navigation (Legacy)">
    Uses Neo4j with LLM-guided graph traversal.

<Steps>
  <Step title="Start Neo4j">
    ```bash
        docker run -d --name neo4j \
        --restart unless-stopped \
        -p 7474:7474 -p 7687:7687 \
        -e NEO4J_AUTH=neo4j/password \
        neo4j:latest
    ```
  </Step>
  <Step title="Configure connection">
    Add to `.env`:
    ```bash
    NEO4J_URI=bolt://localhost:7687
    NEO4J_USER=neo4j
    NEO4J_PASSWORD=password
    ```
  </Step>
  <Step title="Load knowledge data">
    ```bash
    PYTHONPATH=. python -c "
    from src.knowledge.search.kg_llm_navigation_search import KGLLMNavigationSearch
    import json
    search = KGLLMNavigationSearch()
    with open('benchmarks/mle/data/kg_data.json') as f:
        search.index(json.load(f))
    print('Knowledge graph loaded')
    "
    ```
  </Step>
</Steps>
  </Tab>
</Tabs>

## Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `OPENAI_API_KEY` | Yes | - | OpenAI API key (also for embeddings) |
| `GOOGLE_API_KEY` | Yes | - | Google API key for Gemini |
| `ANTHROPIC_API_KEY` | No | - | Anthropic API key for Claude |
| `CUDA_DEVICE` | No | `0` | GPU device for ML training |
| `NEO4J_URI` | No | `bolt://localhost:7687` | Neo4j connection URI |
| `NEO4J_USER` | No | `neo4j` | Neo4j username |
| `NEO4J_PASSWORD` | No | `password` | Neo4j password |
| `WEAVIATE_URL` | No | `http://localhost:8081` | Weaviate server URL |

## Verify Installation

```bash
# Check core installation
python -c "from src.execution.orchestrator import OrchestratorAgent; print('Core OK')"

# Check MLE-Bench
python -c "import mlebench; print('MLE-Bench OK')"

# Check ALE-Bench
python -c "import ale_bench; print('ALE-Bench OK')"

# Check Neo4j
python -c "from neo4j import GraphDatabase; print('Neo4j driver OK')"

# Check Weaviate
python -c "import weaviate; print('Weaviate client OK')"

# Check Knowledge Search
python -c "from src.knowledge.search import KGGraphSearch; print('Knowledge Search OK')"
```

