---
title: "Quickstart"
description: "Get Kapso running in 5 minutes"
---

## Prerequisites

- Python 3.12+
- Git with Git LFS
- API keys for OpenAI and/or Google (Gemini)

## Installation

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/leeroo-ai/kapso.git
    cd kapso

    # Pull Git LFS files (wiki knowledge data)
    git lfs install
    git lfs pull
    ```
  </Step>
  <Step title="Create conda environment (recommended)">
    ```bash
    conda create -n kapso_conda python=3.12
    conda activate kapso_conda
    ```
  </Step>
  <Step title="Install the package">
    ```bash
    pip install -e .
    ```
  </Step>
  <Step title="Set up API keys">
    Create a `.env` file in the project root:
    ```bash
    OPENAI_API_KEY=your-openai-api-key
    GOOGLE_API_KEY=your-google-api-key       # For Gemini models
    ANTHROPIC_API_KEY=your-anthropic-api-key # For Claude Code
    ```
  </Step>
</Steps>

## Run Your First Experiment

### Option 1: Python API (Recommended)

```python
from src.kapso import Kapso, DeployStrategy

# Initialize Kapso
kapso = Kapso()

# Build a solution â€” Kapso runs experiments automatically
solution = kapso.evolve(
    goal="Build a random forest classifier for the Iris dataset with accuracy > 0.9",
    output_path="./models/iris_v1",
    evaluator="regex_pattern",
    evaluator_params={"pattern": r"Accuracy: ([\d.]+)"},
    stop_condition="threshold",
    stop_condition_params={"threshold": 0.9},
)

# Deploy and run
software = kapso.deploy(solution, strategy=DeployStrategy.LOCAL)
result = software.run({"data_path": "./test.csv"})

# Cleanup
software.stop()
```

### Option 2: CLI

```bash
# Basic usage
PYTHONPATH=. python -m src.cli --goal "Build a random forest classifier for the Iris dataset"

# With options
PYTHONPATH=. python -m src.cli \
    --goal "Build a feature engineering pipeline for tabular data" \
    --iterations 10 \
    --coding-agent aider \
    --evaluator regex_pattern \
    --stop-condition threshold

# List available options
PYTHONPATH=. python -m src.cli --list-agents
PYTHONPATH=. python -m src.cli --list-evaluators
PYTHONPATH=. python -m src.cli --list-stop-conditions
```

## Expected Output

```
============================================================
EVOLVING: Build a random forest classifier for the Iris dataset
============================================================
  Max iterations: 10
  Language: python
  Main file: main.py
  Evaluator: regex_pattern
  Stop condition: threshold
  Coding agent: from config

Running experiments...
Experiment 1 completed with cumulative cost: $0.125
####################################################################################################
Experiment with final score 0.92:
# Solution: Random forest with GridSearchCV hyperparameter tuning...
####################################################################################################

============================================================
Evolution Complete
============================================================
Solution at: ./models/iris_v1
Experiments run: 3
Total cost: $0.450
```

The system creates git branches for each experiment and outputs the best solution path.

## With Knowledge Graph (Optional)

For domain-specific context, index a knowledge graph first:

<Steps>
  <Step title="Start infrastructure">
    ```bash
    # Start Weaviate + Neo4j (required for KG)
    ./scripts/start_infra.sh
    ```
  </Step>
  <Step title="Index wiki pages (one-time setup)">
    ```python
    from src.kapso import Kapso

    kapso = Kapso()
    kapso.index_kg(
        wiki_dir="data/wikis_llm_finetuning",
        save_to="data/indexes/llm_finetuning.index",
    )
    ```
  </Step>
  <Step title="Use the indexed KG">
    ```python
    from src.kapso import Kapso

    # Load from existing index
    kapso = Kapso(kg_index="data/indexes/llm_finetuning.index")

    solution = kapso.evolve(
        goal="Fine-tune Llama-3.1-8B with QLoRA, target loss < 0.5",
        output_path="./models/qlora_v1",
    )
    ```
  </Step>
</Steps>

## Web Research (Optional)

Kapso can do deep web research before evolving:

```python
from src.kapso import Kapso

kapso = Kapso()

# Research best practices
research = kapso.research(
    "unsloth FastLanguageModel example",
    mode="implementation",  # "idea" | "implementation" | "both"
    depth="deep",           # "light" | "deep"
)

# Use research as context for evolving
solution = kapso.evolve(
    goal="Fine-tune a model with Unsloth + LoRA",
    additional_context=research.to_context_string(),
    output_path="./models/unsloth_v1",
)
```

## Understanding the Output

After `evolve()` completes, you get a `SolutionResult`:

```python
solution.goal           # Original goal
solution.code_path      # Path to generated code
solution.experiment_logs  # List of experiment summaries
solution.metadata       # Cost, iterations, final evaluation
```

The code is in a git repository with branches for each experiment:

```bash
cd ./models/iris_v1
git branch -a
# * experiment_2  (best solution)
#   experiment_1
#   experiment_0
#   main
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Full Installation" icon="download" href="/docs/installation">
    Set up MLE-Bench, ALE-Bench, and infrastructure
  </Card>
  <Card title="Architecture" icon="sitemap" href="/docs/concepts/architecture">
    Understand the system design
  </Card>
  <Card title="Configuration" icon="gear" href="/docs/guides/configuration">
    Customize modes and parameters
  </Card>
  <Card title="Execution Flow" icon="diagram-project" href="/docs/concepts/execution-flow">
    How experiments are run
  </Card>
</CardGroup>
