# File: `vllm/forward_context.py`

**Category:** package

| Property | Value |
|----------|-------|
| Lines | 358 |
| Classes | `BatchDescriptor`, `DPMetadata`, `ForwardContext` |
| Functions | `get_forward_context`, `is_forward_context_available`, `create_forward_context`, `override_forward_context`, `set_forward_context` |
| Imports | collections, contextlib, dataclasses, time, torch, typing, vllm |

## Understanding

**Status:** âœ… Explored

**Purpose:** Forward pass context management

**Mechanism:** Manages global context state during model forward passes through ForwardContext dataclass containing attention metadata, batch descriptors, data parallelism metadata (DPMetadata), and CUDA graph mode. Provides context managers (set_forward_context, override_forward_context) for thread-safe context handling. BatchDescriptor tracks batch characteristics for CUDA graph dispatch. DPMetadata handles token distribution across data parallel ranks with chunking support. Includes optional batch size logging for performance analysis.

**Significance:** Core infrastructure for coordinating distributed execution and CUDA graph optimization. Enables different parts of the model (attention layers, MoE layers) to access shared execution context without explicit parameter passing. Critical for data parallelism where token counts must be coordinated across ranks. Essential for CUDA graph caching which requires consistent batch shapes.
