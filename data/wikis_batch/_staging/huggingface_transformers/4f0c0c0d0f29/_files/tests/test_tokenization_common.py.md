**Status:** âœ… Explored

**Purpose:** Tests common tokenization functionality shared across all tokenizer implementations including encoding, decoding, special tokens, and save/load operations.

**Mechanism:** Provides comprehensive test mixins and utilities for tokenizer testing, including subword sampling checks, special token handling, fast/slow tokenizer compatibility verification, and common tokenization patterns, with support for both SentencePiece and Tokenizers backends.

**Significance:** Ensures all tokenizers in the library maintain consistent behavior and API compatibility regardless of their underlying implementation or model architecture.
