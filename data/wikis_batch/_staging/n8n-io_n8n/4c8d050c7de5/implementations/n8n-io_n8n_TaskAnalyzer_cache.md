{| class="wikitable" style="float:right; margin-left:1em; width:300px;"
|-
! Knowledge Sources
|
* [[source::Repo|n8n|https://github.com/n8n-io/n8n]]
|-
! Domains
| [[domain::Security]], [[domain::Performance]], [[domain::Caching]]
|-
! Last Updated
| [[last_updated::2025-12-17 20:00 GMT]]
|}

== Overview ==

Concrete tool for caching validation results to avoid redundant AST parsing and security analysis of identical Python code.

=== Description ===

The `TaskAnalyzer` class implements a FIFO cache using an `OrderedDict` to store validation results keyed by code hash and allowlist configuration. The cache methods `_to_cache_key` and `_set_in_cache` manage cache key generation and entry insertion with automatic eviction.

=== Usage ===

This implementation is used internally by the `TaskAnalyzer` before performing expensive AST parsing. When analyzing task code, the analyzer first checks if the code has been validated before with the same security configuration. If found, it reuses the cached violations list, significantly improving performance for repeated executions.

== Code Reference ==

=== Source Location ===
* '''Repository:''' [https://github.com/n8n-io/n8n n8n]
* '''File:''' packages/@n8n/task-runner-python/src/task_analyzer.py
* '''Lines:''' L203-212

=== Signature ===
<syntaxhighlight lang="python">
def _to_cache_key(self, code: str) -> CacheKey:
    """Generate cache key from code and allowlists."""

def _set_in_cache(self, cache_key: CacheKey, violations: list[str]) -> None:
    """Store violations in cache with FIFO eviction."""
</syntaxhighlight>

=== Import ===
<syntaxhighlight lang="python">
from src.task_analyzer import TaskAnalyzer
from collections import OrderedDict
import hashlib
</syntaxhighlight>

== I/O Contract ==

=== Inputs (_to_cache_key) ===
{| class="wikitable"
|-
! Name !! Type !! Required !! Description
|-
| code || str || Yes || Python source code to be validated
|}

=== Outputs (_to_cache_key) ===
{| class="wikitable"
|-
! Name !! Type !! Description
|-
| cache_key || CacheKey || Tuple of (code_hash, allowlists) for cache lookup
|}

=== Inputs (_set_in_cache) ===
{| class="wikitable"
|-
! Name !! Type !! Required !! Description
|-
| cache_key || CacheKey || Yes || Cache key generated by _to_cache_key
|-
| violations || list[str] || Yes || List of security violations found (or empty list)
|}

=== Outputs (_set_in_cache) ===
{| class="wikitable"
|-
! Name !! Type !! Description
|-
| (none) || None || Method updates cache as side effect
|}

== Implementation Details ==

=== Cache Key Generation ===
The cache key is a tuple combining:
* '''code_hash''': SHA-256 hash of the source code, ensuring identical code produces identical keys
* '''allowlists''': The current allowlist configuration, ensuring cache entries are security-config-specific

This design ensures that the same code with different security policies gets different cache entries.

=== FIFO Eviction Policy ===
The cache uses a First-In-First-Out eviction strategy:
<syntaxhighlight lang="python">
if len(self._cache) >= MAX_VALIDATION_CACHE_SIZE:
    self._cache.popitem(last=False)  # Remove oldest entry
</syntaxhighlight>

When the cache reaches `MAX_VALIDATION_CACHE_SIZE`, the oldest entry is removed before inserting the new one. This prevents unbounded memory growth while maintaining recently validated code.

=== OrderedDict Usage ===
Python's `OrderedDict` maintains insertion order, making FIFO eviction efficient. The `popitem(last=False)` call removes the first (oldest) inserted item.

=== Defensive Copying ===
The cache stores a copy of the violations list:
<syntaxhighlight lang="python">
self._cache[cache_key] = violations.copy()
</syntaxhighlight>

This prevents external modification of cached results, maintaining cache integrity.

== Usage Examples ==

=== Basic Cache Flow ===
<syntaxhighlight lang="python">
from src.task_analyzer import TaskAnalyzer

analyzer = TaskAnalyzer()

# Code to validate
task_code = """
import pandas as pd
df = pd.read_csv('data.csv')
"""

# Generate cache key
cache_key = analyzer._to_cache_key(task_code)
# cache_key = ('a3f2b1c...', (<allowlist tuple>))

# Check cache
if cache_key in analyzer._cache:
    violations = analyzer._cache[cache_key]
    print(f"Cache hit! Violations: {violations}")
else:
    # Perform validation
    violations = analyzer._validate_code(task_code)

    # Store in cache
    analyzer._set_in_cache(cache_key, violations)
    print("Cache miss - validation performed and cached")
</syntaxhighlight>

=== Cache Eviction Demonstration ===
<syntaxhighlight lang="python">
from src.task_analyzer import TaskAnalyzer, MAX_VALIDATION_CACHE_SIZE

analyzer = TaskAnalyzer()

# Fill cache to capacity
for i in range(MAX_VALIDATION_CACHE_SIZE):
    code = f"x = {i}"
    key = analyzer._to_cache_key(code)
    analyzer._set_in_cache(key, [])

print(f"Cache size: {len(analyzer._cache)}")  # MAX_VALIDATION_CACHE_SIZE

# Add one more - triggers eviction
code = "y = 999"
key = analyzer._to_cache_key(code)
analyzer._set_in_cache(key, [])

print(f"Cache size after eviction: {len(analyzer._cache)}")  # Still MAX_VALIDATION_CACHE_SIZE
print("Oldest entry was removed")
</syntaxhighlight>

=== Different Security Configs ===
<syntaxhighlight lang="python">
# Same code, different security configs = different cache entries
code = "import requests"

# Strict config
analyzer.security_config.import_allowlist = []
strict_key = analyzer._to_cache_key(code)

# Permissive config
analyzer.security_config.import_allowlist = ["requests"]
permissive_key = analyzer._to_cache_key(code)

# Different keys despite identical code
assert strict_key != permissive_key
</syntaxhighlight>

== Performance Characteristics ==

=== Time Complexity ===
* '''_to_cache_key''': O(n) where n is code length (SHA-256 hashing)
* '''_set_in_cache''': O(1) for OrderedDict insertion and eviction

=== Space Complexity ===
* '''Cache Size''': O(MAX_VALIDATION_CACHE_SIZE Ã— average_violations_list_size)
* Bounded by configuration constant

=== Cache Effectiveness ===
The cache is most effective for:
* Workflow loops executing the same code repeatedly
* Common utility code patterns reused across tasks
* Development/testing scenarios with repeated executions

== Related Pages ==

=== Implements Principle ===
* [[implements::Principle:n8n-io_n8n_Validation_Caching]]

=== Requires Environment ===
* [[requires_env::Environment:n8n-io_n8n_Python_Task_Runner]]

=== Related Implementations ===
* [[related::Implementation:n8n-io_n8n_TaskAnalyzer_validate]]

=== Used By Workflow ===
* [[used_by::Workflow:n8n-io_n8n_Security_Validation]]
