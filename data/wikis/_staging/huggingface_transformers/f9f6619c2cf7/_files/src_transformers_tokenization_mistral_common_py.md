# File: `src/transformers/tokenization_mistral_common.py`

**Category:** other

| Property | Value |
|----------|-------|
| Lines | 1992 |
| Classes | `MistralTokenizerType`, `MistralCommonBackend` |
| Imports | collections, enum, huggingface_hub, numpy, os, pathlib, re, shutil, transformers, typing, ... +1 more |

## Understanding

**Status:** âœ… Explored

**Purpose:** Wraps Mistral AI's official `mistral-common` tokenizer library to provide a HuggingFace-compatible interface. Supports both SPM (SentencePiece) and Tekken tokenizers used by Mistral models. Provides tokenization, encoding/decoding, and chat template functionality.

**Mechanism:** The `MistralCommonBackend` class loads tokenizers using `MistralTokenizer.from_file()` from the mistral-common library. It implements the PreTrainedTokenizerBase interface by mapping method calls to the underlying mistral-common tokenizer. Handles special tokens differently than standard transformers tokenizers - special tokens are never encoded directly. Supports two validation modes (finetuning/test) that control BOS/EOS token addition. Includes audio support via `load_audio_as` for Voxtral models.

**Significance:** Provides official Mistral tokenizer support in transformers while maintaining compatibility with HuggingFace's tokenizer API. Critical for Mistral models (Mistral, Mixtral, Codestral, Pixtral, Voxtral) to use their official tokenization implementation. Falls back to transformers' native implementation if mistral-common is not installed.
