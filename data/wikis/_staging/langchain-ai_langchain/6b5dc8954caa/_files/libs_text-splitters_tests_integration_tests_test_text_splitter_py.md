# File: `libs/text-splitters/tests/integration_tests/test_text_splitter.py`

**Category:** other

| Property | Value |
|----------|-------|
| Lines | 114 |
| Functions | `test_huggingface_type_check`, `test_huggingface_tokenizer`, `test_token_text_splitter`, `test_token_text_splitter_overlap`, `test_token_text_splitter_from_tiktoken`, `test_sentence_transformers_count_tokens`, `test_sentence_transformers_split_text`, `test_sentence_transformers_multiple_tokens` |
| Imports | langchain_text_splitters, pytest, transformers |

## Understanding

**Status:** âœ… Explored

**Purpose:** Integration tests for tokenizer-based text splitters requiring external dependencies (HuggingFace transformers, tiktoken, sentence-transformers), validating token counting, chunking behavior, and overlap handling.

**Mechanism:** Tests HuggingFace integration by loading GPT-2 tokenizer and validating type checks and splitting. Tests `TokenTextSplitter` with various chunk sizes and overlap settings. Validates tiktoken encoder selection for OpenAI models. Tests `SentenceTransformersTokenTextSplitter` token counting, splitting, and multi-chunk behavior with sentence transformer models. Uses `pytest.mark.requires` to conditionally skip tests when dependencies unavailable.

**Significance:** Validates integration with major tokenizer libraries essential for LLM applications. Token-aware splitting is critical for respecting model context windows and ensuring chunks fit within token limits. These tests ensure accurate token counting across different tokenization schemes (subword, BPE, etc.), which directly impacts RAG quality and cost management.
