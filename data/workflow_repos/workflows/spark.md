# Workflow: spark

{| class="wikitable" style="float:right; margin-left:1em; width:300px;"
|-
! Knowledge Sources
|
* [[source::Repo|spark|https://github.com/apache/spark]]
|-
! Domains
| [[domain::data_engineering]], [[domain::distributed_computing]], [[domain::big_data]], [[domain::apache_spark]], [[domain::batch_processing]]
|-
! Stars
| 42,600
|-
! Last Updated
| [[last_updated::2026-01-12]]
|}

== Overview ==
Apache Spark is a unified analytics engine for large-scale data processing, providing distributed computation with high-level APIs in Scala, Java, Python, and R. It includes built-in libraries and mod...

=== Description ===
Apache Spark is a unified analytics engine for large-scale data processing, providing distributed computation with high-level APIs in Scala, Java, Python, and R. It includes built-in libraries and modules such as Spark SQL/DataFrames, Structured Streaming, MLlib (machine learning), GraphX (graph processing), and the pandas API on Spark.

=== Usage ===
Spark is directly applicable to ML/data workflows for large-scale ETL, feature engineering, distributed model training/inference (via MLlib and integrations), and production data pipelines.

== Github URL ==
https://github.com/apache/spark

== Related Pages ==
* Repository serves as a starter template for ML workflows
* Can be cloned and adapted for specific use cases
