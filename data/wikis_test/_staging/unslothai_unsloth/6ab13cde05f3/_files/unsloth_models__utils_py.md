# File: `unsloth/models/_utils.py`

**Category:** package

| Property | Value |
|----------|-------|
| Lines | 2356 |
| Classes | `HideLoggingMessage`, `_RaiseUninitialized`, `RaiseUninitialized`, `EmptyLogits`, `TorchAOConfig` |
| Functions | `extract_quant_model_param_count`, `get_model_param_count`, `patch_mistral_nemo_config`, `is_big_gpu`, `torch_compile_kwargs`, `patch_regional_compilation`, `prepare_model_for_kbit_training`, `has_internet`, `... +23 more` |
| Imports | accelerate, bitsandbytes, contextlib, dataclasses, device_type, functools, importlib, inspect, logging, math, ... +16 more |

## Understanding

**Status:** âœ… Explored

**Purpose:** Comprehensive model utilities and optimization patches

**Mechanism:** Contains low-level utilities for model preparation, gradient checkpointing, LoRA optimization, quantization handling, compilation, inference setup, and parameter counting. Includes patches for PyTorch compilation, bitsandbytes compatibility, PEFT layer fixes, tokenizer patches, and custom gradient checkpoint implementations. Manages logging suppression, parameter statistics collection, and torch.compile option tuning.

**Significance:** This is the deep technical foundation supporting all optimizations. Handles environment-specific optimizations (CUDA/HIP/XPU), manages memory efficiently through gradient offloading, enables custom inference modes, and maintains compatibility across PyTorch/PEFT/transformers versions. The compilation and inference setup functions are critical for achieving 2x speedups.
