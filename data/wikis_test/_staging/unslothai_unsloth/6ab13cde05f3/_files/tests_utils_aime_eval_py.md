# File: `tests/utils/aime_eval.py`

**Category:** test

| Property | Value |
|----------|-------|
| Lines | 545 |
| Functions | `download_and_combine_aime_datasets`, `load_aime_dataset`, `extract_aime_answer`, `get_num_tokens`, `evaluate_model_aime`, `compare_aime_results` |
| Imports | json, logging, os, re, requests, tqdm, typing, vllm |

## Understanding

**Status:** âœ… Documented

**Purpose:** AIME math reasoning dataset evaluation framework

**Mechanism:** Downloads AIME datasets, evaluates models with vLLM, extracts numerical answers

**Significance:** Provides standardized math reasoning benchmark for model quality assessment
