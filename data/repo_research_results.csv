url,name,description,stars,tags,ml_data_score,score_reasoning,research_status
https://github.com/scikit-learn/scikit-learn,scikit-learn,"scikit-learn is a widely used open-source Python library for machine learning built on top of the SciPy ecosystem. It provides efficient implementations of classical ML algorithms and utilities for preprocessing, model selection, and evaluation.",64600,machine learning|python|scikit-learn|data science|scientific computing|classification|regression|clustering,10,"This repository is the official source code for scikit-learn, a core Python machine learning library implementing a broad set of production-grade classical ML algorithms (e.g., classification, regression, clustering) plus key workflow tooling like preprocessing, pipelines, and model selection. It is directly applicable to everyday ML/data science work, integrates tightly with NumPy/SciPy and the broader Python data stack, and is one of the most widely adopted ML libraries in the ecosystem (as reflected by its large community and star count). Because it is a foundational, general-purpose ML toolkit used across industry and research for training and evaluating models, it merits the maximum score.",success
https://github.com/keras-team/keras,keras,"Keras 3 is a high-level, multi-backend deep learning framework for building and training neural networks. It supports running the same Keras workflows on top of TensorFlow, JAX, PyTorch, and OpenVINO (inference-only).",63700,deep learning|machine learning framework|neural networks|tensorflow|pytorch|jax|model training|computer vision,10,"This repository contains Keras 3, a core deep learning framework used to define, train, evaluate, and deploy neural network models across multiple backends (TensorFlow, JAX, PyTorch, and OpenVINO for inference-only). It is directly applicable to day-to-day ML workflows (model authoring, training loops, datasets integration, and inference) and is widely adopted in the ML community, making it both a production tool and a strong educational reference. Given its primary purpose as an ML framework and its large community adoption (tens of thousands of GitHub stars), it merits a top score of 10/10.",success
https://github.com/pandas-dev/pandas,pandas,"pandas is a fast, flexible Python library for data analysis and manipulation, providing labeled data structures (Series, DataFrame) and rich functionality for cleaning, transforming, joining, reshaping, and analyzing tabular and time series data.",47500,data analysis|data manipulation|dataframes|python|time series|data engineering|scientific computing,10,"This repository contains the core implementation of pandas, the de facto standard Python toolkit for working with structured data via Series and DataFrame, including robust indexing, joins/merges, groupby aggregation, reshaping, time-series utilities, and I/O connectors. It is directly applicable to nearly all data science and ML workflows for data loading, preprocessing, feature engineering, exploratory analysis, and dataset validation. It has extremely broad adoption across the ML/data ecosystem and integrates tightly with NumPy and the wider PyData stack (e.g., scikit-learn, statsmodels, visualization libraries). Because it is a foundational data-processing dependency for ML projects rather than a niche add-on, it merits the maximum score.",success
https://github.com/apache/spark,spark,"Apache Spark is a unified analytics engine for large-scale data processing, providing distributed computation with high-level APIs in Scala, Java, Python, and R. It includes built-in libraries and modules such as Spark SQL/DataFrames, Structured Streaming, MLlib (machine learning), GraphX (graph processing), and the pandas API on Spark.",42600,data engineering|distributed computing|big data|apache spark|batch processing|stream processing|spark sql|machine learning,10,"This repository contains the core Apache Spark engine and its major libraries for distributed analytics, including Spark SQL, Structured Streaming, and MLlib. Spark is directly applicable to ML/data workflows for large-scale ETL, feature engineering, distributed model training/inference (via MLlib and integrations), and production data pipelines. It has extensive industry adoption and a large ecosystem (e.g., PySpark and DataFrame-based workflows), making it one of the most central tools for modern data science and machine learning infrastructure at scale.",success
https://github.com/deepspeedai/DeepSpeed,DeepSpeed,"DeepSpeed is a deep learning optimization library focused on making large-scale distributed training and inference easier, faster, and more memory-efficient. It provides system and algorithmic optimizations (e.g., ZeRO-family techniques, parallelism/offload capabilities, and performance-focused CUDA/C++ extensions) primarily for PyTorch-based workflows.",41200,deep learning|distributed training|LLM inference|PyTorch|GPU acceleration|optimization|MLOps tooling,10,"DeepSpeed’s primary purpose is to optimize and scale deep learning training and inference, especially for large transformer/LLM workloads, via memory- and throughput-focused techniques and distributed execution features. It is directly applicable to ML engineering workflows because practitioners can integrate it into PyTorch training loops to train larger models, reduce memory usage, and improve multi-GPU/multi-node efficiency. The repository shows strong community adoption (tens of thousands of GitHub stars) and broad integration value for modern model training/inference stacks. Given its core relevance to large-scale model training/inference and widespread use in the ML community, it merits a 10/10.",success
https://github.com/numpy/numpy,numpy,"NumPy is the core scientific computing library for Python, providing the N-dimensional array (ndarray) along with broadcasting, vectorized operations, and a large set of numerical routines (e.g., linear algebra, FFT, random numbers). It also includes tooling to integrate and accelerate code with C/C++ and Fortran extensions.",31200,scientific computing|numerical computing|python|ndarray|linear algebra|FFT|random number generation|C/C++ and Fortran integration,10,"This repository implements NumPy, the foundational numerical array library that underpins most of the Python data science and machine learning ecosystem. It is directly used in ML/data workflows for tensor/array operations, preprocessing, feature engineering, numerical routines (e.g., linear algebra, FFT), and as a base dependency for libraries like SciPy, pandas, scikit-learn, and many deep-learning frameworks. Its community adoption is extremely high and it provides critical performance and interoperability (including C/C++/Fortran integration) that make it indispensable. While it is not an end-to-end ML framework, its centrality to data/ML work justifies a top score.",success
https://github.com/pyg-team/pytorch_geometric,pytorch_geometric,"PyTorch Geometric (PyG) is a Graph Neural Network (GNN) library built on PyTorch for building, training, and scaling deep learning models on graph-structured and other irregular data. It provides a unified API with many implemented GNN architectures, minibatch loaders, dataset utilities/benchmarks, transforms, and support for large-scale and heterogeneous graphs.",23300,graph neural networks|geometric deep learning|pytorch|python|graph machine learning|deep learning library|graph datasets,10,"This repository is a dedicated ML framework for graph-structured learning, providing core primitives (message passing layers), many state-of-the-art GNN models, and end-to-end training utilities on top of PyTorch. It is directly applicable to ML/data workflows involving node/edge/graph prediction, supports common benchmark datasets and transforms, and includes tooling for mini-batching and scaling to large graphs. The project shows strong community adoption (tens of thousands of GitHub stars) and high educational value via examples, documentation, and referenced papers, making it a top-tier library for graph ML.",success
https://github.com/onnx/onnx,onnx,"Reference implementation and specification for the Open Neural Network Exchange (ONNX), an open standard model format enabling interoperability across machine learning frameworks and runtimes. It defines an extensible computation graph, standard operator sets (opsets), data types, and provides tooling such as model checking, shape/type inference, and graph optimization.",20100,machine-learning|model-interoperability|onnx|deep-learning|model-format|inference|python|c-plus-plus,10,"This repository is the core open standard and reference implementation for ONNX, a widely adopted interchange format for representing ML/DL models as computation graphs with standardized operators and types. It is directly applicable in ML workflows for exporting, validating, converting, optimizing, and interoperating models across frameworks and deployment targets, especially for inference. Its broad ecosystem support and central role in moving models from training environments to production runtimes justify a top score for ML/data value.",success
https://github.com/microsoft/onnxruntime,onnxruntime,"ONNX Runtime is a cross-platform, high-performance machine learning inference and training engine for running models in the ONNX format. It provides graph optimizations and supports multiple hardware execution providers (e.g., CPU/GPU/accelerators) to speed up deployment and, in some cases, training workflows.",18900,machine learning|model inference|onnx|runtime|acceleration|pytorch|tensorflow|gpu,10,"This repository is the core ONNX Runtime project, providing production-grade ML model inference (and some training acceleration) across platforms and hardware backends. It is directly applicable to ML engineering and data science workflows for deploying and optimizing trained models from common frameworks (e.g., PyTorch, TensorFlow/Keras) and traditional ML libraries. Its large community adoption (evidenced by high GitHub stars and broad ecosystem usage) and strong integration potential with ML tooling make it a top-tier, foundational ML infrastructure component. As an inference/runtime accelerator used widely in industry, it fits the definition of a core ML tool with major adoption.",success
https://github.com/AUTOMATIC1111/stable-diffusion-webui,stable-diffusion-webui,"A browser-based web interface for running Stable Diffusion image generation locally, implemented with the Gradio UI framework. It provides txt2img/img2img workflows plus a large set of built-in features (inpainting/outpainting, upscaling, model/LoRA handling, training utilities, and an API) and supports community extensions.",160000,generative-ai|stable-diffusion|diffusion-models|computer-vision|gradio|pytorch|web-ui|image-generation,9,"This repository is primarily an end-user and developer interface for running Stable Diffusion inference locally (txt2img, img2img, inpainting/outpainting), managing checkpoints/VAEs/LoRAs, and integrating popular restoration/upscaling models, all exposed via a Gradio-based web UI and an API. It is highly applicable to ML workflows for generative image experimentation, rapid prototyping, prompt/parameter iteration, and model/asset management, though it is not a core training framework like PyTorch itself. Its very large community adoption (about 160k GitHub stars) and extensive feature set/extensions ecosystem make it a highly valuable practical tool for ML engineers and researchers working with diffusion models.",success
https://github.com/langgenius/dify,dify,"Dify is an open-source platform for developing and operating LLM applications, combining a visual agentic workflow builder, RAG pipelines, agent/tool capabilities, model management, and observability/LLMOps features to help teams move from prototype to production.",125000,LLM application development|agentic workflows|RAG|LLMOps|MLOps|prompt engineering|AI platform|self-hosted SaaS,9,"This repository provides a production-oriented platform for building and deploying LLM applications, including visual workflow composition, Retrieval-Augmented Generation (RAG), agent/tool integration, and model/provider management. It is directly applicable to ML/AI product workflows (especially GenAI engineering) because it operationalizes core components like RAG ingestion/retrieval, prompt iteration, and monitoring/logging in one system. The project shows very strong community adoption (large star count) and strong integration potential with many model providers and tool plugins, making it highly valuable for ML engineers and applied data/AI teams. It is not a model-training framework, but it is a core enabling layer for building ML/LLM-powered applications in production, justifying a high score.",success
https://github.com/d2l-ai/d2l-zh,d2l-zh,"《动手学深度学习》（Dive into Deep Learning, D2L.ai）的中文开源版本：以可执行的 Jupyter 笔记本形式讲解深度学习概念，并配套可运行代码、数学推导与讨论内容，面向教学与自学使用。",74800,deep learning|machine learning|educational|jupyter notebooks|pytorch|computer vision|natural language processing,9,该仓库是知名深度学习教材《Dive into Deep Learning》的中文版本，核心内容围绕深度学习方法与实践，提供可执行的 Jupyter 笔记本与配套代码，直接服务于 ML 学习与实验。它与数据科学/机器学习工作流高度相关，可用于课程教学、自学训练、复现实验与快速原型验证。仓库在 GitHub 上拥有极高关注度（约 7.48 万星），体现了广泛社区采用与教育影响力。它更偏“教育与参考实现”而非通用训练框架/生产级工具，因此给到 9 分而非 10 分。,success
https://github.com/josephmisiti/awesome-machine-learning,awesome-machine-learning,"A curated “awesome list” of machine learning frameworks, libraries, and software, organized primarily by programming language and subdomain (e.g., NLP, computer vision, deep learning). It also links to related learning resources such as books, courses, blogs, meetups, and events.",71200,machine learning|awesome-list|ml-libraries|data-science-resources|deep-learning|NLP|computer-vision,9,"This repository is a curated directory of machine-learning frameworks, libraries, and tooling across many languages and subdomains, plus supplementary ML learning resources (books/courses/events/blogs). It is highly applicable to ML/data workflows as a discovery and reference hub (helping practitioners choose libraries, compare ecosystems, and find learning materials), though it is not itself a runnable ML framework. Its very large star count indicates strong community adoption and sustained usefulness as an educational and practical index, which justifies a high score rather than a perfect 10.",success
https://github.com/vllm-project/vllm,vllm,"vLLM is a high-throughput, memory-efficient inference and serving engine for large language models (LLMs). It focuses on fast, scalable serving features like PagedAttention KV-cache management, continuous batching, distributed inference, quantization, and an OpenAI-compatible API server.",67100,machine learning|LLM inference|LLM serving|NLP|PyTorch|CUDA|OpenAI-compatible API,9,"This repository provides an inference and serving engine specifically designed for large language models, emphasizing throughput and memory efficiency (notably via PagedAttention), plus practical serving features like continuous batching and an OpenAI-compatible API server. It is directly applicable to ML engineering workflows for deploying and scaling LLMs in production, and it integrates tightly with common ML ecosystems (e.g., Hugging Face models and GPU acceleration). The very large community adoption signal (tens of thousands of GitHub stars) and breadth of supported deployment features justify a high score, though it is primarily an inference/serving system rather than a general-purpose data science library.",success
https://github.com/hiyouga/LLaMA-Factory,LlamaFactory,"LLaMA Factory is a unified toolkit for efficient fine-tuning of 100+ large language models (LLMs) and vision-language models (VLMs), providing a zero-code CLI and Web UI. It supports multiple training paradigms (e.g., SFT, reward modeling, PPO, DPO) and efficient adaptation/quantization methods (e.g., LoRA/QLoRA, low-bit tuning) plus deployment options like OpenAI-style APIs with vLLM/SGLang workers.",65200,llm-fine-tuning|nlp|vision-language-models|pytorch|lora-qlora|rlhf-dpo-ppo|gradio-webui,9,"This repository is a purpose-built ML engineering toolkit focused on training and adapting LLMs/VLMs, offering end-to-end fine-tuning workflows (pretraining, supervised fine-tuning, preference optimization like DPO, and RL methods like PPO) via CLI and web UI. It directly supports common data/ML workflows by integrating widely used techniques (LoRA/QLoRA, quantization, optimizers, monitoring/logging) and deployment paths (OpenAI-style API, vLLM/SGLang workers). Its very large community adoption (tens of thousands of GitHub stars) indicates broad use in the ML community. It earns a 9 (not 10) because it is highly impactful for applied LLM training, but it is not a foundational general-purpose ML framework on the scale of PyTorch/TensorFlow.",success
https://github.com/labmlai/annotated_deep_learning_paper_implementations,annotated_deep_learning_paper_implementations,"A large collection of simple PyTorch implementations/tutorials of deep learning papers and related algorithms, documented with explanations and rendered as side-by-side annotated notes on an accompanying website (nn.labml.ai). It covers many model families (e.g., Transformers/LLMs, diffusion, GANs) plus optimizers and reinforcement learning implementations.",65200,deep learning|PyTorch|paper implementations|transformers|diffusion models|reinforcement learning|computer vision|NLP,9,"This repository’s primary purpose is to provide educational, readable implementations of a wide range of deep learning papers/algorithms in PyTorch, with detailed side-by-side explanations via nn.labml.ai. It is directly applicable to ML workflows for learning, prototyping, and experimenting with canonical architectures (Transformers/LLMs, diffusion models, GANs) and training methods (optimizers, RL). Community adoption is very strong (65,200 GitHub stars at the time of lookup), and the documentation-first approach increases its practical and educational value; it’s not a foundational framework like PyTorch itself, so it scores slightly below a 10.",success
https://github.com/CorentinJ/Real-Time-Voice-Cloning,Real-Time-Voice-Cloning,An implementation of the SV2TTS (voice cloning) pipeline that can clone a speaker’s voice from a few seconds of audio and synthesize arbitrary text as speech using an encoder + Tacotron-based synthesizer + real-time WaveRNN vocoder.,59200,voice-cloning|text-to-speech|speech-synthesis|deep-learning|python|pytorch|tensorflow,9,"This repository provides an end-to-end deep learning system for voice cloning (speaker embedding/verification + multi-speaker TTS + neural vocoder) along with scripts and tooling to run demos, preprocess audio, and train the component models. It is directly applicable to ML workflows in speech synthesis, including experimentation, fine-tuning/training on datasets (e.g., LibriSpeech), and integration into voice-generation prototypes. It has strong community adoption (tens of thousands of GitHub stars) and high educational value by implementing well-known papers (SV2TTS/GE2E, Tacotron, WaveRNN), though the author notes the approach is aging compared with newer state-of-the-art systems.",success
https://github.com/ultralytics/yolov5,ultralytics/yolov5,"Ultralytics YOLOv5 is a PyTorch-based computer vision repository for training and running YOLOv5 models, with tooling for object detection plus related tasks like classification/segmentation and utilities for evaluation. It also supports exporting trained models to multiple deployment formats such as ONNX, CoreML, and TensorFlow Lite.",56600,computer vision|object detection|deep learning|PyTorch|YOLO|model training|model deployment,9,"This repository provides end-to-end code for training, validating, and deploying YOLOv5 vision models, making it directly useful for core ML workflows (dataset training, evaluation, inference, and export). It is strongly aligned with practical ML engineering needs via scripting/CLI utilities and export paths to common inference runtimes (e.g., ONNX/CoreML/TFLite). Its very large GitHub adoption (56.6k stars at the time of review) indicates broad community use and substantial educational value for learning modern object detection training and deployment patterns.",success
https://github.com/deepfakes/faceswap,faceswap,"FaceSwap is a Python-based deep learning application for extracting faces, training face-swap models, and converting (swapping) faces in images and videos, with both CLI and GUI workflows.",54900,deep learning|computer vision|face swapping|deepfakes|Python|image processing|video processing|GPU/CUDA,9,"This repository is an end-to-end deep learning system specifically built for a core computer vision ML task: face detection/alignment, model training, and inference (conversion) for face swapping in images/videos. It directly supports ML workflows (data extraction/preprocessing, training, and deployment-like conversion), and is widely used and well-known in the ML/vision community as a practical deepfakes tool. While it’s not a general-purpose ML framework, its strong applicability, educational value for applied CV/generative pipelines, and substantial community adoption justify a high score.",success
https://github.com/ultralytics/ultralytics,ultralytics,"Ultralytics YOLO is a Python package and CLI for training, validating, predicting, tracking, and exporting state-of-the-art YOLO computer vision models. It supports tasks including object detection, instance segmentation, image classification, and pose estimation, with deployment/export options to multiple formats.",50900,machine learning|computer vision|object detection|YOLO|PyTorch|model training|model deployment,9,"This repository provides the core Ultralytics YOLO training/inference stack, including a Python API and `yolo` CLI for end-to-end workflows (train/val/predict/export) across major vision tasks like detection, segmentation, classification, tracking, and pose. It is directly applicable to ML engineering and data science work: dataset-driven model training, evaluation, and production-oriented export/deployment are first-class features. The project is widely adopted in the ML community (tens of thousands of GitHub stars) and has strong educational value via examples and extensive documentation. It is not a general-purpose ML framework on the scale of PyTorch/TensorFlow, so it scores slightly below a 10, but it is a highly impactful, ML-centric toolkit.",success
https://github.com/coqui-ai/TTS,TTS,"A deep learning toolkit/library for Text-to-Speech (TTS) generation that provides pretrained models plus tools to train new models and fine-tune existing ones, along with utilities for dataset analysis and curation.",44200,machine learning|deep learning|text-to-speech|speech synthesis|NLP|PyTorch|audio,9,"This repository is a full-featured deep learning toolkit focused on text-to-speech generation, including pretrained models and training/fine-tuning workflows. It is directly applicable to ML workflows for speech synthesis and voice generation, covering model development, inference, and dataset utilities that data scientists/ML engineers can use end-to-end. Its large community adoption (44.2k GitHub stars) and breadth of supported models and tooling make it highly valuable for ML practice and learning, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/hpcaitech/ColossalAI,ColossalAI,"ColossalAI is an open-source system for training and serving large AI models more efficiently, focusing on reducing cost and improving speed via distributed training strategies (e.g., tensor/pipeline/data parallelism and ZeRO-style sharding), optimizations, and tooling for scaling LLM workloads.",41300,distributed training|large language models|pytorch|deep learning optimization|model parallelism|llm inference|gpu acceleration,9,"This repository provides a practical framework and optimization stack aimed specifically at making large-model (LLM and other deep learning) training/inference cheaper and faster, which is a central ML engineering problem. It is directly applicable to ML workflows because practitioners can use it to scale PyTorch model training across multiple GPUs/nodes and to improve memory/throughput via parallelism and sharding strategies. The project also shows strong community adoption (tens of thousands of GitHub stars), indicating it is widely used/recognized in the ML systems space. It is not a general-purpose data science library (like pandas), but as an ML systems tool for large-scale training/inference it is highly valuable, warranting a 9/10.",success
https://github.com/gradio-app/gradio,gradio,"Gradio is an open-source Python library for rapidly building and sharing web UIs (demos or full apps) for machine learning models, APIs, or arbitrary Python functions. It provides Python-first UI building blocks and built-in sharing so you can publish interactive demos without needing JavaScript/CSS or separate web hosting.",41200,machine learning|python|web apps|model demos|interactive ui|llm apps|data science tooling,9,"This repository provides a Python-first framework for building interactive web interfaces around ML models, APIs, and data-driven Python functions, making it directly useful for common ML workflows like prototyping, evaluation, and demo deployment. It is widely adopted in the ML community (tens of thousands of GitHub stars) and integrates naturally with typical Python ML stacks by wrapping inference code in easy-to-serve UIs. It is not itself a training framework like PyTorch, but it is a highly practical and popular tool for presenting, testing, and sharing models, which justifies a high score rather than a perfect 10.",success
https://github.com/ray-project/ray,ray,"Ray is a unified framework (AI compute engine) for scaling Python and AI applications from a single machine to a cluster. It provides a core distributed runtime plus libraries for scalable data processing (Ray Data), distributed training (Ray Train), hyperparameter tuning (Ray Tune), reinforcement learning (RLlib), and model serving (Ray Serve).",40700,distributed computing|machine learning|MLOps|data processing|distributed training|hyperparameter tuning|model serving|reinforcement learning,9,"This repository implements Ray, a widely used distributed runtime and set of ML-focused libraries (Data/Train/Tune/RLlib/Serve) for scaling end-to-end ML workloads across clusters. It is directly applicable to common ML/data workflows such as large-scale dataset processing, distributed model training, tuning, reinforcement learning, and production inference/serving. Given its broad adoption and deep integration into ML engineering and MLOps stacks, it is highly valuable for ML/data use cases, though it is more of a scaling/compute framework than a single “core ML” modeling library.",success
https://github.com/google-research/bert,bert,"Official Google Research repository providing TensorFlow implementations, scripts, and pre-trained checkpoints for BERT (Bidirectional Encoder Representations from Transformers), including code for pretraining, fine-tuning (e.g., classification, SQuAD), and feature extraction.",39800,machine learning|natural language processing|transformers|bert|tensorflow|pretrained-models|fine-tuning,9,"This repository is a reference implementation of BERT in TensorFlow and includes training/fine-tuning scripts plus links to downloadable pre-trained model checkpoints, making it directly applicable to many NLP workflows. It has very high community adoption (tens of thousands of GitHub stars) and strong educational value for understanding classic transformer pretraining and downstream fine-tuning. The score is 9 (not 10) mainly because the repo is archived (read-only as of Sep 25, 2025) and much of the ecosystem has moved toward more actively maintained libraries, but it remains foundational and highly useful for research and reproduction.",success
https://github.com/2noise/ChatTTS,ChatTTS,"ChatTTS is a generative text-to-speech (TTS) model designed for dialogue scenarios (e.g., LLM assistants), emphasizing natural conversational prosody with controls for features like pauses, laughter, and interjections. The repository provides the algorithm/infrastructure code plus examples and references pretrained model releases (with usage and licensing constraints).",38500,text-to-speech|speech-synthesis|generative-ai|deep-learning|pytorch|nlp|audio|llm-applications,9,"This repository implements and documents a dialogue-oriented generative TTS system, including infrastructure and examples for running the model and working with pretrained weights, making it directly applicable to ML engineering workflows in speech/audio generation. It is strongly ML-centric (model inference, training-related components, and integration into assistant-style applications), and it has substantial community adoption as indicated by its very large GitHub star count. It is not a general-purpose data tool, but it is highly valuable for applied ML work in speech synthesis and for learning/practicing modern generative audio modeling, justifying a 9/10.",success
https://github.com/mindsdb/mindsdb,mindsdb,"MindsDB is an open-source AI query engine/server that connects to many databases, data warehouses, and SaaS sources, lets you unify/prepare data (e.g., via knowledge bases, views, and jobs), and enables agents/MCP apps to answer questions over that federated data via MindsDB SQL and built-in agent capabilities.",38200,machine learning|LLM|MCP|agents|data integration|SQL|data platform|MLOps,9,"This repository provides a deployable server that connects to numerous data sources, unifies structured and unstructured data (including indexing via knowledge bases), and serves AI/agent-driven Q&A and workflows over that data (including built-in MCP support). It is directly applicable to modern ML/data workflows—especially LLM/agent systems, RAG-style knowledge access, and enterprise data federation—rather than being a pure model-training library. Strong community adoption (tens of thousands of GitHub stars) and broad integration surface make it highly valuable for data/ML engineers building production AI-on-data systems, justifying a 9/10 rather than a 10 reserved for foundational, ubiquitous ML frameworks.",success
https://github.com/TencentARC/GFPGAN,GFPGAN,"GFPGAN is a blind face restoration project that uses a pretrained face GAN prior (e.g., StyleGAN2) to restore realistic facial details from degraded real-world images. The repository provides pretrained models plus inference and training code, with optional background enhancement via Real-ESRGAN and demos (e.g., Colab/Gradio).",37300,machine learning|computer vision|face restoration|image restoration|GAN|PyTorch|super-resolution,9,"This repository implements GFPGAN, a GAN-prior-based blind face restoration method used to improve/restore faces in low-quality or degraded images, and it includes pretrained weights, inference scripts, and training code. It directly supports common ML workflows in computer vision (research reproduction, model fine-tuning/training, and integration into image-processing pipelines) and is built on PyTorch. Community adoption is strong (tens of thousands of GitHub stars), and the included demos/tooling (e.g., Colab/Gradio) add practical integration value, so it merits a high score but is not a general-purpose ML framework.",success
https://github.com/babysor/MockingBird,MockingBird,MockingBird is a PyTorch-based voice cloning (AI voice mimicry) project that can clone a speaker’s voice from a short sample (advertised as ~5 seconds) and generate arbitrary speech. It provides tooling for dataset preparation/training and includes demo and web-serving scripts for running inference and serving generated audio.,36800,voice cloning|text-to-speech|speech synthesis|deep learning|PyTorch|audio processing|vocoder,9,"This repository focuses on machine learning for speech synthesis/voice cloning, providing code, scripts, and configuration to train and run a TTS-style pipeline (encoder/synthesizer/vocoder) and serve results via a web interface. It is directly applicable to ML workflows in audio (data preprocessing, model training, inference, and deployment) and is widely referenced in the community (tens of thousands of stars). It scores a 9 because it is highly ML-centric and practical for experimentation/education in speech generation, though it is not a general-purpose ML framework and the maintainer notes the repo is no longer actively updated.",success
https://github.com/roboflow/supervision,supervision,"Supervision is an open-source Python toolkit of reusable, model-agnostic computer vision utilities for working with detections/segmentations (e.g., converting model outputs), annotating and visualizing images/video, tracking/counting, and handling datasets (load/split/merge/save across common formats). It’s intended to reduce repeated “glue code” in practical CV applications and integrates with popular model/tooling ecosystems.",36300,computer vision|python|object detection|image annotation|video analytics|object tracking|dataset utilities|ml tooling,9,"This repository provides a broad set of practical computer vision utilities—visualization/annotation tools, dataset I/O and conversion helpers, and connectors for common model outputs—aimed at speeding up end-to-end CV application development. It is directly applicable to ML workflows (post-processing detections, evaluating/inspecting results, preparing datasets, and building video pipelines) and is designed to plug into multiple model frameworks rather than being tied to a single one. Its high GitHub star count indicates strong community adoption and sustained usefulness for ML engineers and data scientists building real-world CV systems.",success
https://github.com/hankcs/HanLP,HanLP,"HanLP (Han Language Processing) is a production-oriented multilingual NLP toolkit providing pretrained models and pipelines for tasks such as tokenization, POS tagging, NER, dependency/constituency parsing, semantic parsing (e.g., SDP/SRL), text classification, and more. It supports large-scale multilingual processing (including Chinese-focused tooling) and offers both PyTorch and TensorFlow 2.x backends.",36100,natural language processing|multilingual NLP|Chinese NLP|deep learning|PyTorch|TensorFlow|tokenization|named entity recognition,9,"This repository is a full-featured NLP toolkit centered on machine-learning (including deep learning) models for core language understanding tasks like segmentation/tokenization, POS, NER, and parsing, with extensive pretrained model support. It is directly applicable to ML/data workflows for text preprocessing, feature extraction, and end-to-end NLP inference, and it integrates with major ML frameworks (PyTorch and TensorFlow 2.x). Its strong community adoption (tens of thousands of GitHub stars) and broad task coverage make it highly valuable for data science and ML engineering, though it is more of an applied NLP library than a general-purpose ML framework.",success
https://github.com/microsoft/qlib,qlib,"Qlib is an AI-oriented quantitative investment research platform from Microsoft that supports the end-to-end workflow for quant research, including data handling, factor/model research, backtesting, and deployment-oriented pipelines. It supports multiple ML paradigms (e.g., supervised learning, market dynamics modeling, and reinforcement learning) and integrates with Microsoft RD-Agent to help automate parts of the R&D process.",35300,quantitative finance|algorithmic trading|machine learning|time series|backtesting|reinforcement learning|Python,9,"This repository provides a full-stack quant research framework focused on applying ML to financial time-series data, from dataset preparation and feature/factor engineering to model training and evaluation/backtesting. It is directly applicable to ML/data workflows (experiment management, model pipelines, and evaluation loops) and is designed specifically for data-driven trading research. Its strong community adoption (tens of thousands of stars) and breadth of supported modeling paradigms (including RL) justify a high score, though it is more domain-specific than general-purpose ML frameworks.",success
https://github.com/BVLC/caffe,caffe,"Caffe is a BSD-licensed deep learning framework focused on speed and modularity, primarily for training and deploying convolutional neural networks. It provides a C++ core with Python and MATLAB bindings, supports CPU/GPU execution, and includes reference models and examples for computer vision workloads.",34800,deep learning|machine learning|computer vision|CNN|C++|CUDA|Python bindings,9,"BVLC/caffe is a dedicated deep learning framework for defining, training, and deploying neural networks (especially CNNs) with strong emphasis on performance and a modular architecture. It is directly applicable to ML workflows (model training/inference, model zoo/reference models, CPU/GPU support) and has historically seen broad adoption in computer vision research and production systems. While its ecosystem is not as dominant today as newer frameworks, it remains highly educational and practically useful for legacy Caffe models and for understanding classic DL framework design.",success
https://github.com/CMU-Perceptual-Computing-Lab/openpose,openpose,"OpenPose is a real-time multi-person keypoint detection library that estimates 2D/3D human pose, including body, face, hands, and foot keypoints, from images/video. It provides command-line tools plus C++ and Python APIs, with GPU (CUDA/OpenCL) and CPU support.",33600,computer vision|pose estimation|keypoint detection|deep learning|real-time inference|c++|python,9,"This repository implements OpenPose, a widely used computer-vision system for multi-person 2D keypoint detection (body/face/hands/feet) and includes modules/features for 3D reconstruction and camera calibration. It is directly applicable to ML workflows for human motion analysis, activity understanding, dataset annotation/preprocessing, and downstream modeling (e.g., action recognition or behavior analysis) via its CLI plus C++/Python APIs and structured outputs (e.g., JSON). Its broad adoption and practical deployment focus (real-time performance and GPU acceleration) make it highly valuable for ML practitioners, though it is more of an inference/vision system than a general-purpose training framework, so it falls short of a “10” category framework like PyTorch/TensorFlow.",success
https://github.com/explosion/spaCy,spaCy,"spaCy is an industrial-strength natural language processing (NLP) library for Python (with Cython components) providing production-ready pipelines and training for tasks like tokenization, POS tagging, dependency parsing, named entity recognition, and text classification, including integration with transformer models.",33000,natural language processing|machine learning|python|cython|transformers|named entity recognition|text classification|information extraction,9,"This repository implements spaCy, a widely used, production-focused NLP framework that ships pretrained pipelines and provides tooling to train and deploy custom NLP models. It is directly applicable to ML/data workflows for text processing and model training (e.g., NER, parsing, classification) and integrates with transformer-based approaches used in modern NLP. Its large community adoption and mature ecosystem make it highly valuable for data science, though it is specialized to NLP rather than a general-purpose ML framework.",success
https://github.com/google-ai-edge/mediapipe,mediapipe,"MediaPipe is a cross-platform framework and set of customizable, on-device ML solutions for live and streaming media, enabling real-time perception and multimodal tasks across mobile, web, desktop, and edge/IoT. It includes ready-to-run APIs (MediaPipe Tasks), pre-trained models, and tools to customize and evaluate solutions.",32800,machine learning|computer vision|real-time inference|on-device ML|multimodal media processing|edge AI|mobile development|TensorFlow Lite,9,"This repository provides MediaPipe’s framework plus deployable ML “Solutions/Tasks” and pre-trained models for real-time perception and media pipelines (e.g., vision/text/audio tasks) across Android, iOS, web, desktop, and edge devices. It is directly applicable to ML engineering workflows focused on on-device inference, streaming pipelines, and integrating perception models into products. Community adoption is strong (tens of thousands of GitHub stars) and the codebase has high educational and integration value for building and customizing efficient ML pipelines, though it is more deployment/solutions-focused than a general-purpose training framework.",success
https://github.com/yunjey/pytorch-tutorial,pytorch-tutorial,"A collection of concise PyTorch example projects and tutorial code for deep learning researchers, covering fundamentals through advanced models (e.g., CNNs, ResNets, RNNs, GANs, VAEs, style transfer, image captioning) with minimal, runnable implementations.",32100,pytorch|deep-learning|neural-networks|machine-learning|tutorials|computer-vision|nlp,9,"This repository is primarily an educational set of end-to-end PyTorch training examples that implement many canonical deep learning models and workflows in small, runnable scripts. It is directly applicable to ML practice for learning, prototyping, and referencing standard architectures and training loops, though it is not a production-grade library or MLOps tool. Community adoption appears strong (tens of thousands of GitHub stars), and the content maps closely to common ML/data science tasks (model definition, training, evaluation, and utilities like TensorBoard). A score of 9 reflects its high relevance and educational/practical value for ML engineers, slightly reduced because it is a tutorial/example repo rather than a core framework or widely deployed production component.",success
https://github.com/Lightning-AI/pytorch-lightning,pytorch-lightning,"PyTorch Lightning (part of Lightning) is a deep learning framework that structures PyTorch training code and automates engineering boilerplate like training loops, mixed precision, logging, and distributed/multi-GPU training to scale from CPU to multi-node GPUs with minimal code changes.",30700,deep learning|PyTorch|model training|distributed training|MLOps|GPU acceleration|Python,9,"This repository provides PyTorch Lightning, a high-level training framework that standardizes and simplifies building, training, and scaling deep learning models while handling common engineering concerns (loops, precision, multi-GPU/distributed execution, etc.). It is directly applicable to ML workflows for researchers and ML engineers who train neural networks in PyTorch and want easier scaling and cleaner project structure. With strong community adoption (tens of thousands of GitHub stars) and broad integration across typical ML tooling, it is highly valuable for ML practice, though it is not the underlying core tensor framework itself (hence not a 10).",success
https://github.com/eriklindernoren/ML-From-Scratch,ML-From-Scratch,"Educational Python project providing bare-bones NumPy implementations of fundamental machine learning models and algorithms to make their inner workings transparent and accessible, spanning topics from linear regression to deep learning.",30200,machine learning|from scratch|numpy|python|deep learning|reinforcement learning|supervised learning|unsupervised learning,9,"This repository is an educational collection of machine-learning algorithms implemented from scratch in Python (primarily using NumPy), with example scripts demonstrating techniques across supervised, unsupervised, reinforcement, and deep learning. It is highly relevant to ML/data workflows as a learning and reference resource for understanding algorithm internals, prototyping, and teaching, though it is not intended to be a production-optimized framework. Community adoption is strong (tens of thousands of stars), indicating broad usefulness and recognition. I scored it a 9 because it is directly ML-focused and widely used for education and understanding, but it is not a core industry-standard production library on the level of major frameworks.",success
https://github.com/microsoft/graphrag,graphrag,"GraphRAG is a modular, graph-based Retrieval-Augmented Generation (RAG) system that provides a data pipeline and transformation suite to extract structured information (e.g., knowledge-graph-like memory) from unstructured text using LLMs. It is intended to improve an LLM’s ability to reason over private or domain-specific corpora via graph-enriched retrieval and prompting.",30200,retrieval-augmented generation (RAG)|LLMs|knowledge graphs|NLP|information extraction|data pipelines|Python,9,"This repository implements GraphRAG: an LLM-driven indexing and transformation pipeline that turns unstructured text into structured graph/memory representations and then uses those structures to improve retrieval and generation. It is directly applicable to modern ML/NLP workflows (enterprise search over private data, LLM app indexing, graph-enriched retrieval, prompt tuning) and includes practical tooling (CLI, docs, notebooks) for running real indexing and querying pipelines. Community adoption appears strong (tens of thousands of stars and substantial usage/forks), and the project is highly educational for understanding graph-based RAG patterns, but it is not a general-purpose ML framework on the scale of core libraries like PyTorch—hence a 9 rather than 10.",success
https://github.com/donnemartin/data-science-ipython-notebooks,data-science-ipython-notebooks,"A curated collection of Jupyter/IPython notebooks covering core data science topics and tools, including deep learning tutorials (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle analyses, big data (Spark, Hadoop/MapReduce, HDFS), and Python scientific computing (NumPy, pandas, SciPy, matplotlib).",28800,data science|jupyter notebooks|machine learning|deep learning|scikit-learn|tensorflow|pandas|big data,9,"This repository is primarily an educational and reference library of Jupyter/IPython notebooks that demonstrate data science and machine learning workflows across classical ML (scikit-learn) and deep learning (TensorFlow/Theano/Keras/Caffe), along with supporting tooling like NumPy/pandas/SciPy/matplotlib and big-data platforms (Spark/Hadoop/MapReduce). It is directly applicable for learning, prototyping, and revisiting canonical examples, and its large star count indicates strong community adoption for DS/ML education. It’s not a single cohesive ML framework or production pipeline tool, which keeps it just below a perfect score, but it remains highly valuable for practical DS/ML study and experimentation.",success
https://github.com/JaidedAI/EasyOCR,EasyOCR,"EasyOCR is a ready-to-use Python OCR library that detects and recognizes text in images across 80+ languages and multiple writing scripts. It provides a simple API/CLI, automatically downloads pretrained model weights, and supports GPU/CPU execution (with optional Docker usage).",28700,optical character recognition|computer vision|deep learning|pytorch|multilingual|text detection|text recognition,9,"This repository provides an end-to-end OCR system (text detection + text recognition) with pretrained deep learning models and an easy-to-consume Python/CLI interface, making it directly usable in real-world ML/data extraction workflows. It is highly relevant to data science for document understanding, data digitization, and building pipelines that convert images/PDF renders into structured text, and it also includes guidance for training/customizing models. Strong community adoption (tens of thousands of GitHub stars) and practical integration options (GPU/CPU, Docker, demo integrations) justify a very high score, though it is more of an applied OCR toolkit than a general-purpose ML framework.",success
https://github.com/deezer/spleeter,spleeter,"Spleeter is Deezer’s open-source audio source separation library (written in Python) that uses pretrained TensorFlow models to split music into stems such as vocals/accompaniment (2-stems), vocals/drums/bass/other (4-stems), or vocals/drums/bass/piano/other (5-stems). It provides both a CLI and a Python API and can be installed via pip or used via Docker.",27900,audio-source-separation|music-information-retrieval|deep-learning|tensorflow|python|signal-processing|command-line-tool,9,"This repository provides an end-to-end ML-driven audio source separation system, including pretrained deep learning models and tooling to run inference via a CLI or integrate as a Python library. It directly supports common ML/audio workflows (dataset-based training, model-based inference, and stem generation for downstream tasks), and its adoption is strong as indicated by its large GitHub star count and broad use in audio tooling ecosystems. While it is narrower than general-purpose ML frameworks, it is highly valuable for applied ML in audio/MIR tasks, justifying a 9/10.",success
https://github.com/svc-develop-team/so-vits-svc,so-vits-svc,"SoftVC VITS Singing Voice Conversion (SVC): a VITS-based voice conversion project focused on converting/controlling singing voice (not TTS), providing training and inference code plus tooling such as a WebUI/API and ONNX export options.",27900,singing-voice-conversion|voice-conversion|audio|deep-learning|pytorch|vits|onnx|webui,9,"This repository implements and packages a deep-learning system for singing voice conversion, including model training scripts, inference pipelines, and utilities (e.g., dataset/preprocessing folders, WebUI/API, and ONNX export). It is directly applicable to ML workflows for audio generation/voice conversion (data preparation, training, evaluation, deployment), and is widely used/visible in the community (tens of thousands of GitHub stars). It scores slightly below a 10 because it is a specialized application domain (SVC) rather than a general-purpose ML framework, and the repository is archived/read-only (archived Nov 11, 2023), which can limit ongoing maintenance and integration support.",success
https://github.com/d2l-ai/d2l-en,d2l-en,"The English source repository for D2L.ai (Dive into Deep Learning), an open-source interactive deep learning book written in Jupyter notebooks that combines narrative, math, figures, and runnable multi-framework code examples.",27700,deep learning|machine learning education|Jupyter notebooks|PyTorch|MXNet|TensorFlow|NLP|computer vision,9,"This repository contains the full source (notebooks/chapters, build tooling, and supporting code) for the widely used Dive into Deep Learning interactive textbook, focused squarely on teaching and practicing modern deep learning. It is directly applicable to ML workflows because it provides runnable implementations and end-to-end examples across major DL frameworks, making it useful for learning, prototyping, and reference. Community adoption and educational value are both very high (large star count and broad academic use), but it is primarily educational content rather than a production ML library/framework, so it does not merit a 10.",success
https://github.com/mozilla/DeepSpeech,DeepSpeech,"DeepSpeech is an open-source, offline/on-device speech-to-text (ASR) engine built around a TensorFlow-based model inspired by Baidu’s Deep Speech research. It provides tooling for running inference and for training/evaluating speech recognition models, targeting deployments from embedded devices (e.g., Raspberry Pi 4) to GPU servers.",26700,automatic speech recognition|speech-to-text|deep learning|TensorFlow|NLP|audio processing|edge AI,9,"This repository is a full automatic speech recognition (ASR) system, including code and tooling for training, evaluating, and running speech-to-text models (i.e., it is directly an ML application/framework for audio). It is highly applicable to ML workflows involving supervised learning on speech datasets, model training/inference, and deployment (including offline/embedded use cases), making it valuable for ML engineers and researchers. Although the project has been archived/discontinued (archived June 19, 2025), its large community adoption (~26.7k stars) and educational value as a reference ASR implementation keep it highly relevant, but not at the very top tier of actively maintained core frameworks.",success
https://github.com/HumanSignal/label-studio,label-studio,"Label Studio is an open-source, multi-type data labeling and annotation platform for creating training data across text, images, audio, video, and time series. It provides a web UI, standardized export formats, and integrations to support ML workflows from dataset preparation to model-assisted labeling.",26100,data annotation|data labeling|machine learning|computer vision|nlp|human-in-the-loop|web application|python,9,"This repository provides Label Studio, a full-featured annotation tool used to create and manage labeled datasets across many modalities (text, images, audio, video, time series) with standardized exports. It is directly applicable to ML workflows because high-quality labeled data is foundational for training and evaluating models, and the project is built specifically for dataset labeling and iterative data improvement. The repository shows strong community adoption (tens of thousands of GitHub stars) and includes deployment options (e.g., Docker) and ML-related features/integration points, making it highly valuable for data science and ML teams. It is scored 9 (not 10) because it is not an ML framework itself (training/inference), but a critical upstream data/annotation system.",success
https://github.com/WZMIAOMIAO/deep-learning-for-image-processing,deep-learning-for-image-processing,"An educational deep-learning repository focused on image processing/computer vision, providing tutorials and runnable implementations for tasks like image classification, object detection, and segmentation using PyTorch and TensorFlow (with accompanying course PPTs and linked video lessons).",26000,deep learning|computer vision|image classification|object detection|image segmentation|PyTorch|TensorFlow,9,"This repository is primarily an end-to-end learning and implementation tutorial for deep learning in computer vision, covering key tasks (classification, detection, segmentation) with substantial code and training workflows in PyTorch and TensorFlow. It is directly applicable to ML practice because users can study architectures, train models, and adapt the provided pipelines to their own datasets. Community adoption appears strong for an educational repo (about 26k GitHub stars and ~8.3k forks), indicating broad utility and visibility. It is not a core industry framework like PyTorch itself, but it is highly valuable for ML learners and practitioners seeking reference implementations and training examples, justifying a score of 9.",success
https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix,pytorch-CycleGAN-and-pix2pix,"PyTorch implementations of CycleGAN (unpaired image-to-image translation) and pix2pix (paired image-to-image translation), including training/testing scripts, dataset utilities, and reference notebooks for reproducing paper results.",24900,machine learning|computer vision|image-to-image translation|generative adversarial networks|PyTorch|CycleGAN|pix2pix,9,"This repository provides production-ready PyTorch code for training and evaluating two widely used GAN-based image-to-image translation methods (CycleGAN and pix2pix), making it directly applicable to common ML workflows in computer vision. It includes end-to-end training/testing pipelines, dataset handling, and example notebooks, which adds strong educational and practical value for ML engineers and researchers. The repo has substantial community adoption (tens of thousands of stars) and has been actively maintained with modern Python/PyTorch support updates, supporting its high relevance to ML work.",success
https://github.com/lucidrains/vit-pytorch,vit-pytorch,A PyTorch implementation of Vision Transformer (ViT) and a large collection of related vision-transformer variants and training ideas. Provides installable modules (via pip) with example usage for image classification and associated transformer-based vision architectures.,24800,machine-learning|deep-learning|computer-vision|vision-transformer|pytorch|transformers|image-classification,9,"This repository implements Vision Transformer (ViT) in PyTorch and includes many related vision-transformer variants, making it directly usable for building and experimenting with modern computer-vision models. It maps cleanly onto ML workflows (model definition, training experimentation, architecture comparisons) and is distributed as a pip-installable package, which improves integration into research and prototyping. Its very high GitHub star count indicates strong community adoption and practical relevance for ML engineers and researchers. It is not a full end-to-end training framework or MLOps platform, so it scores slightly below a 10.",success
https://github.com/microsoft/JARVIS,JARVIS,"JARVIS (also referenced in the repo as HuggingGPT) is a research codebase for an LLM-controlled system that plans tasks, selects appropriate expert models (e.g., from Hugging Face), executes them, and synthesizes results to solve complex multi-step/multimodal user requests. It includes tooling and subprojects such as TaskBench (evaluation) and EasyTool (tool-usage improvements), plus server/CLI modes and API endpoints for running the system.",24500,LLM agents|tool use|multi-model orchestration|Hugging Face|multimodal AI|benchmarking|task automation|Python,9,"This repository implements an agentic ML system where an LLM acts as a controller to decompose requests, choose specialist ML models, run them, and aggregate outputs (i.e., a practical orchestration framework for combining LLMs with downstream ML models). It is directly applicable to modern ML/agent workflows (tool calling, model routing, multimodal pipelines) and includes evaluation/benchmarking assets (e.g., TaskBench) and tool-instruction improvements (EasyTool). Community adoption appears strong for a research repo given its high star count and association with the HuggingGPT paper, but it is not a general-purpose, industry-standard framework at the level of core libraries like PyTorch—hence a 9 rather than 10.",success
https://github.com/fastai/fastbook,fastbook,"The official companion repository for the fastai deep learning book, published as Jupyter Notebooks. It provides hands-on notebooks covering deep learning concepts and workflows using fastai and PyTorch, and is used in the fast.ai course.",24200,deep learning|machine learning|fastai|PyTorch|Jupyter notebooks|education,9,"This repository primarily consists of Jupyter notebooks that teach and demonstrate end-to-end deep learning workflows using fastai and PyTorch (vision, NLP, tabular, deployment/production topics). It is directly applicable for data scientists and ML practitioners as a practical learning resource and as runnable reference implementations for common modeling tasks. Community adoption appears strong (tens of thousands of stars) and it is tied to a widely used MOOC and book, making it highly valuable for ML education and practice. It is not a general-purpose ML framework itself, so it scores slightly below a 10.",success
https://github.com/PaddlePaddle/Paddle,Paddle,"PaddlePaddle (Paddle) is a parallel, distributed deep learning and machine learning framework focused on high-performance single-machine and distributed training, plus cross-platform deployment. It provides core DL framework capabilities and tooling to support industrial-scale model development, training, and inference.",23600,deep learning framework|machine learning|distributed training|model training|inference|GPU acceleration|scientific computing,9,"This repository is the core PaddlePaddle deep learning framework, designed for building, training, and deploying machine learning and deep learning models, including high-performance single-node and distributed training. It is directly applicable to ML/data workflows as a primary training/inference engine and includes features like automatic parallelism and integrated training/inference for large models. The project shows substantial community adoption and maturity (large star count, many commits, and active development), making it highly valuable for ML engineers and data scientists. I scored it a 9 (rather than 10) because, while it is a core ML framework, global industry mindshare and ubiquity are typically considered higher for a few dominant frameworks.",success
https://github.com/Tencent/ncnn,ncnn,"ncnn is a high-performance, cross-platform neural network inference framework optimized for mobile/edge deployment. It is implemented in C++ with no third-party dependencies and supports CPU optimizations (e.g., ARM NEON) and GPU acceleration via Vulkan.",22600,machine learning|deep learning|neural network inference|edge ai|mobile|cpp|vulkan|model deployment,9,"This repository provides a production-oriented neural network inference framework designed to run deep learning models efficiently on mobile and other edge platforms, with strong performance optimizations and optional Vulkan GPU acceleration. It is highly applicable in ML workflows for deploying trained models (e.g., converting/importing models from common ecosystems and running inference in apps and embedded systems), though it is not a training framework. The repo has substantial community adoption and ecosystem usage (including many downstream projects and integrations), making it a highly valuable tool for ML engineers focused on deployment and on-device inference.",success
https://github.com/sgl-project/sglang,sglang,"SGLang is a high-performance serving framework for large language models (LLMs) and multimodal models, designed for low-latency and high-throughput inference from single-GPU setups to large distributed clusters. It supports broad model/hardware backends and provides serving optimizations such as prefix caching (RadixAttention), continuous batching, structured outputs, and multiple parallelism strategies.",22300,llm-serving|inference-engine|generative-ai|multimodal|transformers|cuda|distributed-systems|mlops,9,"This repository is primarily an LLM/multimodal inference serving framework focused on production-grade, high-throughput, low-latency deployment, including optimizations like prefix caching (RadixAttention), batching/scheduling, disaggregated prefill/decode, quantization, and parallelism. It is directly applicable to ML engineering workflows for deploying and scaling foundation models and is compatible with common ecosystems (e.g., Hugging Face models and OpenAI-style APIs). Its large community adoption and strong production focus make it highly valuable for ML practitioners, though it is less centered on model training or classic data-science analysis, which keeps it below a perfect 10.",success
https://github.com/microsoft/unilm,unilm,"Microsoft's UniLM repository is a collection of research code and model implementations for large-scale self-supervised pre-training across tasks, languages, and modalities, covering many foundation-model projects (e.g., BEiT, LayoutLM, MiniLM, WavLM, Kosmos, etc.). It serves as an umbrella repo aggregating multiple sub-projects for NLP, vision, speech, document AI, and multimodal modeling.",21900,foundation-models|large-language-models|natural-language-processing|multimodal|computer-vision|speech|pretraining|pytorch,9,"This repository aggregates a wide range of Microsoft Research foundation-model projects and codebases for self-supervised pre-training and downstream tasks spanning NLP, vision, speech, document AI, and multimodal learning. It is directly useful for ML practitioners as reference implementations and research baselines, and it supports common workflows such as pretraining, fine-tuning, and evaluation across multiple model families. The strong community adoption (high GitHub stars) and breadth of state-of-the-art research implementations make it highly valuable for ML/data science, though it is more of a research umbrella repo than a single cohesive end-to-end production framework.",success
https://github.com/jina-ai/serve,serve,"Jina-serve is a Python framework for building and deploying AI/ML services and pipelines that communicate via gRPC, HTTP, and WebSockets. It supports scaling features like streaming and dynamic batching and provides orchestration/deployment options via Docker, Kubernetes, and Jina AI Cloud.",21800,machine learning|model serving|MLOps|microservices|gRPC|Kubernetes|Docker|LLM serving,9,"This repository provides an end-to-end framework for serving ML models as production-grade services (Executors/Deployments/Flows), exposing them over gRPC/HTTP/WebSockets and supporting orchestration patterns for scalable AI pipelines. It is directly applicable to ML engineering workflows (LLM serving, streaming outputs, batching/dynamic batching, multi-replica/sharded deployments) and integrates with common ML tooling and deployment targets (Docker, Kubernetes, cloud). Its strong adoption signal (21.8k GitHub stars) indicates substantial community usage, and its documentation/examples focus explicitly on deploying real ML workloads rather than generic web APIs. The score is 9 (highly relevant) because it is a core MLOps/model-serving tool, though not itself a model training framework.",success
https://github.com/mlc-ai/mlc-llm,mlc-llm,"MLC LLM is a machine learning compiler and high-performance deployment engine for large language models that compiles models to run efficiently across many hardware backends (CUDA, Vulkan, ROCm, Metal, WebGPU/WASM, OpenCL). It provides a unified inference runtime (MLCEngine) with an OpenAI-compatible API surfaced via REST server and multiple language/platform bindings (Python, JavaScript, iOS, Android).",21800,large language models|LLM inference|model deployment|ML compiler|TVM|cross-platform runtime|OpenAI-compatible API|GPU acceleration,9,"This repository focuses on compiling and deploying large language models for high-performance inference across a wide range of devices and GPU backends, with a unified runtime (MLCEngine) and an OpenAI-compatible API. It is directly useful to ML engineers and applied data scientists who need to package, optimize, and serve LLMs locally or on-device (including mobile and browser targets), rather than being a model-training repository. The project shows strong community adoption (large star count) and high integration potential (REST + multi-language bindings), making it highly valuable for ML deployment workflows, though it is less centered on data processing or model training itself.",success
https://github.com/serengil/deepface,deepface,"DeepFace is a lightweight Python framework for face recognition and facial attribute analysis (age, gender, emotion, race). It wraps multiple state-of-the-art face recognition models and provides simple APIs for verification, identification/search, embedding extraction, and real-time webcam analysis.",21400,computer vision|face recognition|facial attribute analysis|deep learning|python|biometrics|embeddings|MLOps-integration,9,"This repository provides production-oriented APIs for core computer vision ML tasks: face verification/recognition, embedding extraction, and facial attribute prediction, while abstracting common pipeline steps (detect/align/normalize/represent/verify) behind simple function calls. It is directly applicable to ML workflows for identity matching, similarity search, dataset embedding generation, and downstream analysis, and it integrates with common storage/search backends for face databases. Community adoption appears strong (21.4k GitHub stars), indicating broad usage and practical value. It is not a general-purpose ML framework (so not a 10), but it is a highly useful, specialized ML library for face analytics.",success
https://github.com/recommenders-team/recommenders,recommenders,"Recommenders is an open-source Python project providing best practices, utilities, and Jupyter notebook examples for building recommendation systems—from data preparation and model training to evaluation, tuning, and production operationalization (including Azure-oriented scenarios). It includes implementations and tutorials for classical and modern recommender algorithms (e.g., ALS, SAR, deep/sequential models) and supports CPU/GPU/Spark workflows.",21194,recommender systems|machine learning|python|deep learning|jupyter notebooks|spark|mlops,9,"This repository is purpose-built for machine learning, specifically recommender systems, and provides end-to-end materials: data loading/prep utilities, multiple recommendation algorithms (classical and deep/sequential), and offline evaluation/benchmarking plus guidance for operationalization. It is directly applicable to ML/data workflows because practitioners can use the included library utilities and notebooks to prototype, compare, and productionize recommenders (including Spark and GPU configurations). Community adoption is strong (21,194 stars and 3,271 forks shown on the org page), and the project is positioned as a major open-source reference for recommendation systems under LF AI & Data, which supports its educational and practical value. I rated it a 9 (not a 10) because it is a specialized ML domain toolkit rather than a general-purpose, ubiquitous core ML framework.",success
https://github.com/google/langextract,langextract,LangExtract is a Python library that uses LLMs to extract structured information from unstructured text based on user-defined instructions and few-shot examples. It emphasizes precise source grounding (mapping extractions back to exact spans) and can generate interactive HTML visualizations for reviewing extracted entities.,20400,python|llm|information-extraction|nlp|structured-data|gemini|ollama|data-annotation,9,"This repository provides an LLM-driven information extraction framework that turns free text (e.g., clinical notes, reports, long documents) into structured outputs guided by prompts and examples, with strong traceability via span-level source grounding and built-in review visualization. It fits directly into common ML/data workflows for dataset creation, entity/attribute extraction, document structuring, and evaluation/QA of model outputs. The high score reflects its direct applicability to NLP and data engineering tasks around LLM-powered extraction, its flexible support for both cloud models (e.g., Gemini) and local models (via Ollama), and strong practical tooling (schema consistency + visualization) that makes it especially useful for production data pipelines and annotation-like review loops.",success
https://github.com/langfuse/langfuse,langfuse,"Langfuse is an open-source LLM engineering platform for building and operating AI applications, offering LLM observability/tracing, metrics, evaluations, prompt management, datasets, and a playground. It integrates with popular tooling such as OpenTelemetry, LangChain, the OpenAI SDK, and LiteLLM.",20300,LLM observability|MLOps|prompt management|LLM evaluation|OpenTelemetry|LangChain|TypeScript,9,"This repository provides an end-to-end platform to instrument, monitor, evaluate, and debug LLM-powered applications, including tracing/observability, metrics, eval workflows, prompt management, and datasets. It is directly applicable to ML/LLM production workflows (especially for LLMOps) and integrates with common ML/LLM tooling (e.g., OpenTelemetry, LangChain, OpenAI SDK, LiteLLM), making it easy to adopt in real systems. Given its strong relevance to deploying and improving LLM applications plus substantial community adoption (20.3k GitHub stars at the time checked), it merits a high score, though it is not itself a model-training framework.",success
https://github.com/SYSTRAN/faster-whisper,faster-whisper,A high-performance reimplementation of OpenAI’s Whisper speech-to-text model built on CTranslate2 for faster and more memory-efficient transcription. It supports GPU/CPU inference and can further speed up and reduce memory via 8-bit quantization.,20200,speech-to-text|automatic-speech-recognition|whisper|NLP|audio-processing|inference-optimization|CTranslate2|Python,9,"This repository provides a production-oriented, faster inference implementation of the Whisper ASR model using CTranslate2, focusing on efficient transcription with lower latency and memory use (including int8 quantization). It is directly applicable to ML/data workflows for speech analytics, dataset transcription/labeling, and building ASR-powered products, and it integrates cleanly into Python pipelines. Its high GitHub star count indicates strong community adoption among ML engineers and practitioners, but it is primarily an inference/runtime library rather than a full training framework, which keeps it just below a perfect 10.",success
https://github.com/graphdeco-inria/gaussian-splatting,gaussian-splatting,"Official reference implementation of the SIGGRAPH 2023 / ACM TOG paper ""3D Gaussian Splatting for Real-Time Radiance Field Rendering"", providing a PyTorch + CUDA training pipeline that fits a scene as 3D Gaussians from SfM/COLMAP inputs and enables real-time novel-view rendering via dedicated viewers.",20200,computer vision|3d reconstruction|novel view synthesis|radiance fields|gaussian splatting|PyTorch|CUDA|real-time rendering,9,"This repository implements a widely used ML-adjacent method for photorealistic novel-view synthesis by optimizing a 3D Gaussian scene representation from Structure-from-Motion (e.g., COLMAP) data and rendering it in real time. It is directly applicable to ML/computer-vision workflows (dataset-to-model training, evaluation metrics, and rendering/visualization tooling) and is a standard baseline/reference codebase in the rapidly growing 3DGS ecosystem. Community adoption is very high (20.2k stars) and the code is educational for learning modern radiance-field alternatives and GPU-accelerated training/rendering pipelines. It’s not a general-purpose ML framework, but it is a highly impactful, domain-specific ML/graphics training system, justifying a 9/10.",success
https://github.com/QwenLM/Qwen,Qwen,"Official repository for Alibaba Cloud's Qwen (通义千问) pretrained and chat large language models, providing code and guidance for inference, quantization (e.g., GPTQ), deployment demos (CLI/Web/API), evaluation, and finetuning (including LoRA/Q-LoRA). The repository notes it is no longer actively maintained and directs users to QwenLM/Qwen2 for newer work.",20100,large-language-models|nlp|transformers|llm-inference|model-quantization|fine-tuning|deepspeed|openai-api-compatible,9,"This repository is centered on Qwen pretrained/chat LLMs and includes practical tooling and examples for core ML workflows: running inference, quantizing models, reproducing evaluation results, and performing finetuning (including LoRA/Q-LoRA). It is directly applicable to ML engineering and NLP work, and it has strong community adoption signals (about 20.1k GitHub stars). The score is not 10 primarily because the repo states it is no longer actively maintained and points users to a newer Qwen2 repository, which reduces its long-term value as the canonical implementation.",success
https://github.com/facebook/prophet,prophet,"Prophet is an open-source forecasting library (Python and R) for time series data using an additive model with flexible non-linear trends, multiple seasonalities (yearly/weekly/daily), and holiday effects. It is designed to produce high-quality forecasts that are robust to missing data, outliers, and trend changes.",19900,time series forecasting|machine learning|data science|statistics|python|r|stan,9,"This repository provides Prophet, a widely used time-series forecasting tool implemented for Python and R, built around an additive model with seasonality and holiday components and fitted via Stan. It is directly applicable in ML/data workflows for demand forecasting, capacity planning, KPI forecasting, and other business time-series problems, with strong educational value due to its interpretable components and extensive documentation. Community adoption is high (large GitHub star count and broad ecosystem packaging via PyPI/CRAN/conda), but it is more specialized (forecasting-focused) than general-purpose ML frameworks, so it falls just short of a perfect 10.",success
https://github.com/tensorflow/tfjs,tensorflow/tfjs,"TensorFlow.js is an open-source, hardware-accelerated JavaScript library for training and deploying machine learning models in the browser and in Node.js, with backends such as WebGL/WASM (and WebGPU). The repo is a monorepo that contains the core APIs, higher-level layers API, data utilities, model conversion tooling, and multiple runtime backends.",19100,machine learning|deep learning|javascript|tensorflow|browser-ml|webgl|nodejs|model-deployment,9,"This repository provides TensorFlow.js, a primary ML framework for building, training, and running neural-network models directly in JavaScript across browsers and Node.js, using accelerated backends (e.g., WebGL/WASM/WebGPU). It is directly applicable to ML workflows for inference and (in many cases) training, plus it includes tooling for running existing TensorFlow models via conversion. Its large community adoption and broad ecosystem integration (front-end apps, Node services, edge/client inference) make it highly valuable for ML engineers and data scientists, though it is somewhat less central than Python-first frameworks for large-scale training—hence a 9 rather than 10.",success
https://github.com/Unity-Technologies/ml-agents,ml-agents,"Unity ML-Agents is an open-source toolkit that turns Unity games and simulations into training environments for intelligent agents, supporting deep reinforcement learning and imitation learning. It includes a Unity SDK plus Python (PyTorch-based) trainers and APIs for training, evaluating, and deploying agents in 2D/3D/VR/AR scenarios.",19000,reinforcement learning|imitation learning|Unity|PyTorch|simulation environments|multi-agent systems|game AI,9,"This repository’s primary purpose is to provide a full reinforcement-learning/imitation-learning toolkit (Unity SDK + Python trainers) for training agents inside Unity-based simulation environments. It is directly applicable to ML workflows because it includes PyTorch-based implementations of common RL algorithms (e.g., PPO, SAC) and supports training through a Python API, including multi-agent and self-play setups. The project is widely adopted (about 19k GitHub stars) and is commonly used for both research and applied ML-in-simulation/game-AI work, making it highly valuable for ML engineers and researchers, though it is more specialized than general-purpose frameworks like PyTorch itself.",success
https://github.com/ymcui/Chinese-LLaMA-Alpaca,Chinese-LLaMA-Alpaca,"An open-source project providing Chinese-adapted LLaMA models and instruction-tuned Chinese Alpaca models by expanding the Chinese vocabulary and continuing pretraining on Chinese data, plus scripts and guides for training, fine-tuning, quantization, and local CPU/GPU deployment. It also includes integration guidance for common LLM ecosystems such as Hugging Face Transformers, llama.cpp, and related tooling.",19000,large language models|natural language processing|Chinese NLP|fine-tuning|transformers|llama.cpp|model quantization,9,"This repository focuses on Chinese LLaMA and instruction-tuned Chinese Alpaca LLMs, including pretrained model variants and tooling (pretraining and instruction fine-tuning scripts) to reproduce or extend the models. It is directly applicable to ML/NLP workflows (model training, fine-tuning, evaluation, and deployment/quantization) and explicitly supports popular LLM ecosystems like Transformers and llama.cpp. Its strong community adoption (high star count) and practical documentation/examples make it highly valuable for ML engineers and researchers working with Chinese LLMs, though it is not a general-purpose ML framework at the scale of PyTorch/TensorFlow.",success
https://github.com/iperov/DeepFaceLab,DeepFaceLab,"DeepFaceLab is a deep learning-based face swap/deepfake creation tool that provides an end-to-end workflow for extracting faces from video/images, training face-swap models, and merging results back into target footage.",18900,computer vision|deep learning|deepfakes|face swap|video processing|tensorflow|CUDA,9,"This repository is primarily an applied machine learning tool for generating face swaps (deepfakes), including dataset preparation (face extraction/alignment), model training, and inference/merging back into video. It is directly usable by ML engineers and researchers working on face manipulation, image-to-image translation-style pipelines, and related computer vision workflows, and it exposes many practical considerations (data curation, masks/segmentation, training iterations, and artifact reduction). Community adoption is high (large star count), and the repo is educational for learning applied deep learning in vision, though it is specialized in a controversial domain and the repository is archived (read-only), which slightly reduces ongoing integration/maintenance value.",success
https://github.com/camel-ai/owl,owl,"OWL (Optimized Workforce Learning) is an open-source framework from CAMEL-AI for building autonomous, general-purpose multi-agent systems that collaborate to automate real-world tasks. It supports tool-using agents (e.g., web browsing/automation, code execution, document parsing, multimodal analysis) and integrates with Model Context Protocol (MCP) for interoperable tool connections.",18600,multi-agent systems|LLM agents|task automation|agentic workflows|MCP (Model Context Protocol)|Python|tool calling,9,"This repository provides an autonomous multi-agent framework focused on real-world task automation, including tool-using agents for web interaction (e.g., Playwright/MCP), code execution, and multimodal/document processing—capabilities frequently needed in modern ML/LLM engineering workflows. It is highly applicable for data/ML practitioners building agentic pipelines for research, data gathering, evaluation, and automation, and its MCP integration improves interoperability with external tools/services. Community adoption appears strong (18.6k GitHub stars), indicating meaningful usage and visibility in the agent/LLM ecosystem. It is not a core model-training framework like PyTorch, but it is a highly relevant agent framework for applied ML/LLM systems, justifying a 9/10 score.",success
https://github.com/Alibaba-NLP/DeepResearch,DeepResearch,"Tongyi DeepResearch is an open-source “deep research” agentic LLM project from Alibaba-NLP/Tongyi Lab, providing model assets and code for long-horizon web information-seeking, tool-using research workflows (e.g., ReAct and IterResearch/""Heavy"" inference modes), plus evaluation and inference utilities.",17900,agentic-llm|deep-research-agent|web-search|tool-use|nlp|reinforcement-learning|synthetic-data-generation|benchmarking,9,"This repository centers on an agentic LLM (“Tongyi DeepResearch”) and provides inference scripts, evaluation tooling, and documentation for running deep information-seeking research agents, including compatibility with ReAct and an IterResearch-based heavy inference mode. It is highly relevant to ML workflows because it targets model development and deployment for agentic search, includes mentions of synthetic data generation and RL training methodology, and offers practical code paths for evaluating agentic behavior on research benchmarks. Community adoption appears strong (high star and fork counts), and it is directly applicable for ML engineers working on LLM agents, evaluation, and research automation, though it is not a general-purpose foundational framework on the scale of PyTorch/TensorFlow—hence a 9 rather than 10.",success
https://github.com/microsoft/AirSim,AirSim,"AirSim is an open-source, cross-platform simulator for drones, cars, and other vehicles built as an Unreal Engine plugin (with an experimental Unity option) for high-fidelity autonomy and AI research. It provides APIs (e.g., Python/C++/C#/Java) to control vehicles and capture sensor data (images, depth, segmentation, etc.) for tasks like computer vision and reinforcement learning.",17800,robotics simulation|autonomous vehicles|reinforcement learning|computer vision|synthetic data generation|Unreal Engine|Unity|PX4/ArduPilot,9,"AirSim’s primary use case is high-fidelity simulation for autonomy research, providing programmatic APIs to control vehicles and to collect labeled/sensor-rich synthetic data (RGB, depth, segmentation, poses, etc.) for training and evaluation. This makes it directly applicable to ML workflows in reinforcement learning, imitation learning, and computer vision, and it’s widely recognized and adopted in academic and industry research for synthetic-data and sim-to-real experimentation. While it is not a general-purpose ML framework, it is a highly valuable ML enabler because it produces training data and closed-loop environments that many autonomy ML pipelines depend on. Note: the repository states that no further updates will be made (it will be archived) as focus shifts to “Project AirSim,” but the existing code remains usable for ML research and dataset generation.",success
https://github.com/deepseek-ai/Janus,Janus,"Janus-Series provides DeepSeek's unified multimodal models (Janus, JanusFlow, and Janus-Pro) for both vision-language understanding and visual generation in a single transformer-based framework, with code and examples for local inference and demos. It includes model links, a quick-start installation flow, and scripts for multimodal chat and generation inference.",17700,multimodal|vision-language|text-to-image|image-generation|LLM|transformers|PyTorch|inference,9,"This repository is primarily an ML project that ships code and guidance for running DeepSeek's Janus-series unified multimodal models, covering both multimodal understanding (vision-language chat/QA) and visual generation (e.g., text-to-image). It is directly applicable to ML workflows (model inference, evaluation/usage, demos) and integrates with common tooling such as Hugging Face Transformers and PyTorch. Community adoption appears strong based on the repository’s star/fork counts and the presence of multiple released model variants (Janus, JanusFlow, Janus-Pro) with accompanying technical reports and demos. It’s not a general-purpose framework on the scale of PyTorch/TensorFlow, but it is highly valuable for practitioners working on or deploying multimodal LLM systems, justifying a 9/10.",success
https://github.com/eriklindernoren/PyTorch-GAN,PyTorch-GAN,"A collection of PyTorch implementations of many Generative Adversarial Network (GAN) variants from research papers, intended as reference/educational code and runnable examples rather than exact paper-faithful reproductions. The README notes the repository has gone stale and is no longer actively maintained by the original author.",17400,machine learning|deep learning|pytorch|generative adversarial networks|computer vision|research implementations|model training,9,"This repository provides runnable PyTorch code for a wide range of GAN architectures (e.g., DCGAN, CycleGAN, Pix2Pix, WGAN variants) and is primarily used to learn, prototype, and compare generative modeling approaches. It is directly applicable to ML workflows for training and experimenting with image generation and image-to-image translation models, and it has strong community adoption as a reference implementation set (17.4k stars). The score is not a 10 because it is explicitly described as stale/unmaintained and is more of an educational/reference collection than a production-grade, actively maintained core ML library.",success
https://github.com/comet-ml/opik,opik,"Opik is an open-source platform for AI/LLM observability, evaluation, and optimization, providing end-to-end tracing, automated evaluations (including LLM-as-a-judge), and production dashboards for LLM apps, RAG systems, and agentic workflows. It supports cloud or self-hosted deployment and offers client SDKs (e.g., Python) to instrument applications and run experiments.",17200,LLMOps|AI observability|LLM evaluation|RAG|agentic workflows|tracing|MLOps|Python SDK,9,"This repository provides a production-oriented platform to debug, evaluate, and monitor LLM applications via tracing, experiment/evaluation tooling (including LLM-as-a-judge), and dashboards, which are central needs in modern ML/GenAI workflows. It is directly applicable to data scientists and ML/LLM engineers building RAG pipelines and agent systems, and it integrates into developer workflows through SDKs and deployment options (cloud/self-host). Community adoption appears strong based on its high GitHub star count, though it is more focused on LLM ops/observability than on model training itself, so it falls short of a perfect 10.",success
https://github.com/mlc-ai/web-llm,web-llm,"WebLLM is a high-performance in-browser LLM inference engine that runs fully client-side (no server required) and uses WebGPU/WebAssembly for hardware-accelerated inference. It provides an OpenAI API–compatible interface (e.g., chat completions with streaming and JSON mode) for running open-source models locally in the browser.",17100,large language models|inference|webgpu|webassembly|javascript|typescript|openai-api-compatible|edge-ai,9,"This repository provides a production-focused runtime for running LLM inference directly in the browser with WebGPU acceleration, exposing an OpenAI API–compatible interface for chat/completions and related features. It is highly relevant to ML engineering workflows because it enables practical deployment of open-source LLMs to end-user devices for privacy-preserving, low-latency inference without server infrastructure. The project shows strong community adoption (high star count) and significant integration value for building ML-powered web apps, though it is primarily an inference/deployment engine rather than a training or data-processing toolkit.",success
https://github.com/piskvorky/gensim,gensim,"Gensim is a Python library for topic modeling, document indexing, and similarity retrieval on large text corpora, designed for efficient (streamed/out-of-core) processing. It provides implementations of popular NLP/IR algorithms such as LDA, LSA/LSI, HDP, and word2vec, along with extensive documentation and tutorials.",16300,natural language processing|topic modeling|information retrieval|python|machine learning|text similarity|word embeddings,9,"This repository is a core NLP/data-science library focused on unsupervised text modeling and vector-space representations (topic models, embeddings, similarity search) that are directly applicable in ML workflows for analyzing and retrieving information from large corpora. It is widely adopted in the ML/NLP community (high star count) and provides practical, production-oriented implementations that emphasize memory efficiency and scalable processing. While the project is in stable maintenance mode (limited new features), it remains highly valuable for applied ML and educational use in topic modeling and text representation learning.",success
https://github.com/ddbourgin/numpy-ml,numpy-ml,"A collection of machine learning algorithms implemented primarily in pure NumPy for educational use and prototyping, including classical ML models, neural-network components, and reinforcement-learning agents. It provides a broad set of reference implementations (e.g., GMM/HMM/LDA, trees/linear models, CNN/RNN/attention/Transformers) with accompanying documentation.",16200,machine learning|numpy|educational|deep learning|reinforcement learning|NLP|probabilistic models|classical ML,9,"This repository is explicitly focused on implementing a wide range of machine learning algorithms (from classical statistical models to neural networks and reinforcement learning) using NumPy, making it directly relevant to ML practice and learning. It is highly applicable for understanding and experimenting with ML internals (reference implementations, layer/optimizer/loss modules, and various model families), though it is not optimized for production training like major frameworks. Strong community adoption (16.2k stars) and broad coverage across ML subfields justify a high score, but it’s not a dominant industry-standard framework (so not a 10).",success
https://github.com/stas00/ml-engineering,ml-engineering,"Machine Learning Engineering Open Book: a practical, operations-focused collection of guides, scripts, and copy‑paste commands for training, fine-tuning, and running inference for large language and multimodal models. Covers hardware (compute/storage/network), orchestration (e.g., SLURM), training, inference, debugging, testing, and benchmarking utilities.",16200,machine learning engineering|LLM training|MLOps|distributed training|GPU/accelerator benchmarking|cluster orchestration|SLURM|inference,9,"This repository is a hands-on ""open book"" of ML engineering practices aimed at successfully training and fine-tuning large language/multimodal models and operating their inference, with many actionable scripts and command-driven workflows. It directly supports core ML engineering tasks (hardware selection/performance, networking, orchestration, distributed training debugging, and inference operations), making it highly applicable for ML engineers running real training jobs. While it is not a general-purpose ML framework, its practical guidance and utilities are broadly useful in modern LLM/VLM workflows and it shows strong community adoption (high star count), justifying a high score.",success
https://github.com/lukas-blecher/LaTeX-OCR,LaTeX-OCR,"pix2tex (LaTeX-OCR) is a learning-based system that converts images of mathematical formulas into corresponding LaTeX code using a Vision Transformer (ViT) approach. It provides a CLI, a GUI tool, a Python API, and options for training on custom datasets.",16100,machine learning|computer vision|OCR|LaTeX|Vision Transformer|PyTorch|Streamlit,9,"This repository implements an end-to-end ML system for recognizing mathematical expressions from images and emitting LaTeX, including pretrained checkpoints and multiple inference interfaces (CLI/GUI/API). It directly supports common ML workflows (model inference, dataset preparation, and training/fine-tuning on custom data) and is built on standard ML tooling (notably PyTorch). Its large community adoption on GitHub and practical utility for document understanding, data extraction, and research/education in vision-to-text modeling justify a high score, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/zai-org/ChatGLM2-6B,ChatGLM2-6B,"Official repository for ChatGLM2-6B, an open bilingual (Chinese-English) chat large language model. It provides model usage demos (CLI/web/API), utilities, evaluation resources, and fine-tuning tooling (e.g., p-tuning) around the released ChatGLM2 weights.",15700,large-language-model|nlp|chatbot|transformers|pytorch|inference|fine-tuning,9,"This repository centers on an open chat LLM (ChatGLM2-6B) and includes code to run inference via CLI/web/API along with supporting utilities and evaluation materials, making it directly usable in ML engineering workflows. It is highly relevant for NLP practitioners who want to deploy, evaluate, or adapt the model (including long-context variants and parameter-efficient tuning like p-tuning). Community adoption is strong (15.7k stars), indicating broad use and educational value for understanding and applying open LLMs. It scores a 9 because it’s a highly applicable ML repo focused on a specific model ecosystem rather than a general-purpose, foundational framework.",success
https://github.com/wkentaro/labelme,labelme,"Labelme is a Python + Qt graphical annotation tool for creating image labels using multiple primitives (polygon, rectangle, circle, line, point) and image-level flags. It saves annotations as JSON and supports exporting datasets in common computer-vision formats such as VOC and COCO, including segmentation use cases.",15400,computer vision|data annotation|image labeling|dataset creation|segmentation|Qt|Python,9,"This repository provides a widely used GUI tool for producing high-quality labeled image datasets (polygons/bboxes/points/flags) and exporting them to standard CV dataset formats (e.g., VOC/COCO), which is a core step in many ML workflows. It directly supports common tasks like semantic/instance segmentation and integrates well with downstream training pipelines via structured JSON and converters. Strong community adoption (high star count) and practical features like video annotation and model-assisted annotation options make it highly valuable for ML/data work, though it is primarily a labeling tool rather than a model-training framework.",success
https://github.com/iterative/dvc,dvc,DVC (Data Version Control) is an open-source CLI tool and VS Code extension for building reproducible ML projects by versioning datasets/models outside Git (via external remotes) while keeping lightweight metadata in the Git repo. It also supports pipeline automation and local experiment tracking/comparison to help teams iterate and collaborate on ML workflows.,15300,machine learning|data versioning|MLOps|data engineering|experiment tracking|pipeline orchestration|Git integration|Python CLI,9,"This repository provides DVC, a purpose-built tool for ML/data workflows: dataset/model versioning (Git-like), reproducible pipelines, and experiment tracking/compare features. It is directly applicable for data scientists and ML engineers who need to manage large artifacts, automate end-to-end training pipelines, and collaborate via Git + cloud/on-prem storage. The project is widely adopted (15.3k stars) and integrates well with common ML tooling and infrastructure, making it highly valuable for MLOps and reproducible research. I scored it a 9 (highly relevant) because it is a core workflow tool for ML/data teams, but it is not itself an ML framework/library like PyTorch/TensorFlow.",success
https://github.com/albumentations-team/albumentations,albumentations,"Albumentations is a fast, flexible Python library for image augmentation used in deep learning and computer vision workflows (e.g., classification, segmentation, detection), supporting images along with related targets like masks, bounding boxes, and keypoints. Note: this repository was archived on Jul 10, 2025 and is no longer actively maintained; development has moved to AlbumentationsX.",15200,computer-vision|image-augmentation|deep-learning|machine-learning|image-processing|python|data-augmentation|object-detection,9,"This repository provides a widely used image augmentation library that directly plugs into common ML/computer-vision training pipelines to generate augmented training samples and handle associated labels/targets (masks, boxes, keypoints). It is highly applicable for ML practitioners working on vision tasks and shows strong community adoption (15.2k GitHub stars). The score is slightly reduced from a 10 because the repo is archived (read-only) and no longer maintained, which limits future compatibility and ongoing value despite its strong utility and adoption.",success
https://github.com/cvat-ai/cvat,cvat,"Computer Vision Annotation Tool (CVAT) is a web-based interactive image and video annotation platform for computer vision datasets, supporting common labeling tasks (e.g., detection, segmentation, tracking) and integrations like APIs/SDKs and optional auto-annotation workflows.",15100,computer vision|data annotation|labeling tool|dataset curation|MLOps|Django|React,9,"This repository provides CVAT, a widely used platform for creating and managing labeled image/video datasets for computer vision. It is directly applicable to ML workflows because high-quality annotations are a core dependency for training and evaluating supervised CV models, and CVAT includes workflow features (projects/tasks, formats, APIs/SDK/CLI, and optional auto-labeling) that integrate into data pipelines. The strong community adoption and its focus on data-centric AI make it highly valuable for ML/data teams, though it is not itself a model training framework—hence a 9 rather than a 10.",success
https://github.com/BrainJS/brain.js,brain.js,"brain.js is a GPU-accelerated neural network library for JavaScript that runs in both browsers and Node.js. It provides multiple neural network types (including feedforward and recurrent variants) with utilities for training, running inference, and exporting/importing models (e.g., via JSON).",14800,machine-learning|neural-networks|javascript|nodejs|browser|gpu-acceleration|deep-learning,9,"This repository is an ML-focused JavaScript library for building and training neural networks (with optional GPU acceleration) and deploying them in Node.js or directly in the browser. It is directly applicable to ML workflows for prototyping, lightweight model training/inference, and client-side ML demos, and it supports exporting/importing trained networks for reuse. Its community adoption is strong for the JavaScript ML ecosystem (high GitHub stars and widespread usage), but it is not as central/ubiquitous in industry as the top-tier Python frameworks—hence a 9 rather than a 10.",success
https://github.com/aleju/imgaug,imgaug,"imgaug is a Python library for image augmentation in machine learning workflows, generating randomized variations of input images. It supports consistent augmentation of related annotations such as heatmaps, segmentation maps, keypoints, bounding boxes, polygons, and more.",14700,computer vision|image augmentation|machine learning|data augmentation|python|deep learning|image processing,9,"This repository provides a comprehensive image augmentation toolkit designed specifically for machine learning experiments, enabling high-performance, randomized transformations (e.g., affine/perspective transforms, noise, contrast, blurs, cropping/padding). It directly supports common ML computer-vision data pipelines by augmenting both images and aligned labels/structures (e.g., segmentation maps, keypoints, bounding boxes) in a coordinated way. It appears widely adopted by the ML community (notably a very high GitHub star count), making it a highly practical, drop-in utility for training more robust vision models. It’s not a full ML framework, but it is a key enabling component for CV dataset preparation, justifying a high (but not maximum) score.",success
https://github.com/horovod/horovod,horovod,"Horovod is a distributed deep learning training framework that makes it easy to scale model training across multiple GPUs and machines using collective communication (e.g., allreduce). It integrates with major ML frameworks including TensorFlow/Keras, PyTorch, and Apache MXNet and supports multiple backends such as MPI, NCCL, and Gloo.",14600,distributed-training|deep-learning|machine-learning-infrastructure|pytorch|tensorflow|keras|mxnet|mpi-nccl-gloo,9,"This repository provides Horovod, a purpose-built system for scaling deep learning training workloads across multiple GPUs and nodes with minimal code changes, primarily via synchronous data-parallel training using collectives like allreduce. It is directly applicable to ML engineering workflows (speeding up training, enabling multi-node runs) and integrates tightly with major frameworks such as TensorFlow/Keras, PyTorch, and MXNet. Its strong adoption and mature ecosystem (multiple execution environments like Spark/Ray/Kubernetes plus multiple communication backends) make it highly valuable for ML practitioners, though it is more of a training infrastructure tool than a general ML library, keeping it just below a perfect 10.",success
https://github.com/ShangtongZhang/reinforcement-learning-an-introduction,reinforcement-learning-an-introduction,"A Python implementation that replicates many experiments, figures, and example problems from Sutton & Barto’s book ""Reinforcement Learning: An Introduction (2nd Edition)"", organized by book chapter with runnable code to reproduce results.",14500,reinforcement learning|machine learning|educational|python|sutton-barto|bandits|dynamic programming|temporal-difference learning,9,"This repository provides end-to-end Python implementations of core reinforcement learning algorithms and classic benchmark tasks (e.g., bandits, gridworld, blackjack, windy gridworld), largely aimed at reproducing the book’s figures and experiments. It is highly applicable for ML practitioners and researchers who want reference implementations and reproducible baselines for fundamental RL methods, though it is not a general-purpose production RL framework. Its strong educational value and broad adoption in the RL learning community justify a high score, but it falls short of a 10 because it is primarily a companion/replication codebase rather than an industry-standard training platform.",success
https://github.com/nltk/nltk,nltk,"NLTK (Natural Language Toolkit) is an open-source Python toolkit providing modules, datasets, and tutorials for natural language processing tasks such as tokenization, tagging, parsing, and text classification, widely used in research and education.",14500,natural language processing|nlp|python|text processing|machine learning|computational linguistics,9,"This repository contains the core source code for NLTK, a widely adopted Python library for building NLP pipelines (tokenization, stemming/lemmatization, POS tagging, parsing, feature extraction, and classic ML-oriented text classification utilities) and for working with NLP datasets/corpora. It is directly applicable to data science workflows for text preprocessing, exploratory NLP, and prototyping, and is especially valuable for educational use due to its tutorials and breadth of classic NLP functionality. It is not a modern deep-learning training framework, but its strong community adoption and practical NLP tooling make it highly valuable for ML/data work, justifying a 9/10.",success
https://github.com/BlinkDL/RWKV-LM,RWKV-LM,"RWKV-LM is the reference repository for RWKV, a parallelizable RNN-based architecture that targets transformer-level LLM performance while enabling linear-time inference and constant-space memory (no KV-cache). It contains multiple RWKV generations (v1 through newer variants) plus research/training artifacts and documentation for using and training RWKV language models.",14300,large language models|natural language processing|deep learning|pytorch|RNN architecture|transformer alternatives|model training|generative AI,9,"This repository provides an LLM architecture (RWKV) and associated code/materials for training and running language models, making it directly applicable to core ML workflows (model development, training, inference, and evaluation). It is explicitly focused on state-of-the-art language modeling research and implementation, and is widely used/recognized in the RWKV community (evidenced by substantial GitHub traction). It has strong educational value as a transformer-alternative design and practical value for building or fine-tuning RWKV-based models, but it is not as universally foundational or industry-standard as top general frameworks (e.g., PyTorch/TensorFlow), so it fits best at a 9 rather than a 10.",success
https://github.com/davidsandberg/facenet,facenet,"TensorFlow-based implementation of the FaceNet approach for face recognition that learns 128D face embeddings for verification/identification and clustering. The repository includes training/evaluation code and references to pre-trained models and common face-alignment preprocessing (e.g., MTCNN).",14300,computer vision|face recognition|deep learning|TensorFlow|FaceNet|MTCNN|metric learning,9,"This repository implements a well-known deep learning method (FaceNet) for learning face embeddings, with code for training and evaluating face recognition models in TensorFlow. It directly supports core ML workflows (data preprocessing/alignment, model training, embedding generation, and benchmark evaluation) and is widely used/cited in practice for face recognition baselines and education. While it is tied to older TensorFlow versions and a specific application domain, its relevance to metric learning and real-world CV pipelines justifies a high score.",success
https://github.com/davisking/dlib,dlib,"dlib is a modern C++ toolkit for building real-world machine learning, computer vision, and data analysis applications. It includes a wide range of ML algorithms/utilities and also provides a Python API for using dlib from Python workflows.",14300,machine learning|computer vision|deep learning|C++|Python|ML library|data analysis,9,"This repository provides a well-known, production-oriented machine learning and computer vision library (primarily C++, with a supported Python API) used to implement ML algorithms and build ML-driven applications. It directly supports ML/data workflows through reusable algorithms, feature extraction/vision utilities, and Python integration, making it practical for research prototyping and deployment. Its strong community adoption (large star count and long-running release history) and breadth of ML functionality justify a high score, though it is more of a general ML toolkit than a dominant end-to-end training framework like PyTorch/TensorFlow.",success
https://github.com/flairNLP/flair,flair,"Flair is a PyTorch-based NLP framework and library for applying and training state-of-the-art models for tasks like named entity recognition, sentiment analysis, and part-of-speech tagging, with strong support for embeddings (including transformers) across many languages.",14300,natural language processing|NLP|PyTorch|deep learning|text embeddings|transformers|named entity recognition,9,"This repository provides a full-featured NLP framework built on PyTorch, including pretrained models and training utilities for common ML tasks like sequence labeling (e.g., NER/PoS) and text classification (e.g., sentiment). It is directly usable in ML/data workflows via pip installation and high-level APIs for inference and model training, and it supports modern embedding approaches including transformer-based models. The large GitHub star count indicates strong community adoption, and the project has clear educational and practical value for applied NLP. It is not a general-purpose core ML framework like PyTorch itself, but it is a highly relevant, production-usable NLP toolkit, hence a 9/10.",success
https://github.com/microsoft/nni,nni,"NNI (Neural Network Intelligence) is an open-source AutoML toolkit for automating key parts of the ML lifecycle, including hyperparameter optimization, neural architecture search (NAS), model compression, and feature engineering. It provides experiment/trial management and supports running tuning jobs across multiple training environments with monitoring via a web UI.",14300,automl|hyperparameter-optimization|neural-architecture-search|model-compression|mlops|deep-learning|python,9,"This repository is a full-featured AutoML toolkit designed specifically for machine learning workflows, covering hyperparameter tuning, neural architecture search, model compression, and feature engineering, along with experiment management and visualization. It is directly applicable to ML engineers and data scientists who need to automate model search and optimization and integrate these capabilities into training pipelines. The repository shows substantial community adoption (14.3k GitHub stars) and strong practical/educational value through documentation, examples, and multiple supported algorithms/services, justifying a high score. Note: the GitHub repository itself is archived (read-only) as of September 18, 2024, which can limit ongoing maintenance despite its continued usefulness.",success
https://github.com/deeplearning4j/deeplearning4j,deeplearning4j,"Suite of JVM-based tools for training and deploying deep learning models, including the DL4J high-level neural network API, ND4J (numerical computing/linear algebra), SameDiff (automatic differentiation), DataVec (ETL for ML data), and native backends via LibND4J with CPU/GPU acceleration and model import from Keras/TensorFlow/ONNX.",14200,deep learning|java|jvm|nd4j|numerical computing|model deployment|distributed training (spark)|onnx/tensorflow/keras model import,9,"This repository is a comprehensive deep learning ecosystem for the JVM, providing both high-level neural network APIs (DL4J) and core numerical/automatic-differentiation infrastructure (ND4J/SameDiff), plus data ingestion/ETL tooling (DataVec). It is directly applicable to ML workflows for training, inference, and deployment in Java/Scala/Kotlin environments, with support for CPU/GPU acceleration and importing models from common ecosystems (e.g., Keras/TensorFlow/ONNX). Community adoption appears strong for a JVM ML framework (notably ~14.2k GitHub stars), but it is less dominant than the top Python-first frameworks, so it scores slightly below a 10.",success
https://github.com/dmlc/dgl,dgl,"Deep Graph Library (DGL) is a high-performance, scalable Python library for deep learning on graphs (Graph Neural Networks). It provides GPU-ready graph data structures and message-passing primitives, and integrates with major deep learning frameworks like PyTorch, TensorFlow, and Apache MXNet.",14200,graph neural networks|deep learning|machine learning|graph learning|PyTorch|TensorFlow|distributed training,9,"This repository provides DGL, a core library for building and training graph neural networks with efficient graph data structures and message-passing APIs, supporting CPU/GPU and scaling to very large graphs. It is directly applicable to ML workflows involving graph data (e.g., node classification, link prediction, graph classification) and integrates with widely used DL frameworks such as PyTorch and TensorFlow. Its substantial community adoption (14.2k GitHub stars) and extensive examples/tutorials make it valuable both operationally and educationally. It scores a 9 (highly relevant) because it is a widely used GNN framework, though it is more specialized than general-purpose ML staples like PyTorch itself.",success
https://github.com/jindongwang/transferlearning,transferlearning,"A curated “awesome”-style collection and knowledge hub for transfer learning, including domain adaptation and domain generalization, with organized papers, tutorials, datasets/benchmarks, and accompanying code/notebooks and documentation.",14200,machine learning|transfer learning|domain adaptation|domain generalization|awesome-list|deep learning|datasets,9,"This repository serves primarily as a comprehensive, curated resource for transfer learning (including domain adaptation and domain generalization), aggregating papers, tutorials, datasets/benchmarks, and links to code and notebooks. It is highly applicable to ML research and practice because it helps practitioners find methods, references, and implementation starting points for adapting models across domains. Community adoption appears strong (14.2k stars and 3.9k forks on GitHub), indicating it is widely used as a reference. It is not a single cohesive training framework like PyTorch/TensorFlow, so it falls short of a 10, but its breadth and educational value make it a 9.",success
https://github.com/alibaba/MNN,MNN,"MNN is a blazing fast, lightweight deep learning framework from Alibaba focused on on-device inference (and also supports training) across mobile/embedded platforms, with tooling for model conversion, compression/quantization, and deployment. It supports multiple model formats (e.g., TensorFlow, Caffe, ONNX, TorchScript) and can run on heterogeneous backends (CPU/GPU, including Metal/OpenCL/Vulkan/CUDA).",13900,deep learning|model inference|edge ai|mobile|embedded|model conversion|quantization,9,"This repository is primarily a deep learning framework and inference engine optimized for deploying neural networks on-device (mobile/embedded) with strong performance and multiple hardware backends. It directly supports core ML workflows such as converting models from major ecosystems (TensorFlow/Caffe/ONNX/TorchScript), optimizing/compressing them (e.g., FP16/Int8 quantization), and running inference efficiently in production apps. With substantial adoption (13.9k GitHub stars) and a broad toolchain (converter, compression, training, Python API), it is highly valuable for ML engineers working on deployment, edge inference, and performance optimization, warranting a 9/10 score.",success
https://github.com/tracel-ai/burn,burn,"Burn is a Rust-based tensor library and deep learning framework focused on flexible model development with high performance for both training and inference. It supports multiple compute backends (CPU/GPU/WebGPU/WASM), provides autodiff via a backend decorator, and includes features like kernel fusion and ONNX import for portable deployment.",13900,deep learning|machine learning|tensor library|rust|autodiff|onnx|gpu-compute|webgpu,9,"This repository is a full deep learning framework (not just a utility library), providing tensors, autodifferentiation, training/inference workflows, and model portability features like ONNX import. It is directly applicable to ML engineering workflows—users can train and deploy models across many targets (CPU/GPU/WebGPU/WASM) with largely backend-generic code and performance features such as fusion and autotuning. The project also shows strong community adoption (on the order of ~13.9k GitHub stars), suggesting meaningful real-world interest and usage. It’s not as universally standard as PyTorch/TensorFlow, but it is clearly highly relevant and capable for ML work, hence a 9/10.",success
https://github.com/ggml-org/ggml,ggml,"ggml is a low-level, cross-platform tensor library for machine learning focused on efficient on-device inference and training primitives. It supports integer quantization, broad hardware backends (e.g., CUDA/HIP/SYCL), automatic differentiation, and aims for zero runtime memory allocations with no third-party dependencies.",13800,machine-learning|tensor-library|llm-inference|quantization|automatic-differentiation|c-cpp|edge-ai,9,"This repository provides a foundational tensor computation library used for machine learning workloads, emphasizing efficient execution on commodity/edge hardware (e.g., CPU/GPU backends) and model compression via quantization. It is directly applicable to ML engineering workflows for building/running local inference stacks (notably used alongside projects like llama.cpp and whisper.cpp) and includes key ML primitives like autograd and optimizers. Community adoption appears strong (high GitHub stars and active development), and it has substantial integration potential as a core compute backend in ML systems. It is slightly below a 10 because it is primarily a low-level compute library rather than a full end-to-end DS stack (data prep/training pipelines/serving framework) like the largest general-purpose ML frameworks.",success
https://github.com/carla-simulator/carla,carla,"CARLA is an open-source simulator for autonomous driving research, designed to support development, training, and validation of autonomous driving systems with configurable sensors, traffic scenarios, and environmental conditions. The repository contains the core simulator (Unreal Engine-based), Python API, and supporting tooling/assets for building and running simulations.",13500,autonomous driving|robotics|simulation|reinforcement learning|computer vision|synthetic data|unreal engine|python api,9,"This repository provides the CARLA autonomous driving simulator, a widely used platform for creating controlled driving environments with configurable sensors (e.g., cameras, LiDAR) and conditions to test and validate AV stacks. It is highly relevant to ML/data workflows because it enables synthetic data generation and closed-loop evaluation/training for perception, planning, and reinforcement learning. Its strong adoption in the autonomous driving research community and direct integration via a Python API make it immediately applicable for ML experimentation and dataset creation. It is not an ML framework itself, but it is a core upstream dependency for many AV ML pipelines, justifying a high (but not perfect) score.",success
https://github.com/ydataai/ydata-profiling,ydata-profiling,"Generates automated data profiling and exploratory data analysis (EDA) reports for datasets, producing rich summaries, warnings, and visualizations with minimal code. Supports exporting reports (e.g., HTML/JSON) and includes support for Pandas DataFrames and Spark DataFrames.",13300,data science|exploratory data analysis|data profiling|data quality|python|pandas|apache spark|jupyter,9,"This repository provides an automated profiling/EDA tool that summarizes datasets, detects data types, computes descriptive statistics, highlights data-quality issues (e.g., missingness, correlations, duplicates), and outputs shareable reports (HTML/JSON) for analysis workflows. It is directly applicable to common ML/data preparation steps (understanding distributions, spotting leakage/quality issues, and validating datasets) and integrates naturally with standard Python data tooling (Pandas/Jupyter) and Spark for larger-scale data. Its large community adoption (high star count) and broad feature set make it highly valuable for day-to-day data science, though it is not a model-training framework itself, which is why it is scored 9 rather than 10.",success
https://github.com/isl-org/Open3D,Open3D,"Open3D is an open-source library for 3D data processing, offering optimized 3D data structures and algorithms for tasks like reconstruction, registration/surface alignment, visualization, and rendering. It provides both Python and C++ APIs, plus GPU-accelerated core operations and integrations for 3D machine learning workflows (PyTorch/TensorFlow).",13200,3D data processing|point clouds|computer vision|robotics|geometry processing|C++|Python|GPU acceleration,9,"This repository provides a full-featured 3D data processing stack (point clouds/meshes, reconstruction, registration, visualization, rendering) with production-grade C++/Python APIs and GPU acceleration, making it directly usable in ML and data-centric 3D pipelines. It explicitly supports 3D machine learning via an Open3D-ML extension and integrates with both PyTorch and TensorFlow, which lowers friction for model training/inference workflows on 3D data. Its large community adoption (13.2k stars) and broad applicability across robotics, 3D vision, and 3D deep learning justify a high score, though it is not itself a general-purpose ML framework (hence not a 10).",success
https://github.com/mlfoundations/open_clip,open_clip,"OpenCLIP is an open source implementation of OpenAI's CLIP (Contrastive Language-Image Pre-training), providing PyTorch code to train and use contrastive text-image models along with many published pretrained checkpoints. It includes utilities to create models and transforms, tokenize text, and run zero-shot evaluation/inference with a broad set of CLIP-like architectures and training datasets.",13200,machine learning|computer vision|multimodal|contrastive learning|CLIP|PyTorch|representation learning,9,"This repository implements and maintains a widely used open-source CLIP ecosystem: training code plus convenient inference APIs and a catalog of pretrained vision-language models usable for embeddings and zero-shot classification. It is directly applicable to common ML workflows (feature extraction, retrieval, zero-shot transfer, and fine-tuning) and integrates cleanly with PyTorch tooling and external model hubs. Community adoption appears strong (high GitHub star count and active issue/PR activity), and the repo also has educational value via documentation and reproducible scaling-law/model training references. It is not a general-purpose ML framework on the scale of PyTorch itself, but it is a highly relevant, production-usable vision-language library, justifying a 9/10.",success
https://github.com/Lightning-AI/litgpt,litgpt,"LitGPT is a Python toolkit for running, pretraining, and fine-tuning 20+ open-source large language models with an emphasis on high performance, minimal abstractions, and hackable implementations. It includes optimized recipes and features like quantization, FSDP, and LoRA/QLoRA to scale from consumer GPUs to large multi-GPU/TPU setups.",13100,large-language-models|llm-training|llm-finetuning|pytorch|distributed-training|quantization|nlp,9,"This repository is primarily an LLM engineering/training toolkit: it provides implementations and workflows to pretrain, fine-tune (including parameter-efficient methods like LoRA/QLoRA), and run inference for many popular open-source LLM architectures. It directly supports core ML workflows (model training, evaluation/inference, memory/performance optimizations, and scaling via distributed strategies like FSDP), making it immediately useful for ML engineers and applied researchers. Community adoption appears strong (13.1k GitHub stars at time of lookup), and the repo is positioned as a practical, production-oriented, hackable alternative for working with modern LLMs rather than a general-purpose library unrelated to ML.",success
https://github.com/microsoft/LoRA,LoRA,"Official Microsoft implementation of LoRA (Low-Rank Adaptation), providing the Python package `loralib` plus examples for integrating low-rank adapter layers into PyTorch models (including Hugging Face-style workflows) to enable parameter-efficient fine-tuning of large language models.",13100,machine learning|deep learning|llm fine-tuning|parameter-efficient fine-tuning|pytorch|nlp|model adaptation,9,"This repository provides `loralib`, a PyTorch-focused implementation of LoRA, a widely used parameter-efficient fine-tuning technique for adapting large language models by training low-rank matrices while freezing base weights. It is directly applicable to ML workflows for training and deploying LLM adaptations with reduced storage and training cost, and includes practical integration examples (including Hugging Face-style usage). Given its strong relevance to modern LLM fine-tuning and substantial community adoption (13.1k stars), it merits a high score, though it is more a focused method implementation than a full end-to-end training framework.",success
https://github.com/apache/tvm,apache/tvm,"Apache TVM is an open machine learning compiler framework used to compile and optimize ML models for efficient deployment across diverse hardware backends (e.g., CPUs, GPUs, and accelerators). It provides a Python-first workflow and compiler stack to transform, tune, and generate high-performance runtime modules.",13000,machine learning|deep learning|ml compiler|model optimization|hardware acceleration|gpu|code generation|deployment,9,"This repository implements Apache TVM, a compiler framework that compiles and optimizes machine learning models for deployment on many hardware targets, with a Python-first interface and major components for graph- and tensor-level optimization. It is directly applicable to ML engineering workflows (especially inference deployment and performance tuning), and is widely recognized in the ML systems/compiler community with substantial adoption and an active release cadence. It is less focused on data science experimentation/training than frameworks like PyTorch, but is highly valuable for production performance and cross-hardware deployment, justifying a score of 9.",success
https://github.com/PaddlePaddle/PaddleNLP,PaddleNLP,"PaddleNLP is an easy-to-use and powerful NLP/LLM & SLM library built on the PaddlePaddle deep learning framework, providing training, compression/quantization, and high-performance inference utilities along with a model zoo for modern language models.",12900,natural language processing|large language models|deep learning|model training|inference|quantization|PaddlePaddle,9,"This repository is a dedicated NLP/LLM development toolkit on top of PaddlePaddle, offering capabilities for training, model compression/quantization, and high-performance inference plus a broad model zoo. It is directly applicable to ML engineer and data scientist workflows for building and deploying language models, and it integrates tightly with a major deep learning framework (PaddlePaddle). Its strong community adoption (12.9k GitHub stars) and breadth of LLM-focused features justify a high score, though it is less universally standard than top cross-framework staples like PyTorch/TensorFlow.",success
https://github.com/jupyter/notebook,jupyter/notebook,"Jupyter Notebook is a web-based, interactive notebook environment for creating and running notebooks (code, text, and outputs) in a browser. The repository contains the Classic Notebook v6 (security/maintenance-focused) and the newer Notebook v7 architecture built on Jupyter Server and JupyterLab frontend components.",12900,jupyter|interactive-computing|data-science|python|notebooks|web-application|jupyter-server|jupyterlab,9,"This repository provides the Jupyter Notebook application, a core tool for interactive computing used to write and run code alongside narrative text and rich outputs in the browser. It is a central part of many data science and machine learning workflows (experimentation, EDA, prototyping, reporting, and teaching), and is widely adopted across industry and academia. While it is not an ML framework itself, it is one of the most common execution and presentation environments for ML/data work, with strong integration into the broader Jupyter ecosystem (kernels, Jupyter Server, and JupyterLab components).",success
https://github.com/jina-ai/clip-as-service,clip-as-service,"CLIP-as-service is a low-latency, horizontally scalable microservice for generating CLIP embeddings for images and text, and for doing cross-modal ranking/visual reasoning. It supports multiple serving backends (e.g., PyTorch/ONNX/TensorRT) and exposes APIs over protocols like gRPC/HTTP/WebSocket for easy integration into neural search and multimodal pipelines.",12800,machine learning|computer vision|multimodal|embeddings|CLIP|model serving|neural search|gRPC,9,"This repository packages OpenAI CLIP-style image/text embedding and ranking capabilities as a production-oriented, scalable service with client/server components and multiple protocol options, making it directly usable in real ML systems. It is highly relevant to ML workflows such as multimodal embedding generation, similarity search, reranking, and integrating embeddings into downstream retrieval or search stacks. Strong community adoption (12.8k stars) indicates significant real-world usage and mindshare, and the service design (scaling, multiple runtimes, streaming, and integration with neural search tooling) makes it especially valuable for ML engineers deploying embedding infrastructure.",success
https://github.com/ShishirPatil/gorilla,gorilla,"Gorilla is a research and engineering repository for training and evaluating LLMs to reliably perform function/tool calling by selecting and composing correct API calls from natural-language queries. It includes models/datasets (e.g., APIBench), inference code, and evaluation/benchmarking infrastructure such as the Berkeley Function Calling Leaderboard (BFCL).",12700,machine learning|large language models|tool calling|function calling|LLM evaluation|benchmarks|datasets|API integration,9,"This repository focuses on building and evaluating LLM tool/function-calling capabilities, including datasets (APIBench), model artifacts, and evaluation/benchmark infrastructure (BFCL) for measuring function-calling performance. These assets are directly applicable to ML workflows involving agent/tool use, model training/fine-tuning, and standardized evaluation of LLMs on API/tool invocation tasks. It also shows strong community adoption (12.7k GitHub stars) and offers substantial educational and integration value for practitioners working on LLM agents and tool-use reliability.",success
https://github.com/NVIDIA/TensorRT,NVIDIA/TensorRT,"Open-source components of NVIDIA TensorRT, an SDK for high-performance deep learning inference on NVIDIA GPUs. Includes TensorRT plugins, the ONNX parser, and sample applications demonstrating TensorRT usage and capabilities.",12600,deep learning inference|TensorRT|GPU acceleration|CUDA|ONNX|model optimization|C++|Python,9,"This repository provides the open-source parts of NVIDIA TensorRT, focused on optimizing and executing trained deep learning models for high-throughput, low-latency inference on NVIDIA GPUs (e.g., plugins and the ONNX parser). It directly supports ML engineering workflows by enabling deployment-time optimization and runtime acceleration, and it integrates with common ML model formats (notably ONNX) and GPU software stacks (CUDA). TensorRT is widely adopted in production inference pipelines across industry, making it highly valuable for ML practitioners, though it is primarily an inference/deployment tool rather than a general-purpose training framework.",success
https://github.com/zalandoresearch/fashion-mnist,fashion-mnist,"Fashion-MNIST is a dataset of Zalando article (fashion product) images designed as a drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. The repository provides the dataset in MNIST-compatible format plus utilities, benchmarks, and visualization scripts.",12600,machine learning|dataset|computer vision|benchmarking|MNIST-compatible|classification|python,9,"This repository’s primary purpose is to distribute the Fashion-MNIST dataset (60,000 training and 10,000 test 28x28 grayscale labeled images across 10 classes) and supporting scripts for loading, benchmarking, and visualization. It is directly applicable to ML workflows as a standard, MNIST-format computer-vision classification benchmark and is commonly integrated into ML libraries and educational materials. The score is 9 (not 10) because it is a widely used benchmark dataset rather than a full ML framework or end-to-end production tool.",success
https://github.com/jacobgil/pytorch-grad-cam,pytorch-grad-cam,"A PyTorch library for explainable AI in computer vision, providing a comprehensive set of CAM/pixel-attribution methods (e.g., Grad-CAM variants) and utilities for interpreting CNNs and Vision Transformers across tasks like classification, detection, and segmentation.",12500,machine learning|computer vision|explainable ai|pytorch|model interpretability|grad-cam|vision transformers,9,"This repository is purpose-built for ML practitioners to generate and evaluate visual explanations (CAM/pixel-attribution) for deep vision models in PyTorch, including CNNs and Vision Transformers, and supports multiple CV task types. It directly fits common ML workflows for debugging, validation, and explainability reporting, and also includes advanced tutorials and metrics for assessing explanation quality. The high star count and broad method coverage indicate strong community adoption and practical utility, but it is not a core training framework/dataset tool, so it falls just short of a 10.",success
https://github.com/zai-org/CogVideo,CogVideo,"Official repository for the CogVideo and CogVideoX series of generative video models, providing text-to-video and image-to-video inference demos plus fine-tuning tooling (including SAT and Diffusers-based workflows). It includes model usage guides, scripts/notebooks, and utilities for tasks like quantized inference and LoRA fine-tuning.",12300,generative-ai|video-generation|text-to-video|image-to-video|diffusion-models|pytorch|diffusers|fine-tuning,9,"This repository is primarily an ML project: it provides code and workflows to run and fine-tune large video generation models (CogVideoX/CogVideo) for text-to-video and image-to-video synthesis, including inference demos and LoRA fine-tuning support. It directly fits common ML engineering workflows (model inference, optimization/quantization, and fine-tuning) and integrates with popular tooling such as PyTorch and Diffusers. The repo also shows strong community adoption (12.3k stars) and is practical for researchers and practitioners working on generative video modeling, warranting a high score (9) rather than a perfect 10 reserved for foundational, broadly universal ML libraries.",success
https://github.com/sapientinc/HRM,HRM,"Official release of the Hierarchical Reasoning Model (HRM), a recurrent hierarchical architecture for sequential reasoning tasks that performs planning and detailed computation via two interdependent recurrent modules. The repo includes PyTorch training/evaluation code, dataset builders (e.g., ARC/ARC-AGI, Sudoku, mazes), and pretrained checkpoints for benchmarking reasoning performance.",12200,machine learning|deep learning|PyTorch|reasoning|recurrent neural networks|ARC (Abstraction and Reasoning Corpus)|benchmarking|CUDA,9,"This repository primarily provides an ML research model (HRM) plus end-to-end code for training and evaluating it on reasoning benchmarks such as ARC/ARC-AGI, Sudoku, and maze pathfinding, including dataset construction utilities and evaluation scripts. It is directly applicable to ML workflows (model training, experiment tracking, checkpoint evaluation) and is clearly aimed at ML engineers/researchers working on reasoning and sample-efficient learning. The strong relevance to core ML tasks and the presence of benchmarks/checkpoints make it highly valuable for data science/ML, though its usefulness is specialized to reasoning benchmarks rather than general-purpose data tooling.",success
https://github.com/OpenMOSS/MOSS,MOSS,"MOSS is an open-source, tool-augmented conversational large language model project from Fudan University, providing model checkpoints, SFT data, and code for local deployment, inference demos, and fine-tuning. It includes plugin/tool-use variants (e.g., search, text-to-image, calculator) and example integrations (CLI/Gradio/Streamlit).",12100,large language models|chatbot|NLP|tool-augmented LLM|instruction tuning|fine-tuning|inference|Gradio,9,"This repository centers on an open-source conversational LLM (MOSS) and provides the core assets and code needed to run and adapt it, including model variants (base/SFT/tool-augmented) and local inference demos. It is directly applicable to ML/NLP workflows for serving, experimenting with, and fine-tuning instruction-following chat models, and it also exposes conversation SFT datasets that are valuable for training and evaluation. While it is not a general-purpose ML framework, its focus on LLM deployment and instruction-tuning data makes it highly relevant for applied NLP and LLM engineering, justifying a high score.",success
https://github.com/explodinggradients/ragas,ragas,"Ragas is a toolkit for evaluating and optimizing LLM applications, providing objective evaluation metrics (LLM-based and traditional), automated test dataset generation, and integrations with popular LLM frameworks (e.g., LangChain) and observability tools.",12100,llm-evaluation|rag|nlp|machine-learning|python|test-data-generation|langchain|observability,9,"This repository is purpose-built for evaluating LLM applications (including RAG systems) using objective metrics and production-aligned workflows, and it also supports automated test set generation and feedback loops. These capabilities map directly to common ML engineering and data science tasks around model/agent quality measurement, regression testing, and continuous improvement. Its strong GitHub adoption (12.1k stars) suggests meaningful community usage and maturity, making it highly valuable in practical ML/data workflows even though it is not a general-purpose ML training framework.",success
https://github.com/tonybeltramelli/pix2code,pix2code,"A research/educational deep learning project that generates UI code from a single GUI screenshot by predicting a DSL representation and compiling it into platform-specific code (iOS, Android, or web/HTML). It includes dataset tooling, model training/inference scripts, and compilers to translate generated DSL into target UI code.",12100,machine learning|deep learning|computer vision|sequence-to-sequence|code generation|ui automation|keras|research,9,"This repository demonstrates an end-to-end ML system (image-to-sequence/code) for converting GUI screenshots into a DSL and then compiling to platform-specific UI code, aligning directly with ML workflows (data preparation, model training, inference, decoding strategies like greedy/beam search). It is highly educational and practically useful for researchers/engineers exploring vision-to-text, code generation, and multimodal sequence modeling, and it ships both code and datasets/tooling to reproduce experiments. While the author explicitly frames it as experimental and not production-ready for real-world front-end projects, its clear ML focus and strong community interest (star count) justify a high score.",success
https://github.com/bentoml/OpenLLM,OpenLLM,"OpenLLM is a self-hosting framework/CLI for running open-source LLMs (and custom models) as OpenAI-compatible API endpoints. It includes a built-in chat UI and supports production deployment workflows (e.g., Docker/Kubernetes/BentoCloud) and multiple inference backends.",12000,llm|model-serving|openai-compatible-api|inference|mlops|python|docker-kubernetes,9,"This repository primarily provides infrastructure and tooling to serve and operate large language models (LLMs) in a production-friendly way, exposing OpenAI-compatible endpoints and a chat UI. It is directly applicable to ML engineering workflows for deploying and integrating open-source LLMs (e.g., Llama/Qwen/DeepSeek) into applications and systems via standard APIs, plus container and Kubernetes deployment patterns. Community adoption appears strong (about 12k GitHub stars), indicating broad usage/interest in the ML/GenAI ecosystem. It’s not a training framework, but it is highly valuable for inference, deployment, and operationalization, justifying a score of 9.",success
https://github.com/h2oai/h2ogpt,h2ogpt,"h2oGPT is an Apache-2.0 open-source project for running private/local LLM chat and document Q&A (RAG), with a web UI/CLI for summarization and retrieval over many file types. It supports multiple backends and model runtimes (e.g., Ollama, llama.cpp) and includes integrations for embeddings/vector stores and multimodal features.",12000,LLM|RAG|chatbot|document-question-answering|gradio|vector-database|llama.cpp|ollama,9,"This repository provides a full stack for practical LLM applications: private chat, document ingestion, retrieval-augmented generation (RAG), and summarization, with UI/CLI tooling and support for multiple model runtimes and embedding/vector-store options. It is directly applicable to ML/data workflows for building internal knowledge assistants, experimenting with local inference, and prototyping RAG pipelines over diverse enterprise documents. Strong community adoption (12k GitHub stars) and broad integration surface (models, embeddings, vector DBs, multimodal) justify a high score, though it is more an application/framework than a foundational ML library.",success
https://github.com/modelscope/ms-swift,ms-swift,"SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning) is a ModelScope-community framework for training, aligning, evaluating, quantizing, and deploying large language models (LLMs) and multimodal LLMs. It supports both full-parameter training and PEFT methods (e.g., LoRA/QLoRA), plus integrations for inference/deployment stacks like vLLM, SGLang, and LMDeploy across hundreds of models.",12000,machine learning|large language models|multimodal|fine-tuning|PEFT|RLHF|MLOps,9,"This repository is purpose-built for modern ML workflows around LLM/MLLM training and post-training (e.g., SFT, preference learning like DPO, and reinforcement-learning variants such as GRPO-family methods), as well as evaluation, quantization, inference, and deployment. It directly supports common ML engineering tasks (dataset-driven training pipelines, PEFT/full-parameter training, and deployment integrations like vLLM/SGLang/LMDeploy), making it highly applicable for practitioners. Its sizable community adoption (notably ~12k GitHub stars) and broad model coverage increase its practical value, but it is not a foundational general-purpose library on the scale of PyTorch/Transformers, so it falls short of a 10.",success
https://github.com/neuml/txtai,txtai,"txtai is an all-in-one AI framework for semantic search and LLM orchestration, centered around an embeddings database that combines vector indexes with graph and relational capabilities. It supports building RAG/agent workflows, multimodal embeddings, and exposes APIs (including MCP) for integrating language-model pipelines into applications.",12000,semantic search|vector database|NLP|LLM orchestration|RAG|embeddings|FastAPI|Hugging Face Transformers,9,"This repository provides a production-oriented framework for embedding creation, vector/semantic search, and orchestrating language-model pipelines (e.g., QA, summarization, transcription) into workflows and agents. It is directly applicable to common ML/data workflows such as retrieval-augmented generation, search over documents, and building “chat with your data” systems, with strong integration into the Python ML ecosystem (e.g., Transformers/Sentence Transformers) and API deployment via FastAPI. It also shows substantial community adoption (12k GitHub stars), indicating real-world usage beyond a niche demo project. It’s not a general-purpose training framework like PyTorch, but it is a highly relevant applied ML/data tool for LLM applications, hence a 9/10.",success
https://github.com/allenai/allennlp,allennlp,"AllenNLP is an open-source natural language processing (NLP) research library built on PyTorch for building, training, and evaluating deep learning models across many language tasks. The repository is archived (read-only) and the project is in maintenance mode, with AI2 recommending alternatives such as AI2 Tango for experiment management.",11900,natural language processing|deep learning|PyTorch|machine learning framework|research library|model training|NLP pipelines,9,"This repository provides a full-featured NLP research and model-development framework on top of PyTorch, including dataset readers, modules, training utilities, and a CLI/config-driven workflow for experiments. It is directly applicable to ML workflows for training and evaluating NLP models, and it has strong community adoption (about 11.9k GitHub stars). The score is not a 10 because the repository is archived and in maintenance mode (no new features or dependency upgrades), which reduces its long-term integration potential compared with actively maintained core ML libraries.",success
https://github.com/ludwig-ai/ludwig,ludwig,"Ludwig is a low-code, declarative (YAML-configured) framework for training and fine-tuning AI models—including LLMs and other deep neural networks—supporting multi-task and multi-modal learning, distributed training, and production-oriented export/deployment options.",11600,machine learning|deep learning|LLM fine-tuning|PyTorch|MLOps|AutoML|distributed training,9,"This repository provides an end-to-end, low-code framework for building, training, and fine-tuning deep learning models (including LLMs) via declarative YAML configuration, which directly targets core ML workflows. It includes capabilities that ML engineers commonly need in practice—multi-modal/multi-task training, distributed training (e.g., PyTorch DDP/DeepSpeed), parameter-efficient fine-tuning, and deployment/export integrations—making it highly applicable for real projects. With a large GitHub community (about 11.6k stars), it shows strong adoption and is also educational for learning structured model configuration and training best practices. It is not a foundational tensor library like PyTorch itself (so not a 10), but it is a highly valuable ML framework and workflow tool, warranting a 9.",success
https://github.com/cleanlab/cleanlab,cleanlab,"Cleanlab is an open-source data-centric AI library that helps automatically detect and diagnose issues in real-world ML datasets (e.g., label errors, outliers, duplicates) using your existing model outputs. It provides tools (e.g., Datalab, CleanLearning) to improve data quality and train more robust models across modalities like text, image, audio, and tabular data.",11300,machine learning|data quality|data-centric ai|noisy labels|dataset cleaning|outlier detection|active learning|python,9,"This repository provides a purpose-built ML/data science toolkit for improving dataset quality by automatically finding common data and label issues using predicted probabilities/embeddings from any model. It fits directly into standard ML workflows (train model → compute predictions/embeddings → find issues → clean/relabel → retrain) and supports many task types (classification, regression, segmentation, etc.) and frameworks (scikit-learn, PyTorch, TensorFlow, etc.). With strong community adoption (11.3k GitHub stars) and clear applicability to real-world messy data, it merits a 9/10 (highly relevant and widely useful, though not a full end-to-end training framework).",success
https://github.com/lucidrains/DALLE2-pytorch,DALLE2-pytorch,"A PyTorch implementation of core components of OpenAI’s DALL·E 2 text-to-image system, focusing on training and sampling with a diffusion prior and decoder (cascaded U-Nets), with utilities for training workflows and dataloading.",11300,machine learning|deep learning|computer vision|text-to-image|diffusion models|pytorch|generative ai|clip,9,"This repository implements and packages major DALL·E 2-style text-to-image components in PyTorch (diffusion prior + decoder/cascaded diffusion U-Nets) and includes training scripts/wrappers and dataset/dataloader utilities aimed at replication and experimentation. It is directly applicable to ML workflows for training and evaluating generative models, and its strong community adoption (11.3k stars) indicates broad use and educational value. It’s not a general-purpose foundational framework like PyTorch itself (so not a 10), but it is highly relevant for practitioners working on diffusion-based text-to-image research and engineering.",success
https://github.com/qubvel-org/segmentation_models.pytorch,segmentation_models.pytorch,"A PyTorch library providing high-level APIs for building image semantic segmentation models (e.g., U-Net, U-Net++, SegFormer, DPT) with hundreds of pretrained CNN/transformer encoders, plus common losses/metrics and export-friendly support (ONNX/TorchScript).",11300,machine learning|deep learning|computer vision|semantic segmentation|PyTorch|pretrained models|timm,9,"This repository is a purpose-built PyTorch library for creating and training semantic segmentation neural networks using ready-made encoder–decoder architectures and a large catalog of pretrained backbones. It fits directly into ML/computer-vision workflows by accelerating model prototyping, providing standard losses/metrics, and supporting deployment-oriented exports (e.g., ONNX/TorchScript). Its strong community adoption (11.3k GitHub stars and ~1.8k forks at the time of review) indicates broad usage and practical relevance. It is not a general-purpose framework on the scale of PyTorch itself, but it is a highly valuable, widely used specialization for segmentation tasks.",success
https://github.com/thuml/Time-Series-Library,Time-Series-Library,"TSLib is an open-source deep learning codebase/benchmark for general time series analysis, providing implementations and evaluation pipelines for advanced models across key tasks like long-/short-term forecasting, imputation, anomaly detection, and classification.",11200,time series|deep learning|forecasting|anomaly detection|imputation|classification|PyTorch|benchmarking,9,"This repository is a dedicated deep learning library/benchmark for time series analysis, bundling many state-of-the-art model implementations plus training/evaluation scripts across five core tasks (forecasting, imputation, anomaly detection, classification, and more recently zero-shot forecasting for large time series models). It maps directly onto common ML workflows (dataset prep, experiment scripts, model training, metrics/leaderboards) and is immediately usable by ML engineers and researchers working on time series. Its sizeable GitHub adoption (11,200 stars) and broad coverage of modern architectures make it highly valuable for ML/data science work, though it is not a general-purpose, industry-standard framework on the level of PyTorch/TensorFlow—hence a 9 rather than 10.",success
https://github.com/FlagOpen/FlagEmbedding,FlagEmbedding,"FlagEmbedding is the BGE one-stop retrieval toolkit for search and retrieval-augmented generation (RAG), providing embedding models, rerankers, and utilities for building and evaluating modern neural retrieval pipelines (including multilingual and multimodal variants). It includes code, examples, tutorials, datasets, and research artifacts to train, run, and integrate BGE-based retrievers and rerankers in downstream applications.",11100,machine learning|NLP|information retrieval|RAG|embeddings|reranking|LLMs|PyTorch,9,"This repository is primarily an ML/NLP toolkit focused on retrieval for search and RAG, centered around the BGE (BAAI General Embedding) model family and related rerankers, with code and resources to run, train, and evaluate retrieval components. It directly supports common ML workflows (building embedding indexes, retrieval + reranking, and RAG system construction) and includes datasets/examples/tutorials that make it immediately usable by ML engineers and data scientists. The project shows strong community adoption (11.1k GitHub stars at the time of lookup) and broad integration potential for real-world retrieval stacks, which justifies a high score. It is not a general-purpose ML framework on the scale of PyTorch/TensorFlow, but it is highly impactful within the retrieval/RAG domain, hence 9/10.",success
https://github.com/milesial/Pytorch-UNet,Pytorch-UNet,"A PyTorch implementation of U-Net for semantic image segmentation, including training, evaluation, and inference scripts. It targets high-resolution images (e.g., Kaggle Carvana Image Masking Challenge) and supports Docker-based workflows.",11100,deep learning|computer vision|semantic segmentation|pytorch|u-net|medical imaging|docker,9,"This repository provides an end-to-end PyTorch implementation of the U-Net architecture for image semantic segmentation, with scripts for training (train.py), evaluation (evaluate.py), and prediction/inference (predict.py), plus Docker support. It is directly applicable to ML workflows involving pixel-wise labeling (e.g., medical/portrait/multiclass segmentation) and includes practical guidance for data setup and running experiments. Community adoption appears strong (about 11.1k GitHub stars), suggesting broad usage and educational value. It scores a 9 (not a 10) because it is a specific model/project implementation rather than a general-purpose, industry-standard core ML library/framework.",success
https://github.com/nerfstudio-project/nerfstudio,nerfstudio,"Nerfstudio is a modular PyTorch-based framework and toolchain for creating datasets, training, visualizing, and rendering Neural Radiance Fields (NeRFs). It provides end-to-end pipelines (e.g., from real captures to trained models) plus an interactive web viewer and multiple built-in neural rendering methods.",11100,neural-rendering|nerf|computer-vision|3d-reconstruction|pytorch|gaussian-splatting|graphics,9,"This repository is an end-to-end ML system for neural rendering (NeRFs), including dataset ingestion pipelines, modular model components, training commands, and interactive visualization/rendering tooling. It directly supports ML workflows (data preparation, model training, evaluation/benchmarking, and experiment tracking integrations like TensorBoard/W&B) and is broadly useful to ML engineers and researchers working in 3D vision and graphics. With strong community adoption (11.1k stars) and high educational value via documentation and modular architecture, it merits a 9/10; it is highly relevant and widely used, though not as universally foundational as general-purpose ML frameworks like PyTorch itself.",success
https://github.com/kornia/kornia,kornia,"Kornia is a PyTorch-based, differentiable computer vision library providing GPU-accelerated image processing, geometric vision operators, and augmentation pipelines that integrate directly into deep learning workflows. It also includes and is expanding toward end-to-end vision models (e.g., feature matching, detection, segmentation, and VLM/VLA-oriented components).",11000,computer vision|pytorch|deep learning|image augmentation|differentiable programming|geometric vision|spatial ai,9,"This repository provides differentiable computer vision primitives and higher-level vision components (augmentations, geometric ops, and model integrations) designed to plug into PyTorch training/inference pipelines. It is directly applicable to ML workflows for vision model training (data augmentation, preprocessing, geometry, feature matching) and supports GPU acceleration and autograd-friendly operators. Community adoption is strong (about 11k GitHub stars) and the library is widely used/recognized in the vision/ML ecosystem, making it a highly valuable dependency for ML practitioners, though it is not a general-purpose ML framework on the scale of PyTorch itself.",success
https://github.com/lengstrom/fast-style-transfer,fast-style-transfer,"A TensorFlow-based convolutional neural network implementation for fast neural style transfer, enabling real-time stylization of images and videos using a feed-forward transformation network trained with perceptual losses (VGG-based) and instance normalization.",11000,machine-learning|deep-learning|computer-vision|style-transfer|tensorflow|neural-networks|image-processing|video-processing,9,"This repository implements fast neural style transfer by training a feed-forward CNN in TensorFlow to apply artistic styles to images (and optionally video frames) in real time, using perceptual loss functions derived from a pretrained VGG network and instance normalization. It is directly applicable to ML/computer-vision workflows for training and inference of style-transfer models, and also has strong educational value for understanding perceptual losses and transformation networks. The repo shows substantial community adoption (about 11k GitHub stars and ~2.6k forks), but it is older (originally targeting TensorFlow 0.11 / Python 2.7), which slightly reduces its “drop-in” usefulness compared with modern frameworks—hence a 9 rather than a 10.",success
https://github.com/microsoft/promptflow,promptflow,"Prompt flow is a suite of development tools for building high-quality LLM applications end-to-end—from prototyping and debugging prompt/tool workflows to batch testing, evaluation, CI/CD integration, and production deployment/monitoring. It provides a workflow/""flow"" abstraction plus CLI and a VS Code extension to develop, trace, and iterate on LLM app pipelines.",11000,llm|generative-ai|prompt-engineering|mlops|evaluation|python|workflow-orchestration|azure-ai,9,"This repository provides an end-to-end tooling suite (CLI + VS Code extension + Python packages) to create executable LLM “flows” that connect prompts, LLM calls, and Python/tools into a debuggable workflow, with tracing and iteration support. It is directly applicable to modern ML/GenAI workflows because it focuses on testing and evaluation over datasets, quality/performance measurement, and CI/CD integration for LLM applications. It also supports production deployment patterns and has strong community adoption signals (roughly 11k GitHub stars), making it highly valuable for ML engineers and data scientists building LLM-powered systems.",success
https://github.com/speechbrain/speechbrain,speechbrain,"SpeechBrain is an open-source, PyTorch-based toolkit for building speech and text processing systems used in conversational AI. It provides training recipes and pretrained models for tasks like ASR (speech-to-text), speaker recognition, speech enhancement/separation, and related audio/NLP workflows.",11000,machine learning|deep learning|PyTorch|speech processing|automatic speech recognition (ASR)|speaker recognition|audio ML,9,"This repository is a PyTorch-based speech toolkit aimed at accelerating development and research in conversational AI, spanning many speech/audio (and some text) tasks with standardized training recipes and inference APIs. It is directly applicable to ML workflows (training, fine-tuning, and deploying speech models) and integrates with common ML tooling and pretrained model ecosystems. Its large community adoption (about 11k GitHub stars) and breadth of recipes/tutorials make it highly valuable for ML engineers and researchers. It falls short of a perfect 10 mainly because it is domain-specialized (speech/audio) rather than a general-purpose, ubiquitous ML foundation library like PyTorch itself.",success
https://github.com/aws/amazon-sagemaker-examples,amazon-sagemaker-examples,"A large collection of example Jupyter notebooks demonstrating how to prepare data, build/train models, deploy/monitor endpoints, and run end-to-end ML workflows using Amazon SageMaker (including newer areas like generative AI, MLOps, and responsible AI).",10800,amazon-sagemaker|aws|machine-learning|jupyter-notebooks|mlops|generative-ai|model-training|model-deployment,9,"This repository’s primary purpose is to provide practical, runnable Jupyter notebook examples for building, training, and deploying ML models on Amazon SageMaker, organized across the ML lifecycle (data prep, training, deployment/monitoring) and specialized areas like MLOps, responsible AI, and generative AI. It is directly applicable for ML engineers and data scientists working on AWS because it demonstrates real SageMaker workflows and integrations rather than being a generic utility library. Its strong community adoption (10.8k stars) and breadth of up-to-date examples make it highly valuable for learning and accelerating production ML work on SageMaker. It scores 9 (not 10) because it is primarily a reference/examples repository tied to the SageMaker platform rather than a foundational, general-purpose ML framework used across all environments.",success
https://github.com/GeeeekExplorer/nano-vllm,nano-vllm,"Nano vLLM is a lightweight vLLM-like LLM inference engine implemented from scratch in ~1,200 lines of Python. It focuses on fast offline inference and includes optimizations such as prefix caching, tensor parallelism, torch compilation, and CUDA graphs.",10700,LLM inference|NLP|transformers|PyTorch|deep learning|inference optimization|tensor parallelism,9,"This repository provides a compact, readable implementation of a vLLM-style inference engine for transformer-based LLMs, aiming for high-throughput offline generation with practical systems optimizations (e.g., prefix caching, tensor parallelism, torch compile, CUDA graph). It is directly applicable to ML engineering workflows focused on serving/benchmarking LLM inference and can also be used educationally to understand how vLLM-like engines are built. While it is not a dominant industry standard like vLLM itself, its strong relevance to LLM inference plus notable community interest (10.7k stars) justifies a high score.",success
https://github.com/huggingface/text-generation-inference,text-generation-inference,"Text Generation Inference (TGI) is a Rust/Python/gRPC server and toolkit for deploying and serving large language models (LLMs) with high-performance features like token streaming, continuous batching, tensor parallelism, metrics/tracing, and OpenAI-compatible chat/completions-style APIs. It is used in production by Hugging Face to power services like Hugging Chat and their Inference API/Endpoints, and is currently in maintenance mode (accepting lightweight fixes and docs).",10700,LLM inference|model serving|NLP|MLOps|GPU acceleration|Rust|gRPC,9,"This repository provides a production-oriented inference server/toolkit specifically designed to serve LLMs efficiently (e.g., streaming, batching, tensor parallelism, and optimized transformer inference paths). It is directly applicable to ML engineering workflows for deploying generative models and integrates with common ML ecosystem components (Transformers models, OpenTelemetry/Prometheus, containerized deployment). Community adoption is strong (10k+ stars) and it is used in real production systems, but it is in maintenance mode and newer inference engines are recommended for forward-looking deployments, so it is not scored a full 10.",success
https://github.com/kedro-org/kedro,kedro,"Kedro is an open-source Python framework/toolbox for building production-ready, reproducible, maintainable, and modular data engineering and data science pipelines. It provides a project template, a data catalog of dataset connectors (with versioning for file-based systems), and a pipeline abstraction with dependency resolution and visualization integrations.",10700,data engineering|machine learning|data science|python|pipelines|workflow orchestration|reproducibility|mlops,9,"This repository provides Kedro, a Python framework focused on structuring data/ML projects into modular, reproducible pipelines with a standardized project template, a Data Catalog for loading/saving datasets across storage systems, and pipeline dependency management. It is directly applicable to typical ML/data workflows (feature engineering, training pipelines, batch inference, and productionization) and is explicitly positioned as a toolbox for production-ready data science and data engineering. Its broad integration and deployment support (e.g., common orchestration/deployment targets mentioned in the README) makes it highly useful for MLOps-style pipeline development, justifying a high score rather than a perfect 10 reserved for foundational ML libraries.",success
https://github.com/wandb/wandb,wandb,"Official Weights & Biases (W&B) client and tooling for tracking, visualizing, and managing machine learning experiments and artifacts. Provides a Python SDK and CLI to log metrics, hyperparameters, system stats, and other run metadata to the W&B platform for analysis and collaboration.",10700,machine-learning|mlops|experiment-tracking|model-monitoring|dataset-versioning|python|developer-tools,9,"This repository is the core open-source SDK/CLI used to connect ML training and evaluation code to the Weights & Biases platform, enabling experiment tracking, visualization, and management of ML workflow metadata. It is directly applicable to day-to-day data science and ML engineering workflows (logging metrics, configs, artifacts, and debugging training runs) and integrates broadly with common ML frameworks. It also has strong community adoption (evidenced by its large GitHub star count and active development), making it a highly valuable MLOps/experiment-tracking tool, though it is not itself an ML modeling framework.",success
https://github.com/ultralytics/yolov3,yolov3,"Ultralytics' YOLOv3 implementation built on PyTorch, providing training/validation/inference workflows for object detection and export paths for deployment formats like ONNX, CoreML, and TFLite. The repository includes scripts and configs for running YOLOv3 models and integrating them into common ML deployment pipelines.",10500,computer vision|object detection|YOLOv3|PyTorch|ONNX|CoreML|TensorFlow Lite,9,"This repository is a dedicated computer-vision ML codebase focused on YOLOv3 object detection, including core scripts for training, validation, and inference, plus model export utilities for production deployment. It directly supports common ML workflows (dataset training loops, evaluation, inference, and conversion to ONNX/CoreML/TFLite), making it immediately usable for ML engineers and practitioners. Community adoption is strong (10.5k GitHub stars), and the repo serves as a practical reference for implementing and deploying real-time detectors. It is scored 9 (not 10) because it is a specific model implementation rather than a broad, general-purpose foundational ML library/framework.",success
https://github.com/Yorko/mlcourse.ai,mlcourse.ai,"Open Machine Learning Course (mlcourse.ai) materials maintained by Yury Kashnitsky and the OpenDataScience community, providing a self-paced curriculum with lectures, articles, and hands-on assignments via Jupyter/Kaggle notebooks.",10400,machine learning|data science education|jupyter notebooks|kaggle|python|exploratory data analysis|supervised learning|time series,9,"This repository is primarily an educational ML/data science curriculum (self-paced) with structured weekly topics, lecture links, and practical assignments/notebooks, making it directly applicable for learning and practicing core ML workflows. It covers foundational DS/ML areas like EDA with Pandas, visualization, classification/regression, ensembles/gradient boosting, unsupervised learning, and time series, which are central to many real-world projects. It also shows strong community adoption (10.4k stars) and integrates well with common DS tooling via Jupyter and Kaggle notebooks. It is scored 9 (highly relevant) because it is not a production ML framework/library, but it is a widely used, comprehensive, hands-on ML learning resource.",success
https://github.com/huggingface/tokenizers,tokenizers,"Hugging Face Tokenizers is a high-performance tokenizer library (implemented in Rust with language bindings) for training and using modern NLP tokenization algorithms like BPE, WordPiece, and Unigram. It supports fast training/tokenization, configurable normalization and pre-tokenization, alignment tracking, and common preprocessing steps (truncation, padding, special tokens) for research and production use.",10400,nlp|tokenization|transformers|rust|python|language-modeling|hugging-face,9,"This repository provides a production-grade, widely used tokenization toolkit that underpins many NLP and LLM workflows by converting raw text into model-ready token IDs and attention inputs. It is directly applicable to ML/data pipelines (dataset preprocessing, tokenizer training, and inference-time encoding) and integrates broadly via bindings (notably Python) and Hugging Face’s ecosystem. Its strong community adoption (10.4k stars and frequent releases, with v0.22.2 released on Dec 2, 2025) indicates it is a standard component for modern NLP/transformer workflows. It is not a full training framework, but it is a critical, high-impact dependency for most text-model training and deployment stacks.",success
https://github.com/lucidrains/denoising-diffusion-pytorch,denoising-diffusion-pytorch,"A PyTorch implementation of Denoising Diffusion Probabilistic Models (DDPM) for generative modeling, providing UNet-based diffusion modules plus training utilities (e.g., a Trainer) and sampling (including faster DDIM-style sampling).",10400,machine learning|deep learning|generative models|diffusion models|pytorch|computer vision|image generation|model training,9,"This repository implements core diffusion-model training and sampling (DDPM and related options) in PyTorch, including UNet architectures and a ready-to-use Trainer for training on image folders. It is directly applicable to ML workflows for building and experimenting with diffusion-based generative models, and it includes practical features like multi-GPU training via Hugging Face Accelerate and configurable sampling steps. Community adoption is strong (10.4k GitHub stars), and the codebase is widely used as a reference implementation for diffusion-model experimentation. It scores a 9 (highly relevant) because it is a purpose-built ML model training library, though not an industry-standard foundational framework on the level of PyTorch/TensorFlow.",success
https://github.com/Megvii-BaseDetection/YOLOX,YOLOX,"YOLOX is a high-performance, anchor-free YOLO object detection framework (PyTorch implementation) aimed at bridging research and industrial deployment. It provides training/evaluation utilities plus multiple deployment/export targets including ONNX, TensorRT, ncnn, OpenVINO, and MegEngine support.",10200,computer vision|object detection|YOLO|PyTorch|deep learning|model training|model deployment|ONNX/TensorRT,9,"This repository implements YOLOX, an anchor-free deep learning object detector, and includes end-to-end tooling for model training, evaluation, and inference workflows commonly used by ML engineers. It is directly applicable to data science/ML work (dataset preparation, training on COCO/custom datasets, benchmarking, and exporting models to production runtimes like ONNX/TensorRT/OpenVINO/ncnn). Community adoption is strong (10k+ GitHub stars) and the project has clear documentation and practical deployment paths, making it highly valuable for applied CV ML, though it is not a general-purpose ML framework on the scale of PyTorch/TensorFlow.",success
https://github.com/triton-inference-server/server,server,"Triton Inference Server is an open-source model serving system for high-performance AI inference across cloud, data center, edge, and embedded environments. It supports multiple frameworks/backends (e.g., TensorRT, PyTorch, ONNX, OpenVINO, Python) and provides features like concurrent execution, dynamic/sequence batching, ensembles/BLS, and HTTP/REST + gRPC APIs.",10200,machine-learning|model-serving|inference-server|MLOps|GPU-acceleration|gRPC|Kubernetes,9,"This repository implements NVIDIA Triton Inference Server, a production-grade system for serving trained ML/DL models with optimized performance, batching, and multi-backend execution. It is directly applicable to ML engineering workflows (deploying and scaling inference for models from common frameworks) and integrates with standard inference protocols (HTTP/REST and gRPC) and deployment approaches (e.g., Docker/Kubernetes). Community adoption is strong (10.2k stars) and the project includes extensive documentation/tutorials, making it highly valuable for ML practitioners, though it is focused on inference (not training) which keeps it below a perfect 10.",success
https://github.com/voxel51/fiftyone,fiftyone,"FiftyOne is an open-source Python toolkit (with an interactive web app) for visualizing, curating, and analyzing computer vision datasets and model predictions. It helps teams improve data quality and iterate on visual AI workflows via slicing/filtering, embeddings exploration, and dataset/model evaluation.",10200,computer vision|dataset curation|data visualization|model evaluation|python|MLOps,9,"This repository provides a purpose-built tool for data-centric computer vision: exploring images/videos and labels, inspecting model predictions, and iterating on dataset quality through interactive analysis in the FiftyOne App. It is directly applicable to day-to-day ML workflows like dataset debugging, error analysis, embeddings-based exploration, and evaluation, and it integrates naturally with Python-based CV pipelines. With strong community adoption (10.2k stars on GitHub at the time of lookup), it has high practical and educational value for ML engineers and data scientists working on visual AI, though it is not itself a model-training framework—hence a 9 rather than 10.",success
https://github.com/ymcui/Chinese-BERT-wwm,Chinese-BERT-wwm,"Provides Chinese pre-trained BERT-family models trained with Whole Word Masking (WWM), including BERT-wwm/BERT-wwm-ext and RoBERTa-wwm variants, along with download links and usage guidance for common NLP workflows (e.g., Transformers/PaddleHub). It is maintained by the HFL (Harbin Institute of Technology & iFLYTEK Joint Lab) and references an accompanying TASLP paper.",10200,natural language processing|pretrained language models|BERT|RoBERTa|whole word masking|Chinese NLP|transformers,9,"This repository primarily distributes and documents Chinese pre-trained Transformer encoder models (BERT/RoBERTa variants) trained with Whole Word Masking, intended for direct downstream fine-tuning and evaluation on Chinese NLP tasks. It fits directly into ML workflows via common tooling (e.g., Hugging Face Transformers) and serves as a widely referenced baseline/model source in Chinese NLP. Community adoption is strong (10.2k GitHub stars), and the repo has high educational value by explaining WWM and providing model comparisons and practical loading guidance; it is not a general ML framework, so it falls just short of a 10.",success
https://github.com/microsoft/RD-Agent,RD-Agent,"R&D-Agent is a multi-agent framework from Microsoft that automates data-driven research and development workflows (e.g., proposing ideas and implementing them) for machine learning engineering tasks such as Kaggle-style iteration, feature engineering, and model development. It includes demos, documentation, and scenarios like a Data Science Agent and quant research automation, and reports strong performance on MLE-bench.",10100,AI agents|machine learning engineering|data science|Kaggle|MLOps|LLM orchestration|quantitative finance|Python,9,"This repository’s primary purpose is to automate end-to-end, data-driven ML R&D using an agentic “R (research/idea)” + “D (development/implementation)” framework, including workflows like feature engineering, model tuning, and iterative experimentation. It directly targets ML/data workflows (not just general infrastructure), and explicitly benchmarks itself on ML engineering tasks (MLE-bench) and provides dedicated data science/Kaggle/quant scenarios and docs. While it is not a foundational library like PyTorch (so not a 10), it is highly applicable for ML engineers/data scientists interested in agentic automation and reproducible ML experimentation, with meaningful community adoption indicated by its star count.",success
https://github.com/shiyu-coder/Kronos,Kronos,"Kronos is an open-source decoder-only foundation model for financial market candlestick (K-line) sequences, using a two-stage approach: a specialized tokenizer that discretizes OHLCV data into tokens and an autoregressive Transformer trained on those tokens. It provides pretrained models (via Hugging Face) and utilities for probabilistic forecasting and fine-tuning on downstream quantitative tasks.",10000,machine learning|time series|quantitative finance|foundation model|transformer|tokenization|forecasting|python,9,"This repository implements and distributes a financial time-series foundation model (K-line/candlestick sequences) along with tooling to run forecasts and fine-tune the model, which is directly applicable to ML workflows in quantitative finance and time-series modeling. It includes pretrained model checkpoints hosted on Hugging Face and a predictor API that integrates naturally with common data-science tools like pandas. The project also shows strong community adoption for a research repo (about 10k GitHub stars), indicating practical interest and reuse. It is not a general-purpose ML framework, but it is highly relevant as a specialized model/toolkit for financial time-series modeling, hence a 9/10.",success
https://github.com/stanfordnlp/CoreNLP,CoreNLP,"Stanford CoreNLP is a Java suite of core natural language processing tools that runs an end-to-end text annotation pipeline (e.g., tokenization, sentence splitting, POS tagging, NER, parsing, coreference, and sentiment). It supports multiple languages and can be used as an integrated framework to produce structured linguistic analyses from raw text.",10000,natural language processing|NLP pipeline|information extraction|named entity recognition|parsing|coreference resolution|Java,9,"This repository provides a widely used, production-grade NLP pipeline (Stanford CoreNLP) that transforms raw text into structured annotations such as entities, syntactic parses, coreference chains, and sentiment, making it directly useful for many data science and ML text workflows. It is highly applicable for feature extraction, text preprocessing, and building downstream NLP systems, and it also has strong educational value as a reference implementation of classic and modern NLP components. Community adoption is high (notably strong GitHub engagement) and the toolkit integrates well via Java APIs and typical build systems, though its GPL licensing can constrain some proprietary deployment use cases, which is why it is not scored a full 10.",success
https://github.com/bigscience-workshop/petals,petals,Petals lets you run and fine-tune very large language models by connecting to a distributed peer-to-peer “swarm” where different users host different model layers (BitTorrent-style). It provides a Transformers/PyTorch-like API for inference and fine-tuning without needing the entire model to fit on a single machine.,9900,large-language-models|distributed-inference|p2p-networking|fine-tuning|pytorch|huggingface-transformers|nlp,9,"This repository is an ML-first system for running and fine-tuning LLMs via distributed hosting of model layers across a peer-to-peer network, enabling local-style inference/training workflows on hardware that can’t hold the full model. It integrates directly with common ML tooling (notably PyTorch and Hugging Face Transformers) and targets practical ML engineering tasks like serving, experimenting, and fine-tuning large causal language models. Community adoption appears strong for a specialized LLM infrastructure project (thousands of stars and active ecosystem links like swarm monitoring, tutorials, and a hosted demo). It scores 9 (not 10) because it’s a specialized distributed LLM execution framework rather than a general-purpose, industry-standard core library like PyTorch/TensorFlow.",success
https://github.com/google-deepmind/sonnet,sonnet,"Sonnet is a TensorFlow 2-based neural network library from DeepMind that provides simple, composable abstractions for machine learning research via a core `snt.Module` concept and a collection of common layers and network building blocks.",9900,machine learning|deep learning|TensorFlow|neural networks|research framework|Python,9,"This repository provides Sonnet, a neural network library built on top of TensorFlow 2, centered on `snt.Module` for defining reusable model components (layers, nets, and stateful modules). It is directly applicable to ML workflows for building and composing model architectures (e.g., MLPs, convolutions, batch norm) and is aimed at research usage rather than being a full training framework. Its purpose and design are strongly ML-focused and it has significant community adoption (high GitHub stars), but it is narrower than full-stack ML ecosystems (e.g., end-to-end training/inference platforms), which is why it scores 9 instead of 10.",success
https://github.com/autogluon/autogluon,autogluon,"AutoGluon is an open-source AutoML toolkit (developed by AWS AI) that automates training and deployment of high-accuracy models with a simple Python API. It supports tabular prediction, multimodal (image/text/tabular) learning, and time series forecasting with strong out-of-the-box performance.",9800,automl|machine-learning|tabular-data|time-series-forecasting|multimodal-learning|model-training|python,9,"This repository provides AutoGluon, a practical AutoML framework aimed at quickly producing strong predictive models (tabular, multimodal, and time series) via high-level predictors and sensible presets. It is directly applicable to common ML workflows (data ingestion, training, ensembling, evaluation, and inference) and is designed for real-world performance with minimal code. The project shows substantial community adoption (thousands of GitHub stars) and strong integration potential in Python ML stacks. It is not quite a universal foundational library on the scale of PyTorch/TensorFlow, but it is a highly valuable, widely-used ML tool—hence a 9/10.",success
https://github.com/OpenGVLab/InternVL,InternVL,"InternVL is an open-source suite of multimodal large language models (MLLMs) and training/inference code aimed at closing the gap to commercial vision-language assistants (e.g., GPT-4o-class models). The repository includes model families (e.g., InternVL2/3/3.5), chat/inference demos, and components for related vision tasks (classification, segmentation, retrieval) and training pipelines.",9700,multimodal-llm|vision-language|computer-vision|nlp|pytorch|transformers|llm-training|inference,9,"This repository primarily provides multimodal LLM models and accompanying code for training, evaluation, and deployment (including chat demos and released pipelines/scripts mentioned in the project updates). It is directly applicable to ML workflows—model fine-tuning/pretraining, multimodal inference, benchmarking, and building VLM assistants—using common ML tooling (e.g., PyTorch/Transformers). The project shows strong community adoption (high star count) and substantial educational/practical value for practitioners working on vision-language modeling, though it is not a general-purpose data-science library like Pandas/Spark, so it scores slightly below a 10.",success
https://github.com/espnet/espnet,espnet,"ESPnet is an end-to-end speech processing toolkit built primarily on PyTorch, providing Kaldi-style data preparation and reproducible “recipes” for training and evaluating models across many speech tasks (e.g., ASR, TTS, speech translation, enhancement, diarization, and spoken language understanding). It includes training/inference pipelines, model implementations, and extensive examples for common datasets.",9700,speech-processing|deep-learning|pytorch|automatic-speech-recognition|text-to-speech|speech-translation|audio-ml|speech-enhancement,9,"This repository is a comprehensive, research- and production-oriented ML toolkit for building state-of-the-art speech models (ASR, TTS, speech translation, enhancement, diarization, and SLU) with full training and evaluation pipelines. It is directly applicable to ML workflows because it provides ready-to-run recipes, data preparation conventions, and model code built on PyTorch, enabling practitioners to reproduce results or fine-tune pretrained systems. Its strong community adoption (thousands of GitHub stars) and breadth of supported tasks/datasets make it highly valuable for ML engineers and researchers, but it is more domain-specific (speech/audio) than general-purpose ML frameworks, so it is scored slightly below a 10.",success
https://github.com/drivendataorg/cookiecutter-data-science,cookiecutter-data-science,"A Cookiecutter-based tool and template for creating a standardized, best-practice data science project structure (data/ notebooks/ models/ reports/ etc.). The repository supports Cookiecutter Data Science v2 via the `ccds` CLI (installed from the `cookiecutter-data-science` Python package) and also provides guidance for using the older v1 template.",9600,data-science|machine-learning|cookiecutter|project-template|python|reproducibility|mlops,9,"This repository provides a widely adopted project template and CLI workflow for organizing end-to-end data science and ML work (data acquisition/processing, notebooks, training, inference, reporting, and project documentation) into a consistent structure. It is directly applicable to most ML/data workflows because teams can use it to bootstrap new projects with conventions that improve reproducibility, collaboration, and maintainability. While it is not an ML framework itself (it doesn’t implement modeling algorithms), its strong ecosystem fit and broad community adoption make it highly valuable for practical data science and MLOps-oriented project setup.",success
https://github.com/jadore801120/attention-is-all-you-need-pytorch,attention-is-all-you-need-pytorch,"A pure-PyTorch implementation of the original Transformer (encoder-decoder) model from the paper ""Attention Is All You Need"", including scripts for preprocessing, training, and translation for machine translation tasks (with partial/WIP BPE support).",9600,machine-learning|deep-learning|nlp|machine-translation|transformer|pytorch|attention,9,"This repository implements the Transformer architecture described in ""Attention Is All You Need"" in PyTorch, and includes end-to-end training and inference/translation scripts plus dataset preprocessing utilities. It is directly applicable to common ML/NLP workflows (sequence-to-sequence modeling, machine translation experimentation, and educational reference for transformer internals) and is broadly useful for ML engineers working with PyTorch. The community adoption is strong (about 9.6k GitHub stars), but it is not a general-purpose, production-grade ML framework, and some parts are explicitly marked WIP (e.g., BPE and some evaluation/testing items), which keeps it below a 10.",success
https://github.com/open-mmlab/Amphion,Amphion,"Amphion is an open-source toolkit for audio, music, and speech generation, focused on reproducible research and practical recipes for tasks like TTS (text-to-speech), voice conversion, accent conversion, and text-to-audio. It includes implementations of multiple state-of-the-art model families, neural vocoders, evaluation metrics, dataset preprocessing utilities, and model/architecture visualizations.",9600,machine learning|deep learning|audio generation|text-to-speech|voice conversion|neural vocoders|speech synthesis|PyTorch,9,"This repository is primarily an ML toolkit centered on generative modeling for speech/audio/music, providing training/inference pipelines, multiple state-of-the-art architectures (e.g., TTS and voice conversion models), and supporting components like vocoders and objective evaluation metrics. It is directly applicable to ML workflows because it covers end-to-end steps (data preprocessing, model training, evaluation, and deployment-oriented recipes) and references large-scale datasets and foundation-model style systems for speech generation. Community adoption appears strong (about 9.6k GitHub stars) and the repo is structured for learning and research reproducibility via clear task recipes and visualization tools. It is not a “core” general-purpose ML library like PyTorch itself, but it is highly valuable for practitioners working on speech/audio generation, hence a 9/10.",success
https://github.com/xuebinqin/U-2-Net,U-2-Net,"Official PyTorch implementation of U^2-Net (U Square Net) from the Pattern Recognition 2020 paper ""U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection"". The repo provides code and pretrained models for salient object detection and related foreground/background segmentation use cases (e.g., background removal, portrait/human segmentation demos).",9600,machine learning|deep learning|computer vision|image segmentation|salient object detection|PyTorch|background removal,9,"This repository implements a well-known deep learning model (U^2-Net) for salient object detection/foreground segmentation and includes inference and training scripts plus pretrained weights, making it directly usable in ML workflows (e.g., background removal, matting-like segmentation pipelines). It is strongly aligned with computer vision practice and is commonly integrated into downstream apps and tools, indicating broad community adoption. It’s not a general-purpose ML framework (so not a 10), but it is a highly practical, widely referenced model repo for vision segmentation tasks.",success
https://github.com/openvinotoolkit/openvino,openvino,"OpenVINO is an open-source toolkit for optimizing and deploying deep learning inference across platforms from edge to cloud. It supports converting and running models from common frameworks (e.g., PyTorch, TensorFlow, ONNX) and targets multiple devices including CPUs (x86/ARM), Intel GPUs, and Intel NPUs.",9500,machine learning|deep learning inference|model optimization|computer vision|NLP|generative AI|C++|Python,9,"This repository is a core ML inference and deployment toolkit focused on optimizing and running deep learning models efficiently across diverse hardware targets (CPU/GPU/NPU), making it directly applicable to real-world ML engineering workflows. It is widely used in production-oriented inference scenarios (edge-to-cloud), supports multiple training ecosystems via model conversion, and provides extensive documentation, tutorials, and examples that benefit practitioners. It is slightly less central for pure data science/model training than full training frameworks, but it is highly valuable for model deployment, acceleration, and inference optimization—hence a 9 rather than 10.",success
https://github.com/FMInference/FlexLLMGen,FlexLLMGen,"FlexLLMGen is a high-throughput generation engine for running large language models with limited GPU memory on a single GPU. It achieves this via IO-efficient offloading, compression, and large effective batch sizes, targeting throughput-oriented batch inference workloads.",9400,large-language-models|llm-inference|gpu-offloading|throughput-optimization|pytorch|nlp|systems-for-ml,9,"This repository provides an inference/runtime system specifically designed to run LLM generation workloads efficiently on constrained hardware (e.g., a single commodity GPU) using techniques like offloading and compression. It directly supports common ML/data workflows that involve large-scale batch inference (e.g., benchmarking and data wrangling) and includes concrete usage examples and integration points (e.g., HELM execution backend). The project shows strong community adoption (thousands of GitHub stars), indicating meaningful real-world interest and use, though it is archived (read-only as of Dec 1, 2024), which slightly limits ongoing evolution compared to actively maintained inference engines.",success
https://github.com/Oneflow-Inc/oneflow,oneflow,"OneFlow is an open-source deep learning framework focused on being user-friendly, scalable, and efficient, with a PyTorch-like API. It emphasizes large-scale/distributed training via Global Tensor and acceleration/deployment via a graph compiler.",9400,deep learning framework|distributed training|machine learning|GPU acceleration|PyTorch-like API|graph compiler|CUDA,9,"This repository provides the core OneFlow deep learning framework (training/inference runtime, APIs, compilation/graph execution) intended for building and training neural networks, including large-scale distributed workloads. It is directly applicable to ML engineer and data scientist workflows as an alternative to frameworks like PyTorch/TensorFlow, and includes installation paths (pip/docker/source) and extensive documentation. The score is 9 (not 10) because, while highly relevant and production-oriented, it is not at the adoption level of the most dominant industry frameworks.",success
https://github.com/sktime/sktime,sktime,"sktime is a Python library providing a unified, scikit-learn-compatible framework for machine learning with time series. It supports multiple time-series tasks including forecasting, classification, clustering, and anomaly/changepoint detection, with tools for pipelines, tuning, and validation.",9400,time series|machine learning|python|scikit-learn|forecasting|time series classification|anomaly detection|data science,9,"This repository is a dedicated ML/data science toolkit focused on time-series learning, offering a unified API and a broad set of algorithms across forecasting, classification, clustering, and anomaly/changepoint detection. It directly fits typical data science workflows (model building, evaluation, tuning) and is explicitly designed to interoperate with the scikit-learn ecosystem. With substantial community adoption (about 9.4k GitHub stars) and strong educational/documentation resources, it is highly valuable for ML practitioners working with temporal data. It is scored 9 (not 10) because it is a specialized domain framework (time series) rather than a general-purpose, industry-dominant ML foundation library.",success
https://github.com/arogozhnikov/einops,einops,"A Python library providing flexible, readable tensor rearrangement and reduction operations (e.g., rearrange/reduce/repeat, pack/unpack, and an einsum wrapper) that work across multiple tensor backends such as NumPy, PyTorch, TensorFlow, and JAX.",9300,machine learning|deep learning|tensor operations|PyTorch|JAX|TensorFlow|NumPy,9,"einops is a core utility for expressing tensor reshaping, permutation, reduction, and packing/unpacking in a concise, pattern-based syntax, with support for major ML frameworks (PyTorch/JAX/TensorFlow) and NumPy. It is directly applicable to everyday ML workflows (model architecture code, attention blocks, vision tokenization, batching/patching, etc.) and is widely adopted in the deep learning community, improving code readability and correctness. While it is not a full training framework, its broad backend support and frequent use inside ML models make it highly valuable for ML engineers and researchers. The score is 9 (highly relevant) because it’s a widely used enabling tool for ML code, though not itself an end-to-end ML platform.",success
https://github.com/dotnet/machinelearning,machinelearning,"ML.NET is an open-source, cross-platform machine learning framework for .NET that lets developers build, train, evaluate, and deploy ML models directly in C#/F# applications. It includes data loading/transforms and a variety of built-in algorithms, and can also consume TensorFlow and ONNX models.",9300,machine learning|dotnet|csharp|mlnet|model training|onnx|tensorflow,9,"This repository is the core ML.NET framework used to build and train machine learning models within the .NET ecosystem, providing end-to-end tooling (data loading, feature engineering transforms, trainers, evaluation, and model consumption). It is directly applicable to ML workflows for .NET developers and supports interoperability by enabling use of ONNX and TensorFlow models. With thousands of stars and being the primary upstream repo for ML.NET, it shows strong community adoption and high educational/practical value for ML in C#/.NET. It’s scored a 9 (highly relevant) rather than 10 because it is prominent mainly within the .NET ecosystem compared to cross-language industry-standard ML stacks like PyTorch/TensorFlow.",success
https://github.com/keras-team/autokeras,autokeras,"AutoKeras is an AutoML library based on Keras that automates neural architecture search and provides high-level, end-to-end APIs (e.g., ImageClassifier/TextClassifier) for quickly training deep learning models with minimal code.",9300,automl|deep-learning|keras|tensorflow|neural-architecture-search|hyperparameter-optimization|python,9,"This repository provides an AutoML system built on Keras for automating model selection/architecture search and simplifying end-to-end training via ready-to-use task APIs. It is directly applicable to common ML workflows (image, text, structured/tabular use cases) and integrates tightly with the Keras ecosystem, making it practical for data scientists and ML engineers. The project shows strong community adoption (thousands of GitHub stars) and meaningful educational value for learning AutoML concepts and workflows. It is not as universally foundational as core frameworks like TensorFlow/PyTorch, so it falls just below a perfect 10.",success
https://github.com/PeterL1n/RobustVideoMatting,RobustVideoMatting,"Official implementation of Robust Video Matting (RVM), a recurrent neural network for real-time human video matting with temporal guidance. Provides pretrained models and inference exports across PyTorch, TensorFlow, TensorFlow.js, ONNX, and CoreML, plus training/evaluation code and demos.",9200,computer vision|video matting|deep learning|PyTorch|TensorFlow|ONNX|CoreML|real-time inference,9,"This repository implements a state-of-the-art video matting model (RVM) and includes pretrained weights, inference utilities, and training/evaluation code, making it directly useful for ML engineers working on segmentation/matting and video pipelines. It strongly aligns with ML workflows (model loading, training scripts, evaluation, and multiple deployment formats like ONNX/TFLite-adjacent TF/TFJS/CoreML exports). Community adoption is high for a specialized vision task (thousands of stars and many forks), and it has strong educational value for recurrent/temporal video modeling. It is not a general-purpose ML framework, so it falls just below a 10.",success
https://github.com/eriklindernoren/Keras-GAN,Keras-GAN,"A collection of Keras implementations of many Generative Adversarial Network (GAN) variants from research papers (e.g., DCGAN, CycleGAN, Pix2Pix, WGAN/WGAN-GP, SRGAN). It provides runnable example scripts per model to help learn and experiment with core GAN ideas, though the maintainer notes the repository is now stale/unmaintained.",9200,machine learning|deep learning|generative adversarial networks|keras|tensorflow|computer vision|research-implementations,9,"This repository is explicitly focused on ML: it offers end-to-end Keras implementations of numerous GAN architectures from published papers, with example scripts and basic setup instructions. It is directly applicable for ML engineers and data scientists who want reference implementations, baselines, or educational code for generative modeling and image-to-image tasks. The repo has strong community adoption (thousands of stars), but it is described as “gone stale,” which reduces its practical value for modern Keras/TensorFlow versions—hence a 9 rather than a 10.",success
https://github.com/replicate/cog,cog,"Cog is an open-source tool for packaging machine learning models into standardized, production-ready Docker containers. It generates best-practice images and provides a type-driven prediction interface that can run locally or be deployed to your infrastructure or Replicate.",9200,machine-learning|MLOps|model-deployment|Docker|containers|FastAPI|OpenAPI,9,"This repository provides a packaging and deployment tool specifically designed for machine learning models, using a simple config (cog.yaml) plus a Python Predictor interface to build reproducible Docker images and run predictions. It directly supports common ML workflow needs (GPU/CUDA compatibility handling, dependency/environment reproducibility, and an automatic HTTP prediction server using FastAPI with OpenAPI + Pydantic validation). Its focus on productionizing and serving models makes it highly applicable to ML engineering/MLOps, warranting a high score, though it is not itself a training framework or core data-processing library.",success
https://github.com/skypilot-org/skypilot,skypilot,"SkyPilot is an open-source system for running, managing, and scaling AI workloads across heterogeneous infrastructure (Kubernetes, Slurm, 20+ clouds, and on-prem) using a unified interface. It focuses on portable “job/environment as code,” intelligent resource provisioning (GPUs/TPUs/CPUs), and cost/availability optimization features like spot management, autostop, and failover.",9200,MLOps|cloud orchestration|Kubernetes|multi-cloud|GPU scheduling|batch jobs|LLM training/inference|infrastructure automation,9,"This repository provides a practical system for launching and operating AI/ML workloads (including GPU/TPU jobs, batch training, and inference) across many backends (Kubernetes, Slurm, and numerous clouds) via a single workflow. It is directly applicable to ML engineering and data science teams that need scalable, portable compute and cost/availability optimization (e.g., spot instances with recovery, autostop, and multi-region/cloud failover). With substantial community adoption (9.2k GitHub stars as of the repository page crawl) and strong integration with common ML infrastructure patterns, it is highly valuable for ML/data workflows, though it is not an ML algorithm/library itself—hence a 9 rather than a 10.",success
https://github.com/NVIDIA/cutlass,cutlass,"CUTLASS is NVIDIA’s open-source library of CUDA C++ templates and Python DSLs (CuTe DSL) for building high-performance linear algebra kernels such as GEMM and related operations, with strong support for mixed-precision and modern NVIDIA GPU architectures. It provides reusable building blocks, examples, and tooling (e.g., profiler) for creating and tuning kernels used in ML and HPC workloads.",9100,cuda|gpu-kernels|linear-algebra|gemm|tensor-cores|high-performance-computing|machine-learning-infrastructure|python,9,"This repository provides highly optimized GPU kernel building blocks (CUDA C++ templates) and a Python DSL for implementing core linear algebra operations (notably GEMM) that underpin deep learning training and inference. While it is not an end-user ML framework itself, it is directly applicable to ML workloads because it enables or accelerates the primitives used by frameworks and custom kernels (e.g., attention, mixed-precision matmuls) and targets Tensor Core-capable NVIDIA GPUs. Its strong adoption in the GPU/ML performance ecosystem, extensive examples/tooling, and focus on modern architectures make it highly valuable for ML engineers and performance-oriented researchers; it falls just short of a “10” because it’s primarily a low-level kernel library rather than a complete ML framework.",success
https://github.com/roboflow/notebooks,roboflow/notebooks,"A curated collection of Jupyter notebooks and step-by-step tutorials for applying state-of-the-art computer vision models (e.g., YOLO variants, RT-DETR, SAM, vision-language models) to tasks like detection, segmentation, tracking, pose estimation, and OCR, with options to run in Colab/Kaggle/SageMaker Studio Lab.",9100,computer vision|jupyter notebooks|tutorials|object detection|image segmentation|ocr|vision-language-models|roboflow,9,"This repository’s primary purpose is to provide runnable notebook tutorials demonstrating modern computer vision and vision-language models across common ML tasks (detection, segmentation, tracking, OCR, data extraction). It is directly applicable to ML workflows because practitioners can use the notebooks as templates for experimentation, fine-tuning, and inference in environments like Colab/Kaggle/SageMaker Studio Lab. Its high star count indicates strong community adoption, and the educational value is high due to the breadth of model coverage and practical, task-oriented examples. It is not a foundational ML framework itself, so it scores slightly below a 10, but it is highly valuable as an applied learning and prototyping resource.",success
https://github.com/unit8co/darts,darts,"Darts is a Python library for time series forecasting and anomaly detection with a unified, scikit-learn-like API (fit/predict). It includes classical statistical methods (e.g., ARIMA) and deep learning models, plus tooling for backtesting, probabilistic forecasting, and anomaly scoring/detection workflows.",9100,time series|forecasting|anomaly detection|machine learning|deep learning|python|data science,9,"This repository provides an end-to-end time series ML toolkit: model training (including deep learning), forecasting, backtesting, probabilistic forecasts, and anomaly detection utilities. It is directly applicable to common ML/data workflows (feature/covariate handling, evaluation, and standardized APIs) and integrates with popular Python ML practices (scikit-learn-like usage and interoperability with the Python ecosystem). Its strong adoption signal (about 9.1k GitHub stars) and breadth of supported models/features make it highly valuable for data science and ML engineering, though it is more specialized than general-purpose core libraries like PyTorch or Pandas.",success
https://github.com/activeloopai/deeplake,deeplake,"Deep Lake is a database/data lake format optimized for AI workloads, enabling storage, querying (including vector search), versioning, and streaming of multimodal datasets (text, images, audio, video, PDFs, embeddings) directly into ML frameworks like PyTorch and TensorFlow. It also integrates with LLM tooling (e.g., LangChain/LlamaIndex) to act as a vector store for building LLM applications.",9000,machine learning|data engineering|vector database|LLM|RAG|multimodal datasets|PyTorch|TensorFlow,9,"This repository provides an AI-focused database/data-lake system designed to store, version, query, and stream multimodal data (including embeddings) and to support vector search for LLM/RAG applications. It directly supports ML workflows via built-in dataloaders for PyTorch/TensorFlow and integrates with common LLM ecosystem tools like LangChain and LlamaIndex for vector-store use cases. With roughly 9k GitHub stars and broad applicability across dataset management and LLM app development, it shows strong community adoption and high practical value for ML engineers and data scientists. It is not a general-purpose ML framework like PyTorch itself, but it is a highly relevant core data layer for modern ML/LLM pipelines.",success
https://github.com/pyro-ppl/pyro,pyro,"Pyro is a flexible, scalable deep probabilistic programming library built on PyTorch, designed for expressing probabilistic models and performing inference at scale. It provides composable abstractions for building generative models and customizing inference algorithms for Bayesian/deep probabilistic modeling.",8900,probabilistic-programming|bayesian-inference|machine-learning|deep-learning|pytorch|variational-inference|mcmc,9,"This repository implements Pyro, a probabilistic programming language/library on top of PyTorch for defining probabilistic (generative) models and running inference (e.g., variational inference and MCMC) on them. It is directly applicable to core ML/data workflows involving Bayesian modeling, uncertainty estimation, and probabilistic deep learning, and includes extensive examples/tutorials to support practical use and learning. The project is widely recognized in the probabilistic programming community and integrates tightly with PyTorch, making it highly valuable for ML engineers and data scientists, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/xorbitsai/inference,xorbitsai/inference,"Xorbits Inference (Xinference) is a production-ready model serving system that lets you run and serve open-source LLMs as well as speech and multimodal models via a unified inference API. It provides multiple interfaces including an OpenAI-compatible REST API, CLI, RPC, and WebUI, with support for features like batching and distributed inference.",8900,llm-inference|model-serving|openai-compatible-api|mlops|speech-recognition|multimodal|distributed-systems|python,9,"This repository provides Xinference, a model serving/inference platform focused on deploying and operating LLMs (plus speech and multimodal models) with a unified, production-oriented API. It is directly applicable to ML engineering workflows for self-hosted inference, OpenAI-compatible serving, batching, and distributed deployment, making it a practical tool for real systems rather than a research demo. Its substantial community adoption (high GitHub stars) also suggests meaningful real-world usage, but it is not at the level of universal adoption of foundational frameworks (e.g., PyTorch), so it scores a 9 rather than a 10.",success
https://github.com/lazyprogrammer/machine_learning_examples,machine_learning_examples,"A large collection of machine learning examples and tutorial code organized by topic/course (e.g., supervised/unsupervised learning, deep learning, NLP, RL, time series) intended to accompany LazyProgrammer’s blog posts and courses.",8800,machine learning|deep learning|tutorials|python|tensorflow|pytorch|nlp|reinforcement learning,9,"This repository is primarily an educational codebase containing many end-to-end ML examples across core areas like supervised learning, NLP/transformers, time series, and reinforcement learning, with folders corresponding to courses/tutorials. It’s directly useful for data scientists and ML engineers as reference implementations and learning material, and it includes integrations/usage patterns for common ML frameworks like TensorFlow and PyTorch. Community adoption appears strong (about 8.8k GitHub stars) and the breadth of topics gives it high practical and educational value, though it is not a single production-grade library/framework with standardized APIs like PyTorch/TensorFlow—hence a 9 rather than 10.",success
https://github.com/dusty-nv/jetson-inference,jetson-inference,"An instructional guide and library for deploying real-time deep learning inference and vision primitives on NVIDIA Jetson devices using TensorRT (C++/Python), with tutorials and tooling that also cover collecting datasets and training/transfer learning with PyTorch before deployment.",8700,computer vision|deep learning inference|NVIDIA Jetson|TensorRT|PyTorch|CUDA|edge AI|robotics (ROS/ROS2),9,"This repository primarily targets deploying and running optimized deep-learning inference workloads (classification, object detection, segmentation, pose estimation, action recognition, and more) on NVIDIA Jetson using TensorRT, with substantial example code and documentation. It directly supports ML workflows by including transfer learning/training paths in PyTorch, dataset collection guidance, and deployment steps to TensorRT for edge production use. It is widely used in the Jetson/edge-AI community (high star count) and has strong educational value via the ""Hello AI World"" tutorial structure. It’s scored a 9 (highly relevant) because it is focused on applied ML deployment and tutorials rather than being a general-purpose ML framework with broad cross-domain adoption like PyTorch/TensorFlow.",success
https://github.com/fishaudio/Bert-VITS2,Bert-VITS2,"A neural text-to-speech (TTS) project using a VITS2 backbone combined with multilingual BERT features for multilingual speech synthesis. It includes training/inference code and utilities (e.g., preprocessing and a web UI workflow) and supports export/inference-related tooling (e.g., ONNX scripts).",8700,text-to-speech|speech-synthesis|deep-learning|pytorch|multilingual-bert|voice-cloning|onnx,9,"This repository is primarily an ML model implementation for neural TTS, built around a VITS2 architecture augmented with multilingual BERT, and includes code for training, preprocessing, and inference. It is directly applicable to ML workflows involving speech synthesis, dataset preparation (filelists/preprocessing scripts), model training, and deployment/export (e.g., ONNX). Community adoption appears strong (thousands of GitHub stars), indicating meaningful usage and educational value for practitioners learning or implementing modern TTS pipelines. It scores a 9 (highly relevant) because it is a purpose-built ML project for training and deploying deep-learning TTS models, though it is not a general-purpose foundational framework at the scale of PyTorch/TensorFlow.",success
https://github.com/VowpalWabbit/vowpal_wabbit,vowpal_wabbit,"Vowpal Wabbit is a high-performance machine learning system focused on fast, scalable online learning, featuring techniques like feature hashing, reductions, allreduce/distributed learning, and interactive learning methods (including contextual bandits). It provides a CLI and multiple language bindings (notably Python) for training and inference on large, sparse datasets with bounded memory usage.",8600,machine learning|online learning|contextual bandits|reinforcement learning|feature hashing|C++|python bindings|distributed learning,9,"This repository contains the core Vowpal Wabbit (VW) implementation, a production-grade ML system optimized for online/streaming learning, large-scale sparse linear models, and interactive learning (especially contextual bandits). It is directly applicable to ML workflows via its command-line interface and supported bindings (e.g., Python), enabling model training and inference on large datasets efficiently. VW is widely recognized and used in the ML community for fast, scalable learning (especially in recommendation/ads/bandit settings), which justifies a very high score; it falls short of a 10 mainly because it is more specialized (online/linear/bandit-centric) than general-purpose ML ecosystems like PyTorch/TensorFlow.",success
https://github.com/intel/ipex-llm,ipex-llm,"IPEX-LLM (Intel LLM Library for PyTorch) is an acceleration library to run and fine-tune large language models on Intel hardware (GPU/XPU, NPU, and CPU), with low-bit quantization support and performance optimizations. It also provides integrations and tooling to run popular LLM stacks (e.g., llama.cpp, Ollama, Hugging Face Transformers, LangChain/LlamaIndex, vLLM, DeepSpeed, Axolotl) on Intel platforms.",8600,large-language-models|llm-inference|llm-finetuning|pytorch|intel-gpu-xpu|quantization|huggingface-transformers|ollama-llama-cpp,9,"This repository’s primary purpose is to accelerate LLM inference and fine-tuning on Intel hardware (including Intel GPU/XPU, NPU, and CPU) and to enable practical local deployment through integrations with common LLM runtimes and frameworks. It is directly applicable to ML engineering workflows because it focuses on performance, quantization/low-bit execution, and compatibility with widely used libraries (Transformers, vLLM, DeepSpeed, LangChain, etc.). Community adoption appears strong (8.6k GitHub stars at time of lookup), and the repo offers substantial educational and integration value for practitioners deploying or optimizing LLMs on Intel systems. It’s not a general-purpose ML framework like PyTorch itself, but it is a highly relevant optimization/runtime layer for LLM production and local development, justifying a 9/10.",success
https://github.com/mage-ai/mage-ai,mage-ai,"Mage OSS is a self-hosted, notebook-style environment to build, run, and manage modular data pipelines for integrating, transforming, and orchestrating data workflows using Python, SQL, or R. It supports scheduling, visual debugging, and integrates with common data sources and tools (including dbt).",8600,data-engineering|data-pipelines|etl|elt|workflow-orchestration|python|dbt|machine-learning,9,"This repository provides an open-source platform (Mage OSS) for building and orchestrating production-grade data pipelines with a notebook-style UI, connectors to databases/APIs/cloud storage, scheduling, and debugging tooling. It is directly applicable to ML/data workflows because reliable ETL/ELT, transformations, and orchestration are core prerequisites for feature engineering, training data preparation, and recurring batch jobs. The project also signals strong relevance to the ML/data community via its stated focus and topics (e.g., data-science, machine-learning, etl/elt, orchestration, dbt), and meaningful adoption indicated by its star count. It scores a 9 (highly relevant) because it is a core data-pipeline/orchestration tool used in real-world data workflows, though it is not itself a model-training framework like PyTorch/TensorFlow.",success
https://github.com/modelscope/modelscope,modelscope,"ModelScope is an open-source ML framework built around the “Model-as-a-Service (MaaS)” concept, providing unified APIs and implementations for model inference, training/fine-tuning, and evaluation across multiple domains (CV, NLP, speech, multimodal, and AI-for-science). It also integrates with ModelScope backend services such as a model hub and dataset hub for model/dataset discovery, versioning, and caching.",8600,machine learning|model hub|MLOps|deep learning|NLP|computer vision|multimodal,9,"This repository provides a full-featured ML library that standardizes how developers run inference, train/fine-tune, and evaluate a wide range of state-of-the-art models via layered, unified APIs. It is directly applicable to ML workflows because it bundles model implementations and tooling while also integrating with a model/dataset hub for discovery, version control, and cache management. Its substantial community adoption (8.6k GitHub stars) and multi-domain coverage (NLP/CV/audio/multimodal/science) make it highly valuable for data science and ML engineering, though it is not as universally foundational as core frameworks like PyTorch—hence a 9 rather than 10.",success
https://github.com/OptimalScale/LMFlow,LMFlow,"LMFlow is an extensible toolkit for fine-tuning and inference of large foundation models/LLMs, providing scripts, configs, and workflows for training (e.g., full finetuning/LoRA) and running inference/deployment.",8500,large language models|LLM fine-tuning|NLP|transformers|PyTorch|Hugging Face|LoRA|inference,9,"This repository’s primary purpose is to enable practical fine-tuning and inference workflows for large foundation models, including training recipes and tooling around common LLM adaptation approaches (e.g., LoRA) and deployment/inference usage. It directly supports core ML engineering tasks (data preparation, training, evaluation, inference) and integrates naturally into LLM workflows commonly built around transformer models and GPU training stacks. Community adoption appears strong for an OSS LLM toolkit (8.5k stars), indicating meaningful usage and educational value for practitioners. It falls just short of a 10 because it is a specialized toolkit rather than a foundational, industry-standard core library on the level of PyTorch/Transformers.",success
https://github.com/delta-io/delta,delta,"Delta Lake is an open-source storage framework for data lakes that provides ACID transactions, scalable metadata handling, schema enforcement, and time travel via a transaction log. It enables a Lakehouse architecture and integrates with multiple compute engines (notably Apache Spark, plus Trino/Presto/Hive/Flink support) and language APIs.",8500,data engineering|lakehouse|data lake|delta lake|apache spark|acid transactions|data versioning|big data,9,"This repository implements Delta Lake, a transactional table/storage layer for data lakes that adds ACID guarantees, schema enforcement, and time travel through a transaction log, enabling reliable batch and streaming data pipelines. It is highly relevant to ML/data workflows because it is commonly used to build and manage feature tables, training datasets, and reproducible snapshots (time travel) on top of cloud/object storage with engines like Spark and Trino. While it is not an ML model-training framework, its strong industry adoption as core data infrastructure for lakehouse architectures makes it extremely valuable and directly applicable for data science and ML engineering pipelines.",success
https://github.com/tensorflow/tfjs-core,tfjs-core,"TensorFlow.js Core: a JavaScript/TypeScript library providing WebGL-accelerated tensor operations, linear algebra primitives, and automatic differentiation used as the foundation for TensorFlow.js in browsers and Node.js. This repository is archived and development has moved into the tensorflow/tfjs monorepo (tfjs-core folder).",8500,machine learning|deep learning|TensorFlow.js|JavaScript|TypeScript|WebGL|GPU acceleration|automatic differentiation,9,"This repository implements the core tensor engine behind TensorFlow.js, including fundamental tensor ops, linear algebra kernels, and automatic differentiation, with GPU acceleration via WebGL. It is highly applicable to ML/data workflows because it enables building, running, and differentiating ML computations directly in JavaScript environments (especially the browser), and historically underpins many TensorFlow.js models and tooling. Community adoption is strong (thousands of stars), and it has significant educational value for understanding how tensor runtimes and autodiff work; however, it is archived and active development has moved to the tensorflow/tfjs monorepo, which slightly reduces its practical “go-to” value as a standalone repo today.",success
https://github.com/aladdinpersson/Machine-Learning-Collection,Machine-Learning-Collection,"An educational collection of machine learning and deep learning tutorials/projects, including classic ML algorithms and extensive PyTorch/TensorFlow implementations with accompanying YouTube walkthroughs.",8400,machine learning|deep learning|PyTorch|TensorFlow|computer vision|NLP|tutorials|educational,9,"This repository is primarily a learning resource containing numerous ML/DL implementations and tutorials (e.g., classic ML algorithms plus PyTorch/TensorFlow deep learning projects). It is directly applicable to ML workflows as reference code for model building/training and common tasks (vision, sequence models, GANs, etc.), making it highly valuable for practitioners and learners. Its substantial GitHub adoption (8.4k stars) indicates strong community usage for ML education and practical examples. It’s scored 9 (not 10) because it is a broad educational/code collection rather than a foundational, widely-deployed production framework/library.",success
https://github.com/lucidrains/imagen-pytorch,imagen-pytorch,"A PyTorch implementation of Imagen, Google's text-to-image diffusion model, using a cascading DDPM conditioned on pretrained T5 text embeddings. It includes features like classifier-free guidance support (with dynamic clipping), noise-level conditioning, and memory-efficient U-Net variants for training and sampling.",8400,machine learning|generative ai|text-to-image|diffusion models|computer vision|pytorch,9,"This repository provides a practical PyTorch implementation of the Imagen text-to-image diffusion architecture (cascaded DDPMs conditioned on T5 text embeddings), intended for training and sampling generative image models. It is directly applicable to ML workflows for generative modeling research/experimentation, including components commonly needed in real training setups (e.g., guidance mechanisms and U-Net variants). Community adoption appears strong for a research-implementation repo (on the order of ~8.4k GitHub stars), making it a widely referenced/used implementation, though it is not a foundational, general-purpose framework on the level of PyTorch/TensorFlow—hence a 9 rather than a 10.",success
https://github.com/netease-youdao/EmotiVoice,EmotiVoice,"EmotiVoice is an open-source, multi-voice, prompt-controlled text-to-speech (TTS) engine supporting English and Chinese with emotion/style prompting (e.g., happy, sad, angry) and a large voice set (2000+ voices). It includes a web demo/UI, batch/scripted generation, and an OpenAI-compatible TTS HTTP API.",8400,text-to-speech|speech-synthesis|TTS|generative-ai|deep-learning|PyTorch|audio,9,"This repository provides a complete ML-based TTS system (models, inference scripts, demos, and API) focused on controllable emotional/style speech synthesis and multi-speaker generation. It is directly usable in ML workflows for speech generation, experimentation, and product integration (e.g., via its web UI, Docker setup, and OpenAI-compatible HTTP API). Community adoption appears strong (8.4k stars and hundreds of forks), and the repo is educational/practical for understanding and deploying modern neural TTS, justifying a high score but not a 10 because it is an application/model repo rather than a foundational general-purpose ML framework.",success
https://github.com/yichuan-w/LEANN,LEANN,"LEANN is a lightweight, privacy-first vector database / semantic search backend for building local RAG systems, achieving ~97% storage savings by computing embeddings on-demand rather than storing them. It supports indexing and semantic search over large personal and external data sources (e.g., files, emails, browser/chat history) and can act as an MCP service compatible with Claude Code.",8400,retrieval-augmented generation (RAG)|vector database|semantic search|approximate nearest neighbors (ANN)|information retrieval|Python|MCP (Model Context Protocol)|LLM tooling,9,"This repository implements an ultra-low-storage vector indexing and retrieval system aimed at enabling fully local, private RAG/semantic search over large corpora. It is directly applicable to ML/data workflows where embedding-based retrieval is needed (RAG, agent memory, document/code search), and it includes practical integrations (e.g., an MCP service for Claude Code) and benchmarks/examples. While it is not a general-purpose model training framework, it is a highly relevant retrieval infrastructure component for modern LLM applications, and it shows strong community traction (thousands of GitHub stars).",success
https://github.com/google-deepmind/pysc2,pysc2,"PySC2 is DeepMind’s Python component of the StarCraft II Learning Environment (SC2LE), exposing Blizzard’s StarCraft II Machine Learning API as a Python reinforcement-learning environment. It provides an interface for agents to receive observations from StarCraft II and send actions back to the game for RL research and experimentation.",8200,reinforcement learning|starcraft ii|rl environment|game ai|python|deepmind|simulation,9,"This repository provides a widely used reinforcement-learning environment wrapper around the StarCraft II Machine Learning API, enabling training and evaluation of RL agents via standardized observation/action interfaces. It is directly applicable to ML workflows (especially deep RL), supports reproducible experimentation through maps/scenarios, and has strong educational value for learning agent-environment interaction and RL benchmarking. It’s not a general-purpose ML framework, but it is a core research environment with substantial adoption in the RL community, justifying a high score.",success
https://github.com/OpenPipe/ART,ART,"ART (Agent Reinforcement Trainer) is an open-source reinforcement learning framework for training multi-step LLM agents on real-world tasks using GRPO. It provides a client/server training loop, notebooks/examples, and integrations (e.g., W&B “Serverless RL”) to improve agent reliability by learning from experience.",8100,reinforcement learning|LLM agents|GRPO|RLHF/RLAIF|MLOps|python|vLLM|LoRA,9,"This repository is primarily an RL training framework focused on improving agentic LLM reliability via GRPO, with a full training loop (trajectory collection, rewards, and iterative LoRA updates) and multiple task notebooks/examples. It is directly applicable to ML workflows for practitioners building and training tool-using agents, and it integrates with production-relevant inference/training infrastructure (e.g., vLLM and managed training via W&B). Strong community adoption signals (8.1k stars and hundreds of forks) further increase its practical value, though it is more specialized for agent RL than general-purpose data science.",success
https://github.com/brightmart/text_classification,text_classification,"A collection of deep-learning NLP text classification baselines (e.g., fastText, TextCNN/TextRNN/RCNN, Hierarchical Attention Network, BERT, Transformer, memory networks) with training/inference scripts and support for multi-label classification.",8000,natural language processing|text classification|deep learning|tensorflow|multi-label classification|BERT|Transformer,9,"This repository is primarily an ML/NLP codebase that implements many classic and neural text classification architectures (including multi-label setups) and provides runnable training and prediction scripts. It is directly applicable to ML workflows as a baseline/model zoo for experiments, benchmarking, and learning model implementations, and it has substantial community adoption (thousands of GitHub stars). While some of the stack is older (notably TensorFlow 1.x), the breadth of models and educational value for text classification keep it highly valuable for data science and ML.",success
https://github.com/cortexlabs/cortex,cortex,"Cortex is production infrastructure for deploying, managing, and scaling machine learning models on AWS (EKS). It supports real-time, async, and batch model-serving workloads with autoscaling, cluster management, and integrations for CI/CD and observability; however, the repository notes it is no longer actively maintained by its original authors.",8000,mlops|model-serving|kubernetes|aws-eks|infrastructure|autoscaling|devops|machine-learning,9,"This repository provides an end-to-end MLOps/model-serving platform for deploying and scaling ML inference and batch jobs in production, primarily on AWS EKS, with autoscaling and operational integrations (metrics/logging/CI/CD). It is highly applicable to ML engineering workflows because it directly addresses deployment and operations of ML models rather than model training. The score is high due to its direct relevance to production ML infrastructure and clear focus on ML workloads, but it is not a core ML library and appears inactive (latest release shown as Sep 23, 2022 and the README notes it is no longer actively maintained by its original authors), which limits current adoption and long-term integration value.",success
https://github.com/lanpa/tensorboardX,tensorboardX,"TensorboardX lets you write TensorBoard event files from PyTorch (and also supports other libraries like NumPy, Chainer, and MXNet) via a simple SummaryWriter-style API. It supports many summary types (e.g., scalars, images, histograms, audio, text, graphs, embeddings, PR curves, meshes, hparams, and video) for experiment logging and visualization.",8000,machine learning|deep learning|PyTorch|TensorBoard|experiment tracking|visualization|Python,9,"This repository provides a TensorBoard-compatible event writer (primarily via SummaryWriter) used to log metrics and artifacts from model training runs so they can be visualized in TensorBoard. It is directly applicable to day-to-day ML workflows (training monitoring, debugging, and experiment comparison) and integrates tightly with popular ML tooling (PyTorch + TensorBoard) while also supporting additional ecosystems like NumPy/Chainer/MXNet. Its large community adoption (thousands of GitHub stars) and broad summary support make it highly valuable for ML engineering and experiment tracking, though it is not itself an ML framework (hence not a 10).",success
https://github.com/lmcinnes/umap,umap,"Python implementation of UMAP (Uniform Manifold Approximation and Projection), a fast non-linear dimensionality reduction algorithm commonly used for visualization and embedding of high-dimensional data (often as a drop-in alternative to t-SNE). The project also includes related capabilities like densMAP (density-preserving UMAP) and integrations intended for typical scientific Python workflows.",8000,machine learning|dimensionality reduction|data visualization|manifold learning|python|scikit-learn|unsupervised learning,9,"This repository provides a widely used implementation of UMAP, a core unsupervised learning technique for dimensionality reduction and embedding that is directly applicable to many ML and data science workflows (exploratory analysis, visualization, preprocessing for downstream models). It integrates with the standard scientific Python/ML stack (notably scikit-learn-style usage and dependencies) and is heavily adopted by the community for high-dimensional data (including common use in areas like single-cell and general feature embedding). It is scored 9 (not 10) because it is a specialized algorithm/library rather than a broad, general-purpose ML framework, but it remains highly valuable and commonly used in practice.",success
https://github.com/shenweichen/DeepCTR,DeepCTR,"DeepCTR is a Python package implementing a collection of deep-learning-based CTR (click-through rate) prediction models and reusable layers/components. It provides tf.keras-style APIs (fit/predict) and also supports TensorFlow Estimator for large-scale/distributed training, covering many classic and modern CTR/recsys architectures.",8000,machine-learning|recommender-systems|ctr-prediction|deep-learning|tensorflow|keras|python,9,"This repository is explicitly built for machine learning in recommendation/ads ranking, providing implementations of many widely used CTR prediction architectures (e.g., Wide&Deep, DeepFM, DCN, DIN/DIEN-like families) plus core modeling components. It is directly applicable to ML workflows for tabular + sparse/categorical feature modeling and offers production-oriented interfaces (tf.keras and Estimator) that ML engineers can integrate into training pipelines. Its strong community adoption (thousands of GitHub stars) and breadth of models/components make it highly valuable for practical experimentation and learning, though it is more specialized than general-purpose ML frameworks (hence not a 10).",success
https://github.com/bitsandbytes-foundation/bitsandbytes,bitsandbytes,"bitsandbytes is a PyTorch-focused library that enables k-bit (8-bit and 4-bit) quantization and memory-efficient training/inference for large language models. It provides LLM.int8() inference, QLoRA-style 4-bit training primitives, and 8-bit optimizers to reduce VRAM usage while maintaining strong model quality.",7900,machine learning|PyTorch|LLM|quantization|QLoRA|efficient training|GPU acceleration,9,"This repository provides core tooling for running and fine-tuning large language models with substantially reduced memory usage via 8-bit/4-bit quantization (LLM.int8 and QLoRA) and 8-bit optimizers, directly targeting modern ML training/inference pain points. It plugs directly into common PyTorch LLM workflows and is widely adopted in the LLM ecosystem (e.g., via integrations and large downstream usage). It earns a 9 (not 10) because it is a specialized performance/quantization component rather than a full end-to-end ML framework like PyTorch itself.",success
https://github.com/jessevig/bertviz,bertviz,"BertViz is an interactive visualization tool for inspecting attention in Transformer-based NLP models (e.g., BERT, GPT-2, T5/BART) via Jupyter/Colab. It provides multiple views (e.g., head view, model view, neuron view) and a Python API that works with many Hugging Face Transformers models.",7900,nlp|transformers|attention-visualization|interpretability|jupyter|huggingface|python,9,"This repository provides a practical interpretability/visualization toolkit specifically for Transformer attention, a core component of modern NLP models. It plugs directly into common ML workflows (Jupyter/Colab + Hugging Face Transformers) and is useful for debugging, analysis, and education around model behavior. Community adoption appears strong (thousands of GitHub stars), indicating it is widely recognized and used in the ML/NLP ecosystem. It is not a training framework or data pipeline, but its direct applicability to model analysis justifies a high score.",success
https://github.com/lucidrains/PaLM-rlhf-pytorch,PaLM-rlhf-pytorch,"A PyTorch implementation of RLHF (Reinforcement Learning with Human Feedback) built around a PaLM-style transformer, including code for training the base language model, a reward model, and an RLHF training loop. The repository is explicitly a framework/skeleton (no pretrained model provided) intended to reproduce a ChatGPT-like pipeline with PaLM-like architecture.",7900,machine learning|deep learning|natural language processing|reinforcement learning|rlhf|pytorch|large language models,9,"This repository provides an end-to-end RLHF training scaffold for a PaLM-like language model in PyTorch, covering base LM training, reward modeling from feedback, and an RLHF trainer loop. It is directly applicable to ML engineering workflows for experimenting with LLM alignment methods (e.g., reward models + PPO-style training) and has strong educational value because it lays out the full RLHF pipeline in code. It scores a 9 (not a 10) because it does not ship a trained model or turnkey datasets/compute setup, so practical use still requires substantial data and resources despite being a high-quality implementation.",success
https://github.com/mikel-brostrom/boxmot,boxmot,"BoxMOT is a pluggable multi-object tracking (MOT) toolkit that lets you run and evaluate state-of-the-art trackers on top of bounding-box outputs from detection/segmentation/pose models. It provides a unified Python API and CLI for tracking, benchmarking (e.g., MOT17/MOT20/DanceTrack), tuning, and exporting ReID models/embeddings.",7900,computer vision|multi-object tracking|object detection|ReID (person re-identification)|PyTorch|benchmarking|MLOps / model evaluation,9,"This repository is primarily an ML/computer-vision tool: it provides modular, state-of-the-art multi-object tracking algorithms and integrates with detectors/segmenters/pose models that output bounding boxes, plus optional appearance embeddings (ReID). It directly supports core ML workflows such as running inference-time tracking, generating reusable detections/embeddings, benchmarking on standard MOT datasets (MOT17/MOT20/DanceTrack), and hyperparameter tuning via an included CLI. Its strong applicability to vision pipelines and broad utility for practitioners doing tracking evaluation and deployment justify a high score, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/py-why/dowhy,dowhy,"DoWhy is a Python library for end-to-end causal inference that helps users model causal assumptions, identify causal effects, estimate them with multiple methods, and test robustness via refutation/falsification. It combines graphical causal models with potential outcomes and supports tasks like effect estimation, interventions/counterfactuals, and root-cause/causal attribution analyses.",7900,causal-inference|causal-machine-learning|python|graphical-models|counterfactuals|treatment-effect-estimation|explainability,9,"This repository provides a production-usable causal inference toolkit that operationalizes the full workflow: specifying a causal model/assumptions, identifying effects (e.g., backdoor/frontdoor/IV), estimating effects with a unified API, and validating sensitivity via refutation tests. It is directly applicable to common data science workflows where decisions/interventions must be evaluated from observational data (e.g., uplift/treatment effects, policy evaluation, root-cause and distribution-change attribution, counterfactual analysis). The project shows strong community adoption and ecosystem positioning (PyWhy) and integrates with broader causal/ML tooling (e.g., CATE integrations), making it highly valuable for ML/data practitioners though more specialized than general ML frameworks.",success
https://github.com/jaywalnut310/vits,vits,"Reference implementation of VITS (Conditional Variational Autoencoder with Adversarial Learning) for end-to-end text-to-speech (TTS) in PyTorch, supporting training and inference and providing pretrained models and demos. It includes scripts/configs for single-speaker (LJ Speech) and multi-speaker (VCTK) setups plus alignment and preprocessing utilities.",7800,text-to-speech|speech-synthesis|deep-learning|pytorch|generative-modeling|voice-ai|tts,9,"This repository is an end-to-end neural TTS model implementation (VITS) with training/inference code, configs, and utilities for preparing datasets and running experiments, making it directly usable in ML workflows for speech generation. It is strongly ML-centric (variational inference, normalizing flows, adversarial training) and provides practical artifacts like pretrained models and notebooks, which adds significant educational and applied value. It also shows strong community adoption (about 7.8k GitHub stars at the time checked), indicating broad interest and reuse in the ML/speech community.",success
https://github.com/CVHub520/X-AnyLabeling,X-AnyLabeling,"X-AnyLabeling is an AI-assisted annotation/labeling tool for images and videos that integrates models such as Segment Anything (SAM) to enable fast, semi-automatic and automatic labeling. It supports many computer-vision tasks (e.g., classification, detection, segmentation, tracking, OCR, VQA/grounding) and import/export to common dataset formats like COCO/VOC/YOLO.",7700,data labeling|computer vision|dataset annotation|segmentation|object detection|tracking|ocr|vision-language models,9,"This repository’s primary purpose is to create and manage labeled datasets via an AI-powered annotation GUI/workflow for images and videos, including auto-labeling and support for many model families (e.g., SAM and YOLO variants). It is directly applicable to ML/data workflows because it accelerates the most time-consuming part of many CV projects—creating high-quality annotations—and supports common export formats used for training. Its sizeable GitHub popularity (7.7k stars) suggests meaningful community adoption, but it’s not a core training framework (like PyTorch/TensorFlow), so it scores slightly below a 10.",success
https://github.com/Project-MONAI/MONAI,MONAI,"MONAI (Medical Open Network for AI) is a PyTorch-based, open-source framework for deep learning in healthcare/medical imaging. It provides domain-specific building blocks (data transforms, networks, losses, metrics) and scalable training utilities to build end-to-end medical imaging AI workflows.",7700,medical imaging|deep learning|PyTorch|computer vision|healthcare AI|segmentation|data augmentation,9,"This repository is a specialized deep learning framework built explicitly for medical/healthcare imaging workflows on top of PyTorch, including medical-imaging-specific transforms, models, losses, metrics, and multi-GPU/multi-node training support. It is directly applicable to ML engineering and data science work for tasks like segmentation, classification, and other imaging pipelines, and it is packaged for standard installation (e.g., via pip) with extensive documentation and tutorials. The project shows strong community adoption (thousands of GitHub stars and significant activity), and it integrates cleanly into common PyTorch-based research and production workflows. It is scored a 9 (highly relevant) because it is a core domain ML framework (medical imaging), but not as universally general-purpose across all ML domains as top-tier general frameworks like PyTorch itself.",success
https://github.com/stanfordnlp/stanza,stanza,"Stanza is Stanford NLP Group’s official Python library providing pretrained neural NLP pipelines (e.g., tokenization, sentence segmentation, POS/morphology, lemmatization, NER, and dependency parsing) across 60+ languages, and it also includes a Python interface to Stanford CoreNLP.",7700,natural language processing|NLP pipelines|PyTorch|named entity recognition|dependency parsing|multilingual|Stanford CoreNLP,9,"This repository provides end-to-end, pretrained neural NLP pipelines for many languages (tokenization through parsing and NER) and tooling to run/consume these analyses in Python, with models implemented in/depending on PyTorch. It is directly applicable to ML/data workflows for text processing, feature extraction, dataset annotation, and downstream model building, and it is widely adopted in the NLP community (thousands of GitHub stars, active issue tracker, and a cited ACL system demo paper). It scores a 9 (highly relevant) because it is a core applied NLP toolkit with strong practical utility and community usage, though it is not a general-purpose ML framework on the scale of PyTorch/TensorFlow.",success
https://github.com/AntixK/PyTorch-VAE,PyTorch-VAE,"A reproducible collection of Variational Autoencoder (VAE) variants implemented in PyTorch (with PyTorch Lightning support), providing config-driven training and comparable results across many VAE models (commonly trained on CelebA for consistency).",7600,machine learning|deep learning|pytorch|pytorch-lightning|generative models|variational autoencoders|representation learning,9,"This repository is primarily a set of implementations and training code for many VAE-family generative models (e.g., Beta-VAE, IWAE, WAE, VQ-VAE) with configuration files and documented results, making it directly useful for ML engineers and researchers. It fits cleanly into ML workflows for benchmarking, experimentation, and learning latent-variable generative modeling using PyTorch/PyTorch Lightning. Its large community adoption (thousands of stars) indicates strong usage and educational value. It is not a general-purpose ML framework at the scale of PyTorch/TensorFlow, so it scores just below a 10.",success
https://github.com/Morizeyao/GPT2-Chinese,GPT2-Chinese,"Chinese GPT-2 training and text-generation code based on Hugging Face Transformers, supporting BERT tokenizer or BPE/SentencePiece tokenization for training Chinese language models (e.g., poems, news, novels) on large corpora.",7600,natural language processing|language modeling|GPT-2|text generation|PyTorch|Transformers|Chinese NLP|tokenization,9,"This repository provides end-to-end code for training and generating text with Chinese GPT-2 style language models, including scripts for preprocessing/training and inference generation. It is directly applicable to common ML/NLP workflows (fine-tuning or training autoregressive LMs, experimenting with tokenization choices, and generating samples) and is built around widely used tooling in the ML ecosystem (notably Hugging Face Transformers). Community adoption appears strong (thousands of GitHub stars) and it also links to multiple pretrained Chinese GPT-2 models hosted on Hugging Face, increasing practical utility for ML practitioners. It is not a general-purpose ML framework, but it is highly relevant for NLP research/engineering and educational experimentation, justifying a 9/10.",success
https://github.com/PaddlePaddle/ERNIE,ERNIE,"Official PaddlePaddle repository for ERNIE 4.5 models and ERNIEKit, providing an industrial-grade toolkit for training, fine-tuning (e.g., SFT/LoRA), and deploying ERNIE large language and multimodal (vision-language) models on PaddlePaddle.",7600,machine learning|natural language processing|large language models|multimodal|fine-tuning|PaddlePaddle|model training|model deployment,9,"This repository is a core ML project: it hosts ERNIE 4.5 (LLM/VLM) resources and ERNIEKit, a development toolkit centered on training, post-training (e.g., SFT/LoRA), and deployment workflows built on PaddlePaddle. It is directly applicable to ML engineering and data science work involving LLM/VLM experimentation, fine-tuning, and serving. Community adoption appears strong (thousands of GitHub stars and forks), and the repo’s examples/docs/cookbook structure suggests meaningful educational and integration value for practitioners.",success
https://github.com/alteryx/featuretools,featuretools,"Featuretools is an open-source Python library for automated feature engineering, primarily via Deep Feature Synthesis (DFS) to generate feature matrices from relational/time-indexed datasets. It provides built-in and extensible “primitives” and supports scaling workflows (e.g., via optional Dask support).",7600,automated feature engineering|machine learning|data science|python|feature generation|deep feature synthesis|relational data,9,"This repository’s primary purpose is automated feature engineering for machine learning, converting multi-table/relational datasets into model-ready feature matrices using Deep Feature Synthesis and a library of reusable primitives. It is directly applicable to common ML workflows (classification/regression pipelines) and includes extensibility for custom primitives plus add-ons (e.g., NLP primitives) and optional scaling support (e.g., Dask). The repo shows strong community adoption (thousands of GitHub stars) and high practical value for ML practitioners, though it is not a full model-training framework—hence a 9 rather than a 10.",success
https://github.com/1adrianb/face-alignment,face-alignment,"PyTorch-based library for detecting facial landmarks using state-of-the-art Face Alignment Networks (FAN), supporting both 2D and 3D landmark prediction. It includes multiple face-detector backends (e.g., SFD, dlib, BlazeFace) and supports running on CPU/GPU (including Apple M-series via MPS).",7500,computer vision|face alignment|facial landmarks|PyTorch|deep learning|inference|3D vision,9,"This repository provides a production-usable facial landmark detection (2D/3D) pipeline built on PyTorch, centered on FAN-style deep learning models for face alignment. It is directly applicable in ML/computer-vision workflows (preprocessing/alignment for recognition, animation, tracking, and dataset annotation) and offers practical integration options via multiple detector backends and device support. Community adoption is strong (about 7.5k GitHub stars), and the repo’s examples and packaging (pip/conda) make it easy to integrate into ML projects. It is not a general-purpose ML framework, but it is a highly relevant, widely used CV model implementation/library, hence a 9/10.",success
https://github.com/InternLM/lmdeploy,lmdeploy,"LMDeploy is an efficient toolkit for compressing, deploying, and serving large language models (LLMs). It provides optimized inference backends (e.g., TurboMind and a PyTorch engine), quantization support, and production-oriented serving modes (batch inference and API serving).",7500,large-language-models|llm-inference|model-serving|quantization|MLOps|GPU-acceleration|PyTorch,9,"This repository is primarily an LLM deployment/inference toolkit focused on high-performance serving (TurboMind/PyTorch engine), quantization, and scalable online/offline inference workflows. It is directly applicable to ML engineering and MLOps use cases (serving chat models, benchmarking, multi-GPU/multi-node deployments) rather than general software development. Community adoption appears strong given its GitHub popularity (about 7.5k stars) and active feature updates in its release/news log. It scores a 9 because it is a highly relevant, production-oriented ML systems tool, though it is not a general-purpose data science library like pandas nor a dominant training framework like PyTorch itself.",success
https://github.com/wiseodd/generative-models,generative-models,"A collection of classic generative modeling algorithms implemented for learning and experimentation, including many GAN variants, VAE variants, Restricted Boltzmann Machines (RBM), and a Helmholtz Machine. Implementations are provided in PyTorch and TensorFlow, with example training outputs written to per-model output folders.",7500,machine learning|deep learning|generative models|GAN|VAE|PyTorch|TensorFlow|RBM,9,"This repository is primarily an educational/experimental code collection of multiple well-known generative modeling approaches (GANs, VAEs, RBMs, Helmholtz Machine) implemented in PyTorch and TensorFlow. It is directly applicable to ML workflows for researchers and practitioners who want reference implementations to study, reproduce ideas, or use as a starting point for custom experiments. Community adoption appears strong for a learning repo (thousands of GitHub stars), but it is not a production-grade framework or a widely used dependency like major ML libraries, so it does not merit a 10.",success
https://github.com/tensorlayer/TensorLayer,TensorLayer,"TensorLayer is a TensorFlow-based deep learning and reinforcement learning library aimed at researchers and engineers, providing a high-level yet flexible layer/model abstraction plus extensive examples and tutorials for building neural network models.",7400,machine learning|deep learning|reinforcement learning|TensorFlow|neural networks|Python|research tooling,9,"This repository provides a deep learning and reinforcement learning library (TensorLayer) built on top of TensorFlow, focused on making it easier to build, customize, and train neural network models with a higher-level abstraction plus many examples/tutorials. It is directly applicable to ML workflows (model prototyping, training, and experimentation) and includes supporting assets like documentation and examples, indicating strong educational and practical value. Its community adoption appears solid (about 7.4k GitHub stars and ~1.6k forks), but it is not at the ""major industry-standard"" level of the biggest frameworks (e.g., PyTorch/TensorFlow themselves), so it scores just below a 10.",success
https://github.com/FunAudioLLM/SenseVoice,SenseVoice,"SenseVoice is a multilingual speech foundation/understanding model that supports automatic speech recognition (ASR), spoken language identification (LID), speech emotion recognition (SER), and audio event detection (AED). The repository provides model usage demos, export/inference options (e.g., ONNX/libtorch), and tooling for finetuning and service deployment.",7300,speech-recognition|multilingual-asr|audio-understanding|speech-emotion-recognition|audio-event-detection|model-export|onnx|pytorch,9,"This repository provides an end-to-end speech foundation model and associated tooling for core ML tasks including multilingual ASR, language ID, emotion recognition, and audio event detection, making it directly applicable to common ML/audio workflows. It includes practical assets for ML engineers such as demos, finetuning scripts, and deployment/export paths (e.g., ONNX/libtorch), which increases integration potential in production pipelines. Community adoption is strong for a specialized audio model (thousands of stars/forks), and the repo’s documentation and examples add educational value for implementing and serving speech models. It’s not a general-purpose ML framework, but it is a highly relevant applied ML model/toolkit, hence a 9/10.",success
https://github.com/MaartenGr/BERTopic,BERTopic,"BERTopic is a Python topic modeling library that leverages transformer-based embeddings and class-based TF-IDF (c-TF-IDF) to produce dense document clusters and interpretable topic representations. It supports multiple topic modeling paradigms including guided, supervised/semi-supervised, hierarchical, dynamic, online/incremental, multimodal, and LLM-based workflows.",7300,topic-modeling|natural-language-processing|transformers|text-clustering|python|machine-learning|embeddings|nlp,9,"This repository provides a purpose-built topic modeling framework for extracting, representing, and analyzing topics from text corpora using transformer embeddings plus c-TF-IDF for interpretable topic words. It is directly applicable to common ML/data workflows (unsupervised exploration, labeling, monitoring topic drift over time, and large-scale text analytics) and integrates well with typical Python data-science tooling. Community adoption appears strong for a specialized NLP library (7.3k GitHub stars) and the documentation/examples indicate high practical and educational value. It is scored 9 (highly relevant) rather than 10 because it is a specialized NLP application library rather than a foundational, general-purpose data/ML platform.",success
https://github.com/google-deepmind/lab,lab,"DeepMind Lab is a customizable, Quake III–based 3D learning environment that provides a suite of challenging navigation and puzzle-solving tasks for AI agents. It is primarily used as a research testbed for artificial intelligence, especially deep reinforcement learning, with a Python API and Lua-based level/task configuration.",7300,reinforcement learning|3D simulation|AI research environments|game engine (Quake III/ioquake3)|Python API|Lua scripting|Bazel build|robotics & embodied AI,9,"This repository provides a full 3D agent environment (DeepMind Lab) designed specifically to run AI experiments, offering standardized tasks and an API for stepping agents through observations/actions/rewards. It is highly applicable to ML workflows for deep reinforcement learning and embodied AI because it supplies the core component needed for training and evaluating agents: a controllable, instrumented environment with many task variants. Its long-standing use and recognition in the RL research community, plus its integration points (Python bindings, dm_env compatibility, configurable Lua levels), make it a highly valuable ML research tool rather than a general-purpose game project. It is not a general ML framework like PyTorch/TensorFlow, but as an environment/testbed it remains a top-tier asset for RL research, justifying a 9/10.",success
https://github.com/PaddlePaddle/Paddle-Lite,Paddle-Lite,"Paddle-Lite is PaddlePaddle’s high-performance, lightweight deep learning inference engine for mobile, embedded, and edge devices. It provides model optimization (e.g., quantization/subgraph fusion/kernel selection) and multi-language APIs (C++/Java/Python) with broad hardware acceleration support across Android, iOS, Linux, Windows, and macOS.",7200,machine-learning|deep-learning|inference-engine|edge-ai|mobile-deployment|model-optimization|hardware-acceleration,9,"This repository’s primary purpose is ML model inference and deployment: it is a dedicated inference framework/engine optimized for running PaddlePaddle models on resource-constrained mobile/edge hardware, including tooling to optimize models and select/accelerate kernels. It is directly applicable to ML engineering workflows focused on production inference, on-device deployment, and edge optimization rather than model training. Community adoption appears solid (thousands of GitHub stars and broad integration in the Paddle ecosystem), and it has strong practical/educational value for learning edge inference and optimization techniques, justifying a high score short of general-purpose training frameworks.",success
https://github.com/ymcui/Chinese-LLaMA-Alpaca-2,Chinese-LLaMA-Alpaca-2,"A project that builds Chinese-adapted LLaMA-2 base models and Alpaca-2 instruction-tuned/chat models by expanding/optimizing the Chinese vocabulary and continuing pretraining on large-scale Chinese data. It also provides training/fine-tuning scripts plus deployment/quantization guidance and supports LLaMA ecosystem tooling (e.g., Transformers, llama.cpp, vLLM), including long-context variants up to 64K.",7200,large language models|NLP|Chinese language|LLaMA-2|instruction tuning|fine-tuning|long-context|transformers,9,"This repository focuses on producing and using Chinese-enhanced LLaMA-2 and Alpaca-2 LLMs (base, chat/instruction-tuned, RLHF-aligned) including long-context versions (16K/64K). It is directly applicable to ML/NLP workflows because it provides model artifacts, training and instruction fine-tuning scripts, and practical integration paths with common LLM tooling (Transformers, llama.cpp, vLLM, etc.). Community adoption is strong (7.2k GitHub stars), and the repo has substantial educational and operational value for practitioners working on Chinese LLM pretraining, alignment, and deployment, justifying a high score.",success
https://github.com/InternLM/InternLM,InternLM,"Official repository for the InternLM series of large language models (InternLM, InternLM2, InternLM2.5, InternLM3), providing model releases, model cards, and tooling/examples for inference, chat, fine-tuning, and long-context usage.",7100,large language models|NLP|transformers|LLM inference|LLM fine-tuning|chat models|PyTorch,9,"This repository is primarily focused on releasing and enabling use of the InternLM family of large language models, including model cards and practical guidance for deploying and running the models (e.g., chat/inference and fine-tuning components). It is directly applicable to ML workflows such as model evaluation, serving, and adaptation (fine-tuning), and is clearly intended for ML practitioners. Its substantial community adoption (thousands of GitHub stars) and integration with common LLM tooling/ecosystems make it highly valuable for ML engineers and data scientists, though it is not a general-purpose foundational ML library on the scale of PyTorch/TensorFlow.",success
https://github.com/PeterL1n/BackgroundMattingV2,BackgroundMattingV2,"Official implementation of the CVPR 2021 paper “Real-Time High-Resolution Background Matting”, providing a deep-learning model that uses an additional captured background image to produce high-quality alpha mattes in real time (e.g., 4K 30fps / HD 60fps on RTX 2080 Ti). It includes inference demos (images/video/webcam), training scripts, and export paths for deployment formats such as TorchScript and ONNX.",7100,computer-vision|image-matting|video-matting|deep-learning|pytorch|onnx|torchscript,9,"This repository provides a state-of-the-art neural network and accompanying code for high-resolution human/background matting, a core computer vision task, with scripts for inference on images/videos/webcams and training workflows. It is directly applicable to ML pipelines for segmentation/matting, virtual backgrounds, video editing, and real-time vision applications, and also supports deployment/export via TorchScript and ONNX for production integration. Community adoption is strong (thousands of GitHub stars) and the repo is educational for understanding modern matting architectures and datasets, which justifies a high score short of foundational frameworks like PyTorch itself.",success
https://github.com/scikit-learn-contrib/imbalanced-learn,imbalanced-learn,imbalanced-learn is a Python library providing resampling techniques and related tools to address class-imbalanced datasets in machine learning. It is scikit-learn compatible and designed to integrate into standard sklearn pipelines and workflows.,7100,machine learning|python|scikit-learn|imbalanced classification|resampling|data preprocessing|model evaluation,9,"This repository provides a dedicated toolbox for handling imbalanced datasets, centered on widely used resampling strategies (over-sampling, under-sampling, and combinations) and sklearn-compatible APIs. It is directly applicable to common ML workflows because it plugs into scikit-learn pipelines and is used to improve model training on skewed class distributions. Community adoption is strong (thousands of GitHub stars) and it has clear educational value by providing canonical implementations and examples for imbalance-handling techniques. It’s not a full end-to-end ML framework, but it is a highly practical, broadly used core add-on for classification problems, warranting a 9/10.",success
https://github.com/OpenNMT/OpenNMT-py,OpenNMT-py,"OpenNMT-py is an open-source (MIT) PyTorch framework for neural machine translation and related NLP/LLM tasks, providing training, fine-tuning, and inference tooling (including support for quantization, LoRA adapters, and tensor parallelism). The repository README notes it is no longer actively supported and directs developers to the newer Eole project.",7000,natural language processing|neural machine translation|large language models|PyTorch|model training|fine-tuning|quantization|sequence-to-sequence,9,"This repository provides a full PyTorch-based toolkit for building and running neural machine translation systems and (more recently) adapting large language models, including scripts and configs for training, evaluation, and inference. It is directly applicable to common ML/NLP workflows (data preprocessing, model training, fine-tuning with LoRA, quantized inference, and evaluation), and has strong community adoption as indicated by its large GitHub star count. The score is not a 10 primarily because the project is explicitly marked as no longer actively supported, which reduces its long-term reliability for new production work despite its strong capabilities and adoption.",success
https://github.com/deeppavlov/DeepPavlov,DeepPavlov,"DeepPavlov is an open-source NLP framework/library for building, training, evaluating, and deploying conversational AI and other NLP models using a modular, configuration-driven approach. It provides pretrained models and a CLI/Python API for common NLP tasks, built on PyTorch and Transformers.",7000,natural language processing|conversational AI|chatbots|deep learning|PyTorch|transformers|model training|MLOps/deployment,9,"This repository provides a full NLP framework for building and deploying state-of-the-art NLP models (including dialog systems/chatbots) via configuration-driven pipelines, with both CLI and Python usage. It is directly applicable to ML workflows (training, evaluation, inference, model/data downloads, and serving via an API) and integrates with core ML tooling like PyTorch and Hugging Face Transformers. With a large open-source footprint (thousands of GitHub stars) and a catalog of pretrained NLP models, it has strong community adoption and high practical/educational value for ML engineers and data scientists. It is not a general-purpose ML framework at the scale of PyTorch/TensorFlow, but it is highly relevant as an end-to-end NLP application framework, hence a 9/10.",success
https://github.com/NVIDIA/pix2pixHD,pix2pixHD,"Official PyTorch implementation of pix2pixHD for high-resolution (up to 2048×1024) photorealistic image-to-image translation using conditional GANs. It is commonly used to synthesize realistic images from semantic label maps (e.g., Cityscapes) and supports interactive semantic manipulation/editing workflows.",6900,machine-learning|deep-learning|computer-vision|generative-adversarial-networks|image-to-image-translation|pytorch|semantic-segmentation|image-synthesis,9,"This repository provides training and inference code for a well-known conditional GAN approach (pix2pixHD) focused on high-resolution image synthesis and semantic manipulation, making it directly applicable to core ML workflows in computer vision. ML practitioners can use it to train on paired datasets (e.g., semantic labels → photos), run pretrained models, and adapt the architecture/losses for related generative tasks. It has strong community adoption (thousands of GitHub stars) and solid educational value for learning high-resolution GAN training techniques in PyTorch, but it is a research implementation rather than a general-purpose, production-grade ML framework—hence a 9 rather than a 10.",success
https://github.com/PaddlePaddle/models,models,"PaddlePaddle’s officially maintained industrial-grade model repository, providing a large collection of deep learning models and end-to-end suites across CV, NLP, speech, recommendation, time series, and large models, aligned with PaddlePaddle framework releases.",6900,paddlepaddle|deep-learning|machine-learning|computer-vision|natural-language-processing|speech|recommendation-systems|time-series,9,"This repository is a comprehensive, officially supported collection of PaddlePaddle model implementations spanning core ML domains (CV, NLP, speech, recommendation, time series, and large models), intended for training, evaluation, and production-style integration. It is directly applicable to ML workflows because it provides ready-to-use model code, examples, and domain-specific suites aligned with PaddlePaddle releases, making it practical for both learning and deployment. It also shows substantial community adoption (thousands of stars and many contributors), which supports its value and reliability. It is scored 9 (not 10) because it is primarily tied to the PaddlePaddle ecosystem rather than being a broadly framework-agnostic tool like the most universally adopted ML libraries.",success
https://github.com/Angel-ML/angel,angel,"Angel is a high-performance distributed machine learning and graph computing platform based on the Parameter Server architecture, designed for large-scale/high-dimensional models. It supports running on YARN and provides integration via Spark-on-Angel for ML and graph workloads.",6800,machine learning|parameter server|distributed training|graph computing|Apache Spark|YARN|Scala|Java,9,"This repository implements Angel, a distributed ML and graph computing platform centered on a Parameter Server design, including a Spark-on-Angel layer with a collection of ML and graph algorithms. It is directly applicable to ML/data workflows that require scalable training/serving of high-dimensional models and large graph analytics, especially in Hadoop/YARN + Spark ecosystems. The repository shows substantial community adoption (thousands of GitHub stars) and includes practical deployment and programming guides plus built-in algorithms, making it highly valuable for ML engineers and data platform teams. It is scored a 9 (not a 10) because it is influential within its niche but not as universally adopted across the broader ML community as the most dominant general-purpose ML frameworks.",success
https://github.com/NicolasHug/Surprise,Surprise,"Surprise is a Python library (a “scikit”) for building, training, and evaluating recommender systems based on explicit user-item rating data. It includes multiple collaborative filtering algorithms (e.g., neighborhood methods and matrix factorization like SVD/SVD++/NMF), dataset utilities (built-in MovieLens/Jester and custom loaders), and evaluation tooling such as cross-validation and parameter search.",6800,machine learning|recommender systems|collaborative filtering|matrix factorization|python|model evaluation|scikit-learn-style API,9,"This repository provides a dedicated toolkit for recommender systems using explicit ratings, offering ready-to-use algorithms (including neighborhood methods and matrix-factorization approaches like SVD/SVD++/NMF), plus dataset handling and evaluation utilities (cross-validation, comparison, and parameter search). It is directly applicable to ML workflows for recommendation tasks and is commonly used as a practical baseline/teaching library for collaborative filtering experiments. It earns a 9 (highly relevant) because it is purpose-built for a core ML problem area and includes end-to-end experimentation support, though it is narrower in scope than general-purpose ML frameworks.",success
https://github.com/interpretml/interpret,interpret,"InterpretML is an open-source library for machine learning interpretability: it provides interpretable “glassbox” models (notably Explainable Boosting Machines) and explanation tools for “blackbox” models, supporting global and local explanations and interactive visualization.",6800,machine learning|model interpretability|explainable AI|python|glassbox models|model explanation|fairness,9,"This repository’s primary purpose is to help practitioners fit interpretable ML models (e.g., Explainable Boosting Machines) and generate explanations for black-box predictors, including both global behavior and per-prediction (local) reasoning. It is directly applicable in common ML workflows for debugging, feature engineering, compliance, and trust-building, and it provides practical APIs and visualization tooling data scientists can use immediately. The repository shows strong community adoption (thousands of GitHub stars) and high educational value by bundling multiple interpretability techniques under one roof. It’s not a general-purpose ML framework like PyTorch/TensorFlow, but it is a highly relevant, widely used XAI toolkit, justifying a 9/10.",success
https://github.com/tensorflow/tfjs-examples,tfjs-examples,"A collection of standalone example projects built with TensorFlow.js, demonstrating how to train and run ML models in the browser and in Node.js across tasks like classification, regression, sequence modeling, transfer learning, and reinforcement learning.",6800,tensorflow.js|machine learning|javascript|deep learning|web development|node.js|example projects,9,"This repository’s primary purpose is to provide practical, runnable TensorFlow.js examples that cover common ML workflows (data loading, model definition, training, evaluation, inference, and saving/loading). It is highly applicable for ML engineers and data scientists who want to deploy or prototype models in JavaScript environments (browser/Node.js), and it has strong educational value due to its breadth of tasks and self-contained example directories. While it is not a general-purpose ML framework itself (it depends on TensorFlow.js), it is a widely used companion repo that accelerates learning and integration of TF.js into real applications, justifying a high relevance score.",success
https://github.com/LMCache/LMCache,LMCache,"LMCache is a KV-cache layer/extension for LLM serving that reduces time-to-first-token (TTFT) and increases throughput, especially for long-context workloads, by caching and reusing KV caches across GPU/CPU/disk (and other storage backends) and across serving instances. It integrates with serving engines like vLLM (v1) and SGLang to enable features such as KV-cache offloading, disaggregated prefill, and peer-to-peer KV-cache sharing.",6700,llm-inference|kv-cache|llm-serving|vllm|sglang|pytorch|gpu-acceleration|performance-optimization,9,"This repository provides infrastructure to accelerate LLM inference by caching and reusing attention KV caches across storage tiers (e.g., GPU/CPU/disk) and across serving instances, directly targeting lower latency (TTFT) and higher throughput in production LLM serving. It is highly applicable to ML engineering workflows for deploying LLMs (especially long-context, multi-turn QA, and RAG) and integrates with popular serving stacks like vLLM and SGLang. Its substantial GitHub adoption (about 6.7k stars) and clear focus on inference-system performance make it highly valuable for ML practitioners, though it is not a general-purpose modeling/training library.",success
https://github.com/arcee-ai/mergekit,mergekit,"mergekit is a toolkit for merging pre-trained large language models using multiple merge algorithms, including out-of-core methods that work in resource-constrained environments. It supports CPU-only merges or GPU acceleration (e.g., with as little as ~8GB VRAM) and provides CLI workflows driven by YAML configurations.",6700,large language models|model merging|transformers|pytorch|huggingface|NLP|LLM tooling,9,"This repository is purpose-built for ML practitioners who want to combine pretrained LLMs directly in weight space, offering multiple merging strategies (including more advanced workflows like multi-stage merging, MoE-style merging, and LoRA extraction). It maps directly onto common ML engineering workflows around model experimentation and deployment, and it integrates naturally with the Hugging Face ecosystem for sharing merged models. Its strong community adoption (thousands of stars and hundreds of forks) indicates it is widely used in the LLM/model-merging space, though it is more of a specialized model-engineering tool than a general-purpose ML framework—hence a 9 rather than a 10.",success
https://github.com/clovaai/donut,donut,"Official implementation of Donut (Document Understanding Transformer), an OCR-free end-to-end Transformer for visual document understanding tasks such as document classification, information extraction/document parsing, and document VQA. The repository also includes SynthDoG, a synthetic document generator used for pretraining across languages/domains.",6700,machine learning|deep learning|computer vision|document understanding|ocr-free|transformers|pytorch|synthetic data generation,9,"This repository provides training/inference code, pretrained models, and demos for Donut, an OCR-free Transformer-based approach to document AI (classification, parsing/information extraction, and document VQA). It is directly usable in ML workflows (fine-tuning on datasets, evaluating models, and running demos) and is tightly aligned with common ML tooling (PyTorch and Transformers ecosystem). Its strong adoption (thousands of GitHub stars) and clear linkage to a peer-reviewed paper and pretrained checkpoints make it highly valuable for ML practitioners working on document understanding, though it is more specialized than general-purpose frameworks.",success
https://github.com/flyteorg/flyte,flyte,"Flyte is an open-source, Kubernetes-native workflow orchestration platform for building and operating production-grade data and machine learning pipelines. It focuses on scalable execution, reproducibility/immutability, strong typing, and cloud/on-prem portability via containerized tasks and a pluggable architecture.",6700,workflow orchestration|MLOps|data pipelines|Kubernetes|machine learning|data engineering|Go,9,"This repository contains Flyte’s core platform components (e.g., control/data-plane services like FlyteAdmin and FlytePropeller) that orchestrate containerized workflows on Kubernetes, with an emphasis on reproducibility, typing, and lineage. It directly targets ML and data workflows by enabling teams to define, schedule, and run multi-step pipelines (including distributed compute) in production environments. Its strong adoption signal (thousands of GitHub stars) and explicit ML/data positioning make it highly applicable for ML engineering and MLOps, though it is orchestration infrastructure rather than a model-training library itself, so it falls short of a 'core ML framework' 10.",success
https://github.com/postgresml/postgresml,postgresml,"PostgresML is an open-source PostgreSQL extension and ecosystem that lets you run machine learning and AI inference directly inside Postgres, with optional GPU acceleration. It includes built-in capabilities for LLM/RAG workflows (chunking, embedding, ranking, transforming), vector search via pgvector, and a broader set of ML algorithms accessible from SQL.",6700,postgresql|database-extension|machine-learning|llm|rag|vector-search|gpu-acceleration|mlops,9,"This repository’s primary purpose is to bring ML/AI inference into PostgreSQL via the pgml extension, aiming to keep data and models co-located and accessible through SQL. It directly supports common ML/data workflows such as in-database inference, embedding generation and vector similarity search for RAG, and integrates with the Postgres ecosystem (e.g., pgvector) for practical deployment. Given its strong alignment with applied ML/data engineering use cases and meaningful community adoption (thousands of GitHub stars), it merits a high score, though it’s not as universally foundational as general-purpose frameworks like PyTorch/TensorFlow.",success
https://github.com/adap/flower,flower,"Flower (flwr) is an open-source framework for building federated AI systems, enabling federated learning and analytics across distributed clients. It is customizable and extendable, and is designed to work with many ML frameworks (e.g., PyTorch, TensorFlow, scikit-learn, JAX, and others).",6600,federated learning|machine learning|distributed training|federated analytics|MLOps|PyTorch|TensorFlow|Python,9,"This repository provides Flower (flwr), a dedicated framework for implementing federated AI systems, including federated learning workflows with pluggable strategies and extensive examples/baselines. It is directly applicable to ML engineering and research workflows where training happens across many devices or silos without centralizing data, and it integrates with major ML ecosystems (PyTorch, TensorFlow, scikit-learn, JAX, etc.). The project shows strong community adoption (thousands of GitHub stars) and high educational value via tutorials, docs, and reproducible baselines, making it highly valuable for ML/data practitioners but not quite a universal core library like PyTorch itself.",success
https://github.com/feast-dev/feast,feast,"Feast is an open source feature store for machine learning that helps manage, version, and serve features consistently for both model training (offline) and low-latency online inference. It provides an abstraction layer over offline/online storage and supports point-in-time correct historical feature retrieval to reduce data leakage.",6600,feature store|MLOps|machine learning|data engineering|online inference|offline training data|Python|Kubernetes,9,"This repository implements Feast, a dedicated feature store designed specifically to operationalize ML features across offline training and online serving, including a feature server and point-in-time correct historical feature generation. It is directly applicable to real-world ML workflows (feature engineering, training dataset creation, real-time inference) and is commonly used by ML platform teams as core MLOps infrastructure. The strong focus on preventing training/serving skew and integrating with existing data infrastructure makes it highly valuable for production ML, warranting a 9/10 rather than 10/10 (reserved for foundational ML frameworks/libraries with broader general-purpose adoption).",success
https://github.com/yangjianxin1/Firefly,Firefly,"Firefly is an open-source large language model (LLM) training toolkit that supports pretraining, supervised fine-tuning (SFT/instruction tuning), and DPO for many popular open LLMs (e.g., Qwen2.5/Qwen2, Llama 3, Gemma, Mixtral, Mistral, Baichuan2, ChatGLM2, InternLM, Yi, Deepseek). It supports full-parameter training as well as efficient fine-tuning methods like LoRA and QLoRA, with configuration-driven workflows and optional Unsloth acceleration.",6600,large language models|llm-training|fine-tuning|dpo|lora|qlora|pytorch|unsloth,9,"This repository is primarily an LLM training framework, explicitly designed for pretraining, instruction fine-tuning (SFT), and DPO across many mainstream open-source chat/model families, with support for full training and parameter-efficient methods (LoRA/QLoRA). It is directly applicable to ML workflows because it provides practical training pipelines/configurations and references datasets and model weights aimed at producing fine-tuned LLMs. The repo shows strong community adoption (thousands of stars) and high educational value for practitioners learning modern LLM fine-tuning and preference optimization workflows, justifying a high score though it is not at the ecosystem scale of core libraries like PyTorch/Transformers.",success
https://github.com/open-compass/opencompass,opencompass,"OpenCompass is an LLM evaluation platform that runs standardized evaluations across a wide range of large language models (e.g., Llama, Mistral, GPT-4, Qwen, GLM, Claude) using 100+ datasets/benchmarks. It provides tooling and configurations to reproduce and customize evaluation pipelines and reporting for model comparison.",6500,LLM evaluation|benchmarking|NLP|machine learning|Python|MLOps|model assessment,9,"This repository’s primary purpose is evaluating and benchmarking large language models across many datasets, with configurable evaluation pipelines and support for multiple model backends. It is directly applicable to ML/NLP workflows (model selection, regression testing, reproducible benchmarking, LLM-as-judge style evaluations), making it a practical tool for ML engineers and researchers. The project shows strong community adoption (thousands of GitHub stars) and ongoing feature updates in its documented changelog, supporting its high relevance score. It is not a core training framework like PyTorch, but it is a highly valuable, purpose-built evaluation platform for modern LLM development, hence a 9/10.",success
https://github.com/clearml/clearml,clearml,"ClearML is an open-source MLOps/LLMOps suite (Python SDK + CLI) for experiment tracking, dataset/version management, pipeline/orchestration & remote execution, and model serving/monitoring, typically used together with the ClearML Server and agents to run and manage ML/GenAI workloads across local, cloud, Kubernetes, and on-prem infrastructure.",6400,MLOps|LLMOps|experiment-tracking|pipeline-orchestration|dataset-versioning|model-serving|Python|Kubernetes,9,"This repository is the core ClearML Python SDK/CLI that powers experiment management (automatic logging of code, environment, metrics, artifacts), data/dataset management with versioning on object storage, and workflow automation/orchestration features used in production ML and GenAI stacks. It is directly applicable to everyday ML engineering workflows (training, tracking, reproducibility, remote execution, pipelines) and integrates broadly with common ML frameworks (e.g., PyTorch, TensorFlow, scikit-learn, XGBoost) and infrastructure (cloud/Kubernetes). It has strong community adoption for an open-source MLOps tool (6.4k GitHub stars) and high integration potential, but it is not itself a modeling framework like PyTorch/TensorFlow, so it falls just short of a perfect 10.",success
https://github.com/deepchem/deepchem,deepchem,"DeepChem is an open-source Python toolkit for applying deep learning and machine learning to scientific domains such as drug discovery, quantum chemistry, materials science, and biology. It provides datasets, featurizers, models, and training utilities with optional backends/integrations for TensorFlow, PyTorch, and JAX.",6400,machine learning|deep learning|cheminformatics|drug discovery|computational chemistry|materials science|bioinformatics|python,9,"This repository is a dedicated ML/deep-learning toolkit focused on real-world scientific ML use cases (cheminformatics, drug discovery, quantum chemistry, materials science, and biology), offering core building blocks like datasets, featurization, and model training utilities. It is directly applicable to data science/ML workflows in these domains and supports common ML frameworks (TensorFlow, PyTorch, JAX), making it practical for both research and production prototyping. The project shows strong community adoption for a specialized scientific ML library (thousands of GitHub stars and substantial activity), and it has significant educational value via documentation and tutorials.",success
https://github.com/flashlight/wav2letter,wav2letter,"Facebook AI Research's wav2letter++ automatic speech recognition (ASR) toolkit, providing end-to-end speech recognition recipes and pretrained models. The repository is largely focused on reproducible ASR research workflows and notes that ongoing development has moved into the Flashlight ASR application.",6400,automatic-speech-recognition|speech-recognition|deep-learning|end-to-end-asr|flashlight|cpp|python,9,"This repository is an ASR toolkit (wav2letter++) and includes training/evaluation recipes and pretrained models for end-to-end speech recognition research, which is directly in the core ML domain. It is highly applicable to ML workflows (data preparation, model training, evaluation, and recipe-based reproducibility), and is clearly positioned for deep learning-based speech recognition. While active development is consolidated into Flashlight (so this repo may function more as recipes/legacy reference), it remains a strong, widely used resource for speech ML practitioners and for learning modern end-to-end ASR setups.",success
https://github.com/zhouhaoyi/Informer2020,Informer2020,"Official PyTorch implementation of the Informer model (AAAI 2021 Best Paper) for long-sequence time-series forecasting, featuring ProbSparse attention and scripts to reproduce experiments on benchmarks like ETT.",6400,time-series-forecasting|deep-learning|transformers|pytorch|long-sequence-modeling|attention-mechanisms,9,"This repository provides the original PyTorch implementation of Informer, a transformer-based architecture designed specifically for long-horizon time-series forecasting with an efficient ProbSparse attention mechanism. It is directly applicable to ML workflows for training, evaluating, and reproducing forecasting experiments (including scripts, dataset guidance, and Docker/Makefile support). Community adoption is strong (thousands of GitHub stars and frequent citation/acknowledgement in later time-series transformer repos), and it has high educational value for understanding efficient attention in forecasting; it’s not a general-purpose ML framework, so it does not merit a perfect 10.",success
https://github.com/haifengl/smile,smile,"SMILE (Statistical Machine Intelligence & Learning Engine) is a fast, comprehensive machine learning framework for the JVM (primarily Java), with additional Scala and Kotlin APIs. It includes a broad set of algorithms across classical ML (classification/regression/clustering), deep learning and LLM inference tooling, plus supporting components like linear algebra, graph algorithms, and data visualization.",6300,machine learning|java|scala|kotlin|data science|nlp|deep learning|llm-inference,9,"This repository is primarily a full-featured machine learning engine for Java/JVM, providing many production-usable algorithms (e.g., classification, regression, clustering, feature selection) and adjacent DS tooling like linear algebra and visualization. It directly supports ML workflows (training, evaluation, and inference) and also includes modern capabilities like deep learning and LLM-related components, making it broadly applicable to data science and ML engineering in JVM stacks. It has strong open-source adoption signals (thousands of GitHub stars) and substantial educational value given its wide algorithm coverage and accessible APIs. It is scored a 9 (not a 10) because its ecosystem impact/adoption is significant but not at the level of the most dominant cross-industry ML foundations (e.g., PyTorch/TensorFlow).",success
https://github.com/tensorflow/serving,tensorflow/serving,"TensorFlow Serving is a flexible, high-performance serving system for machine learning models designed for production inference. It supports serving multiple model versions simultaneously and exposes both gRPC and HTTP/REST endpoints, with features like batching, canarying, and A/B testing.",6300,machine learning|model serving|MLOps|TensorFlow|inference|gRPC|REST API|C++,9,"This repository provides TensorFlow Serving, a production-grade system for deploying and operating ML models for inference, including version management, batching, and high-performance request handling. It is directly applicable to ML engineering workflows (deploying SavedModel artifacts and serving predictions over gRPC/HTTP) and is widely used within the TensorFlow ecosystem for production serving. It scores a 9 (highly relevant) because it is a core MLOps/inference infrastructure component rather than a model-training framework, but it is still central to real-world ML deployment.",success
https://github.com/tensorpack/tensorpack,tensorpack,"Tensorpack is a high-level neural network training interface built on graph-mode TensorFlow, focused on high training speed and flexibility for research workflows. It includes efficient data loading utilities (tensorpack.dataflow), scalable multi-GPU/distributed training support, and many non-toy example implementations that reproduce published papers.",6300,machine learning|deep learning|tensorflow|neural network training|data pipeline|distributed training|computer vision|reinforcement learning,9,"This repository provides a TensorFlow-based training framework designed specifically for building and running neural network training pipelines with an emphasis on performance (including multi-GPU/distributed training) and research flexibility. It is directly applicable to ML engineering workflows because it supplies training abstractions, high-performance Python data input pipelines (tensorpack.dataflow), and numerous full training scripts that reproduce well-known papers across CV/RL/NLP. While it is highly relevant and has strong adoption (thousands of GitHub stars and many dependent repositories), its TensorFlow-graph/TF1-compatibility orientation makes it less universally current than modern PyTorch-first ecosystems, so it is not a perfect 10.",success
https://github.com/guardrails-ai/guardrails,guardrails,"Guardrails is an open-source Python framework for building more reliable LLM applications by running input/output “guards” (validators) to detect/mitigate risks and by helping generate structured outputs (e.g., JSON/Pydantic) from LLM responses.",6216,LLM|AI safety|output validation|structured generation|Python|MLOps|prompting,9,"This repository provides a Python framework to validate, constrain, and correct LLM inputs/outputs via composable guards/validators (including a hub/CLI workflow) and structured generation utilities. It is directly applicable to ML/LLM engineering workflows for productionizing LLM apps (safety, quality, schema enforcement, and reliability), and integrates naturally with common LLM stacks (e.g., OpenAI-style calls and Pydantic models). Community adoption appears strong (6k+ GitHub stars and active issues/PRs), indicating meaningful real-world use. It is not a model-training framework, but it is highly valuable infrastructure for deploying and governing LLM-driven systems, justifying a 9/10.",success
https://github.com/zihangdai/xlnet,xlnet,"Official TensorFlow implementation of XLNet, a pretrained language representation model using generalized permutation language modeling with a Transformer-XL backbone. The repository provides code and scripts for pretraining and fine-tuning XLNet on downstream NLP tasks such as classification and question answering, along with released pretrained checkpoints.",6200,natural language processing|transformers|language model|pretraining|fine-tuning|tensorflow|question answering|text classification,9,"This repository is the official implementation of XLNet, a transformer-based pretrained language model designed for language understanding via generalized permutation language modeling and built on Transformer-XL. It is directly applicable to ML workflows for NLP (pretraining and fine-tuning) and includes task runners/utilities for common benchmarks like SQuAD and GLUE-style classification. It also has strong community adoption (6.2k GitHub stars), reflecting broad use and educational value for understanding and reproducing a major pretrained-model approach. It scores 9 (highly relevant) because it is a core NLP model training/fine-tuning codebase, though not a general-purpose ML framework with the breadth/industry footprint of libraries like PyTorch/TensorFlow themselves.",success
https://github.com/KevinMusgrave/pytorch-metric-learning,pytorch-metric-learning,"A PyTorch library for deep metric learning that provides modular, flexible components (losses, miners, samplers, trainers, etc.) to train embedding models with minimal boilerplate. It supports common metric-learning workflows like pair/triplet mining and a wide range of metric-learning loss functions.",6115,machine learning|deep learning|pytorch|metric learning|representation learning|loss functions|computer vision,9,"This repository is a dedicated deep metric learning toolkit for PyTorch, offering a large set of ready-to-use loss functions plus utilities like online miners and samplers that plug directly into training loops. It is directly applicable to common ML workflows that learn embeddings (e.g., retrieval, clustering, re-identification, face/product recognition) and integrates naturally with standard PyTorch training code. Community adoption appears strong (6,115 GitHub stars), and the project includes extensive documentation and examples, making it both practical and educational. It scores a 9 because it is highly relevant and broadly useful for ML engineers, though it is more specialized than foundational, universally-used core frameworks (e.g., PyTorch itself).",success
https://github.com/RangiLyu/nanodet,nanodet,"NanoDet-Plus is a super fast, lightweight, anchor-free one-stage object detection project designed for real-time inference on mobile/edge devices. It provides training code and deployment support across multiple inference backends (e.g., ncnn, MNN, OpenVINO) plus demos (including Android).",6100,computer vision|object detection|deep learning|PyTorch|edge AI|mobile inference|anchor-free detection,9,"This repository implements and trains NanoDet/NanoDet-Plus, a compact anchor-free object detection model intended for real-time deployment on mobile/edge hardware, and includes benchmarking and model zoo/release artifacts. It is directly applicable to ML workflows (training, evaluation, and inference) for computer vision detection tasks and integrates with common ML tooling (PyTorch training and multiple deployment runtimes like ncnn/MNN/OpenVINO). It has strong community adoption for a specialized CV model repo (on the order of ~6.1k GitHub stars) and solid educational value for understanding lightweight detector design and deployment constraints, justifying a high (but not “framework-level”) score.",success
https://github.com/yl4579/StyleTTS2,StyleTTS2,"StyleTTS 2 is a research codebase for training and running a human-level neural text-to-speech (TTS) system using style diffusion and adversarial training with large speech language models (e.g., WavLM) as discriminators. The repo includes training scripts (multi-stage), configs, and demo/inference tooling for datasets like LJSpeech/VCTK/LibriTTS.",6100,text-to-speech|speech-synthesis|deep-learning|pytorch|diffusion-models|speech-processing|generative-models|audio-ml,9,"This repository provides the full implementation of the StyleTTS 2 model (a neural TTS system) along with training pipelines, configs, and supporting code to reproduce results on standard speech datasets and perform inference. It is directly applicable to ML workflows in speech generation (training, finetuning, evaluation, and deployment experiments) and integrates with common deep learning tooling (notably PyTorch/Accelerate). Community adoption appears strong (thousands of GitHub stars), and the repo is educational for advanced generative speech modeling (diffusion-based style modeling and adversarial training with large pre-trained speech models), justifying a high score.",success
https://github.com/FederatedAI/FATE,FATE,"FATE (Federated AI Technology Enabler) is an industrial-grade federated learning framework that lets multiple organizations collaboratively train models without sharing raw data, using privacy-preserving secure computation (e.g., homomorphic encryption and MPC). It provides a broad set of federated ML algorithms (e.g., LR, tree-based methods, deep learning, transfer learning) plus deployment options for standalone and cluster environments.",6000,federated learning|privacy-preserving machine learning|secure multi-party computation|homomorphic encryption|machine learning framework|MLOps|distributed systems,9,"This repository is a full federated learning platform aimed at production use, enabling collaborative model training across parties while keeping data local and protected via secure computation techniques (homomorphic encryption, MPC). It is directly applicable to ML workflows (training, evaluation, and deployment patterns) and includes a wide range of federated algorithms and supporting components for real-world scenarios. The project shows strong community adoption signals for a specialized ML framework (thousands of stars and an ecosystem of related repos like scheduling/serving/visualization), making it highly valuable for ML engineers and data science teams working on privacy-sensitive or cross-silo learning use cases. It is scored 9 (not 10) because, while very strong in its niche, it is more specialized than general-purpose core ML libraries used universally across all ML tasks.",success
https://github.com/aimhubio/aim,aim,"Aim is an open-source, self-hosted ML experiment and AI-metadata tracker. It lets you log training runs (metrics, parameters, artifacts, system usage, etc.), explore and compare them in a UI, and query runs programmatically via an SDK.",5900,machine learning|experiment tracking|MLOps|metadata logging|model monitoring|Python|visualization,9,"This repository is primarily an ML experiment/AI-metadata tracking tool intended to be used directly in model training workflows to record metrics, hyperparameters, artifacts, and system/resource telemetry, and then visualize/compare runs in a dedicated UI. It is highly applicable for data scientists and ML engineers because it provides both an SDK for logging/querying runs and a UI for analysis and run comparison, which are central MLOps needs. The project also shows strong community adoption signals (thousands of GitHub stars) and supports integrations/migration patterns for common ML tooling, making it broadly usable in real-world ML pipelines. It’s not an ML modeling framework itself, but it is a core workflow tool for ML experimentation and governance—hence a 9/10 rather than a 10/10.",success
https://github.com/canopyai/Orpheus-TTS,Orpheus-TTS,"Orpheus TTS is a state-of-the-art open-source text-to-speech system built on a Llama-3B backbone, demonstrating LLM-based speech synthesis with human-like prosody. The repo provides pretrained/finetuned (and multilingual) models plus code and examples for low-latency streaming inference and fine-tuning.",5900,text-to-speech|speech-synthesis|LLM|voice-cloning|streaming-inference|PyTorch|vLLM|HuggingFace,9,"This repository is primarily an ML system for neural text-to-speech: it ships model artifacts (pretrained/finetuned and multilingual releases) and code for inference, real-time streaming, and fine-tuning. It directly supports common ML workflows (prompting, dataset preparation, training scripts, and deployment/inference paths such as vLLM), making it immediately usable by ML engineers building TTS applications. The strong community adoption signal (thousands of GitHub stars) and the included training guidance/data processing scripts add practical and educational value, justifying a high score though it is more domain-specific than general-purpose ML frameworks.",success
https://github.com/dmlc/gluon-cv,gluon-cv,"GluonCV is a computer vision deep learning toolkit that provides implementations of state-of-the-art models plus training scripts and a large set of pre-trained models. It supports both MXNet and PyTorch and is aimed at helping engineers/researchers prototype and reproduce results across common CV tasks (classification, detection, segmentation, pose, video action recognition, etc.).",5900,machine learning|deep learning|computer vision|model zoo|MXNet|PyTorch|object detection|image segmentation,9,"This repository is an end-to-end computer vision ML toolkit that ships SOTA model implementations, reproducible training scripts, and many pre-trained weights across multiple CV tasks, making it directly useful in ML engineering workflows. It integrates with major deep learning frameworks (MXNet and PyTorch) and is designed for prototyping and research reproduction, which gives it strong practical and educational value. Community adoption appears substantial (about 5.9k GitHub stars), indicating meaningful real-world usage. I scored it a 9 (not a 10) because it is a specialized CV toolkit/model zoo rather than a general-purpose foundational ML library on the scale of PyTorch/TensorFlow.",success
https://github.com/lance-format/lance,lance,"Lance is an open lakehouse format (file/table/catalog specs) designed for multimodal AI workloads, providing fast random access, hybrid search (vector + full-text), indexing, and dataset versioning/ACID features. It integrates with common data/ML tools like PyArrow, Pandas, Polars, DuckDB, Spark, Ray, and PyTorch to support storage and querying of embeddings and multimodal data at scale.",5900,lakehouse|data-format|vector-search|multimodal-data|data-engineering|apache-arrow|python|rust,9,"This repository implements the Lance lakehouse format and related tooling to store, version, index, and query large multimodal datasets (including embeddings) with very fast random access and hybrid search. It is directly applicable to ML workflows such as feature stores, dataset management for training, and building retrieval/search systems, and it integrates with widely used data/ML ecosystems (Arrow/Pandas/Polars/DuckDB/Spark/Ray/PyTorch). Given its strong alignment with data/ML needs and meaningful community adoption (thousands of GitHub stars), it merits a 9 rather than a 10 primarily because it is a specialized storage/format layer rather than a general-purpose ML framework.",success
https://github.com/multimodal-art-projection/YuE,YuE,"YuE is an open-source foundation model series for full-song music generation (lyrics-to-song), producing multi-minute tracks with both vocals and accompaniment across diverse genres and languages. The repository provides inference tooling and updates such as incremental generation, music continuation, and LoRA fine-tuning support, alongside links to released models and a technical report.",5900,generative-ai|music-generation|audio|deep-learning|foundation-model|pytorch|finetuning-lora|inference,9,"This repository’s primary purpose is ML-driven music generation: it hosts and documents the YuE foundation models for generating complete songs from lyrics, plus inference utilities and training-related features like LoRA fine-tuning. It is directly applicable to ML/audio workflows (model inference, prompting/ICL, continuation, and fine-tuning), and integrates with common ML tooling and model distribution (e.g., links to Hugging Face model weights and an arXiv technical report). Given its clear ML focus, strong practical utility for audio-generative modeling, and significant community adoption (thousands of GitHub stars), a 9/10 is appropriate; it’s highly relevant but not a general-purpose, industry-standard core framework on the level of PyTorch/TensorFlow.",success
https://github.com/snorkel-team/snorkel,snorkel,"Snorkel is a Python system for programmatically building and managing ML training data using weak supervision (e.g., labeling functions) to generate labels at scale. It provides tooling to combine noisy supervision sources into higher-quality labeled datasets to accelerate model development.",5900,weak supervision|training data|data labeling|machine learning|python|programmatic labeling|data-centric AI,9,"This repository’s primary purpose is to help create and manage machine-learning training labels using weak supervision, enabling faster iteration on labeled datasets without exhaustive manual annotation. It is directly applicable to ML workflows (especially classification/IE/NLP-style pipelines) because it sits upstream of model training and can materially improve dataset quality and iteration speed. The project has strong community adoption (thousands of stars and broad usage/visibility) and high educational value for learning weak supervision and data-centric ML development. It scores a 9 (not a 10) because it is not a general-purpose model training framework like PyTorch/TensorFlow, but it is still a highly impactful, ML-focused data tool.",success
https://github.com/Trusted-AI/adversarial-robustness-toolbox,adversarial-robustness-toolbox,"Adversarial Robustness Toolbox (ART) is a Python library for machine learning security that helps evaluate and defend ML models against adversarial threats such as evasion, poisoning, model extraction, and inference attacks. It supports many ML frameworks (e.g., TensorFlow, PyTorch, scikit-learn, XGBoost, LightGBM) across multiple data types and tasks.",5800,adversarial-machine-learning|ml-security|adversarial-attacks|robustness|privacy|python|red-teaming|blue-teaming,9,"This repository provides a comprehensive, production-usable toolbox for adversarial ML: generating attacks (evasion/poisoning/extraction/inference), benchmarking robustness, and applying defenses across common frameworks. It is directly applicable to ML/data workflows for security testing, robustness evaluation, and model hardening, with extensive examples, notebooks, and broad estimator/framework support. Community adoption is strong (5.8k stars, 757 dependents shown by GitHub, and ongoing releases—latest listed as ART 1.20.1 on July 7, 2025), making it highly valuable for ML engineers and researchers. It’s not a general-purpose training framework, but as a specialized ML security standard toolkit it merits a high score.",success
https://github.com/lucidrains/x-transformers,x-transformers,"A PyTorch library providing a concise but fully-featured full-attention Transformer implementation, including encoder-only (BERT-like), decoder-only (GPT-like), and encoder-decoder architectures, plus a variety of experimental attention/model features drawn from recent papers.",5800,machine learning|deep learning|transformers|PyTorch|NLP|attention mechanisms|generative models,9,"This repository is a practical PyTorch implementation of Transformer architectures (encoder, decoder, and encoder-decoder) with many modern/experimental features, making it directly usable for building and training NLP and vision-language models. It is highly applicable to ML workflows (model prototyping, research experimentation, and custom architecture development) and includes runnable examples for common paradigms like GPT-style and BERT-style modeling. The repo shows strong community adoption (thousands of GitHub stars) and substantial educational value for understanding and experimenting with Transformer variants. It is not a full end-to-end training framework like PyTorch Lightning or Hugging Face Transformers, but it is a highly relevant modeling toolkit, justifying a score of 9.",success
https://github.com/om-ai-lab/VLM-R1,VLM-R1,"VLM-R1 is an R1-style reinforced vision-language model project focused on improving visual understanding tasks (e.g., Referring Expression Comprehension and open-vocabulary detection) via reinforcement learning (GRPO) and related training recipes. The repo provides training scripts and code supporting full/LoRA fine-tuning, freezing vision modules, multi-node training, multi-image inputs, and multiple VLM backbones (e.g., QwenVL and InternVL).",5800,machine learning|computer vision|vision-language models|reinforcement learning|fine-tuning|PyTorch|LoRA|distributed training,9,"This repository is directly focused on training and improving large vision-language models using reinforcement learning (R1-style/GRPO) for concrete visual understanding tasks like referring expression comprehension and open-vocabulary detection. It is immediately applicable to ML workflows by providing end-to-end training scripts (including LoRA, multi-node training, and multi-image support) and integrations for multiple VLM backbones. Given its clear ML-first purpose and strong community interest (5.8k GitHub stars at the time of lookup), it merits a high score, though it is not a foundational general-purpose framework on the scale of PyTorch/TensorFlow.",success
https://github.com/princeton-nlp/tree-of-thought-llm,tree-of-thought-llm,"Official implementation of the NeurIPS 2023 paper ""Tree of Thoughts: Deliberate Problem Solving with Large Language Models"". It provides code, prompts, and logged trajectories to run Tree-of-Thoughts style search (e.g., BFS/DFS over intermediate ""thought"" states) on tasks like Game of 24, creative writing, and crosswords.",5800,large language models|prompting|tree search|reasoning|NLP|Python|research code,9,"This repository is a research-grade implementation of the Tree-of-Thoughts (ToT) prompting/search framework for improving LLM problem-solving by exploring and evaluating multiple intermediate reasoning paths (e.g., via BFS/DFS). It is directly applicable to ML/LLM experimentation workflows (prompting strategies, search over generations, evaluation/voting/value functions) and includes code, prompts, and experiment logs/trajectories that are useful for reproducing and extending published results. Community adoption appears strong for a research repo (about 5.8k GitHub stars), and the educational value is high because it concretely demonstrates ToT-style deliberative reasoning and task integrations. It scores a 9 (highly relevant) rather than 10 because it is not a general-purpose, industry-standard ML framework like PyTorch/TensorFlow, but it is still a widely referenced and practical LLM reasoning implementation.",success
https://github.com/datajuicer/data-juicer,data-juicer,"Data-Juicer is a one-stop system for processing and improving text and multimodal datasets for use with foundation models (typically LLMs). It provides a large operator library, reusable recipes, and scalable/robust execution (e.g., Ray-based parallelism) to support data cleaning, analysis, selection, synthesis, and data-model co-development workflows.",5700,machine learning|LLM|data processing|data cleaning|multimodal|data pipeline|Ray|MLOps,9,"This repository is purpose-built for preparing and optimizing training/post-training data (text and multimodal) for foundation models, offering a broad set of operators and recipes plus tooling for iterative data-model co-development. It directly maps to common ML/LLM workflows (dataset cleaning, deduplication, filtering, synthesis/augmentation, and scalable processing) and is positioned as an end-to-end data pipeline system rather than a general utility. Its sizeable community adoption (multi-thousand GitHub stars) and integrations/production mentions (e.g., Ray ecosystem and Alibaba Cloud PAI integration described in the repo) support a high score. It is not itself a model-training framework, so it falls short of a perfect 10, but it is highly valuable as a core LLM data engineering tool.",success
https://github.com/mindee/doctr,doctr,"docTR (Document Text Recognition) is a deep-learning OCR library that provides end-to-end pipelines for document text detection and text recognition, with pretrained models and utilities to run OCR on PDFs, images, and URLs (webpages). It also supports related tasks like KIE (Key Information Extraction) and includes tooling such as demos/notebooks and a deployable API.",5700,optical character recognition|computer vision|deep learning|PyTorch|TensorFlow|document AI|text detection|text recognition,9,"This repository is primarily an ML library for document understanding, focusing on OCR via a two-stage deep-learning pipeline (text detection + text recognition) and providing pretrained models and predictors for practical use. It directly fits common ML/data workflows for extracting structured text from PDFs/images, enabling downstream analytics, labeling, and information extraction (including KIE). Community adoption appears strong for a specialized OCR library (thousands of stars), and it integrates with major ML frameworks (notably PyTorch, with TensorFlow support), making it highly valuable for ML practitioners. It is not a general-purpose ML framework at the scale of PyTorch/TensorFlow themselves, but within document OCR it is highly applicable and production-oriented.",success
https://github.com/online-ml/river,river,"River is a Python library for online (incremental) machine learning on streaming data. It provides stream-friendly model training and evaluation utilities plus a wide set of algorithms (e.g., linear models, trees, anomaly/drift detection, time series, bandits) designed to learn one sample at a time.",5700,online-learning|streaming-machine-learning|incremental-learning|data-stream-mining|python|concept-drift|time-series|anomaly-detection,9,"This repository is purpose-built for machine learning on streaming/online data, offering incremental learning APIs, progressive validation, metrics, preprocessing, and many online algorithms (including drift detection, anomaly detection, and time-series forecasting). It is directly applicable to ML/data workflows where models must update continuously without retraining from scratch, and it integrates naturally into Python-based data science stacks. Community adoption appears strong for a specialized library (thousands of GitHub stars and an active ecosystem/documentation). It is not a general-purpose dominant framework like PyTorch/TensorFlow, so it earns a 9 rather than a 10.",success
https://github.com/uber/causalml,causalml,CausalML is a Python library for uplift modeling and causal inference using machine learning methods. It provides a unified interface to estimate heterogeneous treatment effects such as CATE/ITE from experimental or observational data for use cases like campaign targeting and personalized interventions.,5700,causal-inference|uplift-modeling|treatment-effect-estimation|machine-learning|python|counterfactual-analysis|experimentation-ab-testing,9,"This repository is purpose-built for causal inference and uplift modeling, offering implementations and a standard interface for estimating CATE/ITE from observational or experimental data. It is directly applicable to common ML/data science workflows (e.g., A/B testing analysis, marketing uplift, personalization) and integrates naturally with Python-based ML stacks. Its substantial community adoption (thousands of GitHub stars) and extensive documentation/examples make it both practically useful and educational. It scores a 9 (highly relevant) because it is a specialized ML library for causal effect estimation, though it is not as universally foundational as general-purpose frameworks like PyTorch or scikit-learn.",success
https://github.com/Layout-Parser/layout-parser,layout-parser,"LayoutParser is a unified Python toolkit for deep learning–based document image analysis, providing APIs and pretrained model access for document layout detection, layout data structures, OCR integration, visualization utilities, and loading/exporting layout annotations across formats.",5600,document-ai|computer-vision|deep-learning|document-layout-analysis|ocr|object-detection|python,9,"This repository is built specifically for ML-driven document image analysis, centering on deep-learning layout detection (including model backends like Detectron2) and practical tooling to run inference, manage layout representations, and visualize results. It directly supports common data/ML workflows such as preprocessing scanned documents, extracting structured information (e.g., tables/regions + OCR), and building end-to-end document understanding pipelines. With thousands of GitHub stars and an associated academic paper, it shows strong community adoption and clear educational value for applied document AI. It scores a 9 because it is highly relevant and immediately usable for ML/data work, though it is more of a domain toolkit than a general-purpose ML framework.",success
https://github.com/NVIDIA/DALI,DALI,NVIDIA DALI (Data Loading Library) is a GPU-accelerated data loading and preprocessing library with an execution engine designed to speed up deep learning training and inference by moving input pipelines (decode/augment/transform) onto the GPU and overlapping processing with model execution.,5600,machine learning|data loading|data preprocessing|gpu acceleration|computer vision|deep learning|PyTorch|TensorFlow,9,"This repository provides a high-performance, GPU-accelerated input pipeline library (loading, decoding, augmentation, and transformations for image/video/audio) specifically aimed at removing CPU bottlenecks in deep learning training and inference. It integrates directly with major ML frameworks (notably PyTorch and TensorFlow, and also others like JAX/PaddlePaddle) and is intended to be used as a drop-in replacement for typical data loaders/iterators in production and research workflows. Its strong alignment with core ML data pipeline needs and notable community adoption (5.6k GitHub stars) justify a 9/10 rather than a 10/10 (it’s a specialized pipeline component rather than an end-to-end general ML framework).",success
https://github.com/facebookresearch/mmf,mmf,"MMF is a modular PyTorch-based framework from Facebook AI Research for vision-and-language multimodal research. It provides reference implementations and training tooling for tasks such as VQA, image captioning, multimodal dialog, and related benchmark/challenge workflows.",5600,multimodal|vision-language|pytorch|deep-learning|visual-question-answering|image-captioning|nlp|computer-vision,9,"This repository is a dedicated ML research framework for building, training, and evaluating vision-language multimodal models, with reference implementations of state-of-the-art approaches and support for common tasks (e.g., VQA, captioning, multimodal dialog). It is directly applicable to ML workflows because it provides an end-to-end codebase (datasets, models, training loops, metrics, and distributed training support) intended for researchers and ML engineers. The project also shows meaningful adoption signals (thousands of GitHub stars, many contributors) and strong educational value as a reference framework for multimodal modeling. It is scored 9 (not 10) because it is a specialized multimodal research framework rather than a ubiquitous general-purpose ML library on the scale of PyTorch itself.",success
https://github.com/keras-rl/keras-rl,keras-rl,"keras-rl is a Python library that implements several deep reinforcement learning (DRL) algorithms and integrates them with Keras, with out-of-the-box compatibility for training/evaluating agents in OpenAI Gym environments.",5600,reinforcement learning|deep learning|keras|openai gym|python|dqn|policy gradients,9,"This repository provides a practical DRL toolkit (e.g., DQN, Double DQN, DDPG, A3C, PPO, CEM) designed to plug directly into Keras models and workflows, and it supports OpenAI Gym environments for experimentation and benchmarking. It is highly applicable for ML engineers and researchers working on reinforcement learning, offering both implementation reference value and ready-to-run examples. Its strong community adoption (thousands of GitHub stars) and clear educational utility for learning canonical RL algorithms justify a high score, though it is not a general-purpose data science library (e.g., for tabular data pipelines) which keeps it below a perfect 10.",success
https://github.com/lucidrains/DALLE-pytorch,DALLE-pytorch,"A PyTorch implementation/replication of OpenAI's original DALL·E text-to-image Transformer, including code to train a discrete VAE for image tokenization and to train/generate images with a DALL·E-style autoregressive transformer (with optional CLIP-based ranking of generations).",5600,machine-learning|deep-learning|pytorch|text-to-image|generative-models|transformer|computer-vision|diffusion-and-vae,9,"This repository implements a full text-to-image generation pipeline centered on the original DALL·E architecture (discrete VAE/VQ-style image tokenization plus an autoregressive transformer), making it directly applicable to ML research, prototyping, and educational use. It is tightly aligned with ML workflows (model training, sampling, and experiment scripts) and is built on PyTorch, which is widely used in the ML community. The project also shows notable community adoption (thousands of stars and many forks), indicating broad interest and reuse. It is scored a 9 (not 10) because it is a specialized model implementation/replication rather than a general-purpose, industry-standard core ML framework.",success
https://github.com/mlpack/mlpack,mlpack,"mlpack is a fast, flexible, header-only C++ machine learning library that implements a broad set of ML algorithms and utilities. It also provides command-line tools and language bindings (including Python, Julia, R, and Go) for easier integration and prototyping.",5600,machine learning|C++|header-only library|classical machine learning|deep learning|Python bindings|command-line tools,9,"This repository is a full-featured machine learning library focused on implementing many ML methods efficiently in C++ (with a consistent API and production-oriented performance). It is directly applicable to ML/data workflows because it provides ready-to-use algorithms, CLI utilities, and multiple language bindings (notably Python) that enable model training, experimentation, and deployment. With thousands of GitHub stars and an established project ecosystem, it shows strong community adoption and practical utility. It scores a 9 (highly relevant) because it is a general-purpose ML toolkit/framework, though it is not as ubiquitous as top-tier industry defaults like PyTorch/TensorFlow that would justify a 10.",success
https://github.com/biolab/orange3,orange3,"Orange is an open-source, component-based data mining and visualization toolkit that lets users build interactive, workflow-based data analysis pipelines (often without programming). It provides a GUI (“Orange Canvas”) plus a Python library and supports add-ons for domain-specific analytics.",5500,data science|machine learning|data mining|data visualization|workflow automation|python|gui,9,"This repository is the core Orange Data Mining framework and application, providing interactive, workflow-based data analysis and visualization with a broad set of data mining and ML widgets and a Python backend. It is directly usable in ML/data workflows for tasks like data preprocessing, model training/evaluation, and exploratory analysis, especially for users who prefer visual pipelines and rapid prototyping. Its sizeable community adoption (e.g., ~5.5k GitHub stars and widespread distribution via conda/pip) and extensibility through add-ons make it highly valuable for practical data science and education. It scores a 9 (not 10) because it is not a foundational low-level ML training framework like PyTorch/TensorFlow, but rather an end-user workflow/visual analytics platform built on top of common ML tooling.",success
https://github.com/mosaicml/composer,composer,"Composer is an open-source deep learning training library built on PyTorch that provides a high-performance Trainer, distributed training utilities (e.g., DDP/FSDP), and a system for composing training “algorithms” and callbacks to speed up and scale model training on multi-GPU/multi-node clusters.",5500,machine learning|deep learning|PyTorch|distributed training|FSDP|training framework|MLOps,9,"This repository is a dedicated ML training framework (not a general-purpose utility), focused on scaling and accelerating neural network training with a PyTorch-based Trainer abstraction, distributed training support, and modular speedup/recipe mechanisms. It is directly applicable to ML engineer and data scientist workflows for training modern models (e.g., LLMs, diffusion models, CNNs) and includes practical infrastructure like checkpointing and dataset streaming integrations. Community adoption is solid (5.5k GitHub stars as of the repository page) and it has strong educational value because it demonstrates production-grade training loop design, extensibility via callbacks, and distributed training patterns.",success
https://github.com/DeepLabCut/DeepLabCut,DeepLabCut,"DeepLabCut is the official toolbox for state-of-the-art markerless 2D/3D pose estimation (keypoint tracking) of user-defined features in animals and humans using deep learning. It provides an end-to-end workflow (including GUIs and APIs) for labeling, training, evaluating, and running inference on videos, with modern PyTorch-based support and optional TensorFlow components.",5400,computer-vision|pose-estimation|deep-learning|pytorch|behavior-analysis|keypoint-detection|video-analysis,9,"This repository is a purpose-built ML application for training and deploying deep neural networks to perform markerless pose estimation (keypoint tracking) from video, including tooling for data labeling and model training/inference. It is directly applicable to common ML/data workflows in neuroscience, biology, and behavioral research, and integrates with mainstream ML frameworks (notably PyTorch) while also offering GUIs and project management utilities. The project shows strong community adoption (thousands of GitHub stars and a large ecosystem of related repos/tools), and it has substantial educational/practical value for applied computer vision practitioners. It is scored 9/10 because it is highly relevant and widely used in applied ML, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/Fanghua-Yu/SUPIR,SUPIR,"SUPIR is the official CVPR 2024 codebase for photo-realistic image restoration “in the wild,” focused on recovering high-quality images from degraded inputs and optionally performing upscaling. It provides pretrained checkpoints and scripts for batch inference as well as interactive Gradio demos, and integrates external models (e.g., SDXL and LLaVA components) for its pipeline.",5400,computer vision|image restoration|super-resolution|diffusion models|PyTorch|Gradio demo|multimodal (LLaVA),9,"This repository implements a state-of-the-art research system for practical, photo-realistic image restoration and upscaling (CVPR 2024), including inference scripts and interactive demos, plus links to pretrained checkpoints. It is directly usable in ML/CV workflows for restoration benchmarking, applied enhancement pipelines, and as a strong reference implementation for diffusion-based restoration systems. Community adoption appears strong for a research code release (thousands of GitHub stars), and it integrates with widely used ML tooling (notably PyTorch and Gradio) and external model checkpoints, which increases practical utility. It is not a general-purpose ML framework (so not a 10), but it is highly valuable for ML practitioners working on low-level vision and generative restoration.",success
https://github.com/google-deepmind/graph_nets,graph_nets,"DeepMind's Graph Nets library for building graph networks (a type of graph neural network) in TensorFlow and Sonnet. It provides modules and utilities plus demo notebooks for learning and training GNNs on graph-structured tasks (e.g., shortest-path, sorting, physics prediction).",5400,machine learning|graph neural networks|graph networks|tensorflow|sonnet|deep learning|python,9,"This repository is a dedicated library for constructing and training graph neural networks/graph networks, providing reusable TensorFlow + Sonnet components and end-to-end demo notebooks. It is directly applicable to ML workflows involving graph-structured data and is educationally strong due to its tutorials and examples. Community adoption appears solid (thousands of GitHub stars), though it is more specialized than general-purpose ML frameworks, so it falls just short of a 10.",success
https://github.com/charlesq34/pointnet,pointnet,"Official TensorFlow implementation and training code for PointNet, a deep learning architecture that directly consumes 3D point clouds (unordered point sets) for tasks like object classification, part segmentation, and semantic scene parsing. The repo includes scripts to train/evaluate models and download/prep common datasets (e.g., ModelNet40 and ShapeNetPart).",5300,machine learning|deep learning|3D point clouds|computer vision|classification|segmentation|TensorFlow,9,"This repository provides the reference implementation and training pipelines for PointNet, a foundational neural network for learning directly from 3D point sets for classification and segmentation. It is directly applicable to ML workflows involving point-cloud data (e.g., 3D shape recognition and segmentation) and includes dataset download/preprocessing plus training/evaluation scripts, making it immediately usable for experimentation and research. It is widely cited and historically influential in 3D deep learning, though it targets older TensorFlow/Python environments, which can add friction for modern production use.",success
https://github.com/hzwer/ECCV2022-RIFE,ECCV2022-RIFE,"PyTorch implementation of the ECCV 2022 paper “Real-Time Intermediate Flow Estimation (RIFE)” for video frame interpolation, supporting arbitrary-timestep interpolation between two images and CLI tools for image/video inference and training.",5300,computer vision|video frame interpolation|optical flow|deep learning|pytorch|video processing,9,"This repository provides a complete deep-learning system for video frame interpolation (RIFE), including pretrained models, inference scripts for images/videos, and training code, making it directly useful for ML engineers working on video enhancement and motion estimation tasks. It is tightly aligned with ML workflows (PyTorch-based, model checkpoints, training/inference entrypoints) and has strong community adoption (thousands of GitHub stars). The score is not a 10 because it is a specialized application model (VFI) rather than a general-purpose ML framework used across many domains.",success
https://github.com/HIT-SCIR/ltp,ltp,"LTP (Language Technology Platform) is an open-source Chinese NLP toolkit providing end-to-end pipelines for core tasks such as word segmentation, POS tagging, NER, dependency parsing, semantic dependency parsing, and semantic role labeling. It includes both deep-learning (PyTorch-based) models and a faster legacy (Rust-based) inference path for some tasks.",5200,natural language processing|chinese nlp|tokenization|named entity recognition|dependency parsing|semantic role labeling|pytorch|rust,9,"This repository is a dedicated Chinese NLP platform offering pretrained models and pipeline APIs for multiple fundamental NLP tasks (segmentation, POS, NER, dependency parsing, semantic parsing, and SRL). It is directly useful in ML/data workflows for text preprocessing, feature extraction, and building/benchmarking Chinese-language NLP systems, with both PyTorch-based deep models and a Rust implementation for faster inference in some tasks. Its substantial community adoption (thousands of GitHub stars) and the breadth of supported tasks make it highly valuable for data science and machine learning, though it is more application-focused than a general-purpose ML framework.",success
https://github.com/LaurentMazare/tch-rs,tch-rs,"Rust bindings for the C++ PyTorch API (libtorch), providing thin wrappers that stay close to the upstream C++ interface. It includes build tooling and examples for linking against system libtorch, a Python PyTorch install, or downloading prebuilt libtorch binaries.",5200,rust|pytorch|libtorch|machine-learning|deep-learning|ffi-bindings|tensor-computation|gpu-cuda,9,"This repository provides the Rust crate `tch`, which exposes PyTorch (libtorch) tensor operations, neural network building blocks, and model execution/training from Rust via bindings to the C++ API. It is directly applicable to ML workflows because it enables implementing and running PyTorch-style deep learning code (including optional CUDA via libtorch builds) in Rust. The project is widely used within the Rust ML ecosystem (evidenced by thousands of GitHub stars) and offers practical examples and docs for setup and usage, making it both usable and educational. It scores 9 (not 10) because it is a language binding rather than a foundational new ML framework and its adoption is smaller than PyTorch itself, though it remains highly valuable for Rust-based ML development.",success
https://github.com/amdegroot/ssd.pytorch,ssd.pytorch,"A PyTorch implementation of the Single Shot MultiBox Detector (SSD) object detection model, including training, evaluation, and demo code. It provides dataset setup scripts/loaders (e.g., VOC and COCO), pretrained weights, and utilities for running SSD300-style detectors.",5200,computer-vision|object-detection|pytorch|deep-learning|ssd|training|evaluation,9,"This repository implements an end-to-end object detection pipeline for the SSD model in PyTorch, including code to train, evaluate, and run demos with pretrained weights. It directly supports common ML workflows (dataset preparation for VOC/COCO, model training loops, and evaluation metrics), making it immediately usable for CV practitioners and learners. Its substantial community adoption (thousands of GitHub stars/forks) and educational value as a reference implementation justify a high score, though it is more of a specific model implementation than a broadly general-purpose ML framework.",success
https://github.com/microsoft/SynapseML,SynapseML,"SynapseML (formerly MMLSpark) is an open-source library for building massively scalable machine learning pipelines on Apache Spark. It provides composable distributed APIs (SparkML-compatible) for tasks like text analytics, computer vision, anomaly detection, deep learning, and integrations such as LightGBM/ONNX and Azure AI services across Python, R, Scala, Java, and .NET.",5200,machine learning|data engineering|apache spark|spark-ml|distributed computing|pyspark|lightgbm|computer vision,9,"SynapseML’s primary purpose is to enable large-scale, distributed machine learning and intelligent data pipelines directly on Apache Spark, extending SparkML with additional algorithms and integrations (e.g., LightGBM, deep learning, and Azure AI services). It is directly applicable to common data science and ML engineering workflows where training or scoring must be done at scale in Spark-based environments (Databricks, Synapse/Fabric, etc.). The repository shows strong community adoption for an enterprise Spark ML library (thousands of stars) and offers significant integration value by staying compatible with SparkML APIs and supporting multiple languages. It is just below a “10” because it’s not a general-purpose foundational ML framework like PyTorch/TensorFlow, but it is highly impactful within the distributed Spark ecosystem.",success
https://github.com/salesforce/CodeGen,CodeGen,"Official Salesforce AI Research release of the CodeGen family of open-source large language models for program synthesis (CodeGen1, CodeGen2, and CodeGen2.5). The repo provides model information and usage examples (e.g., via Hugging Face Transformers) for code generation and infill-style completion.",5200,large language models|code generation|program synthesis|generative AI|NLP|transformers|PyTorch,9,"This repository centers on CodeGen, an open-source family of LLMs trained for program synthesis/code generation, with guidance for using the models (notably through the Hugging Face Transformers ecosystem). It is directly applicable to ML workflows for inference and experimentation with code LLMs, and it also references the associated research publications describing training lessons and capabilities. While it is not a general-purpose data-science library (and full training infrastructure is pointed to a separate repo), its primary purpose is strongly ML-focused and it has notable community adoption/visibility, justifying a high score.",success
https://github.com/Eventual-Inc/Daft,Daft,"Daft is a high-performance, Python-native (Rust-powered) data engine/dataframe system designed for AI and multimodal workloads, enabling unified processing of structured data alongside images, audio, video, and embeddings. It also includes built-in AI operations such as running LLM prompts and generating embeddings, and can scale from local execution to distributed clusters (e.g., via Ray/Kubernetes).",5100,data-engineering|dataframes|multimodal-data|machine-learning|llm|embeddings|ray|rust,9,"Daft’s primary purpose is to provide a fast data engine/dataframe framework for AI-centric and multimodal data processing, explicitly supporting images/audio/video/embeddings together with tabular data and offering built-in AI operations (LLM prompting, embedding generation, classification) at scale. This maps directly onto common ML/data workflows like dataset preparation, feature/embedding creation, and large-scale inference/evaluation pipelines, with straightforward Python usage and distributed execution options (e.g., Ray/Kubernetes). The repository also shows meaningful adoption signals (thousands of GitHub stars) and strong integration potential with modern AI tooling, making it highly valuable for data science/ML engineering, though it is not itself a model-training framework (hence not a 10).",success
https://github.com/Giskard-AI/giskard-oss,giskard-oss,"Giskard is an open-source Python evaluation and testing framework for AI systems, focused on detecting performance, bias, and security issues in LLM applications (including RAG/agents) as well as traditional ML models. It includes automated scanning for issues like hallucinations and prompt injection and provides tooling to generate evaluation datasets and score RAG components.",5100,machine learning|LLM evaluation|RAG|MLOps|AI safety|model testing|python,9,"This repository is primarily an ML evaluation/testing toolkit designed to find quality, bias, and security problems in AI applications, especially LLM agents and RAG systems. It directly supports common ML workflows by scanning systems for issues (e.g., hallucinations, harmful content, prompt injection) and by generating evaluation datasets and component-level scores for RAG pipelines. It is broadly applicable for ML engineers and data scientists deploying LLM-powered apps and also supports more traditional ML use cases, making it highly relevant though not a core training framework. Community adoption appears strong for its niche (thousands of GitHub stars), supporting a high score.",success
https://github.com/apple/coremltools,coremltools,"Core ML Tools (coremltools) is Apple’s Python toolkit for converting trained models from popular ML frameworks (e.g., PyTorch, TensorFlow, scikit-learn, XGBoost) into the Core ML format. It also provides utilities to read, write, optimize, and validate Core ML models (including running predictions for verification on macOS).",5100,machine-learning|core-ml|model-conversion|pytorch|tensorflow|python|on-device-ml,9,"This repository’s primary purpose is ML model conversion and tooling around the Core ML format, enabling deployment of trained models to Apple devices. It is directly applicable to common ML engineering workflows by providing converters and model optimization/validation utilities, and it integrates with widely used training frameworks like PyTorch and TensorFlow. Its substantial adoption on GitHub (thousands of stars and many dependents) indicates strong community usage for production deployment. It’s not a training framework itself, so it falls short of a 10, but it is a highly impactful, widely used ML deployment tool—hence a 9.",success
https://github.com/ashleve/lightning-hydra-template,lightning-hydra-template,"A project template for machine learning experimentation built around PyTorch Lightning and Hydra, providing a structured codebase with composable configs, experiment tracking/logging, testing, CI, and utilities for rapid iteration on deep learning projects.",5100,machine learning|deep learning|pytorch|pytorch-lightning|hydra|mlops|experiment tracking|project template,9,"This repository is a ready-to-use template specifically designed for ML/deep learning experimentation using PyTorch Lightning for training loops and Hydra for configuration management and experiment composition. It directly supports common ML workflows (training/evaluation entrypoints, experiment configs, logging/tracking integrations, hyperparameter search via Hydra plugins, and reproducible run folders), which makes it immediately applicable to day-to-day ML engineering. While it is not a core ML framework itself, it is a highly practical scaffolding and MLOps-oriented starter that many practitioners can adopt to standardize experiments quickly, warranting a high score.",success
https://github.com/awslabs/gluonts,gluonts,"GluonTS is a Python library for probabilistic time series modeling and forecasting, with a strong focus on deep learning-based models and tooling for datasets, training, and evaluation. It supports both PyTorch- and MXNet-based model implementations and provides end-to-end components for building forecasting pipelines.",5100,time series forecasting|probabilistic modeling|machine learning|deep learning|PyTorch|MXNet|Python,9,"This repository provides a comprehensive framework for probabilistic time series forecasting, including model implementations (notably deep learning approaches), dataset utilities, and training/evaluation workflows. It is directly applicable to common ML/data science tasks involving forecasting, and integrates with major ML frameworks (PyTorch and MXNet), making it easy to incorporate into real modeling pipelines. Its substantial community adoption (thousands of GitHub stars) and extensive examples/documentation make it both practical for production experimentation and valuable for learning modern probabilistic forecasting methods.",success
https://github.com/lyst/lightfm,lightfm,"LightFM is a Python library implementing hybrid recommendation algorithms for implicit and explicit feedback, supporting ranking losses such as BPR and WARP. It can incorporate user and item metadata (feature-based representations) to improve recommendations and handle cold-start via user/item features.",5100,recommender systems|machine learning|matrix factorization|learning to rank|implicit feedback|python,9,"This repository provides a production-usable Python implementation of hybrid matrix-factorization recommender models, including common ranking losses (e.g., BPR/WARP) and tooling for training/evaluation. It is directly applicable to ML workflows for recommendation systems, especially for implicit-feedback problems and cold-start scenarios where metadata features matter. With strong community adoption (thousands of GitHub stars) and clear documentation/examples, it is highly valuable for data scientists and ML engineers building recommenders, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/mdbloice/Augmentor,Augmentor,"Augmentor is a Python image augmentation library for machine learning that lets you build stochastic augmentation pipelines (e.g., rotations, zooms, elastic distortions, perspective transforms) to generate expanded training datasets. It supports augmenting ground-truth/mask images in parallel and includes generator/transform integrations for workflows like Keras and PyTorch.",5100,computer-vision|image-augmentation|machine-learning|deep-learning|python|data-augmentation|keras|pytorch,9,"This repository provides a dedicated image data augmentation toolkit aimed at expanding computer-vision datasets for machine learning (especially deep learning) via configurable, probabilistic augmentation pipelines. It is directly applicable to common ML workflows, including segmentation use cases through parallel ground-truth/mask augmentation, and it offers integration points such as Keras generators and PyTorch transforms. With strong adoption on GitHub (about 5.1k stars), it is a highly relevant, practical utility for ML practitioners, though it is not itself a full training framework—hence a 9 rather than a 10.",success
https://github.com/rapidsai/cuml,cuml,"cuML is the RAPIDS GPU-accelerated machine learning library, providing implementations of common ML algorithms and primitives with APIs largely compatible with scikit-learn. It supports single-GPU workflows as well as multi-GPU/multi-node execution for a growing set of algorithms via Dask.",5100,machine learning|gpu acceleration|rapids|cuda|scikit-learn compatible|dask|clustering|dimensionality reduction,9,"This repository provides GPU-accelerated implementations of widely used machine learning algorithms (e.g., clustering and dimensionality reduction) and exposes a Python API that largely mirrors scikit-learn, making it directly usable in many existing ML workflows. It is tightly aligned with data science/ML tasks (tabular ML on GPUs) and also supports distributed multi-GPU operation through Dask, improving its applicability to large-scale data. Community adoption appears strong (about 5.1k GitHub stars) and the project is part of the broader RAPIDS ecosystem, which increases integration potential with common GPU data tooling. It’s not as universally adopted as core general-purpose frameworks (e.g., PyTorch/TensorFlow), but it is a highly relevant, production-oriented ML library for GPU-based analytics, justifying a 9/10.",success
https://github.com/rasbt/mlxtend,mlxtend,"Mlxtend (machine learning extensions) is a Python library providing extension and helper modules for day-to-day data science and machine learning tasks, especially as complements to scikit-learn and the scientific Python stack. It includes utilities for ensemble methods (stacking/voting), feature selection, evaluation and visualization helpers, and frequent pattern mining (e.g., Apriori for association rules).",5100,machine learning|data science|python|scikit-learn|feature selection|model evaluation|visualization|association rule mining,9,"This repository is a dedicated machine-learning utilities library that extends common Python ML/data tools, with practical components like ensemble classifiers, feature selection/extraction, evaluation metrics/tests, plotting helpers, and frequent pattern mining. It maps directly onto typical ML workflows (model building, validation, interpretation, and feature engineering) and is designed to integrate with scikit-learn and the broader scientific Python ecosystem. The GitHub star count (~5.1k) indicates substantial community adoption for a specialized ML utility library, supporting a high score. It is not a full end-to-end training framework like PyTorch/TensorFlow, so it falls just short of a 10.",success
https://github.com/roboflow/rf-detr,rf-detr,"RF-DETR is an Apache-2.0 licensed, real-time transformer-based model architecture for object detection and (preview) instance segmentation, designed to be strong on COCO and to fine-tune well on custom datasets. The repo provides the Python package, pretrained checkpoints, and training/inference utilities for deploying and fine-tuning RF-DETR models.",5100,computer-vision|object-detection|instance-segmentation|transformers|pytorch|model-training|fine-tuning|mlops-inference,9,"This repository’s primary purpose is to provide an end-to-end implementation of RF-DETR, a real-time detection transformer architecture, including pretrained weights, benchmarking claims/results, and a Python package for inference and fine-tuning. It directly supports common ML workflows (training on custom datasets, evaluation, and deployment) and is tightly aligned with computer vision model development in PyTorch. Community adoption appears strong (5.1k GitHub stars as of the repository page), and the repo has solid educational value via documented benchmarks and usage examples. It’s scored a 9 (rather than 10) because it is a specialized CV model library (not a general foundational framework like PyTorch/TensorFlow) even though it is highly applicable for detection/segmentation practitioners.",success
https://github.com/zenml-io/zenml,zenml,"ZenML is an open-source MLOps framework and Python SDK for building production-ready AI/ML workflows as reproducible pipelines (including LLM workflows and agents) that can run on multiple infrastructure backends. It provides code/container management, run tracking (metadata/logs/metrics), and integrations with common ML and cloud tooling.",5100,MLOps|machine-learning-pipelines|LLMOps|workflow-orchestration|experiment-tracking|Python|cloud-integrations|reproducibility,9,"This repository implements ZenML, a dedicated MLOps/LLMOps framework for defining ML/AI workflows as pipelines and operationalizing them across different infrastructure stacks. It directly supports core ML engineering needs like reproducibility (code/version tracking), containerization, artifact/run tracking with logs/metrics/metadata, and broad integration with common ML tooling and cloud services. Its primary audience is ML/AI engineers and teams running production workflows, making it highly applicable to real-world data science and ML operations. It scores a 9 (not 10) because it is an orchestration/operations layer rather than a foundational ML compute library like PyTorch/TensorFlow.",success
https://github.com/AutoGPTQ/AutoGPTQ,AutoGPTQ,"AutoGPTQ is a Python package for weight-only GPTQ quantization of large language models (LLMs), providing user-friendly APIs to quantize and run models efficiently (e.g., 4-bit) with optimized GPU kernels. The repository is archived (read-only) and marked unmaintained, with the maintainers suggesting GPTQModel for ongoing fixes and new model support.",5000,llm|model-quantization|gptq|pytorch|transformers|inference-optimization|cuda,9,"This repository provides an end-to-end toolkit for quantizing and serving LLMs using the GPTQ algorithm, including APIs to quantize, save/push, and load quantized Transformer models with high-performance kernels. It is directly applicable to ML engineering workflows focused on reducing GPU memory and accelerating inference for LLM deployment, and it integrates with common ecosystem tools like Hugging Face Transformers. The score is slightly below 10 because the repo is archived/unmaintained (read-only as of April 11, 2025), which reduces long-term reliability despite strong relevance and adoption.",success
https://github.com/InternLM/xtuner,xtuner,"XTuner (V1) is a next-generation LLM training engine optimized for ultra-large Mixture-of-Experts (MoE) model training, emphasizing dropless training, long-sequence support, and high-throughput efficiency at very large scales. It aims to serve as a flexible training backend that integrates with popular deployment/inference frameworks and supports multimodal pretraining/fine-tuning and RL methods.",5000,machine learning|large language models|Mixture-of-Experts|distributed training|LLM pretraining|fine-tuning|reinforcement learning|PyTorch,9,"This repository’s primary purpose is to provide a high-performance training engine for ultra-large MoE LLMs, including features like dropless MoE training, long-context training optimizations, and scaling to extremely large parameter counts. It is directly applicable to ML engineering workflows for pretraining, supervised fine-tuning, and RL (e.g., GRPO), and it targets integration with common inference/deployment stacks. The strong relevance to modern large-scale model training plus substantial community adoption signals (≈5k GitHub stars) justify a high score, though it is more specialized (MoE/ultra-scale training) than broadly general-purpose ML libraries, keeping it below a 10.",success
https://github.com/XiaoMi/mace,mace,"MACE (Mobile AI Compute Engine) is an open-source deep learning inference framework optimized for mobile heterogeneous computing (CPU/GPU/DSP) across platforms like Android, iOS, Linux, and Windows. It provides tooling to convert and deploy models (e.g., from TensorFlow/Caffe/ONNX) with an emphasis on performance, power efficiency, and small footprint.",5000,deep learning|inference|edge ai|mobile|model deployment|quantization|C++,9,"This repository is primarily a deep learning inference and deployment framework for running trained neural-network models efficiently on mobile/edge devices, including heterogeneous accelerators (e.g., CPU/GPU/DSP) and support for model conversion workflows. It is directly useful to ML engineers for productionizing models on-device (including optimizations like quantization and platform-specific acceleration paths). While it is not a model-training or data-processing library, its core purpose is ML inference at the edge and it has substantial community adoption for that niche, justifying a high score.",success
https://github.com/obss/sahi,sahi,"SAHI (Slicing Aided Hyper Inference) is a lightweight computer vision library that performs sliced/tiled inference to improve object detection and instance segmentation on large images (especially for small objects). It is framework-agnostic and includes CLI utilities, visualization integrations, and COCO slicing/evaluation/error-analysis tooling.",5000,computer vision|object detection|instance segmentation|sliced inference|COCO|PyTorch|MLOps tooling,9,"This repository provides practical tooling for large-scale vision inference via slicing/tiled prediction, plus dataset utilities (e.g., COCO slicing/conversion) and evaluation/error analysis workflows, which directly support common ML engineering needs in detection/segmentation projects. It integrates with popular ML ecosystems (e.g., Ultralytics/YOLO, MMDetection, Hugging Face, TorchVision) and offers both Python APIs and a CLI, making it easy to drop into real pipelines. Community adoption appears strong (thousands of GitHub stars and extensive citations referenced in the README), which increases its practical value for ML practitioners. It is not a full training framework, but it is highly relevant for production inference, dataset preparation, and model analysis in computer vision, justifying a 9/10.",success
https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese,Huatuo-Llama-Med-Chinese,"BenTsao (originally HuaTuo/华驼) provides Chinese medical instruction-tuned large language models and related training/inference scripts, primarily using LoRA fine-tuning on base LLMs (e.g., LLaMA, Bloom, Alpaca-Chinese, and others). The repo includes medical instruction-tuning data construction notes (knowledge graph + medical literature, with ChatGPT API assistance), model weight download links, and benchmarking/inference utilities.",4900,large-language-models|LLM-fine-tuning|medical-NLP|Chinese-NLP|LoRA|PyTorch|instruction-tuning|healthcare-AI,9,"This repository is directly focused on ML/LLM workflows: it provides medical-domain instruction-tuned Chinese LLM releases plus code for LoRA fine-tuning and inference, along with templates and example datasets for training and evaluation. It is highly applicable for data scientists/ML engineers working on domain adaptation, instruction-tuning, and medical QA in Chinese, and it includes practical assets (scripts, prompts/templates, and dataset format examples) to reproduce or extend the work. Community adoption appears strong for a research/model-release repo (about 4.9k GitHub stars at time of lookup), but it is not a general-purpose foundational framework on the scale of core libraries like PyTorch, so it falls short of a 10.",success
https://github.com/microsoft/muzic,muzic,"Muzic is a Microsoft research codebase for AI music understanding and generation, providing implementations of multiple deep-learning systems (e.g., MusicBERT, CLaMP, SongMASS, Museformer, GETMusic, MuseCoco, and MusicAgent) for symbolic music modeling, lyric/melody tasks, and related music AI workflows.",4900,machine learning|deep learning|music information retrieval|music generation|symbolic music|transformers|diffusion models|LLM agents,9,"This repository is primarily an ML research suite focused on music understanding and music generation, bundling multiple published models and methods (e.g., symbolic music pretraining, cross-modal contrastive pretraining, and generative systems). It directly supports ML workflows by providing reference implementations, training/inference code, and dependencies for reproducing results across several music AI tasks, which is highly applicable for ML engineers and researchers working in audio/music. While it is not a general-purpose framework with broad industry adoption on the level of PyTorch/TensorFlow, it has strong educational and research value and meaningful community usage for music AI, justifying a high score.",success
https://github.com/minimaxir/textgenrnn,textgenrnn,"A Python 3 library built on Keras/TensorFlow for quickly training and using character-level or word-level RNN text generation models (char-rnn style), including support for pretrained weights, configurable architectures, and interactive generation.",4900,machine learning|natural language processing|text generation|deep learning|tensorflow|keras|python,9,"This repository provides an end-to-end tool for training and sampling neural text generation models (character-level and word-level) with minimal code, including pretrained weights, dataset examples, and architecture/configuration options. It is directly applicable to ML/NLP workflows for prototyping generative text models and learning sequence modeling concepts, and integrates tightly with common ML tooling (Python, Keras, TensorFlow). Community adoption appears strong (about 4.9k GitHub stars), indicating broad use/recognition among practitioners and learners. It scores slightly below a 10 because it is a specialized text-generation utility rather than a general-purpose, industry-standard core ML framework.",success
https://github.com/open-mmlab/mmaction2,mmaction2,"MMAction2 is OpenMMLab’s PyTorch-based toolbox and benchmark suite for video understanding. It provides modular components, training/inference tools, and a model zoo covering tasks such as action recognition, temporal/action localization, spatio-temporal action detection, skeleton-based action analysis, and video retrieval.",4900,machine learning|deep learning|computer vision|video understanding|action recognition|PyTorch|OpenMMLab,9,"This repository is a dedicated deep learning framework for video understanding, offering end-to-end pipelines (configs, datasets, training/evaluation scripts, demos) and implementations of many state-of-the-art models for multiple video-related tasks. It is directly applicable to ML workflows for building, training, fine-tuning, and benchmarking video models, and it integrates into the broader OpenMMLab ecosystem (e.g., MMCV/MMEngine). Its strong community adoption (thousands of GitHub stars) and extensive documentation/model zoo make it highly valuable for ML engineers and researchers, though it is more specialized than general-purpose ML libraries—hence a 9 rather than 10.",success
https://github.com/shibing624/text2vec,text2vec,"text2vec is a Python toolkit for converting text (words/sentences/paragraphs) into vector embeddings and computing semantic similarity. It provides multiple text representation approaches and ready-to-use models including Word2Vec-style averaging, RankBM25, Sentence-BERT (SBERT), and CoSENT, with CLI support and pretrained models.",4900,natural language processing|text embeddings|sentence transformers|semantic similarity|information retrieval|pytorch|python,9,"This repository is primarily an NLP/ML library focused on generating text and sentence embeddings and performing semantic similarity/matching, providing implementations of methods like SBERT and CoSENT along with practical tooling (including a CLI) for batch vectorization. It is directly applicable in ML/data workflows such as retrieval, clustering, deduplication, and semantic search, and it integrates naturally with common ML tooling (Python/PyTorch and pretrained model ecosystems). The project shows meaningful community adoption (thousands of GitHub stars) and strong educational value via documented features and examples, so it rates as highly relevant to ML/data use cases.",success
https://github.com/MegEngine/MegEngine,MegEngine,"MegEngine is a fast, scalable deep learning framework with automatic differentiation, designed to unify training and inference and enable efficient deployment across platforms (e.g., x86/Arm/CUDA/RoCM). It includes optimization features such as quantization, dynamic shape handling, and memory/planning optimizations for efficient inference.",4800,deep learning|machine learning framework|autograd|model training|model inference|quantization|GPU acceleration|C++,9,"This repository is the core implementation of MegEngine, an end-to-end deep learning framework (training + inference) with automatic differentiation and deployment-focused optimizations. It is directly applicable to ML workflows for building, training, optimizing (e.g., quantization), and deploying neural network models across multiple hardware backends. While it is not as universally adopted as PyTorch/TensorFlow, it is clearly a primary-purpose ML framework with substantial practical and educational value for ML engineers, justifying a high score.",success
https://github.com/argilla-io/argilla,argilla,"Argilla is an open-source collaboration platform (server + UI + SDK) for AI engineers and domain experts to build, curate, and review high-quality datasets via human/AI feedback workflows. It supports labeling/feedback for NLP, LLM, and multimodal use cases and is commonly used to prepare datasets for training, fine-tuning, and evaluation.",4800,data-annotation|data-curation|human-in-the-loop|LLM|NLP|MLOps|dataset-management|python,9,"This repository provides a full data curation/annotation system (UI + backend + Python SDK) aimed at collecting and managing human (and assisted AI) feedback to produce high-quality ML datasets. It is directly applicable to ML/LLM workflows such as labeling, preference data collection, RAG evaluation, and iterative dataset refinement, and it integrates well with common ecosystem tools (e.g., Hugging Face-based workflows). The GitHub repository indicates substantial adoption (thousands of stars) and a mature codebase, making it highly valuable for ML/data teams, though it notes that new feature development is not expected going forward (maintenance/patches).",success
https://github.com/h2oai/h2o-llmstudio,h2o-llmstudio,"H2O LLM Studio is an open-source framework with a no-code GUI (and CLI) for fine-tuning state-of-the-art large language models. It supports modern tuning techniques like LoRA and low-memory (e.g., 8-bit) training, experiment tracking integrations, evaluation, and model export to the Hugging Face Hub.",4800,large-language-models|fine-tuning|NLP|MLOps|LoRA|DeepSpeed|HuggingFace|no-code,9,"This repository provides a purpose-built platform (GUI + CLI) for training and fine-tuning LLMs, including practical features like hyperparameter control, evaluation/metrics, and experiment tracking integrations. It maps directly onto common ML workflows (dataset preparation, training, comparison, and export/sharing via Hugging Face), making it immediately usable by ML engineers and data scientists working on LLM adaptation. The repo shows strong community adoption (thousands of GitHub stars) and includes tooling aimed at real-world LLM training (e.g., LoRA, low-memory training, and distributed/sharded training support), justifying a high relevance score.",success
https://github.com/idealo/image-super-resolution,image-super-resolution,"Image Super-Resolution (ISR) is a Python/Keras library for upscaling and enhancing low-resolution images using Residual Dense Networks and adversarial (GAN-based) training. It includes pre-trained weights plus tooling (scripts, notebooks, Docker) to train and run super-resolution models.",4800,machine learning|computer vision|image super-resolution|deep learning|GAN|Keras|TensorFlow,9,"This repository is purpose-built for an ML computer-vision task: single-image super-resolution, providing Keras implementations of RDN/RRDN-style models, perceptual loss via VGG features, and an adversarial discriminator for GAN training. It is directly usable in ML workflows (training and inference) and includes practical assets like pre-trained weights, notebooks, and Docker/AWS-oriented scripts to run experiments. Community adoption appears strong (thousands of GitHub stars), and the codebase is educational for learning super-resolution architectures and GAN/perceptual-loss training patterns. The main limitation is that the repo is archived/read-only as of January 7, 2025, which can reduce long-term maintenance and compatibility with newer ML stacks.",success
https://github.com/roboflow/sports,sports,"A Roboflow open-source repository focused on computer vision for sports analytics, providing reusable tools and examples for tasks like object detection, segmentation, keypoint detection, and related sports-specific challenges (e.g., ball/player tracking, jersey number OCR, camera calibration). It also links to sports datasets (notably soccer and basketball) and demos/notebooks to help build and test CV pipelines.",4800,computer vision|deep learning|object detection|keypoint detection|sports analytics|Python|datasets|MLOps tooling,9,"This repository is purpose-built for ML/computer vision in sports, explicitly targeting core CV problems like detection, segmentation, and keypoint detection, with practical tooling, notebooks, and examples that can be reused beyond sports. It directly supports common ML workflows by providing code and pointers to curated datasets (e.g., soccer player/ball detection, pitch/court keypoints, jersey number OCR), making it immediately useful for model training and evaluation. Community adoption appears strong (about 4.8k GitHub stars), indicating meaningful usage and educational value for practitioners exploring sports CV systems.",success
https://github.com/tencentmusic/cube-studio,cube-studio,"Cube Studio is an open-source cloud-native, end-to-end ML/DL/LLM platform (MLOps) that provides browser-based notebook development, drag-and-drop pipeline orchestration, distributed training, hyperparameter search, and model serving. It targets multi-tenant Kubernetes deployments with heterogeneous compute (CPU/GPU/NPU), plus features like GPU/vGPU management, monitoring, data labeling, and LLM fine-tuning/inference integrations.",4800,MLOps|machine-learning-platform|Kubernetes|pipeline-orchestration|distributed-training|LLM-fine-tuning|model-serving|notebooks,9,"This repository is primarily an end-to-end, cloud-native MLOps/AI platform built to run the full ML lifecycle on Kubernetes, including notebook-based development, pipeline orchestration, distributed training, hyperparameter tuning, and inference/service deployment. It is directly applicable to ML engineering workflows because it provides the infrastructure and UI/SDK to operationalize training and serving across heterogeneous compute (including GPU/NPU) and supports common ML frameworks and distributed systems integrations. Community adoption appears meaningful (thousands of stars and hundreds of forks), indicating real-world usage beyond a niche demo. It is not a core ML framework like PyTorch/TensorFlow, but it is highly valuable as an applied platform for building and operating ML/LLM systems at scale, justifying a 9/10.",success
https://github.com/thunlp/OpenPrompt,OpenPrompt,"OpenPrompt is an open-source framework for prompt-learning that provides a standardized, flexible pipeline (templates, verbalizers, and prompt models) to adapt pretrained language models to downstream NLP tasks. It supports loading PLMs from Hugging Face Transformers and includes tutorials, experiments, and reusable components for building and evaluating prompting methods.",4800,natural language processing|prompt learning|large language models|huggingface transformers|pytorch|few-shot learning|text classification,9,"This repository is a purpose-built ML/NLP framework focused on prompt-learning, providing core abstractions (PromptModel, Template, Verbalizer) plus training/inference utilities and examples for adapting pretrained language models to tasks like sentiment analysis and other NLP benchmarks. It integrates directly with common ML tooling (notably Hugging Face Transformers and PyTorch) and is immediately usable in ML workflows for research and prototyping prompting methods. Community adoption appears strong for a research framework (on the order of ~4.8k GitHub stars), indicating meaningful usage and educational value, though it is not as universally foundational as major general-purpose frameworks (e.g., PyTorch itself), which is why it is scored 9 rather than 10.",success
https://github.com/FluxML/Flux.jl,Flux.jl,"Flux.jl is a pure-Julia machine learning and deep learning library that provides lightweight, hackable abstractions for building and training neural networks on CPU/GPU with Julia’s native automatic differentiation and GPU ecosystem.",4700,machine-learning|deep-learning|julia|neural-networks|automatic-differentiation|gpu-computing|data-science,9,"Flux.jl is a full-featured ML/deep-learning framework for Julia, aimed directly at defining models and training them with automatic differentiation and GPU acceleration. It is directly applicable to core ML workflows (model building, training loops, optimizers, layers) and integrates well with the wider Julia data/ML ecosystem. Community adoption is strong within the Julia ML community (multi-thousand GitHub stars and active releases/maintenance), making it a highly valuable library for data science and machine learning. It is scored 9 (not 10) because its adoption is significant but not at the cross-language, industry-dominant level of frameworks like PyTorch or TensorFlow.",success
https://github.com/KaiyangZhou/deep-person-reid,deep-person-reid,"Torchreid is a PyTorch-based library for deep-learning person re-identification, providing end-to-end training and evaluation for image- and video-based ReID with multi-GPU support, dataset preparation utilities, model zoo/pretrained models, and extensible configs/tools for research workflows.",4700,computer vision|person re-identification|PyTorch|deep learning|model training|benchmarking|ONNX/TFLite/OpenVINO export,9,"This repository (Torchreid) is purpose-built for ML research and engineering in computer vision, specifically person re-identification, offering training/evaluation pipelines, dataset handling, and implementations of state-of-the-art ReID models along with pretrained weights. It is directly applicable to ML workflows (experiment configuration, multi-GPU training, cross-dataset evaluation, visualization, and deployment/export tooling) and is broadly adopted in the ReID community (high star count and extensive documentation/model zoo). It earns a 9 (not a 10) because it is a specialized domain library rather than a general-purpose, industry-wide foundational ML framework.",success
https://github.com/deepjavalibrary/djl,djl,"Deep Java Library (DJL) is an open-source, high-level, engine-agnostic deep learning framework for Java that supports model training and inference. It is designed to integrate deep learning into Java applications while allowing users to switch underlying engines and leverage CPU/GPU automatically based on hardware.",4700,deep learning|machine learning|java|model inference|model training|computer vision|NLP|model serving,9,"This repository provides a full deep learning framework for Java, including APIs for training and inference, model zoo integration, and support for multiple underlying deep learning engines (engine-agnostic). It is directly applicable to ML workflows for Java-based teams building, training, deploying, and serving models in production applications. Its strong focus on ML tasks and substantial community adoption (thousands of GitHub stars) justify a high score, though it is less universally dominant than the largest Python-first ecosystems.",success
https://github.com/open-mmlab/mmocr,mmocr,"MMOCR is an open-source PyTorch-based toolbox from OpenMMLab for optical character recognition workflows, covering text detection, text recognition, and related downstream tasks such as key information extraction. It provides modular components, training/evaluation utilities, dataset preparation tools, and a model zoo for state-of-the-art OCR models.",4700,computer vision|optical character recognition|text detection|text recognition|PyTorch|OpenMMLab|deep learning,9,"This repository is a purpose-built machine learning toolbox for OCR, providing end-to-end pipelines for training, evaluating, and deploying models for text detection/recognition and related tasks like key information extraction. It is directly applicable to ML workflows (dataset preparation, model configuration, training scripts, evaluation utilities, and a model zoo) and is built on widely used ML infrastructure (PyTorch and the OpenMMLab ecosystem). Its sizable community adoption (thousands of GitHub stars and hundreds of forks) and extensive documentation/tutorial resources make it highly valuable for practitioners and learners, though it is more domain-specific than general-purpose ML frameworks.",success
https://github.com/pytorch/ignite,ignite,"PyTorch-Ignite is a high-level PyTorch library that simplifies training and evaluation loops using an Engine + Events/Handlers system, and provides ready-to-use metrics and handlers for building flexible training pipelines.",4700,machine learning|deep learning|PyTorch|model training|training loops|metrics|experiment management|MLOps,9,"This repository provides PyTorch-Ignite, a high-level framework for training and evaluating neural networks in PyTorch, centered around an Engine and an event/handler system, plus built-in metrics and pipeline utilities. It is directly applicable to ML engineering workflows because it reduces boilerplate around epoch/iteration loops while remaining flexible for custom training logic, logging, checkpointing, and evaluation. With thousands of GitHub stars and broad use in the PyTorch ecosystem, it shows strong community adoption and practical integration potential. It is slightly below a 10 because it is a training utility/framework layer rather than a foundational ML platform on the scale of core PyTorch itself.",success
https://github.com/sktime/pytorch-forecasting,pytorch-forecasting,"PyTorch Forecasting is a PyTorch-based library for time series forecasting using state-of-the-art deep learning architectures. It provides a high-level API (built on PyTorch Lightning) with dataset utilities, multi-horizon metrics, model interpretability tools, and support for hyperparameter tuning.",4700,time series forecasting|deep learning|PyTorch|PyTorch Lightning|temporal fusion transformer|probabilistic forecasting|Optuna,9,"This repository provides an end-to-end deep learning toolkit specifically for time series forecasting, including data handling abstractions (TimeSeriesDataSet), training utilities, forecasting metrics, and multiple modern architectures (e.g., Temporal Fusion Transformer, N-BEATS/N-HiTS, DeepAR). It is directly applicable to ML workflows for forecasting problems and integrates with common ML tooling such as PyTorch Lightning for scalable training and Optuna for hyperparameter optimization. Community adoption is strong (about 4.7k GitHub stars), and the project has substantial educational value via documentation and tutorials. It is not a foundational framework like PyTorch itself, but it is a highly relevant, production-oriented library for a major ML subdomain, justifying a 9/10.",success
https://github.com/weiaicunzai/pytorch-cifar100,pytorch-cifar100,"A PyTorch training/testing codebase for CIFAR-100 that implements and benchmarks many classic CNN architectures (e.g., ResNet, VGG, DenseNet, Inception variants, MobileNet, ShuffleNet, SENet, WideResNet). It provides scripts for training and evaluation (with optional TensorBoard logging) and includes model implementations under a unified CLI interface.",4700,machine learning|deep learning|computer vision|image classification|PyTorch|CIFAR-100|CNN architectures|training scripts,9,"This repository is purpose-built for machine learning: it trains and evaluates deep CNN image classifiers on the CIFAR-100 dataset using PyTorch, bundling many well-known architectures behind a consistent training/testing workflow. It is directly applicable to ML engineering work (baseline benchmarking, architecture comparison, and reproducible training runs) and has strong educational value for understanding common network implementations and CIFAR-style training setups. While it is not a general-purpose library with broad industry integration like core frameworks, its focused utility and community adoption (thousands of stars) make it highly valuable for ML practitioners and learners.",success
https://github.com/NVlabs/neuralangelo,neuralangelo,"Official implementation of the CVPR 2023 paper ""Neuralangelo: High-Fidelity Neural Surface Reconstruction"" for reconstructing high-quality 3D surfaces from multi-view imagery/video. It provides training and mesh extraction tooling, with setup via Docker or a Conda environment and preprocessing that assumes known camera poses (e.g., COLMAP outputs / Instant-NGP-style transforms).",4600,computer-vision|3d-reconstruction|neural-rendering|nerf|implicit-surfaces|pytorch|cuda,9,"This repository is a research-grade ML system for neural surface reconstruction (3D geometry extraction) from visual data, including training code and high-resolution mesh extraction scripts. It is directly applicable to ML/CV workflows involving NeRFs/implicit representations, multi-view geometry, and 3D asset reconstruction, and includes practical environment setup (Docker/Conda) and data-prep guidance. Community adoption is strong for a specialized research repo (~4.6k stars) and it has high educational value for implementing and adapting neural implicit surface pipelines.",success
https://github.com/Nixtla/statsforecast,statsforecast,"StatsForecast is a high-performance Python library for univariate time-series forecasting using statistical and econometric models (e.g., AutoARIMA, ETS, CES, Theta), optimized with numba for large-scale forecasting. It provides sklearn-like fit/predict APIs, prediction intervals, support for exogenous variables, and integrations to scale with Spark, Dask, and Ray.",4600,time series forecasting|statistical modeling|econometrics|python|numba|machine learning|distributed computing,9,"This repository provides production-oriented time-series forecasting capabilities with widely used statistical/econometric models (AutoARIMA/ETS/CES/Theta, etc.) and a familiar fit/predict workflow, making it directly usable in data science pipelines. It is highly relevant to ML/data workflows because forecasting is a core applied ML/statistics task, and the library emphasizes scalable fitting/prediction (including integrations with Spark, Dask, and Ray) and probabilistic outputs like prediction intervals. Its strong focus on performance and large-scale forecasting workloads, plus substantial community adoption (4.6k GitHub stars), justify a high score, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/PacktPublishing/LLM-Engineers-Handbook,LLM-Engineers-Handbook,"Official code repository for the book ""LLM Engineer's Handbook"", providing an end-to-end LLM engineering project: data collection/generation, training pipelines, RAG implementation, evaluation/testing, monitoring, and production deployment to AWS using LLMOps best practices.",4600,large language models|rag|llmops|mlops|aws|zenml|vector database|python,9,"This repository contains a full, practical implementation of an end-to-end LLM system, including data collection/generation, LLM training pipelines, a RAG system, and production deployment plus monitoring/testing workflows. It maps directly onto common ML engineering and LLMOps workflows (pipelines, experiment tracking, evaluation, vector DB integration, and cloud deployment), making it highly applicable for ML engineers and data scientists building real systems. The repo also shows integration with widely used ML/LLM tooling (e.g., ZenML for pipelines, Qdrant for vector search, and AWS for deployment), and demonstrates strong community adoption via its star count. It is not a foundational general-purpose ML framework like PyTorch, but it is a highly relevant, comprehensive applied LLM engineering reference, justifying a score of 9.",success
https://github.com/STVIR/pysot,pysot,"PySOT is a SenseTime Research codebase for state-of-the-art single object tracking in videos, implementing Siamese-network trackers such as SiamRPN, DaSiamRPN, SiamRPN++, SiamMask, and SiamFC. It is written in Python on top of PyTorch and includes tooling for testing and evaluating trackers on common tracking benchmarks.",4600,computer vision|object tracking|PyTorch|deep learning|SiamRPN|SiamMask|model training,9,"This repository provides full implementations of multiple deep-learning-based single-object tracking algorithms (including training, inference/demo, and evaluation), making it directly applicable to ML engineering and computer vision research workflows. It is built on PyTorch and includes model zoo assets and benchmark evaluation support for common tracking datasets, which increases its practical and educational value for ML practitioners. Community adoption appears strong (thousands of GitHub stars and substantial forking), but it is still a domain-specific tracking framework rather than a general-purpose ML foundation library, so it scores slightly below a 10.",success
https://github.com/Tencent/TNN,TNN,"TNN (Tencent Neural Network) is a high-performance, lightweight deep learning inference framework from Tencent Youtu Lab and Guangying Lab for deploying neural networks across mobile, desktop, and server platforms. It emphasizes cross-platform runtime support, hardware acceleration (e.g., ARM/OpenCL/Metal/NPU/X86/CUDA), and deployment optimizations such as model compression and code pruning.",4600,deep learning|neural network inference|edge deployment|mobile ai|model optimization|C++|ONNX,9,"Tencent/TNN is primarily an ML engineering tool: a production-oriented inference framework designed to run trained deep learning models efficiently across many devices and accelerators, with strong focus on performance, memory optimization, and deployment footprint. It directly supports common ML deployment workflows via model conversion from major training ecosystems (e.g., TensorFlow/PyTorch/Caffe via ONNX) and provides demos and tooling for running inference on Android/iOS/Linux/Windows. While it is not a data science library for exploration/training, it is highly valuable for taking models into production—especially for edge/mobile scenarios—and shows strong adoption signals (thousands of stars and usage in Tencent apps).",success
https://github.com/amazon-science/chronos-forecasting,chronos-forecasting,"Chronos is a Python package that provides an interface to the Chronos family of pretrained (zero-shot) time series forecasting models, including Chronos-2, Chronos-Bolt, and the original Chronos models. It supports forecasting workflows via simple pipelines and integrates with model checkpoints hosted on Hugging Face, with guidance for deployment (e.g., on AWS/SageMaker).",4600,time series forecasting|machine learning|pretrained models|deep learning|transformers|python|hugging face|aws sagemaker,9,"This repository is purpose-built for ML/time-series work: it provides inference interfaces (pip-installable) for pretrained forecasting models (Chronos-2, Chronos-Bolt, and Chronos) intended for zero-shot forecasting tasks. It is directly applicable to data science workflows because users can load pretrained checkpoints and generate probabilistic forecasts with minimal code, and it includes references/tutorials for benchmarking and deployment (including AWS/SageMaker). Community adoption appears strong for a specialized forecasting library (thousands of GitHub stars and hundreds of forks), and it has clear educational value via documentation and notebooks. It is scored 9 (not 10) because, while highly relevant and widely used within its niche, it is not a general-purpose, foundational ML framework on the scale of PyTorch/TensorFlow.",success
https://github.com/kermitt2/grobid,grobid,"GROBID (GeneRation Of BIbliographic Data) is a machine-learning library and service for extracting, parsing, and restructuring scholarly/technical documents (especially PDFs) into structured TEI XML, including metadata, references, citations, and full-text structure. It provides a REST web service API, batch processing, and training/evaluation tooling for its sequence-labeling models.",4600,NLP|document-ai|pdf-parsing|information-extraction|bibliographic-data|TEI-XML|Java|machine-learning,9,"This repository is a production-grade ML/NLP system focused on document understanding: extracting structured metadata, references, citation contexts, and full-text structure from scholarly PDFs into TEI XML, with REST services and tooling for training/evaluation. It is directly useful in data/ML workflows for building literature corpora, citation graphs, retrieval datasets, and downstream text-mining pipelines, and it is widely adopted across scholarly infrastructure (e.g., large-scale PDF processing and metadata extraction). It scores a 9 (not 10) because it is specialized for scholarly document parsing/extraction rather than being a general-purpose ML framework, but it is still highly valuable and broadly used in applied ML/data pipelines.",success
https://github.com/spotify/basic-pitch,basic-pitch,"Basic Pitch is Spotify’s lightweight automatic music transcription (audio-to-MIDI) library that converts audio files into MIDI note events with pitch bend detection. It provides a Python package and CLI, supports polyphonic/instrument-agnostic transcription, and ships multiple inference runtimes (TensorFlow, CoreML, TFLite, ONNX).",4600,machine learning|audio|music information retrieval|automatic music transcription|audio-to-MIDI|TensorFlow|ONNX,9,"This repository provides a production-oriented ML application for automatic music transcription, converting audio into MIDI (including pitch bends) using a lightweight neural network model released by Spotify. It is directly useful in ML/audio workflows for inference, evaluation, and integration (Python library + CLI), and includes multiple deployment runtimes (TensorFlow/CoreML/TFLite/ONNX) that improve practical usability across platforms. Community adoption appears strong (thousands of GitHub stars), and the repo has clear educational and applied value for audio ML and music information retrieval. It’s not a general-purpose ML framework, but it is a highly relevant, ready-to-use ML model/tool for a common audio-ML task, justifying a high score.",success
https://github.com/Kiln-AI/Kiln,Kiln,"Kiln is a toolset (desktop app + open-source Python library/API) for building, evaluating, and optimizing AI systems. It supports LLM evals, RAG/document search, agents, fine-tuning, synthetic data generation, and git-friendly dataset/task management designed for iterative AI product development.",4500,llm|mlops|llm-evaluation|synthetic-data|fine-tuning|rag|agents|python,9,"Kiln is primarily an AI/ML workflow product for iterating on LLM-powered systems, covering core data-centric activities like creating/labeling datasets, generating synthetic training/eval data, running evaluations, and fine-tuning models. It directly fits common ML engineer/data scientist workflows (experiment tracking-like iteration, dataset curation, model/provider integration, and RAG pipelines) and provides both a desktop UI and an open-source Python library to automate/extend these processes. Community adoption appears strong (about 4.5k GitHub stars), indicating meaningful usage in the LLM tooling space. It is not a general-purpose ML framework like PyTorch, but it is highly applicable to modern LLM development and MLOps, warranting a 9 rather than a 10.",success
https://github.com/Marker-Inc-Korea/AutoRAG,AutoRAG,AutoRAG is an open-source AutoML-style framework to evaluate and automatically optimize Retrieval-Augmented Generation (RAG) pipelines for a specific dataset and use case. It supports creating RAG evaluation datasets (QA + corpus) and searching/evaluating combinations of RAG modules to find an optimal pipeline.,4500,retrieval-augmented generation (RAG)|LLM evaluation|AutoML|NLP|information retrieval|LangChain|LlamaIndex|Python,9,"This repository provides an AutoML-like system focused specifically on RAG evaluation and pipeline optimization, including tooling for dataset creation (QA/corpus) and automated evaluation of many module combinations. It is directly applicable to ML/LLM workflows because it helps practitioners measure and improve retrieval + generation performance on their own data, which is a common production requirement for LLM applications. The repo also appears to have meaningful community adoption (thousands of stars) and strong integration with common LLM tooling (e.g., LangChain/LlamaIndex), making it highly valuable for ML engineers and data scientists working on RAG systems.",success
https://github.com/hudson-and-thames/mlfinlab,mlfinlab,"MlFinLab is a Python toolbox for financial machine learning research and systematic trading, covering the end-to-end workflow from financial data structures and labeling through feature engineering, model selection/validation, and backtest/overfitting analysis. The repository is public-facing primarily to track issues and feature requests for the library.",4500,python|quantitative-finance|financial-machine-learning|algorithmic-trading|portfolio-optimization|feature-engineering|backtesting,9,"This repository centers on a Python library designed specifically for financial machine learning, providing components across the modeling pipeline (data structures, labeling, sampling, feature engineering, models, cross-validation, hyper-parameter tuning, feature importance, and backtest overfitting tools). It is directly applicable to ML/data workflows in quantitative finance, enabling practitioners to build and evaluate ML-driven trading strategies with reusable, documented modules. Its community adoption appears strong for a niche domain (thousands of GitHub stars and substantial forks), and it has high educational/practical value due to its broad coverage of techniques and workflow steps. It is not a general-purpose ML framework at the scale of PyTorch/TensorFlow, so it falls just below a 10 despite being highly relevant within its domain.",success
https://github.com/huggingface/autotrain-advanced,autotrain-advanced,"AutoTrain Advanced is Hugging Face’s no-code/low-code tool for training and deploying state-of-the-art ML models, providing a web UI plus a CLI/config-driven workflow. It supports tasks like LLM fine-tuning (e.g., SFT/DPO/ORPO/reward), text classification/regression, and offers templates/configs to run locally or on Hugging Face Spaces.",4500,machine learning|llm fine-tuning|hugging face|auto-ml|mlops|python|transformers|no-code,9,"This repository provides an end-to-end training and deployment workflow for ML models (including a UI, CLI, and YAML configs), with strong emphasis on practical model fine-tuning—especially LLM fine-tuning methods like SFT/DPO/ORPO/reward. It directly fits common ML engineer/data scientist workflows by simplifying dataset-to-model training runs and integrating with the Hugging Face ecosystem (e.g., pushing to the Hub, running on Spaces). Given its purpose-built ML focus and broad applicability for training modern models, it merits a high score; it is just shy of a 10 because it is a product/tooling layer rather than a foundational, universally adopted core framework like PyTorch or TensorFlow.",success
https://github.com/kwai/DouZero,DouZero,"DouZero is a deep reinforcement learning framework that learns to play the three-player card game DouDizhu (""Fighting the Landlord"") via self-play. It accompanies the ICML 2021 paper ""DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning"" and provides training/evaluation code and an online demo.",4500,reinforcement learning|deep reinforcement learning|self-play|game ai|imperfect information games|pytorch|card games,9,"This repository is primarily an ML project: a deep reinforcement learning system for mastering DouDizhu through self-play, released alongside an ICML 2021 publication. It is directly applicable to ML workflows involving RL training and evaluation, and serves as a strong reference implementation for self-play RL in large, variable action-space games. Community adoption appears solid for a research codebase (about 4.5k GitHub stars), and the repo is educational for practitioners studying RL system design in complex games. It is scored 9 (not 10) because it is a domain-specific RL application/research framework rather than a general-purpose, broadly-integrated ML library.",success
https://github.com/rust-ml/linfa,linfa,"Linfa is a Rust machine learning framework that provides a toolkit for building ML applications, focusing on common preprocessing tasks and classical ML algorithms (in the spirit of scikit-learn). It is organized into sub-crates implementing algorithms such as clustering, regression, SVMs, trees, dimensionality reduction, and text vectorization.",4500,machine learning|rust|scikit-learn-like|classical ml|preprocessing|clustering|supervised learning|scientific computing,9,"This repository is a dedicated machine learning framework for Rust, providing a broad set of classical ML algorithms (e.g., Naive Bayes, clustering methods, random forests/AdaBoost, linear/logistic regression, SVMs, decision trees, t-SNE) and preprocessing utilities (e.g., normalization, vectorization/tf-idf). It is directly applicable to ML/data workflows for feature engineering, model training, and evaluation in Rust projects, with optional BLAS/LAPACK backends for performance-sensitive linear algebra. Its relatively strong GitHub adoption (about 4.5k stars) and breadth of implemented algorithms make it highly valuable for ML practitioners and learners working in the Rust ecosystem.",success
https://github.com/salesforce/Merlion,Merlion,"Merlion is a Salesforce-maintained Python machine learning library for time series intelligence, providing a unified end-to-end framework for forecasting, anomaly detection, and change point detection on univariate and multivariate time series. It includes standardized data loading/benchmarking, model ensembling, AutoML for hyperparameter tuning/model selection, post-processing/calibration, visualization (including a clickable UI), and optional distributed execution via PySpark.",4500,time series|machine learning|anomaly detection|forecasting|change point detection|AutoML|Python|PySpark,9,"This repository’s primary purpose is time series ML, offering a unified interface and end-to-end pipeline components (data loading/transforms, modeling, post-processing/calibration, evaluation/benchmarking, visualization) for forecasting, anomaly detection, and change point detection. It is directly applicable to common ML/data workflows, including experimentation, benchmarking, and production-like evaluation, and it supports both classical and deep learning approaches plus ensembles and AutoML. Community adoption appears strong for a specialized time-series library (thousands of GitHub stars) and it integrates well with standard DS tooling (pandas) and scalable execution (optional PySpark backend). It’s scored 9 (not 10) because it is a domain-specific ML framework rather than a universally foundational library like PyTorch/Pandas, but it is highly valuable for time-series practitioners.",success
https://github.com/shibing624/MedicalGPT,MedicalGPT,"MedicalGPT provides an end-to-end training pipeline to build medical-domain large language models, covering incremental pretraining (PT), supervised fine-tuning (SFT), and alignment methods such as RLHF and preference optimization variants (e.g., DPO/ORPO/GRPO). It also includes scripts for inference, quantization/evaluation, and demo serving (e.g., Gradio/FastAPI).",4500,large-language-models|medical-nlp|llm-training|fine-tuning|rlhf|preference-optimization|pytorch|huggingface,9,"This repository is primarily an ML engineering/training toolkit for building and aligning medical-domain LLMs, explicitly supporting PT, SFT, and multiple RLHF/preference-optimization workflows. It is directly applicable to real ML workflows because it provides runnable training/inference scripts, alignment pipelines (e.g., DPO/ORPO/GRPO), and deployment/demo utilities, which data scientists and ML engineers can integrate into experimentation. Community adoption appears strong for a domain-specific training repo (thousands of GitHub stars), and it has substantial educational value as a reference implementation of modern LLM training stages. It is not a foundational general-purpose framework like PyTorch/Transformers, so it falls short of a 10, but it is still highly valuable for ML/data practitioners working on LLM fine-tuning/alignment, especially in healthcare.",success
https://github.com/sweetice/Deep-reinforcement-learning-with-pytorch,Deep-reinforcement-learning-with-pytorch,"A collection of PyTorch implementations of classic and state-of-the-art deep reinforcement learning algorithms (e.g., DQN variants, policy gradients, actor-critic methods, PPO, SAC, TD3) primarily targeting OpenAI Gym environments, intended as clear reference code for learning and experimentation.",4500,deep reinforcement learning|pytorch|reinforcement learning|openai gym|dqn|ppo|sac|td3,9,"This repository is purpose-built for machine learning, providing runnable PyTorch implementations of many well-known deep reinforcement learning algorithms and examples for training/testing in Gym environments. It is directly applicable to ML workflows for RL research, learning, and prototyping (algorithm study, baseline comparisons, and experimentation). Community adoption appears strong (around 4.5k GitHub stars), indicating it is widely referenced as an educational/practical codebase rather than a production-grade RL framework. The score is 9 (highly relevant) because it is clearly ML-centric and broadly useful for RL practitioners, but it is not an industry-standard core platform/framework on the level of PyTorch itself.",success
https://github.com/tensorflow/datasets,datasets,"TensorFlow Datasets (TFDS) is a library that provides many public datasets as ready-to-use input pipelines (e.g., as tf.data.Dataset) with built-in download, preparation, and reproducible splits. It supports usage with TensorFlow and also integrates with other ecosystems such as JAX.",4500,machine learning|datasets|tensorflow|tf.data|jax|data pipelines|python,9,"This repository implements TensorFlow Datasets (TFDS), a purpose-built dataset ingestion and preparation library that downloads, preprocesses, and exposes standardized datasets through programmatic APIs for training and evaluation workflows. It is directly applicable to ML/data science work because it removes much of the boilerplate around dataset acquisition, canonical splits, caching, and building input pipelines (notably via tf.data), while also supporting use beyond TensorFlow. The project is widely adopted in the ML community (thousands of GitHub stars and tens of thousands of dependents) and is strongly educational because it provides dataset implementations, documentation, and best-practice input pipeline patterns. It is not itself a modeling framework, but it is a core, high-impact dependency for many ML pipelines, justifying a score of 9 rather than 10.",success
https://github.com/JWarmenhoven/ISLR-python,ISLR-python,"A collection of Jupyter notebooks that re-implement (in Python) selected tables, figures, and LAB sections from the 1st edition of ""An Introduction to Statistical Learning with Applications in R"" (James, Witten, Hastie, Tibshirani, 2013). The notebooks use common Python data-science libraries (e.g., pandas, NumPy, scikit-learn, statsmodels, matplotlib/seaborn) to reproduce analyses from the book.",4400,machine learning|statistical learning|educational|jupyter notebooks|python|scikit-learn|statsmodels|data analysis,9,"This repository provides Python implementations of core statistical learning / machine learning methods and workflows demonstrated in the ISLR textbook, organized as executable Jupyter notebooks across multiple chapters (e.g., regression, classification, resampling, regularization, trees, SVMs, unsupervised learning). It is directly applicable to ML/data workflows as a learning reference and a set of working examples using standard DS/ML tooling (pandas/NumPy/scikit-learn/statsmodels and visualization libraries). Community adoption appears strong for an educational repo (thousands of stars), and its educational value for learning practical ML in Python is high, though it is not a general-purpose production ML library—hence a 9 rather than a 10.",success
https://github.com/google-deepmind/dm_control,dm_control,"DeepMind’s Python software stack for physics-based simulation and reinforcement learning environments built on the MuJoCo physics engine. It provides MuJoCo bindings, a standard suite of continuous-control RL tasks, tools for composing new tasks, and an interactive viewer.",4400,reinforcement learning|physics simulation|MuJoCo|continuous control|Python|robotics environments|deep learning,9,"This repository provides the core infrastructure and benchmark tasks for running physics-based reinforcement learning experiments using MuJoCo, including environment suites and utilities for building custom tasks. It is directly applicable to ML workflows (training and evaluating RL agents) and is widely used/recognized in the RL research ecosystem as a canonical MuJoCo-based environment stack. While it is not a general-purpose ML framework, it is a highly valuable dependency for RL experimentation, benchmarking, and education, which justifies a high score.",success
https://github.com/microsoft/VoTT,VoTT,"Visual Object Tagging Tool (VoTT) is an open-source annotation and labeling tool for image and video assets, provided as an Electron desktop app and a web app. It supports labeling frames, importing/exporting datasets via local or cloud storage providers, and exporting labeled data for computer vision workflows (e.g., object detection).",4400,computer vision|data annotation|image labeling|video labeling|object detection|electron|react|typescript,9,"This repository provides a dedicated data-annotation tool (images/videos) used to create labeled datasets for computer vision tasks, especially object detection, and includes import/export mechanisms that fit directly into ML dataset preparation workflows. Its primary purpose is ML-adjacent but highly practical: producing training data is a core step in many real-world ML pipelines, and VoTT is designed specifically to support that end-to-end process. Despite being archived/read-only (archived Dec 7, 2021), it remains highly valuable for understanding and running a labeling workflow and for exporting annotations in formats commonly consumed by CV training pipelines, justifying a high (but not maximum) score.",success
https://github.com/mosaicml/llm-foundry,llm-foundry,"LLM Foundry is a codebase for training, fine-tuning, evaluating, and deploying large language models, built around MosaicML/Databricks tooling (e.g., Composer) and scripts for data preparation, training, inference, and evaluation. It supports workflows for Hugging Face-style models and includes utilities to run/launch workloads (including via MosaicML platform tooling).",4400,large language models|LLM training|fine-tuning|NLP|PyTorch|MLOps|model evaluation|inference,9,"This repository is primarily an end-to-end LLM engineering toolkit: it includes training/finetuning pipelines, evaluation scripts, inference/export tooling, and data preparation utilities (e.g., converting text datasets into streaming-friendly formats). It is directly applicable to ML workflows for practitioners training or adapting LLMs and integrates with common ecosystem components (e.g., Composer and Hugging Face model formats). Community adoption appears strong (thousands of GitHub stars and substantial fork count), and the repo also has educational value via tutorials and example workflows, which justifies a high (but not absolute) score.",success
https://github.com/AI4Finance-Foundation/ElegantRL,ElegantRL,"ElegantRL is a lightweight, scalable deep reinforcement learning (DRL) library focused on massively parallel training and simulation, including cloud-native/elastic scaling patterns. It implements a wide range of model-free DRL algorithms (e.g., DQN/DDPG/TD3/SAC/PPO and multi-agent methods) and provides examples/tutorial notebooks and integrations with common simulators (Gym, MuJoCo, PyBullet, Isaac Gym, FinRL).",4300,deep reinforcement learning|reinforcement learning|pytorch|distributed training|parallel simulation|multi-agent reinforcement learning|fintech,9,"This repository is primarily a deep reinforcement learning training framework, providing implementations of many widely used DRL algorithms and tooling for massively parallel sampling/training (including cloud-native scaling concepts). It is directly applicable to ML workflows for training and benchmarking RL agents across standard simulators (e.g., Gym/MuJoCo/PyBullet/Isaac Gym) and domain environments like FinRL, and includes runnable demos and tutorial notebooks that increase educational and practical value. Community adoption appears solid (thousands of GitHub stars and substantial forks), but it is not at the “industry default” level of the largest general-purpose ML frameworks, so it scores just below a 10.",success
https://github.com/fixie-ai/ultravox,ultravox,"Ultravox is a fast multimodal LLM designed for real-time voice interactions, able to understand speech and text without a separate ASR step. The repository includes code and tooling for training and running Ultravox models (with releases published on Hugging Face) and related infrastructure such as evaluation/training configs and dataset-creation scripts.",4300,multimodal-llm|speech|voice-ai|audio-understanding|real-time-inference|model-training|pytorch|llama,9,"This repository centers on a multimodal large language model that ingests audio and produces streaming text for real-time voice interactions, and it includes training and inference-related components (e.g., training/eval configs and dataset-creation scripts). It is directly applicable to ML workflows involving speech understanding, multimodal modeling, and deploying low-latency voice agents, and it references distributing model weights via Hugging Face. Given its clear ML focus and practical utility for training/inference (though not at the universal-adoption level of foundational frameworks), it merits a high score.",success
https://github.com/gpustack/gpustack,gpustack,"GPUStack is an open-source GPU cluster manager for performance-optimized AI model inference and deployment on your own GPU hardware. It selects and configures inference engines, schedules GPU resources across clusters, and provides operational features like monitoring, auth/access control, and usage metering.",4300,MLOps|LLM inference|GPU scheduling|model serving|cluster management|vLLM|TensorRT-LLM|observability,9,"This repository provides an infrastructure platform for deploying and serving AI models (including LLMs and other modalities) with GPU-aware scheduling and automatic selection/configuration of high-performance inference engines. It is directly applicable to ML engineering and MLOps workflows for running inference at scale on on-prem or multi-environment GPU clusters, and includes practical operational capabilities (monitoring, metering, authentication/access control). While it is not a model-training or data-processing library, it is highly valuable for production inference/serving and performance tuning, and its relatively strong community adoption (thousands of GitHub stars) supports a high score.",success
https://github.com/huggingface/speech-to-speech,speech-to-speech,"An open-source, modular speech-to-speech (voice-in/voice-out) cascaded pipeline that combines VAD, STT, an LLM, and TTS. It is designed to swap components easily and leverage Hugging Face Transformers/HF Hub models (with options for external backends like MLX and OpenAI API), supporting local, server/client, and Docker deployments.",4300,speech-to-speech|speech-recognition|text-to-speech|voice-activity-detection|transformers|hugging-face|llm|audio-streaming,9,"This repository provides a practical end-to-end speech-to-speech pipeline (VAD → STT → LLM → TTS) with configurable modules and multiple runtime modes (local, server/client streaming, Docker), making it directly usable for building voice assistants and audio AI demos. It is highly relevant to ML workflows because it orchestrates and integrates popular model families (e.g., Whisper checkpoints for STT and various TTS/LLM options) and focuses on low-latency inference/streaming rather than general software utilities. Community adoption appears strong for an application repo (thousands of stars), and the project has good educational value as a reference architecture for composing multiple audio/LLM components into a real-time system. It is scored 9 (not 10) because it is primarily an application/pipeline integration project rather than a foundational ML library or ubiquitous framework.",success
https://github.com/microsoft/LMOps,LMOps,"LMOps is a Microsoft research initiative collecting code and artifacts for building AI products with foundation models, with emphasis on general techniques for LLMs/MLLMs such as prompt optimization, long-context prompting, alignment, acceleration, and domain adaptation.",4300,large-language-models|generative-ai|prompt-engineering|prompt-optimization|in-context-learning|llm-alignment|model-acceleration,9,"The repository curates multiple research codebases and experiments focused on enabling capabilities for LLMs/MLLMs (e.g., prompt optimization/retrieval, structured prompting for long context, alignment approaches, and inference acceleration). This is directly applicable to ML engineers and researchers working on LLM training/evaluation and LLM-powered product development, and it links the implementations to the associated papers. It earns a 9 (highly relevant) because it is strongly ML-focused and provides practical, reusable methods for modern LLM workflows, though it is more of a research collection than a single standardized, production-grade MLOps framework. ",success
https://github.com/zjunlp/DeepKE,DeepKE,"DeepKE is an open-source, PyTorch-based knowledge extraction toolkit for knowledge graph construction, providing modular pipelines and model implementations for information extraction tasks such as named entity recognition, relation extraction, attribute extraction, and event extraction across standard, low-resource, document-level, schema-based, and multimodal settings.",4300,natural language processing|information extraction|knowledge graph|named entity recognition|relation extraction|PyTorch|large language models,9,"DeepKE is purpose-built for ML/NLP workflows, offering a unified and extensible toolkit for training and applying deep learning models to core information extraction tasks (e.g., NER/RE/attribute and event extraction) used in knowledge base population and knowledge graph construction. It is directly usable by ML engineers via code examples, pretrained components, documentation, and integrations (including LLM-oriented extensions such as DeepKE-LLM/OneKE and MCP tools mentioned in the repo). The repository shows strong community adoption for an academic toolkit (4.3k GitHub stars and hundreds of forks), and it has high educational value due to comprehensive docs and tutorials. It is not a general-purpose foundational framework (like PyTorch itself), so it falls short of a perfect 10 despite being highly relevant to ML/data practitioners.",success
https://github.com/fundamentalvision/BEVFormer,BEVFormer,"Official implementation of BEVFormer (ECCV 2022), a camera-only autonomous driving perception framework that learns a bird’s-eye-view (BEV) representation from multi-camera images using spatiotemporal transformers, supporting tasks like 3D object detection and semantic map/BEV segmentation.",4200,autonomous driving|3D object detection|bird's-eye view (BEV)|computer vision|transformers|multi-camera perception|PyTorch|nuScenes,9,"This repository provides research-grade training/inference code and configs for BEVFormer, a transformer-based method that constructs BEV representations from multi-view camera images for autonomous-driving perception (notably 3D detection and related BEV tasks). It is directly applicable to ML workflows (model training/evaluation, pretrained checkpoints/configs, dataset preparation—e.g., nuScenes) and is built on common deep-learning tooling, making it practical for ML engineers and researchers. Community adoption is strong (thousands of GitHub stars) and the repo has high educational value for BEV perception and spatiotemporal attention designs. It is scored 9 (highly relevant) rather than 10 because it is a specific research implementation rather than a general-purpose, broadly standardized ML framework.",success
https://github.com/iterative/cml,cml,"CML (Continuous Machine Learning) is an open-source CLI for implementing CI/CD for machine learning workflows (MLOps). It automates tasks like provisioning runners, training/evaluating models in CI, and posting experiment reports (metrics/plots) back to pull requests as comments or checks.",4200,MLOps|CI/CD|machine-learning|GitHub Actions|CLI|experiment-tracking|model-evaluation,9,"This repository provides CML, a dedicated MLOps/CI tool designed to run ML training and evaluation inside CI systems and to publish results (metrics/plots) as PR comments or GitHub checks. It directly supports common ML engineering workflows (continuous training/evaluation, experiment reporting, integration with GitHub/GitLab/Bitbucket, and optional Docker-based environments), making it highly applicable for ML practitioners. The project also shows strong community adoption (4.2k GitHub stars), supporting a high relevance score.",success
https://github.com/joanrod/star-vector,star-vector,StarVector is a multimodal vision-language foundation model that generates Scalable Vector Graphics (SVG) code from images (image-to-SVG/vectorization) and from text prompts (text-to-SVG). It frames SVG creation as a code-generation task and provides training/evaluation assets plus pretrained models and datasets via Hugging Face.,4200,vision-language model|multimodal LLM|image-to-SVG|text-to-SVG|vector graphics|code generation|PyTorch|Hugging Face Transformers,9,"This repository provides an ML-centric system (StarVector) for generating SVG code using a vision-language modeling architecture, with workflows for image2SVG and text2SVG and references to pretrained models and datasets. It is directly applicable to ML/data workflows for multimodal generative modeling, evaluation (SVG-Bench), and dataset usage (SVG-Stack), and includes runnable inference examples via Hugging Face/Transformers. While it is more specialized than general-purpose ML libraries, it is clearly a high-value research/engineering codebase for multimodal generation and structured output (code) modeling, justifying a high score. Community adoption appears solid for a research repo (thousands of stars), but it is not at the level of foundational ML frameworks, so it is not a 10.",success
https://github.com/ourownstory/neural_prophet,neural_prophet,"NeuralProphet is an interpretable time-series forecasting library built on PyTorch, inspired by Facebook Prophet and AR-Net. It provides an easy workflow to fit, predict, visualize forecasts/components, and iterate on forecasting models with configurable trend, seasonality, autoregression, and regressors.",4200,time series forecasting|machine learning|deep learning|PyTorch|forecasting library|data science|interpretable ML,9,"This repository is a purpose-built ML library for time-series forecasting, offering model definition, training, prediction, and plotting utilities for common forecasting components (trend, seasonality, autoregression, lagged regressors). It fits directly into data science workflows for forecasting tasks and exposes a simple, Prophet-like API while leveraging neural networks via PyTorch. The project shows meaningful community adoption (thousands of GitHub stars) and strong educational value for practitioners learning practical forecasting with interpretable components. It is scored 9 (not 10) because it is a specialized forecasting package rather than a general, foundational ML framework with ubiquitous industry adoption.",success
https://github.com/mlfoundations/open_flamingo,open_flamingo,"OpenFlamingo is an open-source PyTorch framework for training and evaluating large multimodal (vision-language) models inspired by DeepMind’s Flamingo, enabling text generation conditioned on interleaved images and text. It provides tooling to build models from pretrained vision encoders (e.g., CLIP/OpenCLIP) and language models (via Hugging Face Transformers), plus training/evaluation support and released checkpoint links.",4100,machine learning|multimodal learning|vision-language models|PyTorch|transformers|computer vision|LLMs|model training,9,"This repository is explicitly focused on implementing, training, and evaluating a large multimodal (vision-language) model family (OpenFlamingo) in PyTorch, including model construction utilities and guidance for training/evaluation workflows. It is directly applicable to ML engineers and researchers building or fine-tuning multimodal LLM systems and integrates with common ML tooling like OpenCLIP and Hugging Face Transformers. With strong community adoption (4.1k GitHub stars) and practical artifacts such as pretrained model links and installable packages, it is highly valuable for ML/data work but not a general-purpose, broadly adopted foundational framework on the scale of PyTorch/Transformers, hence a 9 rather than 10.",success
https://github.com/pytorch/executorch,executorch,"ExecuTorch is PyTorch’s on-device inference and deployment stack for running AI models on mobile, embedded, and edge devices. It supports exporting PyTorch models, compiling/optimizing them (e.g., quantization/partitioning) to a portable .pte format, and executing them with a lightweight C++ runtime across multiple hardware backends.",4100,machine learning|PyTorch|edge inference|mobile ML|model deployment|on-device AI|runtime,9,"This repository provides an end-to-end system for deploying and running PyTorch models on-device, including export tooling, ahead-of-time compilation/optimization, hardware backend partitioning, and a small C++ runtime for inference. It is directly applicable to ML engineering workflows focused on edge/mobile deployment (LLMs, vision, speech, multimodal), and it integrates tightly with PyTorch APIs like torch.export and a multi-backend deployment approach. Community adoption appears strong (thousands of GitHub stars) and it is positioned as PyTorch’s official solution for on-device inference, making it highly valuable for ML practitioners even though it is not a model-training library.",success
https://github.com/FedML-AI/FedML,FedML,"FedML is a unified, scalable machine learning library for large-scale distributed training, model serving/deployment, and federated learning across edge and cloud environments. It also includes tooling for cross-cloud/on-prem scheduling (FedML Launch) to run AI jobs on heterogeneous GPU resources.",4000,federated learning|distributed training|model serving|model deployment|MLOps|edge AI|deep learning|inference,9,"FedML is primarily an ML infrastructure/framework repo aimed at enabling federated learning, large-scale distributed training, and production model serving/monitoring across edge and cloud. It directly supports common ML engineering workflows (training at scale, federated learning across silos/devices, deployment/serving) and integrates with major ML frameworks such as PyTorch, TensorFlow, and JAX as part of its supported stack. The repository shows strong community adoption signals (on the order of ~4k GitHub stars) and broad practical/educational value for ML engineers working on distributed or privacy-preserving learning, which justifies a high score but not a “10” reserved for foundational, universally adopted core libraries.",success
https://github.com/SylphAI-Inc/AdalFlow,AdalFlow,"AdalFlow is a PyTorch-like Python library for building and auto-optimizing LLM (language model) workflows, including chatbots, RAG pipelines, and agents. It provides model-agnostic building blocks plus tooling for prompt optimization and agent execution (e.g., Runner/Agent patterns, tools, tracing/HITL support).",4000,llm|agents|rag|prompt-optimization|nlp|pytorch|mlops,9,"This repository is primarily an LLM application framework focused on composing, running, and auto-optimizing LM workflows (chatbots, RAG, and agent systems) with a PyTorch-like developer experience. It is directly applicable to ML/LLM engineering workflows because it provides model-agnostic pipeline components, agent tooling, and mechanisms aimed at optimizing prompts (including few-shot/zero-shot optimization) rather than only offering generic utilities. Its community adoption appears strong for an application-layer LLM framework (on the order of thousands of GitHub stars), and it includes practical examples and integrations (e.g., documentation, notebooks, and references to MLflow integration) that make it useful for both applied work and learning. It is not a general-purpose training framework like PyTorch itself, so it falls short of a perfect 10, but it is highly relevant to modern ML/LLM application development.",success
https://github.com/deepchecks/deepchecks,deepchecks,"Deepchecks is an open-source Python framework for continuous validation of ML models and data, providing built-in and customizable tests (checks/suites) across the ML lifecycle from research to production. It supports validation for tabular data as well as NLP and computer-vision workflows, with components oriented around testing/CI and monitoring.",4000,machine learning|MLOps|data validation|model validation|model monitoring|python|NLP|computer vision,9,"This repository provides a dedicated ML/data quality and model validation toolkit (checks and suites) meant to be run during development, CI, and production monitoring, making it directly applicable to everyday ML engineering workflows. It explicitly targets validating datasets and model behavior across modalities (tabular, NLP, and computer vision), which places it squarely in the MLOps/ML testing space. With ~4k GitHub stars, it shows meaningful community adoption for an ML validation library. It’s not a core training framework (so not a 10), but it is highly valuable as an end-to-end ML validation and monitoring companion.",success
https://github.com/kenshohara/3D-ResNets-PyTorch,3D-ResNets-PyTorch,"PyTorch implementation of 3D ResNet and related spatiotemporal CNN models for video action recognition, including scripts for training, fine-tuning, inference, and evaluation across common action-recognition datasets. The repository also provides links to pretrained weights and supports features like distributed training and R(2+1)D models.",4000,machine learning|deep learning|computer vision|video understanding|action recognition|PyTorch|3D CNN,9,"This repository is purpose-built for machine learning: it implements and trains spatiotemporal 3D CNN architectures (3D ResNets and R(2+1)D variants) for video action recognition, a core computer-vision task. It is directly applicable to ML workflows because it includes end-to-end training/fine-tuning/testing/inference code and provides pretrained model weights intended for transfer learning on common video datasets. Community adoption appears strong (about 4k GitHub stars and hundreds of forks), and it has substantial educational value as a reference implementation tied to well-known academic papers. It is not a general-purpose framework at the scale of PyTorch itself, but it is a highly relevant, reusable model-training codebase for practitioners working on video classification.",success
https://github.com/kubeflow/pipelines,kubeflow/pipelines,"Kubeflow Pipelines (KFP) is a Kubernetes-native platform for building, deploying, and managing reusable end-to-end machine learning workflows (pipelines). It provides a backend service, UI, and a Python SDK to author pipelines, run experiments, track executions/artifacts, and operationalize ML workflows at scale.",4000,MLOps|machine learning pipelines|workflow orchestration|Kubernetes|Kubeflow|Argo Workflows|Python SDK|ML workflow management,9,"This repository implements Kubeflow Pipelines, a full ML workflow orchestration and experiment execution system (backend + UI + SDK) designed specifically for building and running end-to-end ML pipelines on Kubernetes. It is directly applicable to real-world ML/data workflows (pipeline authoring, reproducible runs, experiment tracking, component reuse, and operational deployment patterns) and integrates tightly with the Kubernetes ecosystem and Argo Workflows. The repo shows strong community adoption as a core Kubeflow project and is commonly used as MLOps infrastructure rather than as an ML algorithm library, which is why it scores just below a perfect 10. Its breadth (SDK, service, samples, manifests) also provides substantial educational and integration value for ML engineers and platform teams.",success
https://github.com/NTMC-Community/MatchZoo,MatchZoo,"MatchZoo is a deep text matching toolkit that provides a unified pipeline to implement, compare, and share neural matching models for tasks like information retrieval, question answering, response ranking, and paraphrase identification. It includes standardized data preprocessing, model configuration, and training/evaluation utilities for deep matching research and experimentation.",3900,natural language processing|text matching|information retrieval|deep learning|keras|tensorflow|ranking,9,"This repository is purpose-built for deep text matching research and applications, providing implementations of many neural matching models (e.g., DSSM, DRMM, MatchPyramid) along with a unified data processing and training/evaluation workflow. It directly supports core ML/NLP workflows (dataset loading, preprocessing, model building, losses/metrics, and training loops) for ranking and classification tasks common in IR and QA. While it is not at the industry-adoption level of major general-purpose frameworks, it is highly relevant and practical for ML practitioners working specifically on semantic matching and ranking problems, earning a high score.",success
https://github.com/Nixtla/neuralforecast,neuralforecast,"NeuralForecast is a Python library providing scalable, user-friendly implementations of state-of-the-art neural network models for time series forecasting (from classic RNN/LSTM/GRU families to modern transformer-based architectures). It offers an sklearn-like .fit/.predict API plus features like exogenous variables, probabilistic forecasting, interpretability utilities, and integrations for tuning and workflow unification.",3900,time series forecasting|deep learning|python|pytorch|transformers|probabilistic forecasting|hyperparameter optimization|ray-optuna,9,"This repository is a dedicated ML library focused on neural time series forecasting, providing many ready-to-train model implementations and a workflow-oriented API (fit/predict) intended for practical forecasting pipelines. It directly supports common data-science needs like covariates/exogenous features, probabilistic outputs, evaluation losses, and interpretability, making it immediately usable by ML engineers and data scientists. Community signals (thousands of GitHub stars and hundreds of forks) indicate meaningful adoption, and the repo’s breadth of modern architectures plus integrations (e.g., Ray/Optuna) further increase its value. It is highly relevant to ML workflows but not at the “core, ubiquitous industry standard” level of foundational libraries (e.g., PyTorch), so a 9/10 is appropriate.",success
https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail,pytorch-a2c-ppo-acktr-gail,"A PyTorch implementation of several core deep reinforcement learning and imitation learning algorithms: A2C, PPO, ACKTR (K-FAC trust-region style optimization), and GAIL. It provides training/evaluation scripts and tuned hyperparameters (notably aligned with OpenAI Baselines-style setups) for standard Gym-style environments (e.g., Atari and continuous-control tasks).",3900,reinforcement learning|imitation learning|pytorch|ppo|a2c|acktr|gail|openai gym,9,"This repository is primarily a training framework for deep reinforcement learning (A2C/PPO/ACKTR) and imitation learning (GAIL) implemented in PyTorch, intended for running experiments on Gym-style environments such as Atari and continuous-control benchmarks. It is directly applicable to ML workflows for researchers and practitioners who need reference implementations, reproducible training scripts, and baseline hyperparameters for RL/IL. The repo is widely cited/used in the RL community (high star count) and has strong educational value for understanding and modifying canonical policy-gradient methods. It scores slightly below a 10 because it is a specialized RL codebase rather than a broadly general-purpose ML library with industry-wide adoption comparable to core frameworks.",success
https://github.com/yahoo/TensorFlowOnSpark,TensorFlowOnSpark,"TensorFlowOnSpark (TFoS) enables distributed TensorFlow training and inference on Apache Spark (and Hadoop/HDFS) clusters, providing a Spark-friendly API to launch/manage TensorFlow worker/parameter-server processes and feed data via Spark or TensorFlow input pipelines.",3900,distributed-training|tensorflow|apache-spark|hadoop-hdfs|data-engineering|deep-learning|mlops,9,"This repository is purpose-built to run TensorFlow workloads on big-data clusters by orchestrating a TensorFlow cluster (workers/PS) from Spark and supporting multiple data ingestion modes (Spark-fed and TensorFlow-native/HDFS). It is directly applicable to ML engineering workflows for scalable training/inference, especially when Spark is already used for data preparation and pipeline orchestration. The project also shows strong community adoption signals (thousands of GitHub stars) and provides practical integration patterns for distributed deep learning on Spark, warranting a high score short of ""core framework"" status.",success
https://github.com/JDAI-CV/fast-reid,fast-reid,"FastReID is a PyTorch-based research toolbox implementing state-of-the-art instance re-identification (e.g., person re-ID), providing training/evaluation pipelines, configs, model zoo baselines, and deployment/export utilities (e.g., ONNX/TensorRT). It is designed as a reusable framework for re-ID and related retrieval/recognition tasks.",3800,computer vision|person re-identification|deep learning|PyTorch|image retrieval|model training|ONNX/TensorRT deployment,9,"This repository is a dedicated machine learning toolbox for training and evaluating state-of-the-art re-identification models (primarily person re-ID) built on PyTorch, with configs, datasets tooling, metrics, and a model zoo of baselines. It is directly applicable to ML workflows (experimenting, benchmarking, fine-tuning, and exporting models for deployment) and is widely used in the re-ID community, as reflected by its substantial GitHub adoption. It earns a 9 (highly relevant) because it is purpose-built for ML model development and research in computer vision, though it is narrower in scope than general-purpose ML frameworks.",success
https://github.com/ModelTC/LightLLM,LightLLM,"LightLLM is a Python-based large language model (LLM) inference and serving framework designed to be lightweight, scalable, and high-performance. It uses Triton-based GPU operators and provides tooling/docs for deploying and serving LLMs efficiently (including Docker-based setup).",3800,large-language-models|llm-inference|model-serving|triton|gpu-acceleration|deep-learning|python,9,"This repository is primarily an LLM inference and serving framework (not a general-purpose app), focused on fast GPU-backed generation and scalable deployment/serving of large language models. It is directly applicable to ML engineering workflows for running and serving LLMs in production, and it provides operator-level optimizations (Triton) plus practical deployment paths like official Docker images and documentation. With thousands of GitHub stars and references/usage by other LLM-serving projects, it shows meaningful community adoption, though it is not a foundational, universal ML library on the level of PyTorch/TensorFlow—hence a 9 rather than 10.",success
https://github.com/benfred/implicit,implicit,"A high-performance Python library for recommender systems on implicit-feedback data, implementing algorithms like ALS, BPR, logistic matrix factorization, and item-item nearest neighbors. It supports multi-threaded CPU training (Cython/OpenMP) and GPU acceleration (CUDA) for some models, with optional approximate nearest-neighbor backends.",3800,machine learning|recommender systems|collaborative filtering|implicit feedback|matrix factorization|GPU acceleration|python,9,"This repository is purpose-built for machine learning workflows around recommendation systems, specifically collaborative filtering on implicit-feedback interaction data. It provides production-oriented implementations of core recommender algorithms (ALS, BPR, logistic MF, and item-item KNN) with significant performance optimizations (multi-core CPU via Cython/OpenMP and optional CUDA GPU kernels), making it directly applicable to real-world ML pipelines. Its strong adoption (thousands of GitHub stars) and practical API for fitting on sparse matrices and generating recommendations make it highly valuable to data scientists and ML engineers, though it is narrower in scope than general-purpose ML frameworks.",success
https://github.com/lucidrains/stylegan2-pytorch,stylegan2-pytorch,"A simple, command-line-friendly PyTorch implementation of StyleGAN2 for training and generating images with a state-of-the-art GAN. Includes features like multi-GPU training, checkpointing/resume, latent truncation, and optional differentiable augmentations for low-data regimes.",3800,machine learning|deep learning|pytorch|generative adversarial networks|stylegan2|computer vision|image generation,9,"This repository implements StyleGAN2 in PyTorch and provides a practical CLI workflow to train GANs on an image dataset and generate samples (including interpolation videos), which is directly useful in ML research and applied generative modeling. It fits squarely into common ML workflows (dataset preparation, GPU training, checkpointing, evaluation via sampling) and exposes training knobs like truncation and differentiable augmentation for small datasets. Community adoption appears strong for a specialized model implementation (thousands of GitHub stars), and the code is educational for understanding and experimenting with StyleGAN2-like architectures. It’s not a general-purpose framework like PyTorch itself, but it is a highly relevant, ready-to-use generative modeling tool, justifying a 9/10.",success
https://github.com/lululxvi/deepxde,deepxde,"DeepXDE is a Python library for scientific machine learning and physics-informed learning, providing implementations of PINNs, DeepONets, and related methods for solving forward/inverse differential equations and operator-learning problems across multiple deep-learning backends (TensorFlow, PyTorch, JAX, PaddlePaddle).",3800,scientific machine learning|physics-informed neural networks|PINN|operator learning|DeepONet|partial differential equations|Python,9,"This repository is a purpose-built ML library for scientific machine learning, centered on physics-informed models (e.g., PINNs) and operator learning (e.g., DeepONet) to solve forward/inverse ODE/PDE and related scientific computing problems. It is directly applicable to ML workflows in computational science and engineering (modeling, training, autodiff-based derivative computation) and supports multiple major ML backends, making integration practical for many teams. Its sizable community adoption (thousands of GitHub stars) and extensive algorithm coverage provide both strong practical utility and educational value for practitioners learning physics-informed and operator-learning methods.",success
https://github.com/opengeos/segment-geospatial,segment-geospatial,"SamGeo (segment-geospatial) is a Python package that applies the Segment Anything Model (SAM) to geospatial/remote-sensing imagery, enabling segmentation of GeoTIFFs and exporting results to common GIS vector formats. It also supports workflows like interactive marker prompting, text-prompt segmentation, and visualization on interactive maps, with an available QGIS plugin.",3800,geospatial|remote sensing|image segmentation|computer vision|segment anything model (SAM)|python|GIS|QGIS plugin,9,"This repository provides a practical ML-powered geospatial segmentation toolkit built around the Segment Anything Model (and related variants like HQ-SAM), specifically targeting tasks such as segmenting GeoTIFF remote-sensing imagery and exporting GIS-ready vectors. It is directly applicable to ML/data workflows for Earth observation—bridging model inference with geospatial IO, prompting, visualization, and downstream vector outputs—so it is highly useful for data scientists working with spatial imagery. The project also shows substantial community adoption (thousands of GitHub stars) and strong educational value via documented, low-code workflows and integrations (e.g., QGIS and interactive mapping). A 9 (vs 10) reflects that it is a specialized application toolkit rather than a general-purpose, industry-standard ML framework.",success
https://github.com/torchgeo/torchgeo,torchgeo,"TorchGeo is a PyTorch domain library (similar to torchvision) that provides datasets, samplers, transforms, and pre-trained models tailored for geospatial/remote-sensing data, including support for multispectral imagery and geospatial metadata (e.g., CRS handling). It aims to make it easier for ML practitioners to work with geospatial data and for remote-sensing practitioners to apply deep learning workflows.",3800,machine learning|deep learning|PyTorch|geospatial|remote sensing|computer vision|datasets,9,"This repository is purpose-built for ML on geospatial/remote-sensing data, providing the core components data scientists need (dataset loaders, sampling utilities, transforms, and pre-trained models) within the PyTorch ecosystem. It directly supports common ML workflows like building DataLoaders, training/transfer learning, and handling geospatial specifics such as multispectral bands and coordinate reference systems. With ~3.8k GitHub stars and an active development history, it shows strong community adoption for the geospatial ML niche. It is not a general-purpose ML framework at the scale of PyTorch itself, but it is a highly relevant, practical library for geospatial ML, justifying a 9/10.",success
https://github.com/bytedance/byteps,byteps,"BytePS is a high-performance, general-purpose framework for distributed deep neural network training. It integrates with major DL frameworks (TensorFlow/Keras, PyTorch, MXNet) and is designed to scale efficiently across multi-GPU, multi-node clusters using optimized communication (including TCP and RDMA).",3700,distributed-training|deep-learning|machine-learning-infrastructure|pytorch|tensorflow|mxnet|rdma,9,"This repository provides a distributed training framework (BytePS) focused on accelerating and scaling DNN training across many GPUs and machines, including cloud/shared-cluster environments. It is directly applicable to ML engineering workflows by enabling faster multi-node training and integrating with major ML frameworks like PyTorch and TensorFlow/Keras. While it is not a modeling library itself, it is highly valuable ML infrastructure for large-scale training; however, its archived/read-only status (archived on 2025-12-08) likely reduces ongoing community momentum and long-term integration benefits compared to actively maintained alternatives.",success
https://github.com/cleardusk/3DDFA,3DDFA,"A PyTorch implementation (""improved version"") of the TPAMI 2017 paper ""Face Alignment in Full Pose Range: A 3D Total Solution"", providing code and pretrained models for 3D dense face alignment/3DMM-based face fitting and related demos/benchmarks.",3700,computer vision|deep learning|face alignment|3D face reconstruction|3D morphable model (3DMM)|PyTorch|Python,9,"This repository implements a well-known research approach for 3D dense face alignment across large pose variations, including training/inference code, demos, benchmarks, and pretrained models, making it directly usable for applied computer-vision ML workflows. It is highly relevant to ML engineers/data scientists working on facial landmarking, 3D face fitting, and related tasks, and it serves as an educational reference for a published method and its engineering details. The repo also indicates release of preprocessed train/test datasets and pretrained models, further improving practical applicability. It is not a general-purpose ML framework with industry-scale adoption, but it is a widely referenced, task-specific CV/ML implementation, justifying a high (but not maximal) score.",success
https://github.com/google-research/scenic,scenic,"Scenic is a JAX/Flax-based research codebase for training and evaluating large-scale computer vision (and multimodal) models, especially attention/transformer-style architectures. It provides shared libraries (experiment boilerplate, optimized training loops, metrics/losses, dataset input pipelines) plus multiple project implementations of SOTA models and baselines.",3700,machine learning|computer vision|JAX|Flax|vision transformers|deep learning|research codebase,9,"This repository is primarily an ML research framework/codebase focused on building, training, and evaluating state-of-the-art computer vision and multimodal models (notably attention/transformer-based approaches) using JAX and Flax. It is directly applicable to ML workflows by providing reusable training/evaluation infrastructure, dataset input pipelines for common vision datasets, and reference implementations/baselines used in published research. The repo shows meaningful community adoption (thousands of GitHub stars) and strong educational/practical value for practitioners who want to study or reproduce modern vision model training at scale, which supports a high (9/10) score.",success
https://github.com/lightly-ai/lightly,lightly,"Lightly is a Python (PyTorch/PyTorch Lightning) library for self-supervised learning (SSL) in computer vision. It provides modular building blocks (e.g., losses, heads, transforms) and reference implementations/examples for many modern SSL methods to pretrain image representations.",3700,self-supervised-learning|computer-vision|pytorch|pytorch-lightning|representation-learning|contrastive-learning|deep-learning,9,"This repository’s primary purpose is to enable self-supervised pretraining for computer vision via a PyTorch/PyTorch-Lightning-friendly framework and implementations of many SSL approaches (e.g., SimCLR/Barlow Twins/BYOL/DINO/DINOv2/MAE and others). It is directly applicable to ML workflows for learning embeddings from unlabeled image datasets and can be integrated into training pipelines as reusable components (losses, heads, transforms, datasets, and examples). The project shows strong community adoption (thousands of GitHub stars) and high educational value because it offers modular code and example implementations of widely used SSL methods. It’s not a general-purpose data tool like Pandas/Spark, but it is a highly relevant, practical library for ML engineers working on vision representation learning, so it merits a 9/10.",success
https://github.com/open-compass/VLMEvalKit,VLMEvalKit,"VLMEvalKit (Python package: vlmeval) is an open-source evaluation toolkit for large vision-language / multimodal models, enabling one-command evaluation across many benchmarks with unified, generation-based evaluation and optional LLM-based answer extraction.",3700,machine learning|computer vision|vision-language models|multimodal evaluation|benchmarking|LLM tooling|python,9,"This repository is purpose-built for evaluating large vision-language/multimodal models, providing standardized pipelines to run many models against many benchmarks with minimal manual dataset/repo setup. It directly supports common ML workflows (model comparison, reproducible evaluation, leaderboard-style reporting) and includes practical evaluation features like generation-based scoring and answer extraction. Community adoption appears strong (thousands of GitHub stars and active development), making it highly useful for ML researchers and engineers. It is not a general training framework, but as an evaluation/benchmarking toolkit for multimodal ML it merits a high score.",success
https://github.com/polyaxon/polyaxon,polyaxon,"Polyaxon is an open-source MLOps platform for managing and orchestrating the machine learning lifecycle, including experiment execution, distributed training, hyperparameter tuning, and workflow/pipeline (DAG) orchestration on Kubernetes.",3700,MLOps|machine-learning|experiment-tracking|hyperparameter-tuning|distributed-training|Kubernetes|workflow-orchestration|Helm,9,"This repository provides a full MLOps platform (Polyaxon) aimed at reproducibility, automation, and scaling of ML workloads, with a CLI and Kubernetes/Helm-based deployment. It directly supports core ML engineering needs such as running experiments, tracking logs/resources, launching notebooks/TensorBoard, orchestrating DAG-based pipelines, and enabling distributed training across frameworks. Because it is purpose-built for ML operations and can be integrated into real-world training and deployment workflows, it is highly valuable for data science/ML teams; however, it is not a foundational ML library/framework itself (e.g., PyTorch), so it scores slightly below a 10.",success
https://github.com/predibase/lorax,lorax,"LoRAX (LoRA eXchange) is a Multi-LoRA inference server for serving thousands of fine-tuned LoRA adapters on top of a shared base LLM, enabling low-cost, high-throughput LLM serving. It supports dynamic adapter loading/merging per request, heterogeneous continuous batching, and production deployment via Docker/Helm with an OpenAI-compatible API.",3700,large language models|LoRA|inference server|model serving|MLOps|Kubernetes|GPU inference|OpenAI-compatible API,9,"This repository provides infrastructure specifically for serving fine-tuned LLMs via LoRA adapters at scale (dynamic adapter loading, batching/scheduling, GPU-optimized inference, and OpenAI-compatible endpoints). It is directly applicable to ML engineering and MLOps workflows for deploying and operating many task-specific LLM variants efficiently, including Docker/Helm deployment and observability hooks. Its substantial GitHub adoption (3.7k stars) suggests meaningful community usage and validation, but it is more specialized than general-purpose ML libraries, so it is not a full 10.",success
https://github.com/zai-org/GLM-4.5,GLM-4.5,"Official repository for the GLM-4.5 series (and related GLM-4.6/4.7) agent-oriented foundation models, focusing on reasoning, coding, and tool-using/agent workflows. Includes docs and inference examples/instructions for running the models with popular serving stacks (e.g., Transformers, vLLM, SGLang) and references to model downloads and technical reports.",3700,large-language-models|generative-ai|nlp|agentic-ai|reasoning-models|code-generation|llm-inference,9,"This repository is centered on GLM-4.5 family foundation models designed for intelligent agents, emphasizing reasoning, coding, and tool use, with practical guidance and code assets for inference/serving. It is directly applicable to ML workflows (model serving, evaluation references, integration with frameworks like Transformers/vLLM/SGLang), making it highly relevant to ML engineers and applied researchers. While it is not a general-purpose data-processing library, it is a core model repo with meaningful adoption signals (thousands of GitHub stars) and strong educational/integration value for LLM deployment, so it merits a high score.",success
https://github.com/Dataherald/dataherald,dataherald,"Dataherald is a monorepo for an enterprise-oriented natural language-to-SQL (text-to-SQL) engine that lets users query relational databases in plain English using LLMs. It includes an API ""engine"" plus optional enterprise/auth layer, an admin console UI, and a Slackbot for end-to-end deployments.",3600,nl-to-sql|text-to-sql|llm|rag|data-analytics|sql|python|typescript,9,"This repository implements an LLM-powered natural-language-to-SQL system for question answering over relational databases, packaged as multiple deployable services (engine API, enterprise/auth layer, admin console, and Slackbot). It is highly relevant to ML/data workflows because it directly enables semantic querying, analytics Q&A, and data access patterns that are common in modern LLM/RAG-driven data products. The project has strong direct applicability for data teams building NL analytics interfaces and shows meaningful community adoption (thousands of GitHub stars), but it is not a general-purpose ML framework on the scale of core libraries like PyTorch—hence a 9 rather than 10.",success
https://github.com/NExT-GPT/NExT-GPT,NExT-GPT,"Code, data, and model weights for the ICML 2024 (oral) paper “NExT-GPT: Any-to-Any Multimodal Large Language Model”, an end-to-end multimodal LLM that can take and generate arbitrary combinations of text, image, video, and audio via instruction tuning and multimodal encoders/decoders.",3600,multimodal LLM|generative AI|diffusion models|computer vision|audio processing|video understanding|PyTorch,9,"This repository provides an end-to-end multimodal large language model system (NExT-GPT) with training/tuning code, datasets/data-construction guidance, checkpoints, and a demo pipeline for any-to-any multimodal generation (text/image/video/audio). It is directly applicable to ML workflows (research and engineering) for multimodal instruction tuning, multimodal representation learning, and multimodal generation using established LLMs, encoders, and diffusion decoders. Community adoption appears strong for a research repo (thousands of GitHub stars) and it has high educational value for understanding practical multimodal LLM system design. It is not a general-purpose foundational framework on the scale of PyTorch/TensorFlow, so it falls just short of a 10 despite being highly relevant.",success
https://github.com/PAIR-code/lit,lit,"The Learning Interpretability Tool (LIT) is a visual, interactive, framework-agnostic web UI for analyzing and debugging machine learning models across text, image, and tabular data. It supports workflows like local explanations (e.g., salience), aggregate/slice analysis, counterfactual generation, and side-by-side model comparisons, and can run as a standalone server or in notebook environments.",3600,machine learning|model interpretability|explainable AI (XAI)|model debugging|NLP|data visualization|TensorFlow|PyTorch,9,"This repository provides LIT, an interactive interpretability and debugging tool specifically designed to help practitioners understand ML model behavior via a browser-based UI (including explanations, slicing/metrics, embedding visualizations, and counterfactual testing). It is directly applicable to common ML workflows for evaluation, error analysis, and responsible/robustness checks, and it supports multiple data modalities (text, image, tabular) and model/task types. Its framework-agnostic approach (compatible with TensorFlow, PyTorch, and others) and broad feature set make it highly valuable for data scientists and ML engineers, though it is not itself a training framework (hence not a 10).",success
https://github.com/PaddlePaddle/FastDeploy,FastDeploy,"FastDeploy is a high-performance inference and deployment toolkit for large language models (LLMs) and vision-language models (VLMs) built on PaddlePaddle. It provides production-oriented serving features (e.g., OpenAI API/vLLM-compatible serving, KV-cache optimizations, quantization, and multi-hardware support) to accelerate and simplify model deployment.",3600,machine-learning|model-deployment|inference-serving|llm|vision-language-models|paddlepaddle|quantization|gpu-acceleration,9,"This repository’s primary purpose is to enable fast, production-grade inference and deployment of modern ML models (especially LLMs and VLMs), including serving interfaces and performance optimizations. It is directly applicable to ML engineering workflows (model serving, acceleration, quantization, hardware-specific deployment) rather than general software tooling. The project shows meaningful community adoption (thousands of GitHub stars and active development history) and integrates with common serving patterns (e.g., OpenAI API / vLLM compatibility), justifying a high score but not a maximum-10 framework-level score.",success
https://github.com/ZhaoJ9014/face.evoLVe,face.evoLVe,"A high-performance face recognition library built on PaddlePaddle and PyTorch, providing end-to-end components for face-related analytics such as face alignment, data processing, multiple backbone architectures, and popular metric-learning/classification losses (e.g., ArcFace, CosFace). It also includes training/validation utilities and model/dataset “zoo” resources for face recognition workflows.",3600,computer vision|face recognition|deep learning|pytorch|paddlepaddle|metric learning|model training,9,"This repository is primarily an ML/computer-vision toolkit focused on training and deploying face recognition models, offering data preprocessing/alignment utilities, many backbone networks, and common loss functions used in modern face recognition. It is directly applicable to ML workflows (training, evaluation, feature extraction) and is broadly useful for researchers and ML engineers working on facial analysis. The strong GitHub adoption signal (thousands of stars) and the breadth of training/data tooling make it highly valuable, though it is specialized to face recognition rather than being a general-purpose ML framework.",success
https://github.com/alibaba/Alink,Alink,Alink is an Apache Flink-based machine learning algorithm platform developed by Alibaba's PAI team. It provides ML algorithms and related components (including Python bindings via PyAlink) for building scalable data processing and ML workflows on Flink.,3600,machine learning|Apache Flink|distributed data processing|feature engineering|ML pipelines|Java|Python|MLOps,9,"This repository is primarily an ML algorithm platform built on Apache Flink, aiming to run machine learning and related data/algorithm components in a distributed streaming/batch environment. It is directly applicable to ML/data workflows (e.g., feature engineering, pipeline-style training/inference components) and includes both Java-side components and Python usage via PyAlink, making it usable by ML engineers and data scientists working with Flink ecosystems. Community adoption appears solid for a specialized Flink-ML stack (thousands of GitHub stars and substantial forks), though it is not as universally adopted as mainstream general-purpose ML frameworks, which is why it scores 9 rather than 10.",success
https://github.com/google/deepvariant,deepvariant,"DeepVariant is a deep learning-based genomics variant calling pipeline that converts aligned sequencing reads (BAM/CRAM) into pileup tensor representations, applies a neural network classifier, and outputs germline variant calls as VCF/gVCF. It supports multiple sequencing technologies (e.g., Illumina, PacBio HiFi, Oxford Nanopore) and includes related tooling such as DeepTrio for family-based calling.",3600,genomics|variant-calling|bioinformatics|deep-learning|tensorflow|next-generation-sequencing,9,"This repository provides an end-to-end ML-driven variant calling system used to infer genetic variants from next-generation sequencing data by generating tensor/pileup representations and running a neural network to produce VCF/gVCF outputs. It is directly applicable to real genomics data workflows (research pipelines for WGS/WES/long reads) and is widely recognized and used in bioinformatics/ML-for-genomics contexts. The score is 9 (not 10) because it is a highly specialized domain application rather than a general-purpose ML framework, but it remains a core, production-grade ML tool within genomics.",success
https://github.com/junxiaosong/AlphaZero_Gomoku,AlphaZero_Gomoku,"An implementation of the AlphaZero self-play reinforcement learning algorithm for the board game Gomoku (Gobang/Five in a Row), using Monte Carlo Tree Search with a policy/value neural network. Includes scripts to train from scratch and to play against trained models, with multiple deep learning backend options (e.g., PyTorch/TensorFlow, plus older Theano/Lasagne support).",3600,reinforcement learning|alphazero|gomoku|monte carlo tree search|self-play training|pytorch|tensorflow,9,"This repository is primarily a reinforcement learning project implementing AlphaZero-style self-play training for Gomoku, combining MCTS with a policy/value neural network and providing end-to-end training and play code. It is directly applicable for ML practitioners learning or prototyping self-play RL workflows (data generation from self-play, training loops, evaluation via gameplay), and includes multiple framework implementations (notably PyTorch and TensorFlow). Community adoption appears strong for an educational RL repo (thousands of stars), and the code is a common reference point for AlphaZero-style implementations; however, it is not a general-purpose ML framework and includes some legacy dependencies, so it does not merit a perfect 10.",success
https://github.com/mrdbourke/zero-to-mastery-ml,zero-to-mastery-ml,"Course repository for the Zero to Mastery Machine Learning & Data Science curriculum, containing notebooks, code, datasets, slides, and supporting materials for learning core DS/ML tools and completing end-to-end projects (classification, regression, and deep learning with TensorFlow/Keras).",3600,machine-learning|data-science|python|scikit-learn|tensorflow|jupyter-notebook|pandas|education,9,"This repository’s primary purpose is teaching practical machine learning and data science through structured lessons, notebooks, and milestone projects (including structured-data modeling and deep learning with TensorFlow/Keras). It directly supports common ML workflows—data exploration, preprocessing, model training/evaluation—and includes datasets in-repo (e.g., via the data/ folder) for hands-on experimentation. While it’s not a production ML framework, it has strong educational value and clear applicability for learners and practitioners building end-to-end ML project skills, supported by notable community adoption (thousands of GitHub stars).",success
https://github.com/opendilab/DI-engine,DI-engine,"DI-engine (OpenDILab Decision AI Engine) is a generalized decision-intelligence / deep reinforcement learning framework with modular abstractions for environments, policies, and models, supporting a wide range of RL, offline RL, imitation learning, and related algorithms with strong documentation and tooling.",3600,reinforcement learning|deep reinforcement learning|offline reinforcement learning|imitation learning|PyTorch|JAX|decision intelligence|MLOps,9,"This repository is primarily a reinforcement learning framework providing core abstractions (environment/policy/model) and training pipelines, plus implementations of many major RL families (e.g., DQN/PPO/SAC, multi-agent RL, imitation learning, offline RL, and model-based RL). It is directly applicable to ML workflows for training, evaluating, and benchmarking decision-making agents, and it integrates with common ML stacks (notably PyTorch and also JAX) while offering substantial documentation and examples. Community adoption appears strong for an RL-specific framework (thousands of GitHub stars and active development), which increases its practical and educational value. It earns a 9 (highly relevant) because it is an ML-first toolkit focused on RL research/engineering, though it is not a broadly universal data-science library on the scale of general-purpose foundations like PyTorch itself.",success
https://github.com/ploomber/ploomber,ploomber,"Ploomber is a Python framework for building and iterating on data pipelines, with a YAML-first API (and a Python API) plus task-level caching to speed up development. It supports developing from notebooks/IDEs and deploying pipelines to different execution backends (e.g., single machine scripts or orchestrators/runtimes like Kubernetes/Airflow/AWS Batch/SLURM) without changing pipeline code.",3600,data-pipelines|data-engineering|machine-learning|mlops|workflow-orchestration|python|jupyter-notebooks|etl,9,"This repository provides a dedicated framework to create, run, and deploy data/ML pipelines, emphasizing iterative development (including notebook-to-pipeline workflows) and efficient execution via caching. It directly supports common ML/data workflows such as ETL/feature generation/model training pipelines and integrates with ML-adjacent tooling and execution backends (e.g., Airflow/Kubernetes/AWS Batch/SLURM). Community adoption appears strong for a specialized pipeline tool (about 3.6k GitHub stars), and the repo is explicitly positioned around data science, machine learning, and MLOps. I scored it a 9 (highly relevant) because it’s a core-enabling tool for ML/data pipelines rather than an ML model framework itself, and it is archived/read-only as of July 12, 2025.",success
https://github.com/princeton-nlp/SimCSE,SimCSE,"Official code and pretrained models for SimCSE (EMNLP 2021), a simple contrastive learning method for learning high-quality sentence embeddings in both unsupervised (dropout noise) and supervised (NLI pairs) settings. The repo also provides a Python package/tooling to encode sentences, compute similarities, and perform sentence retrieval (optionally with FAISS).",3600,natural language processing|sentence embeddings|contrastive learning|representation learning|PyTorch|Hugging Face Transformers|semantic textual similarity,9,"This repository implements SimCSE, a widely used contrastive-learning approach for training and using sentence embedding models, and includes training/evaluation code plus pretrained checkpoints (via Hugging Face model IDs referenced in the README). It is directly applicable to ML/NLP workflows such as semantic search, retrieval, clustering, and STS evaluation, and it integrates with common tooling (PyTorch/Transformers and optional FAISS-based similarity search). The strong community adoption (thousands of GitHub stars) and clear educational value for contrastive representation learning justify a high score, though it is narrower in scope than general-purpose frameworks (so not a 10).",success
https://github.com/pytorch/torchchat,torchchat,"torchchat is a PyTorch-based reference app/codebase for running large language models locally across environments (Python, native C/C++ runner for desktop/server, and mobile on iOS/Android), including support for quantization and multiple execution modes (eager/compile/AOT/ExecuTorch). The repository has been archived and is no longer under active development.",3600,machine learning|large language models|PyTorch|LLM inference|mobile ML|model quantization|C++,9,"This repository’s primary purpose is enabling and showcasing local LLM inference with PyTorch across Python, native C/C++ applications, and mobile deployments, including performance-oriented paths like AOT Inductor/ExecuTorch and quantization options. It is directly applicable to ML engineering workflows for testing, benchmarking, and deploying LLMs on-device or on edge/desktop/server. While it is archived (no longer actively developed), it remains highly relevant and educational as a practical reference implementation for PyTorch-based LLM execution and deployment, justifying a high (but not perfect) score.",success
https://github.com/rlcode/reinforcement-learning,reinforcement-learning,"A collection of minimal, easy-to-read Python implementations of reinforcement learning and deep reinforcement learning algorithms (one file per algorithm), with examples across Grid World, CartPole, and Atari (e.g., DQN/DDQN/A3C and policy gradients). It is intended as clean reference/educational code and includes topic-focused subfolders and basic dependency instructions (notably TensorFlow 1.x-era).",3600,reinforcement learning|deep reinforcement learning|machine learning|python|tensorflow|openai gym|dqn|policy gradient,9,"This repository provides compact reference implementations of core reinforcement learning and deep RL algorithms (e.g., DQN variants, policy gradients, actor-critic/A2C/A3C) across classic environments like Grid World, CartPole, and Atari. It is directly applicable for ML practitioners who want readable baseline code for experimentation, learning, or adapting algorithms to new environments, and it is clearly ML-centric rather than a general software utility. Its strong educational value and community adoption (thousands of stars) support a high score, although some dependencies are dated (TensorFlow 1.x), which slightly limits modern plug-and-play use compared to current RL libraries.",success
https://github.com/BeastByteAI/scikit-llm,scikit-llm,"Scikit-LLM is a Python library that integrates large language models (e.g., ChatGPT/GPT) into scikit-learn-style workflows, enabling tasks like zero-shot text classification using familiar estimator APIs.",3500,machine learning|natural language processing|large language models|scikit-learn|python|text classification|chatgpt,9,"This repository provides scikit-learn-compatible components that let practitioners apply LLMs to text analysis problems (e.g., zero-shot classification) with an estimator-like fit/predict interface. It directly supports common ML/NLP workflows by making LLM usage look and feel like standard scikit-learn pipelines, lowering integration friction for data scientists. With thousands of GitHub stars and a released package, it shows meaningful community adoption and practical applicability, though it is more an integration/utility layer than a full model-training framework—hence a 9 rather than a 10.",success
https://github.com/POSTECH-CVLab/PyTorch-StudioGAN,PyTorch-StudioGAN,"StudioGAN is a PyTorch library that implements a wide range of modern GAN architectures and training components for conditional and unconditional image generation, providing a unified, configurable playground for fair comparison and analysis. It also includes a large-scale benchmark with pretrained models, logs, and evaluation tooling across multiple generative model families.",3500,machine learning|deep learning|generative adversarial networks|image generation|pytorch|computer vision|benchmarking,9,"This repository is primarily an ML research/engineering framework for training and evaluating many representative GAN variants for image synthesis, with a configuration-driven setup (YAML) and modular options for architectures, conditioning, losses, regularization, augmentations, and metrics. It directly supports core ML workflows (model training, evaluation with common metrics like IS/FID and multiple backbones, reproducibility checks, and pretrained checkpoints/logs), making it highly usable for ML practitioners working on generative vision. Community adoption appears strong for a research toolkit (thousands of GitHub stars and hundreds of forks), and the accompanying benchmark and paper references add educational and comparative value. It is not a universal “core” industry standard like PyTorch itself, but it is a highly relevant, specialized toolkit for generative modeling research and experimentation.",success
https://github.com/foolwood/SiamMask,SiamMask,"Official PyTorch implementation of SiamMask (CVPR 2019 / TPAMI 2023), a framework for fast online visual object tracking with simultaneous object segmentation. The repository includes code for both training and inference, plus demo/evaluation scripts and pretrained model download instructions.",3500,computer vision|object tracking|video segmentation|pytorch|deep learning|instance segmentation|research code,9,"This repository implements a published deep learning method (SiamMask) for online single-object tracking and segmentation, providing end-to-end code for training, testing, and running demos. It is directly applicable to ML/CV workflows (model training, evaluation on benchmarks like VOT/DAVIS, and inference with pretrained weights) and is a strong reference implementation for learning and experimentation. Community adoption appears high for an academic CV repo (thousands of stars), and it integrates with common ML tooling (PyTorch, CUDA). It is not a general-purpose ML framework, but it is a highly relevant, practical research implementation, hence a 9/10.",success
https://github.com/google-research/football,football,"Google Research Football (GRF) is a reinforcement-learning environment based on the open-source Gameplay Football game, providing a controllable football/soccer simulator with multiple scenarios, observation/action APIs, and support for training agents (e.g., PPO) and playing against built-in AI or trained agents.",3500,reinforcement learning|RL environment|simulation|soccer|Python|C++|OpenAI Gym-style API|multi-agent,9,"This repository’s primary purpose is to provide a research-grade RL environment for training and evaluating agents in a complex, multi-agent soccer setting, including scenario definitions, observation/action interfaces, and example training scripts. It directly supports common ML workflows by enabling reproducible agent training (e.g., PPO-style training), offline experimentation, and benchmarking in a realistic simulated environment. Its strong fit for RL research and practical agent development makes it highly valuable for ML practitioners, though it is less central for non-RL data science tasks (e.g., tabular modeling), so it scores slightly below a 10.",success
https://github.com/jmschrei/pomegranate,pomegranate,"Pomegranate is a Python library for fast, flexible probabilistic modeling, providing modular probability distributions and higher-level models such as mixture models, Bayesian networks, and hidden Markov models. Newer releases (v1.x) are a ground-up rewrite using PyTorch as the computational backend for better speed and GPU/mixed-precision support.",3500,machine learning|probabilistic modeling|bayesian networks|hidden markov models|mixture models|python|pytorch,9,"This repository is primarily an ML-focused probabilistic modeling library that implements distributions and classic probabilistic models (e.g., mixture models, Bayesian networks, HMMs) used for density estimation, clustering, and sequence modeling. It is directly applicable in data science/ML workflows for modeling uncertainty, generative modeling, and probabilistic inference/training, and it integrates with PyTorch (including GPU and mixed-precision support) which improves interoperability in modern ML stacks. With thousands of GitHub stars, it shows substantial community adoption for a specialized probabilistic modeling toolkit, though it is not as universally foundational as general-purpose libraries like PyTorch itself.",success
https://github.com/microsoft/hummingbird,hummingbird,"Hummingbird is a Python library that compiles trained traditional ML models into tensor computations to accelerate inference by running them on neural-network frameworks. It can convert models (e.g., scikit-learn, LightGBM, XGBoost) to backends like PyTorch/TorchScript, ONNX, and TVM while offering a sklearn-like inference API.",3500,machine-learning|model-inference|model-compilation|pytorch|onnx|tvm|scikit-learn|ml-serving,9,"This repository focuses on compiling classical/traditional ML models into tensor-based representations for faster inference, enabling hardware acceleration and deployment via common ML runtimes (e.g., PyTorch/TorchScript, ONNX, TVM). It directly fits ML engineering workflows for model serving and inference optimization, especially for tree-based models and sklearn-style pipelines. The project also shows meaningful community adoption (thousands of GitHub stars) and strong educational value by demonstrating how classical models can be transformed into tensor computations for optimized execution.",success
https://github.com/podgorskiy/ALAE,ALAE,"Official implementation of the CVPR 2020 paper ""Adversarial Latent Autoencoders (ALAE)"", providing PyTorch code and scripts for training and running demos of ALAE/StyleALAE (a StyleGAN-based autoencoder) for high-quality image generation, reconstruction, and latent-space manipulation.",3500,machine learning|deep learning|computer vision|generative models|GAN|autoencoder|PyTorch,9,"This repository implements Adversarial Latent Autoencoders (ALAE), including a StyleGAN-based variant (StyleALAE), with training code, configs, and an interactive demo for generating and manipulating images in latent space. It is directly applicable to ML workflows for generative modeling research/experimentation (training, inference, and latent editing) and is built around PyTorch with CUDA GPU support. Its strong community adoption (thousands of GitHub stars) and educational value for understanding GAN-style training combined with autoencoder inversion make it highly valuable for ML practitioners, though it is more specialized than general-purpose ML libraries.",success
https://github.com/richzhang/colorization,colorization,"Implements automatic image colorization using deep neural networks from the paper ""Colorful Image Colorization"" (ECCV 2016), with pretrained models and a runnable demo script. The repository was later updated to support minimal test-time inference in PyTorch (with the original training/testing code kept in a legacy Caffe branch).",3500,computer vision|image colorization|deep learning|PyTorch|Caffe (legacy)|pretrained models|research code,9,"This repository provides pretrained deep neural networks and code to perform automatic (and related interactive-method) image colorization, a core computer-vision ML task. It is directly useful in ML workflows for inference, demos, and as a baseline/reference implementation for research or product prototyping, though it is more focused on test-time usage than full modern training pipelines. Community adoption appears strong (thousands of GitHub stars), and it has high educational value because it ties directly to a well-known academic paper and includes clear demo usage.",success
https://github.com/tensorflow/hub,hub,"TensorFlow Hub (`tensorflow_hub`) is a Python library for transfer learning that lets you download, load, and reuse TensorFlow SavedModels (pretrained model modules) with minimal code. It includes documentation and examples for integrating reusable model components such as embeddings and image/text models into TensorFlow workflows.",3500,machine learning|tensorflow|transfer learning|model hub|pretrained models|embeddings|python,9,"This repository provides the official `tensorflow_hub` library, whose primary use case is enabling reuse of pretrained TensorFlow SavedModels for transfer learning (e.g., embeddings, image classification, and other reusable model components). It directly supports common ML engineering workflows by simplifying model retrieval, caching, and loading into TensorFlow programs, and it is part of the broader TensorFlow ecosystem with substantial community usage. While it is not a full training framework by itself (it complements TensorFlow rather than replacing it), it is highly practical and widely applicable for ML practitioners integrating pretrained models into pipelines, so it merits a high score.",success
https://github.com/visionml/pytracking,pytracking,"PyTracking is a PyTorch-based framework for visual object tracking and video object segmentation. It provides implementations, training code, and pretrained models for multiple state-of-the-art trackers (e.g., ATOM, DiMP, PrDiMP, KeepTrack, ToMP, RTS, TaMOs) plus tooling for datasets and benchmark evaluation.",3500,computer vision|object tracking|video object segmentation|pytorch|deep learning|model training|benchmarking,9,"This repository is a research-grade ML framework focused on training and evaluating deep visual trackers and video object segmentation methods, with official implementations of several influential trackers and a dedicated training framework (LTR). It is directly applicable to ML workflows involving dataset handling, model training, inference, and standardized benchmark evaluation in tracking/VOS, and it includes pretrained models and tooling to reproduce/compare results. Community adoption appears strong for a specialized research codebase (about 3.5k GitHub stars), but it is narrower in scope and generality than foundational ML libraries (e.g., PyTorch itself), so it scores below a 10.",success
https://github.com/PaddlePaddle/PARL,PARL,"PARL is a flexible reinforcement learning (RL) framework that provides reusable abstractions (Model/Algorithm/Agent) and supports high-performance distributed/parallel training (e.g., via remote actors) across CPU clusters and multi-GPU setups.",3400,reinforcement learning|distributed training|paddlepaddle|python|deep learning|multi-agent systems|parallel computing,9,"This repository is purpose-built for reinforcement learning, providing core RL abstractions and a collection of reproducible RL algorithms plus examples. It directly supports ML engineering workflows by enabling scalable/distributed RL training through its parallelization and remote execution APIs, which is highly relevant to training and experimentation. Community adoption appears strong for a specialized RL framework (thousands of GitHub stars and hundreds of forks), and the documentation/tutorials make it useful for both practitioners and learning. It is scored 9 (not 10) because its primary focus is RL (a subdomain) rather than a general-purpose, broadly dominant ML foundation library across all ML tasks.",success
https://github.com/SciSharp/TensorFlow.NET,TensorFlow.NET,"TensorFlow.NET (TF.NET) provides .NET Standard bindings for Google’s TensorFlow, enabling .NET developers to develop, train, and deploy machine learning models in C# and F#. It aims to mirror the TensorFlow API and includes a built-in Keras high-level interface (also available as the separate TensorFlow.Keras package).",3400,machine learning|deep learning|tensorflow|.NET|C#|F#|keras,9,"This repository is a core ML framework binding that brings TensorFlow’s APIs to the .NET ecosystem, allowing model training and inference directly from C# and F# rather than only consuming pre-trained Python models. It is directly applicable to common ML workflows (data preprocessing via companion libraries, model building/training, deployment) and integrates with Keras as a high-level API, making it highly useful for .NET-centric data science/ML engineering. Community adoption appears solid for the .NET ML space (thousands of GitHub stars), but it is not as universally dominant as the primary Python TensorFlow ecosystem, and the README notes maintainer bandwidth limitations—so it falls short of a “10” reserved for top industry-standard core libraries.",success
https://github.com/SwanHubX/SwanLab,SwanLab,"SwanLab is an open-source AI/deep-learning experiment tracking, observability, and visualization tool (similar in use case to W&B/TensorBoard) that logs metrics/hyperparameters and provides a web UI for monitoring, comparison, and collaboration. It supports cloud and self-hosted/offline usage and integrates with many training ecosystems (e.g., PyTorch, Transformers, Keras, Ultralytics, MMEngine, etc.).",3400,mlops|experiment-tracking|training-visualization|deep-learning|python|observability|self-hosted,9,"SwanLab’s primary purpose is ML experiment tracking and training observability: it collects and logs training metrics/hyperparameters, monitors hardware/resources, and provides dashboards and comparison views for experiments. This is directly applicable to common ML workflows (research iteration, hyperparameter tuning, reproducibility, and team collaboration) and integrates with a broad set of popular training frameworks. Its star count indicates meaningful community adoption for an MLOps-style tool, but it is not a foundational ML framework/library itself, so it scores slightly below a 10.",success
https://github.com/dair-ai/ML-Notebooks,ML-Notebooks,"A collection of minimal, reusable, and extensible Jupyter notebooks covering practical machine learning tasks and concepts (e.g., PyTorch basics, NLP, transformers, computer vision, GANs, and parameter-efficient fine-tuning like LoRA/QLoRA). Includes ready-to-run Colab notebooks and a Codespaces/devcontainer setup for a preconfigured environment.",3400,machine learning|jupyter notebooks|pytorch|nlp|transformers|computer vision|fine-tuning,9,"This repository primarily provides hands-on machine learning notebooks intended for education, experimentation, and adaptation across many ML problem types (classification, translation, NER, QA, image similarity, GANs, etc.). It maps directly to common ML/data workflows by offering runnable reference implementations (often via Colab) and an environment setup (Codespaces + conda spec) that supports practical execution. Community adoption appears strong for an educational repo (around 3.4k GitHub stars), indicating broad utility. It scores a 9 (highly relevant) because it is an applied ML learning/implementation resource rather than a foundational, widely-depended-on production library.",success
https://github.com/datamllab/rlcard,rlcard,"RLCard is a Python toolkit for reinforcement learning in card games, providing multiple card-game environments plus implementations/interfaces for RL and search algorithms to study imperfect-information, multi-agent settings (e.g., poker variants, Blackjack, UNO, Dou Dizhu, Mahjong).",3400,reinforcement learning|multi-agent learning|game AI|imperfect-information games|Python|PyTorch|TensorFlow|PettingZoo,9,"This repository’s primary purpose is ML research/engineering: it provides standardized card-game environments and agent/training interfaces for reinforcement learning and related search methods in imperfect-information games. It is directly applicable to ML workflows for benchmarking and developing RL algorithms (including deep RL), and it integrates with common ML tooling (e.g., optional PyTorch/TensorFlow components and PettingZoo compatibility). Community adoption appears strong for a specialized RL toolkit (notable star count and ecosystem references like PyPI), but it is not a general-purpose core industry library on the level of PyTorch/TensorFlow, so it scores just below 10.",success
https://github.com/ruc-datalab/DeepAnalyze,DeepAnalyze,"DeepAnalyze is an agentic large language model and toolkit for autonomous data science, designed to run end-to-end workflows such as data preparation, analysis, modeling, visualization, and report generation. It supports “deep research” over multiple data formats (e.g., CSV/Excel/DBs, JSON/XML/YAML, and text/Markdown) and provides demo interfaces (WebUI, Jupyter UI, CLI) plus an OpenAI-style API for deployment.",3400,agentic llm|autonomous data science|data analysis|llm tooling|vllm|openai-style api|jupyter|report generation,9,"This repository provides an agentic LLM system explicitly built to automate core data science tasks (data preparation, analysis, modeling, visualization, and producing analyst-grade reports) across diverse data sources and formats. It is directly applicable to ML/data workflows via its deployable model setup (e.g., vLLM serving), OpenAI-style API endpoints, and multiple user interfaces (WebUI/Jupyter/CLI) that make it usable as a data analysis assistant. Community adoption appears meaningful (thousands of GitHub stars), though it is not at the “industry-standard foundational library” level of tools like PyTorch or Pandas, so a 9 (highly relevant) fits better than a 10.",success
https://github.com/sdv-dev/SDV,SDV,"SDV (Synthetic Data Vault) is a Python library for generating synthetic tabular data by learning patterns from real datasets using a range of statistical and machine-learning models. It supports single-table, multi-table/relational, and sequential data synthesis, plus evaluation, visualization, anonymization, and constraints.",3400,synthetic data|tabular data|python|machine learning|data privacy|data generation|data evaluation,9,"This repository provides a full-featured synthetic tabular data generation toolkit, including multiple modeling approaches (from classical statistical methods to deep-learning-based models), as well as evaluation and reporting tools. It is directly applicable to common ML/data workflows (data augmentation, privacy-preserving data sharing, model development/testing) and is designed specifically for data science use cases. The project shows meaningful community adoption (thousands of GitHub stars) and offers practical integrations via standard Python packaging and documentation, justifying a high relevance score.",success
https://github.com/towhee-io/towhee,towhee,"Towhee is an open-source framework for building neural (LLM- and model-driven) data processing pipelines, especially for unstructured data like text, images, audio, and video. It provides a Pythonic pipeline API plus a library of operators and prebuilt pipelines to generate embeddings and support tasks like retrieval/RAG and multimodal search.",3400,machine learning|data pipelines|embeddings|multimodal|LLM orchestration|vector databases|computer vision|NLP,9,"This repository provides a dedicated framework for neural/unstructured-data pipelines, including operator-based composition and prebuilt workflows (e.g., sentence/image embeddings, video deduplication, and document Q&A/RAG-style pipelines). It is directly applicable to ML engineering and data workflows where you need to transform raw unstructured data into embeddings and feed downstream systems like vector databases or retrieval services. The project shows meaningful community adoption (thousands of GitHub stars) and strong integration value for building practical ML-powered applications, justifying a high score.",success
https://github.com/EvolvingLMMs-Lab/Otter,Otter,"Otter is an open-source instruction-tuned multimodal (vision-language) model built on OpenFlamingo, trained on the MIMIC-IT instruction dataset to improve instruction-following and in-context learning for image/video understanding. The repository includes code for training/fine-tuning pipelines, evaluation/benchmark integrations, and links to released model checkpoints.",3300,multimodal|vision-language-model|instruction-tuning|computer-vision|nlp|pytorch|openflamingo|huggingface,9,"This repository’s primary purpose is ML: it provides an instruction-tuned large multimodal model (based on OpenFlamingo) plus training/fine-tuning and evaluation tooling for vision-language tasks. It is directly applicable to ML workflows (model training, checkpoint usage, and benchmark evaluation) and has substantial community adoption as indicated by its ~3.3k GitHub stars. While it is not a general-purpose framework at the scale of PyTorch/TensorFlow, it is highly educational and practical for researchers/engineers working on instruction-tuned multimodal LMMs, which justifies a score of 9 rather than 10.",success
https://github.com/Farama-Foundation/PettingZoo,PettingZoo,"PettingZoo is a Python library that standardizes APIs for multi-agent reinforcement learning (MARL) environments, similar in spirit to Gymnasium for single-agent RL. It provides a large suite of reference multi-agent environments (e.g., Atari, Classic games, MPE, SISL) plus utilities and documentation to support benchmarking and research workflows.",3300,reinforcement learning|multi-agent reinforcement learning|python|simulation environments|gymnasium-compatible|benchmarking,9,"This repository provides a standardized environment API and a broad set of ready-to-use multi-agent RL benchmark environments, which are foundational components for training and evaluating MARL algorithms. It directly supports core ML workflows (environment interaction loops, reproducible benchmarking via strict environment versioning, and integrations/tutorials with RL libraries), making it highly applicable for ML engineers and researchers. Its strong community adoption and positioning as a key Farama Foundation core project further increase its practical value for ML research and education.",success
https://github.com/MilesCranmer/PySR,PySR,"PySR is an open-source symbolic regression library that searches for compact, interpretable mathematical expressions that fit data. It provides a high-performance Python interface backed by a Julia search engine (SymbolicRegression.jl), with configurable objectives and workflows for discovering analytic equations from datasets.",3300,symbolic-regression|machine-learning|interpretable-ml|equation-discovery|scientific-ml|python|julia,9,"PySR is purpose-built for symbolic regression—an ML task focused on discovering human-interpretable equations from data—making it directly applicable to data science workflows where model transparency and analytic forms matter. It is designed for high performance and configurability, and it integrates a Julia backend search engine (SymbolicRegression.jl) while offering a Python-facing API that is easy to incorporate into typical ML experimentation. The repository also provides documentation, examples, and installation options (pip/conda/docker), indicating strong practical utility and adoption within the interpretable/scientific ML community. It is not a general-purpose ML framework on the scale of PyTorch/TensorFlow, but it is a highly valuable specialized ML tool, justifying a 9/10.",success
https://github.com/MiniMax-AI/MiniMax-01,MiniMax-01,"Official repository for the MiniMax-Text-01 (LLM) and MiniMax-VL-01 (vision-language) models built around linear/lightning attention and MoE, including model cards, a technical PDF, evaluation materials, and inference-related code/assets.",3300,large language models|vision-language models|linear attention|mixture-of-experts|multimodal AI|model evaluation|inference,9,"This repository is centered on two foundation models (MiniMax-Text-01 and MiniMax-VL-01) and includes core documentation (README/model cards/technical PDF) plus evaluation and inference resources, making it directly applicable to ML engineering work. It is highly relevant to ML workflows (model understanding, benchmarking, and running inference for LLM/VLM systems), rather than being a general-purpose software project. Community adoption appears strong for a model release repo (on the order of ~3.3k GitHub stars), indicating meaningful interest and usage in the ML community. It scores a 9 (not a 10) because it is primarily a specific-model release and related tooling/docs, not a ubiquitous general ML framework like PyTorch or TensorFlow.",success
https://github.com/QData/TextAttack,TextAttack,"TextAttack is a Python framework for natural language processing (NLP) adversarial attacks, dataset augmentation, and out-of-the-box model training. It provides a CLI and Python APIs to run attack “recipes,” augment text datasets, and train/finetune models (including Transformers) with built-in integrations.",3300,natural language processing|adversarial machine learning|data augmentation|robustness evaluation|transformers|pytorch|python,9,"This repository’s primary purpose is to generate and evaluate adversarial examples for NLP models, as well as to augment text datasets and train/finetune models via a unified framework and CLI. It is directly applicable to common ML workflows (robustness testing, adversarial training, augmentation pipelines) and integrates with widely used tooling like Hugging Face Transformers/datasets. With thousands of GitHub stars and a packaged PyPI release, it shows strong community adoption and practical/educational value for ML practitioners, warranting a high score (though it is not a general-purpose ML framework on the scale of PyTorch/TensorFlow).",success
https://github.com/algorithmicsuperintelligence/optillm,optillm,"OptiLLM is an OpenAI API-compatible optimizing inference proxy for LLMs that applies 20+ inference-time techniques (e.g., best-of-N, multi-agent methods, planning, MCTS) to improve reasoning accuracy and performance without training or fine-tuning. It acts as a drop-in proxy in front of OpenAI-compatible endpoints and supports multiple providers/models (including via LiteLLM).",3300,LLM|inference-optimization|OpenAI-compatible-API|reasoning|multi-agent|prompting|MLOps|Python,9,"This repository provides a production-oriented inference proxy that improves LLM reasoning quality using a large set of inference-time algorithms (e.g., best-of-N, multi-agent reasoning, planning/search, MCTS) without any model training. It is directly applicable to ML/LLM engineering workflows because it can sit transparently in front of OpenAI-compatible APIs and enhance accuracy on benchmarks and real tasks with minimal integration changes. While it is not a training framework and doesn’t focus on dataset/model development, it is highly relevant for deploying and optimizing LLM-based systems and appears to have meaningful adoption (thousands of stars) and practical demos (Docker, pip install, Colab/HF references).",success
https://github.com/fastai/course22,course22,"Repository containing the fast.ai 2022 “Practical Deep Learning for Coders” course materials, including Jupyter notebooks, slides, and spreadsheets. It also provides cleaned versions of notebooks and guidance for running the materials (e.g., via GitHub Codespaces).",3300,machine learning|deep learning|fastai|python|jupyter notebooks|computer vision|education,9,"This repo is primarily an educational set of practical deep learning course materials (notebooks, slides, and related assets) for the fast.ai 2022 course. It is directly applicable to ML workflows because the notebooks walk through building and training models (e.g., image models, neural nets, random forests) using Python and the fastai ecosystem. While it is not a general-purpose ML framework itself, it has high educational value and practical examples that ML practitioners can reuse and adapt, justifying a high score short of a 10.",success
https://github.com/tianzhi0549/FCOS,FCOS,"Official implementation of the FCOS (Fully Convolutional One-Stage) anchor-free object detection method from ICCV 2019, including training/inference code, configs, demos, and utilities such as ONNX export. Built on the maskrcnn-benchmark codebase and intended for COCO-style object detection experiments and deployment.",3300,computer vision|object detection|deep learning|PyTorch|anchor-free detection|maskrcnn-benchmark|ONNX,9,"This repository implements FCOS, a well-known deep learning model for object detection (computer vision) and includes training/evaluation pipelines, configuration files, and demo tooling, which directly supports ML engineering workflows. It is highly applicable for researchers and practitioners working on detection tasks (e.g., COCO-style datasets) and provides practical artifacts (model zoo references, export tooling) that aid experimentation and deployment. Community adoption appears strong for a research implementation (thousands of GitHub stars and hundreds of forks), and it also has educational value by exposing a complete detection system built on established tooling. It is not a general-purpose ML framework, but it is a highly relevant, production-adjacent model implementation for CV ML work, justifying a 9/10.",success
https://github.com/tirthajyoti/Machine-Learning-with-Python,Machine-Learning-with-Python,"A large collection of practice and tutorial-style Jupyter notebooks demonstrating machine learning and data science techniques in Python, spanning topics like regression, classification, clustering/dimensionality reduction, datasets, and deployment examples.",3300,machine learning|data science|python|jupyter notebooks|scikit-learn|pandas|tensorflow|streamlit,9,"This repository is primarily an educational/learning resource: it contains many tutorial-style Jupyter notebooks organized by ML topics (e.g., regression, classification, clustering/dimensionality reduction) plus supporting areas like datasets and deployment. It is directly applicable to ML/data workflows because practitioners can run, adapt, and reuse the notebooks as references or starting points for experimentation and prototyping with common Python ML libraries. Community adoption appears solid (thousands of GitHub stars), indicating it is widely used as a learning/reference repo. It scores a 9 (highly relevant) because it is strongly focused on ML/data methods and practical code, though it is not a foundational industry framework/library at the level of a 10.",success
https://github.com/VainF/Torch-Pruning,Torch-Pruning,"Torch-Pruning is a PyTorch framework for structural (channel/neurons) pruning of deep neural networks using a dependency-graph algorithm (DepGraph) to automatically track and prune coupled parameters across layers. It provides pruning utilities and examples for many model families (e.g., Hugging Face LLMs, vision transformers, diffusion models, YOLO, SAM) and supports PyTorch 1.x/2.x.",3200,machine-learning|deep-learning|pytorch|model-compression|neural-network-pruning|llm|computer-vision,9,"This repository is primarily a model-compression toolkit for PyTorch, focused on structural pruning via its DepGraph mechanism that handles inter-layer dependencies automatically. It is directly applicable to common ML workflows (speeding up inference, reducing model size/latency, and pruning popular architectures including LLMs and vision foundation models) and includes practical examples for real-world model families. Given its clear ML-first purpose and substantial community adoption (3.2k GitHub stars), it merits a high score, though it is more specialized than broad ML foundations like core frameworks.",success
https://github.com/XinJingHao/DRL-Pytorch,DRL-Pytorch,"A clean, robust, unified set of PyTorch implementations of popular Deep Reinforcement Learning algorithms, with separate runnable folders per algorithm (e.g., Q-learning, DQN variants, PPO, DDPG, TD3, SAC, and Actor-Sharer-Learner). It targets practical training from scratch via simple entry points (e.g., running each folder’s main.py) and uses standard RL dependencies such as Gymnasium and PyTorch.",3200,deep reinforcement learning|pytorch|reinforcement learning|dqn|ppo|sac|td3|gymnasium,9,"This repository primarily provides working PyTorch implementations of multiple deep reinforcement learning algorithms (including value-based and actor-critic methods) intended for training agents in simulation environments. It is directly applicable to ML workflows for RL research/education and as a reference baseline for implementing and comparing algorithms, and it integrates with common ML tooling (PyTorch) and RL environments (Gymnasium). Community adoption appears strong for a specialized RL codebase (thousands of GitHub stars), and the structured per-algorithm folders plus clear dependencies make it highly useful for learning and experimentation. It is not a general-purpose data science library, but as an RL training/implementation resource it is highly relevant, hence a 9/10.",success
https://github.com/adambielski/siamese-triplet,siamese-triplet,"PyTorch implementation of siamese and triplet networks for learning embedding representations, including online pair/triplet mining (negative mining) utilities. Includes example experiments (e.g., MNIST/FashionMNIST) and modular components for datasets, networks, losses, selectors, metrics, and training.",3200,machine learning|deep learning|PyTorch|metric learning|siamese networks|triplet loss|representation learning|computer vision,9,"This repository provides a practical PyTorch codebase for metric learning with siamese and triplet architectures, including key training components like contrastive/triplet losses and online pair/triplet mining. It is directly applicable to ML workflows involving embedding learning, similarity search, face/image retrieval, and few-shot learning, and it includes runnable notebook experiments for learning and validation. Its strong GitHub adoption (~3.2k stars) and clear modular structure make it highly valuable for ML practitioners and learners, though it is not a broad general-purpose framework on the scale of core libraries like PyTorch itself.",success
https://github.com/alpa-projects/alpa,alpa,"Alpa is a system for training and serving large-scale neural networks with automatic parallelization, enabling single-device JAX code to run efficiently on distributed clusters using data, operator, and pipeline parallelism. The repository is archived (read-only) and noted as not actively maintained; its core auto-sharding algorithm has been merged into OpenXLA/XLA.",3200,machine learning|deep learning|distributed training|auto parallelization|JAX|XLA|Ray|LLM serving,9,"This repository provides an ML systems framework focused on scaling the training and inference/serving of very large neural networks through automated distributed parallelization, integrating with JAX/XLA and Ray. It directly supports core ML workflows (distributed training and LLM serving) and includes documentation/examples aimed at ML engineers working on large models. Despite being archived and not actively maintained, it remains highly relevant as a research artifact and because its core auto-sharding work was merged into OpenXLA/XLA, so the technical ideas and implementation remain valuable for advanced ML infrastructure work.",success
https://github.com/determined-ai/determined,determined,"Determined is an open-source machine learning platform for orchestrating deep learning workloads, providing distributed training, hyperparameter tuning, experiment tracking, and cluster/resource management. It integrates with PyTorch and TensorFlow and includes a Python SDK, CLI, and Web UI.",3200,machine learning|deep learning|MLOps|distributed training|hyperparameter tuning|experiment tracking|PyTorch|TensorFlow,9,"This repository implements an end-to-end ML platform focused on training orchestration: distributed training, hyperparameter search, experiment tracking, and resource management via a Python library, CLI, and Web UI. It directly supports common ML workflows (running experiments, tuning, tracking, and managing GPU/cluster utilization) and integrates with major frameworks like PyTorch and TensorFlow. Its scope and adoption (thousands of GitHub stars) indicate meaningful community usage. It scores a 9 because it is a highly relevant, practical MLOps/training platform, though it is not as universally foundational as core ML libraries like PyTorch itself.",success
https://github.com/google-deepmind/dm-haiku,dm-haiku,"Haiku is a JAX-based neural network library that provides a module abstraction (hk.Module) and function transformation (hk.transform) to let you write object-oriented model code while retaining compatibility with JAX transformations like jit/grad/pmap. It is best-effort supported in maintenance mode, focusing on bug fixes and compatibility with new JAX/Python releases (DeepMind recommends Flax for new projects).",3200,machine learning|deep learning|jax|neural networks|python|research library|model building,9,"dm-haiku is explicitly built for machine learning: it’s a neural network library on top of JAX, providing core abstractions for defining models and managing parameters/state in JAX workflows. It’s directly applicable to ML engineering and research (model definition, initialization, application) and integrates tightly with JAX transformations used in training and evaluation. While it has meaningful adoption (thousands of GitHub stars) and strong educational value for learning JAX-style model construction, it is in maintenance mode and DeepMind recommends Flax for new projects, which slightly reduces its forward-looking value versus the most actively developed frameworks.",success
https://github.com/huggingface/huggingface_hub,huggingface_hub,"The official Python client for the Hugging Face Hub, providing programmatic and CLI access to download/upload files, manage Hub repositories (models/datasets/Spaces), search Hub content, and run inference via Hub-hosted APIs.",3200,machine-learning|python|mlops|model-registry|dataset-management|hugging-face|api-client,9,"This repository provides the core Python SDK used to interact with the Hugging Face Hub (models, datasets, and Spaces), including capabilities like snapshot downloads, uploads, repository management, discovery/search, authentication, and inference API access. It is directly applicable to day-to-day ML and data workflows because it is the standard way many practitioners fetch pretrained models/datasets, version artifacts, and integrate Hub assets into training/inference pipelines. Community adoption is high (widely used across the Hugging Face ecosystem and beyond), and it integrates broadly with ML tooling that depends on Hub-hosted artifacts. It is not a training framework itself, but it is a central dependency and workflow enabler for ML practitioners, justifying a 9/10 rather than a perfect 10.",success
https://github.com/mljar/mljar-supervised,mljar-supervised,"mljar-supervised is a Python AutoML package for tabular data that automates preprocessing, feature engineering, model selection, and hyperparameter tuning, while generating detailed markdown reports with explanations (including permutation importance and SHAP). It supports multiple training modes (e.g., Explain/Perform/Compete/Optuna) for exploration, production pipelines, and high-performance ensembling/stacking.",3200,automl|tabular-machine-learning|python|feature-engineering|hyperparameter-optimization|model-explainability|shap|ensemble-learning,9,"This repository provides an end-to-end AutoML system specifically for supervised learning on tabular datasets, including preprocessing, feature engineering, algorithm selection, tuning, and ensembling/stacking, with multiple modes tailored to different ML goals. It directly fits common data science workflows by producing trained models plus experiment artifacts and documentation, and includes explainability outputs (e.g., permutation importance and SHAP) that are valuable for analysis and stakeholder reporting. The project shows strong practical utility and community adoption for an AutoML library (thousands of GitHub stars), though it is narrower than foundational ML frameworks (e.g., not a general deep learning framework), which is why it scores a 9 rather than a 10.",success
https://github.com/wenge-research/YAYI,YAYI,"YaYi (雅意) is a Chinese-optimized large language model project from Wenge Research, providing model releases (e.g., 7B/13B LLaMA 2 and BLOOM-based variants) plus code and configs for inference and instruction/chat fine-tuning. The repo includes training scripts (DeepSpeed), example instruction data formats, and usage guidance with Hugging Face Transformers.",3200,large language model|NLP|Chinese LLM|instruction tuning|fine-tuning|Hugging Face Transformers|DeepSpeed|PyTorch,9,"This repository centers on releasing and using/fine-tuning the YaYi large language models (including LLaMA 2 and BLOOM-based variants) and provides practical code/configuration for inference and training (including full-parameter and LoRA-style fine-tuning via DeepSpeed). It is directly applicable to ML/NLP workflows: model loading with Transformers, prompt formatting, and training pipelines/data formats are provided, making it useful for practitioners building or adapting Chinese LLMs. Community adoption appears solid (about 3.2k GitHub stars), but it is not a general-purpose ML framework at the scale of PyTorch/TensorFlow, and the repo is archived (read-only as of Mar 30, 2025), which slightly limits ongoing integration and maintenance—hence a 9 rather than 10.",success
https://github.com/CVI-SZU/Linly,Linly,"Linly is an open-source collection of Chinese large language models and related resources, including Chinese-LLaMA (v1/v2), Chinese-Falcon, Linly-OpenLLaMA, and the Linly-ChatFlow Chinese chat/instruction-following model. The repository provides model training/evaluation workflows, dataset preparation, and deployment/quantization options for inference on CUDA and edge devices.",3100,large language models|NLP|Chinese language|LLaMA|Falcon|instruction tuning|pretraining datasets|model quantization,9,"This repository’s primary purpose is to develop, train, evaluate, and deploy Chinese-focused LLMs (e.g., Chinese-LLaMA 1/2, Chinese-Falcon, Linly-OpenLLaMA, and Linly-ChatFlow), and it includes reproducible training pipelines plus supporting pretraining and instruction-tuning data resources. It is directly applicable to ML/NLP workflows (model pretraining, instruction fine-tuning, benchmarking, and inference/quantization deployment), making it highly useful for ML engineers and researchers working on Chinese LLMs. While it is not a general-purpose ML library with the broad industry adoption of core frameworks (e.g., PyTorch), it is a substantial, practical LLM/model+data resource with meaningful community usage (3.1k stars at the time of lookup).",success
https://github.com/Farama-Foundation/HighwayEnv,HighwayEnv,"HighwayEnv (highway-env) is a Python/Gymnasium-compatible collection of lightweight 2D driving simulation environments for autonomous driving and tactical decision-making, designed for training and evaluating reinforcement learning agents across tasks like highway driving, merging, roundabouts, intersections, parking, and racetracks.",3100,reinforcement learning|gymnasium|autonomous driving|simulation environments|python|decision-making|multi-agent traffic,9,"This repository provides ready-to-use Gymnasium environments that are purpose-built for reinforcement learning research and experimentation in autonomous driving decision-making (e.g., highway-v0, merge-v0, intersection-v0, parking-v0). It directly supports ML workflows by supplying standardized RL training interfaces (reset/step, observations, rewards) and is commonly paired with RL libraries/agents for large-scale training and benchmarking. Its strong relevance to RL, clear educational value (documented tasks and example agents), and substantial community adoption (3,100 GitHub stars) justify a high score, though it is primarily an environment/dataset generator rather than a full training framework.",success
https://github.com/NVIDIA/TransformerEngine,TransformerEngine,"Transformer Engine (TE) is an NVIDIA library that accelerates Transformer model training and inference on NVIDIA GPUs using highly optimized kernels and mixed-precision support (including FP8 and FP4) to improve throughput and reduce memory usage. It provides framework-integrated Python APIs (e.g., PyTorch, JAX) plus a framework-agnostic C++ API for enabling low-precision Transformer numerics in other DL libraries.",3100,machine learning|deep learning|transformers|LLM training|GPU acceleration|mixed precision|PyTorch|JAX,9,"This repository provides a specialized acceleration library for Transformer models, focusing on optimized building blocks and low-precision (FP8/FP4) numerics to speed up training and inference while reducing memory footprint on NVIDIA GPUs. It directly supports common ML engineering workflows via integrations/APIs for major frameworks (notably PyTorch and JAX) and is aimed at large-scale Transformer/LLM workloads. Given its direct applicability to model training/inference performance and broad relevance to LLM engineering (though more niche than full general-purpose frameworks like PyTorch itself), a 9/10 reflects very high ML value with strong practical adoption potential in GPU-based Transformer stacks.",success
https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On,Deep-Reinforcement-Learning-Hands-On,"Code samples and supporting project files for the Packt book ""Deep Reinforcement Learning Hands-On"" by Max Lapan, organized by chapter and focused on implementing deep RL algorithms and experiments using Python, PyTorch, and OpenAI Gym environments.",3100,reinforcement learning|deep reinforcement learning|pytorch|openai gym|python|educational|book code|rl algorithms,9,"This repository provides end-to-end, chapter-structured implementations of deep reinforcement learning methods (e.g., DQN variants, policy gradients, actor-critic methods, PPO/TRPO, and more) as practical code to accompany a well-known book. It is directly applicable for ML engineers and researchers who want working reference implementations, experiment scaffolding, and learning materials built around PyTorch and Gym-style environments. While it is primarily educational (and some dependencies/environments mentioned historically may be outdated or discontinued), it remains highly valuable for understanding and prototyping deep RL workflows, so it merits a 9 rather than a 10.",success
https://github.com/SkyworkAI/Skywork-R1V,Skywork-R1V,"Skywork-R1V is a repository for Skywork AI’s multimodal (vision-language) reasoning model series, including reports, inference tooling, and evaluation assets. It covers open-source model releases (e.g., R1V2/R1V3 weights and quantizations) and also documents usage for newer closed-source offerings (e.g., R1V4-Lite via API).",3100,multimodal-ai|vision-language-models|reasoning|computer-vision|llm|inference|evaluation,9,"This repository centers on state-of-the-art multimodal reasoning models (vision-language), providing model-related resources such as technical reports, inference code, and evaluation materials. It is directly applicable to ML workflows for running and benchmarking VLMs, and it references practical deployment paths (including quantized open models and an API-accessible variant). With strong community adoption indicated by thousands of GitHub stars, it is highly valuable for ML engineers and researchers working on multimodal reasoning, though it is not a general-purpose data science library like core ML frameworks.",success
https://github.com/THUDM/AgentBench,AgentBench,"AgentBench is a benchmark suite for evaluating large language models (LLMs) as autonomous agents across multiple interactive environments (e.g., OS interaction, databases, knowledge graphs, web shopping/browsing). The repository includes a newer function-calling (AgentBench FC) setup with containerized task deployments and a public leaderboard for comparing model performance.",3100,llm-agents|benchmarking|reinforcement-learning|function-calling|evaluation|docker|nlp,9,"This repository’s primary purpose is to benchmark and analyze LLMs used as agents in interactive, multi-environment tasks, including a function-calling version with containerized task infrastructure. It is directly applicable to ML workflows for agent evaluation, comparing models via standardized tasks/leaderboards, and (via the AgentBench FC/AgentRL integration) supporting agent training and experimentation setups. Community adoption appears strong for a research benchmark (thousands of GitHub stars), and it has significant educational and integration value for researchers/engineers building or evaluating LLM agent systems—hence a high score, though it is not a general-purpose ML framework at the scale of PyTorch/TensorFlow.",success
https://github.com/Tencent/tencent-ml-images,tencent-ml-images,"Tencent ML-Images publishes a large open-source multi-label image dataset defined as image URLs and annotations (sourced from ImageNet and Open Images), plus code and pretrained ResNet-101 checkpoints for pretraining and transfer learning (e.g., finetuning on ImageNet). It includes scripts and TensorFlow-based training/data-processing utilities for preparing TFRecords, training, finetuning, and feature extraction.",3100,machine learning|computer vision|image classification|multi-label classification|dataset|TensorFlow|transfer learning,9,"This repository centers on an ML-focused asset: a very large multi-label image dataset specification (URLs + labels across 11k+ categories) and an ImageNet-transfer-learning-ready pretrained ResNet-101 model, along with training/finetuning code. It is directly applicable to common ML workflows such as large-scale vision pretraining, multi-label learning, and representation learning/feature extraction. While the dataset distribution is URL-based (and some links may expire or require additional downloading steps), its scale, clear ML purpose, and included pretrained model/checkpoints make it highly valuable for ML practitioners, warranting a 9/10.",success
https://github.com/cleardusk/3DDFA_V2,3DDFA_V2,"Official PyTorch implementation of 3DDFA_V2 (ECCV 2020) for fast, accurate, and stable 3D dense face alignment by regressing 3DMM parameters from images. Includes FaceBoxes-based face detection, C++/Cython accelerated rendering, and optional ONNX Runtime inference for low-latency pipelines.",3100,computer vision|3d face alignment|face reconstruction|pytorch|onnxruntime|3d morphable model|face detection,9,"This repository provides a complete, research-grade computer vision system for 3D dense face alignment (3D face reconstruction/alignment) with runnable demos and pretrained components, centered on a PyTorch model that regresses 3DMM parameters. It directly supports ML workflows (inference, latency evaluation, optional ONNX Runtime acceleration) and is broadly applicable to downstream tasks like face tracking, pose estimation, and 3D mesh/texture outputs. Community adoption appears strong for a specialized academic CV repo (thousands of stars, active issues/PRs), and it has high educational value for learning practical 3D face modeling pipelines. It is not a general-purpose ML framework, but it is a highly relevant, well-scoped applied ML implementation, hence a 9 rather than a 10.",success
https://github.com/deepdoctection/deepdoctection,deepdoctection,"DeepDoctection is a Python Document AI / document understanding library that orchestrates document layout analysis, OCR, and document/token classification via configurable pipelines for PDF and scanned documents. It supports training/fine-tuning and inference using PyTorch-based models and integrates with tools like Detectron2, Hugging Face Transformers, Tesseract, DocTR, and AWS Textract.",3100,document-ai|computer-vision|ocr|document-layout-analysis|table-recognition|pytorch|huggingface-transformers|information-extraction,9,"This repository provides an end-to-end Document AI pipeline framework for extracting structure and text from PDFs/scans (layout analysis, OCR, table recognition) and performing document/token classification. It is directly applicable to ML/data workflows because it operationalizes multiple ML components (vision detectors, transformer classifiers) into reproducible pipelines and includes support for fine-tuning and evaluation. The project shows meaningful community adoption (thousands of GitHub stars) and integrates with standard ML tooling (PyTorch, Detectron2, Transformers), making it highly valuable for ML engineers and applied data scientists working on document understanding tasks.",success
https://github.com/docarray/docarray,docarray,"DocArray is a Python library for modeling and working with multimodal (nested, unstructured) data—representing it as typed documents, serializing/transmitting it, and indexing/searching it (including vector search) across multiple backends. It integrates with ML ecosystems (NumPy/PyTorch/TensorFlow/JAX), web frameworks (e.g., FastAPI), and vector databases (e.g., Qdrant, Weaviate, Elasticsearch, Redis, MongoDB, HNSWLib).",3100,machine learning|multimodal data|vector search|vector databases|data modeling|python|pydantic|retrieval-augmented generation,9,"This repository provides a core data structure and tooling to represent, serialize, store, and retrieve/search multimodal documents, including first-class support for tensors and embeddings and integration with multiple vector database backends. It is directly applicable to common ML/data workflows such as building embedding pipelines, similarity search, neural search, and RAG systems, and it interoperates with popular ML and serving stacks (e.g., NumPy/PyTorch/TensorFlow/JAX, FastAPI). Given its strong focus on multimodal ML data representation + retrieval and its visible community adoption (thousands of GitHub stars), it merits a high score, though it is not itself a model training framework.",success
https://github.com/microsoft/torchscale,torchscale,"TorchScale is a PyTorch library for scaling and experimenting with foundation-model architectures (especially Transformer-family and successor architectures) with a focus on training stability and efficiency. It provides configurable encoder, decoder, and encoder-decoder architectures and includes implementations/features from several research lines such as DeepNorm/SubLN, X-MoE, RetNet, and LongNet.",3100,machine learning|deep learning|PyTorch|transformers|LLMs|foundation models|Mixture-of-Experts|model architectures,9,"This repository’s primary purpose is to provide PyTorch implementations of scalable foundation-model architectures (e.g., Transformer variants and successor designs like RetNet/LongNet) along with training-stability and efficiency features used in modern large-model training. It is directly applicable to ML engineering workflows for building, training, and researching LLMs and other foundation models across modalities (language/vision/speech/multimodal), including support for MoE-style modeling. The project shows meaningful community adoption (thousands of GitHub stars) and strong educational value via clear architectural abstractions and examples, but it is not as universally foundational as core frameworks (e.g., PyTorch itself), so a 9 is appropriate.",success
https://github.com/open-mmlab/mmdeploy,mmdeploy,"MMDeploy is an open-source deep learning model deployment toolset from OpenMMLab for exporting and deploying models across multiple inference backends and platforms. It supports converting OpenMMLab models and running them via backends such as ONNX Runtime, TensorRT, OpenVINO, NCNN, TVM, and others, and provides an extensible C/C++ SDK framework for deployment.",3100,machine learning|model deployment|MLOps|computer vision|ONNX|TensorRT|ONNX Runtime|OpenVINO,9,"This repository’s primary purpose is deploying trained deep learning models: converting/exporting models and running inference across many production backends (e.g., ONNX Runtime, TensorRT, OpenVINO, NCNN) and targets (Linux/Windows/macOS/Android and various hardware). It is directly applicable to ML engineering workflows focused on taking models (especially OpenMMLab CV models) into production with performance/portability considerations. The project shows strong adoption signals (thousands of GitHub stars) and offers substantial practical and educational value via documentation on conversion, profiling, quantization, and backend integration. It’s not a training framework itself, but it is a highly relevant, widely useful deployment layer for ML systems, justifying a high score.",success
https://github.com/tslearn-team/tslearn,tslearn,"tslearn is a Python machine-learning toolkit dedicated to time series analysis, providing scikit-learn–style estimators and utilities for tasks like time-series classification, clustering, regression, preprocessing, and distance metrics (including support for variable-length series). It is designed to integrate naturally with scikit-learn pipelines and model selection tooling.",3100,machine learning|time series|python|scikit-learn|clustering|classification|distance metrics,9,"This repository provides a dedicated machine learning toolkit for time series data, including preprocessing/formatting helpers and models for clustering, classification, and regression with a scikit-learn-compatible API. It fits directly into common ML workflows (pipelines, hyperparameter search, standard estimator interface) and targets core time-series ML needs like specialized distance measures and barycenters. Community adoption is strong for a specialized library (on the order of ~3.1k GitHub stars), making it a highly relevant, practical library for ML/data practitioners, though it is not a broad general-purpose ecosystem pillar on the scale of PyTorch or scikit-learn.",success
https://github.com/vietanhdev/anylabeling,anylabeling,"AnyLabeling is an AI-assisted desktop data labeling/annotation tool for computer vision datasets. It supports manual annotation (polygon/box/etc.) and auto-labeling using models such as YOLO and Segment Anything (SAM/SAM2), with additional capabilities for OCR-related labeling workflows.",3100,data-labeling|computer-vision|dataset-annotation|object-detection|image-segmentation|YOLO|Segment-Anything|PyQt,9,"This repository provides an end-user labeling application focused on creating and managing training data for computer vision tasks (e.g., detection and segmentation) and includes auto-labeling via YOLO and Segment Anything (SAM/SAM2). It is directly applicable to ML workflows because high-quality labeled data is a prerequisite for training/evaluating CV models, and the built-in model-assisted annotation can significantly reduce labeling time. The project also appears reasonably adopted (thousands of GitHub stars) and is distributed via PyPI (including a GPU variant), improving integration into ML teams’ tooling. It is not a model-training framework itself, but it is highly valuable as a practical dataset creation tool, warranting a 9/10.",success
https://github.com/MiniMax-AI/MiniMax-M1,MiniMax-M1,"Official repository for MiniMax-M1, an open-weight large-scale hybrid-attention reasoning LLM based on a hybrid MoE architecture with a “lightning attention” mechanism and very long-context support. It includes model documentation, a technical report PDF, and Hugging Face–style model/tokenizer code for deployment (e.g., with vLLM/Transformers).",3000,large language model|reasoning|mixture-of-experts|long-context|transformers|reinforcement learning|inference-serving|NLP,9,"This repository centers on an open-weight reasoning LLM (MiniMax-M1) and provides the materials needed to understand and use it, including a detailed README, a technical report PDF, and model/tokenizer implementation artifacts suitable for common ML inference stacks. It is directly applicable to ML workflows (evaluation, experimentation, and deployment/serving of a large language model) and is clearly aimed at ML engineers and researchers working on long-context reasoning and agentic use cases. With thousands of GitHub stars and explicit guidance for serving via tools like vLLM/Transformers, it has strong practical utility for ML, though it is not a general-purpose data processing library—hence a 9 rather than 10.",success
https://github.com/PennyLaneAI/pennylane,pennylane,"PennyLane is a cross-platform Python library for quantum computing, quantum machine learning, and quantum chemistry. It provides tools to build and run quantum circuits on simulators or hardware and integrates with ML frameworks (e.g., PyTorch, TensorFlow, JAX) for training hybrid quantum-classical models.",3000,quantum computing|quantum machine learning|python|differentiable programming|pytorch|tensorflow|jax|quantum chemistry,9,"This repository is the core PennyLane framework for programming quantum circuits and building differentiable hybrid quantum-classical workflows, including quantum chemistry tooling and access to quantum datasets. It is directly applicable to ML workflows via integrations with major ML stacks (PyTorch, TensorFlow, JAX, Keras/NumPy) and supports training models using quantum-aware gradients/optimizers. Community adoption appears strong for the quantum ML niche (≈3k GitHub stars), and the project has high educational and research value through extensive documentation and research-oriented demos. It’s scored 9 (not 10) because it is highly specialized to quantum computing/quantum ML rather than being a general-purpose, broadly used ML foundation library like PyTorch or TensorFlow.",success
https://github.com/guillaume-be/rust-bert,rust-bert,"Rust-native library providing ready-to-use NLP pipelines and transformer-based models (e.g., BERT, DistilBERT, GPT-2, RoBERTa, T5) with support for GPU inference and multithreaded tokenization. It ports Hugging Face Transformers-style architectures and exposes both task pipelines (QA, NER, summarization, translation, generation, embeddings, etc.) and lower-level model components for custom use.",3000,machine learning|natural language processing|transformers|rust|pytorch/libtorch|onnxruntime|huggingface,9,"This repository is a Rust-native implementation of Transformer-based NLP models and high-level, ready-to-use pipelines (e.g., question answering, NER, summarization, translation, text generation, sentence embeddings), making it directly applicable to common ML/NLP inference workflows. It integrates with core ML tooling via libtorch (through tch-rs) and also supports ONNX Runtime bindings, enabling CPU/GPU deployment options and easier production integration. It has strong community adoption for a Rust ML/NLP project (thousands of GitHub stars) and substantial educational value for understanding Transformer architectures and implementing inference pipelines in Rust, justifying a high (but not ecosystem-defining) score.",success
https://github.com/keithito/tacotron,tacotron,"An unofficial TensorFlow implementation of Google’s Tacotron end-to-end text-to-speech model, including scripts to preprocess datasets, train models, and synthesize speech using checkpoints. It also provides a demo server and a downloadable pre-trained model for quick evaluation.",3000,text-to-speech|speech-synthesis|deep-learning|tensorflow|seq2seq|attention|audio-processing,9,"This repository implements and trains a neural text-to-speech (TTS) model (Tacotron) in TensorFlow, providing core ML functionality (data preprocessing, model training, evaluation, and inference/synthesis). It is directly applicable to ML workflows for speech generation and is widely used as a reference implementation for Tacotron-style architectures, including providing a pre-trained checkpoint and example datasets/configuration guidance. While it targets TensorFlow 1.x-era usage (which may require environment workarounds today), its educational and practical value for speech ML remains high, justifying a 9/10.",success
https://github.com/libffcv/ffcv,ffcv,FFCV (Fast Forward Computer Vision) is a high-throughput data loading and dataset format system designed to remove input pipeline bottlenecks during model training. It provides tooling to convert datasets into an optimized format and a drop-in loader (commonly used with PyTorch) to dramatically speed up training workloads.,3000,machine learning|deep learning|data loading|computer vision|pytorch|dataset format|gpu acceleration,9,"This repository’s primary purpose is accelerating ML training by replacing conventional data loaders with an optimized dataset format and fast loader to increase data throughput. It is directly applicable to common ML workflows (especially computer vision training loops) and integrates naturally with PyTorch pipelines as a drop-in loader after a one-time dataset conversion step. Its community adoption appears strong for a specialized ML systems tool (thousands of GitHub stars) and it is supported by documentation and an associated research paper, making it both practical and educational. It is not a full ML framework (so not a 10), but it is highly valuable for improving end-to-end training performance in data-intensive workloads.",success
https://github.com/openvinotoolkit/openvino_notebooks,openvino_notebooks,"A collection of ready-to-run Jupyter notebook tutorials for learning and experimenting with the OpenVINO™ Toolkit, focusing on optimized deep learning inference workflows and API usage. Includes guidance for running notebooks locally or via hosted environments like Binder/Colab and provides a GitHub Pages-based notebook browser.",3000,openvino|jupyter-notebooks|deep-learning|model-inference|computer-vision|nlp|edge-ai|tutorials,9,"This repository provides hands-on Jupyter notebook tutorials demonstrating how to run and optimize deep learning inference with the OpenVINO Toolkit, including end-to-end examples and environment setup guidance. It is directly useful to ML engineers and data scientists for learning and prototyping inference pipelines (especially deployment- and optimization-oriented workflows) rather than model training. The repo also offers strong educational value (many runnable notebooks, multiple execution options like local/Docker/Binder/Colab, and structured navigation via GitHub Pages), making it highly relevant for practical ML application development and benchmarking. It is not a core training framework like PyTorch/TensorFlow, but it is a major ecosystem tool for inference/acceleration, justifying a high (but not perfect) score.",success
https://github.com/osmr/imgclsmob,imgclsmob,"A research and training sandbox for deep learning computer vision models, providing (re)implementations of classification/segmentation/detection/pose-estimation networks plus scripts to train, evaluate, and convert models across multiple frameworks (MXNet/Gluon, PyTorch, Chainer, Keras, TensorFlow 1.x/2.x).",3000,machine learning|deep learning|computer vision|image classification|model training|PyTorch|TensorFlow|MXNet,9,"This repository is primarily an applied deep-learning codebase focused on computer vision, including extensive model implementations and end-to-end scripts for training, evaluation, and model conversion across several major frameworks. It is directly useful in ML workflows for experimenting with architectures, reproducing results, and leveraging pretrained weights on common datasets (e.g., ImageNet, CIFAR, COCO). Community adoption appears solid (about 3k GitHub stars), and the breadth of supported frameworks and tasks makes it a strong practical and educational resource, though it is not a foundational, universally adopted core framework like PyTorch itself.",success
https://github.com/ridgerchu/matmulfreellm,matmulfreellm,"An implementation of MatMul-Free LM, a language model architecture designed to eliminate standard matrix multiplication operations, provided as a Hugging Face Transformers-compatible package. It includes installation and usage examples plus references to pretrained model checkpoints and an associated arXiv preprint.",3000,large language models|transformers|PyTorch|Triton|efficient inference|efficient training|model architecture research,9,"This repository implements a novel LLM architecture (MatMul-Free LM) and exposes it in a way that integrates directly with standard ML tooling (Hugging Face Transformers), making it practical for researchers and ML engineers to experiment with, fine-tune, and run inference. It is strongly relevant to ML workflows because it provides model code, configuration objects, and generation examples, and points to pretrained models that can be used immediately. While it is not a broad, general-purpose data science library, it is highly valuable for deep learning/LLM research and efficiency-focused model development, warranting a high score despite more limited mainstream adoption compared with foundational frameworks.",success
https://github.com/scikit-learn-contrib/hdbscan,hdbscan,A high-performance Python implementation of the HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) algorithm. It provides a scikit-learn-compatible API for robust clustering with minimal parameter tuning and includes tools for cluster hierarchy visualization and optional outlier detection.,3000,machine learning|clustering|unsupervised learning|scikit-learn|python|density-based clustering|outlier detection|data science,9,"This repository implements the widely used HDBSCAN clustering algorithm and exposes it via a scikit-learn-style estimator interface, making it directly usable in standard ML/data science pipelines. It is highly applicable to exploratory data analysis and unsupervised learning workflows, supports common data formats (NumPy/pandas/sparse matrices), and includes additional utilities like cluster stability/persistence measures, visualization helpers, and GLOSH-based outlier scoring. With substantial community adoption (about 3k GitHub stars) and strong practical utility for real-world clustering tasks, it merits a 9/10 (highly relevant), though it is more specialized than broad foundational libraries like NumPy/Pandas/PyTorch.",success
https://github.com/stellargraph/stellargraph,stellargraph,"StellarGraph is an open-source Python library for graph machine learning, providing implementations of graph neural networks and related algorithms for tasks like node/edge representation learning, node/edge/graph classification, and link prediction. It integrates with TensorFlow/Keras and includes extensive demos and documentation for working with homogeneous and heterogeneous graphs.",3000,graph machine learning|graph neural networks|python|tensorflow|keras|representation learning|link prediction|network analysis,9,"This repository is a dedicated graph machine learning library (not a general-purpose utility), implementing state-of-the-art graph ML and GNN methods and providing end-to-end workflows (data preparation, modeling, and evaluation) through documented APIs and demos. It is directly applicable to common ML tasks on graph-structured data (e.g., node classification, embeddings, link prediction) and is designed to integrate into typical data-science stacks via TensorFlow/Keras, NumPy, Pandas, and scikit-learn. Its substantial GitHub adoption (≈3k stars) and educational value through examples/documentation make it highly valuable for ML practitioners, though it is more specialized and less broadly adopted than top-tier general frameworks, hence a 9 rather than 10.",success
https://github.com/tensorflow/agents,agents,"TF-Agents is a TensorFlow library for reinforcement learning (RL) and contextual bandits that provides modular, well-tested components (agents, policies, environments, replay buffers, drivers, etc.) to implement, train, evaluate, and benchmark RL algorithms.",3000,reinforcement learning|contextual bandits|tensorflow|deep learning|python|rl library|research,9,"This repository is the official TF-Agents library, focused on implementing and running reinforcement learning and contextual bandits workflows on top of TensorFlow, with ready-to-use algorithms and training/evaluation tooling. It is directly applicable to ML engineering and research workflows involving RL (training loops, policies, environments, replay buffers, benchmarking, and tutorials) rather than general software utilities. Community adoption is strong as part of the TensorFlow ecosystem, and the extensive tutorials/API docs provide significant educational value. It is scored 9 (not 10) because RL is a specialized subset of ML (compared to broadly used core data/ML libraries like TensorFlow itself), and some common setups (e.g., Reverb-based replay) have platform constraints.",success
https://github.com/InternLM/InternLM-XComposer,InternLM-XComposer,"InternLM-XComposer is a family of open multimodal (vision-language) large models and systems, including InternLM-XComposer2.5 and related projects like OmniLive and Reward. The repository provides model resources plus code for demos (e.g., Gradio), evaluation, and fine-tuning for long-context, high-resolution image/video understanding and text-image composition tasks.",2900,multimodal|vision-language models|LLM|computer vision|NLP|video understanding|fine-tuning|evaluation,9,"This repository is primarily an ML project: it hosts a multimodal vision-language model family (InternLM-XComposer2.x/2.5) and related systems (e.g., OmniLive for streaming video/audio interaction and a multimodal reward model) along with training/fine-tuning and evaluation assets. It is directly applicable to ML workflows for inference, benchmarking, and finetuning of large multimodal models, and includes demos and tooling that ML engineers can reuse. Community adoption appears strong for a research/model repo (thousands of GitHub stars), but it is not a general-purpose foundational framework on the scale of PyTorch/TensorFlow, so it scores slightly below a 10.",success
https://github.com/KichangKim/DeepDanbooru,DeepDanbooru,"DeepDanbooru is an anime-style image tag estimation system (multi-label classification) implemented in Python using TensorFlow. It provides CLI tooling to create training projects, download Danbooru tags, build training databases, train models, and evaluate/tag images or folders.",2900,machine learning|computer vision|multi-label classification|tensorflow|python|image tagging|danbooru,9,"This repository is a purpose-built ML application for training and running a multi-label image classifier that predicts Danbooru-style tags from anime images, with an end-to-end workflow (dataset preparation conventions, project configuration, training, and evaluation) exposed via a CLI. It directly supports common ML workflows (data preparation, model training, and inference) and uses a mainstream deep learning framework (TensorFlow), making it highly applicable for ML engineers working on image tagging/classification. Community adoption appears strong for a niche tool (on the order of ~2.9k GitHub stars), and the README provides concrete, reproducible steps and data format details that are educational for practitioners.",success
https://github.com/NVIDIA/MinkowskiEngine,MinkowskiEngine,"Minkowski Engine is an auto-differentiation neural network library for high-dimensional sparse tensors, providing sparse convolution/pooling/unpooling and related layers optimized for 3D/4D sparse data (e.g., point clouds and spatio-temporal perception) with CUDA support and PyTorch integration.",2900,machine learning|deep learning|PyTorch|sparse convolution|3D point clouds|3D perception|CUDA,9,"This repository provides a specialized deep learning engine for sparse tensor networks (e.g., sparse convolutions, pooling, and related layers) commonly used in 3D point cloud and spatio-temporal (4D) perception models. It directly supports ML workflows by extending PyTorch with highly optimized CPU/GPU kernels and example networks for tasks like segmentation, classification, and reconstruction. Community adoption appears strong for a domain-specific library (about 2.9k GitHub stars), and it is widely referenced in academic/engineering work on sparse convolutional networks. It is not a general-purpose data science toolkit, but it is highly valuable for practitioners building sparse 3D/4D neural networks, justifying a score of 9.",success
https://github.com/ajbrock/BigGAN-PyTorch,BigGAN-PyTorch,"An officially unofficial PyTorch implementation of BigGAN (and related GAN variants) with scripts for multi-GPU training, evaluation (IS/FID), sampling, and pretrained checkpoints for ImageNet 128x128.",2900,machine learning|deep learning|generative adversarial networks|BigGAN|PyTorch|image generation|ImageNet,9,"This repository provides a full PyTorch training and inference codebase for BigGAN-style generative models, including multi-GPU training scripts, dataset preparation utilities (e.g., HDF5), and evaluation via Inception Score/FID. It is directly applicable to ML workflows for generative modeling research, reproduction, fine-tuning, and large-scale image synthesis experiments. Community adoption is strong (≈2.9k stars) and the repo is educational for understanding large-scale GAN training engineering, but it is somewhat specialized (GAN/image-generation focused) and tied to older dependency assumptions (e.g., specific PyTorch/TensorFlow metric notes), keeping it just below a perfect 10.",success
https://github.com/benedekrozemberczki/pytorch_geometric_temporal,pytorch_geometric_temporal,"PyTorch Geometric Temporal is an extension library for PyTorch Geometric focused on spatiotemporal/dynamic graph deep learning. It provides implemented temporal GNN models, dataset loaders, temporal snapshot iterators, and utilities for training (including GPU support and integrations such as PyTorch Lightning).",2900,machine learning|deep learning|graph neural networks|spatiotemporal modeling|time series|PyTorch|PyTorch Geometric,9,"This repository is a dedicated ML library for spatiotemporal (dynamic/temporal) graph neural networks built on top of PyTorch Geometric, including implementations of published temporal GNN methods and training utilities. It is directly applicable to ML/data workflows involving time-evolving graphs and spatiotemporal forecasting, and it includes dataset loaders and benchmark datasets that support experimentation. With strong community adoption (~2.9k GitHub stars) and documentation/examples/notebooks for practical use, it is highly valuable for data scientists and ML engineers working with temporal graphs, though it is more specialized than general-purpose frameworks (hence not a 10).",success
https://github.com/bethgelab/foolbox,foolbox,"Foolbox is a Python library for generating and benchmarking adversarial attacks against machine learning models. It provides a large collection of state-of-the-art attacks and runs natively with models in PyTorch, TensorFlow, and JAX via EagerPy.",2900,adversarial-attacks|adversarial-robustness|machine-learning|deep-learning|pytorch|tensorflow|jax|security,9,"This repository is purpose-built for adversarial machine learning: it implements many gradient-based and decision-based adversarial attacks and is designed for benchmarking model robustness. It integrates directly into common ML workflows by wrapping existing PyTorch/TensorFlow/JAX models and producing adversarial examples and success metrics that practitioners can use for evaluation and research. It also appears to have strong community adoption for a specialized library (about 2.9k GitHub stars) and is backed by widely cited academic work, making it highly valuable for ML engineers and researchers working on robustness.",success
https://github.com/iscyy/ultralyticsPro,ultralyticsPro,"A YOLO-focused project that aggregates and implements improvement ideas across multiple YOLO variants (e.g., YOLO11/YOLOv8/YOLOv10/YOLOv7/YOLOv5) and RT-DETR, with support for modifying backbone, neck, head, losses, IoU metrics, NMS, and related modules for computer-vision tasks.",2900,computer vision|object detection|deep learning|PyTorch|YOLO|RT-DETR|model training,9,"This repository is primarily an applied deep-learning/computer-vision codebase centered on training and improving YOLO-family object detection models (and RT-DETR) by swapping and experimenting with core architectural and training components (backbone/neck/head, loss functions, IoU/NMS, etc.). It maps directly to common ML workflows—model experimentation, training scripts, and evaluation-oriented module changes—making it highly usable for ML engineers working on detection tasks. While it is not a foundational framework with broad industry-standard adoption on the level of PyTorch/Ultralytics itself, its practical focus and breadth of model-improvement modules make it very valuable for experimentation and learning in detection-centric ML pipelines.",success
https://github.com/keras-team/keras-tuner,keras-tuner,"KerasTuner is a scalable hyperparameter optimization framework for Keras/TensorFlow models. It lets you define search spaces in code and run built-in tuners such as Random Search, Bayesian Optimization, and Hyperband to find strong hyperparameter configurations.",2900,machine learning|deep learning|hyperparameter optimization|AutoML|Keras|TensorFlow|Python,9,"This repository provides KerasTuner, a purpose-built library for hyperparameter tuning of neural network models in Keras/TensorFlow, supporting common search algorithms like Bayesian optimization, Hyperband, and random search. It is directly applicable to ML workflows (model selection/optimization) and integrates cleanly into training loops used by ML engineers and data scientists. Community adoption is strong (thousands of stars and wide downstream usage), and it has substantial educational value for learning practical hyperparameter search patterns. It is slightly short of a 10 because it is a specialized component of the ML stack rather than a general foundational framework like TensorFlow or PyTorch.",success
https://github.com/pytorch/TensorRT,TensorRT,"Torch-TensorRT brings NVIDIA TensorRT acceleration to PyTorch, enabling compilation/optimization of PyTorch models for faster GPU inference via TorchScript/FX and seamless integration with torch.compile. It supports both just-in-time compilation and ahead-of-time export workflows for deployment in Python or C++ (libtorch).",2900,machine learning|deep learning|pytorch|tensorrt|gpu inference optimization|model compilation|cuda|ml deployment,9,"This repository provides Torch-TensorRT, a compiler/backend that optimizes PyTorch models to run efficiently on NVIDIA GPUs using TensorRT, primarily targeting low-latency inference. It is directly applicable to ML engineering workflows (production inference, acceleration, deployment, and export) and integrates with core PyTorch tooling like torch.compile. Given its specialized focus on ML inference optimization and its adoption within the PyTorch + NVIDIA ecosystem, it is highly valuable for ML practitioners, though it is less about data processing/training and more about deployment performance.",success
https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning,a-PyTorch-Tutorial-to-Image-Captioning,"An educational PyTorch implementation of the ""Show, Attend and Tell"" image captioning model (CNN encoder + attention-based RNN/LSTM decoder), including scripts to preprocess MS COCO captions/images, train the model, evaluate with BLEU, and run inference with beam search and attention visualization.",2900,machine learning|deep learning|computer vision|image captioning|attention mechanism|PyTorch|encoder-decoder|MS COCO,9,"This repository is a hands-on PyTorch tutorial that implements an end-to-end image captioning system (Show, Attend and Tell) with data preparation, training, evaluation, and inference utilities. It is directly applicable to ML workflows for vision-language modeling and is highly educational, demonstrating encoder-decoder architectures, attention, transfer learning, and beam search. While it is not a general-purpose production framework, it is a strong practical reference implementation with substantial community adoption (about 2.9k GitHub stars).",success
https://github.com/tensorflow/lingvo,lingvo,"Lingvo is a TensorFlow-based framework for building and training neural networks, with a particular focus on sequence models. It includes reusable components and reference implementations for tasks like speech recognition, machine translation, language modeling, and vision models (e.g., MNIST and 3D object detection).",2900,machine learning|deep learning|tensorflow|sequence modeling|nlp|speech recognition|machine translation|model training,9,"This repository provides Lingvo, a dedicated TensorFlow framework aimed at building and training neural networks—especially sequence models—and includes tooling, configs, and examples for major ML tasks like ASR, MT, and language modeling. It directly supports core ML workflows (model definition, training, and experimentation) and is usable by ML engineers/researchers either via a pip package or by building from source (Bazel/Docker). Its adoption is solid for a specialized framework (thousands of GitHub stars and many publications referenced by the project), but it is not as universally standard today as dominant general-purpose frameworks (e.g., TensorFlow core / PyTorch), so it scores slightly below a 10.",success
https://github.com/webdataset/webdataset,webdataset,"WebDataset is a high-performance Python I/O and streaming dataset library for deep learning that reads and writes sharded tar “WebDataset” files as sequential streams. It provides PyTorch IterableDataset-style pipelines (with shuffling, decoding, caching, and resampling) and can be used for scalable training from local disks or cloud/object storage.",2900,machine learning|deep learning|data loading|dataset format|PyTorch|data pipeline|streaming,9,"This repository implements the WebDataset format and a Python library for building high-throughput, streaming input pipelines (notably via PyTorch IterableDataset) for training deep learning models. It is directly applicable to ML workflows because it focuses on efficient large-scale sample sharding, sequential I/O, shuffle/resample strategies, decoding, and optional caching across local and remote storage. The project shows strong community adoption (thousands of GitHub stars) and integrates naturally into common training stacks, making it highly valuable for ML engineers and data scientists working with large datasets.",success
https://github.com/adapter-hub/adapters,adapters,Adapters is a Python library that extends Hugging Face Transformers with parameter-efficient fine-tuning methods (adapters and related PEFT approaches) and modular composition of multiple adapter modules for training and inference across many Transformer model architectures.,2800,machine learning|NLP|transformers|parameter-efficient fine-tuning|PyTorch|Hugging Face|transfer learning,9,"This repository provides the core implementation of the Adapters library: an add-on to Hugging Face Transformers that integrates many adapter/PEFT methods and supports composing modules during training and inference. It is directly applicable to common ML/NLP workflows (fine-tuning and serving Transformer models with fewer trainable parameters, smaller storage footprint per task, and modular reuse across tasks). Its integration with Transformers and the broader ecosystem (documentation and Hub support) makes it highly usable for ML engineers and researchers, though it is more specialized than general-purpose ML frameworks—hence a 9 rather than a 10.",success
https://github.com/facebookresearch/habitat-lab,habitat-lab,"Habitat-Lab is a modular high-level library for end-to-end embodied AI development, used to train and evaluate embodied agents across tasks like navigation and rearrangement in simulated indoor environments. It builds on Habitat-Sim and includes tooling for reinforcement/imitation learning, benchmarking, and human-in-the-loop interaction.",2800,embodied-ai|robotics|reinforcement-learning|imitation-learning|simulation|deep-learning|python,9,"This repository provides a training/evaluation framework for embodied AI agents, including task definitions, agent/sensor configuration, and baseline training pipelines (e.g., RL/IL) built around the Habitat simulation ecosystem. It is directly applicable to ML workflows for embodied perception and decision-making, enabling reproducible experiments and benchmarking on standardized tasks and datasets. Community adoption is strong for academic/industrial embodied-AI research (as part of the broader Habitat platform), and its documentation/papers make it educational as well. It is not a general-purpose ML framework like PyTorch, but it is a highly relevant, specialized ML research and engineering toolkit—hence a 9 rather than a 10.",success
https://github.com/leptonai/leptonai,leptonai,"Lepton AI is a Python SDK and CLI for turning Python ML/modeling code into deployable AI services via a ""Photon"" abstraction, with utilities like client bindings, configuration for cloud deployment, and support for launching common Hugging Face-style models and example apps (e.g., Llama, SDXL, Whisper).",2800,machine-learning|mlops|model-serving|ai-services|python|huggingface|gpu,9,"This repository provides a Pythonic framework (plus CLI) to package ML/model code into services using its Photon abstraction, including helpers for launching common model types and running them locally or in cloud-like environments. It is directly applicable to ML engineering workflows (model serving, lightweight MLOps, rapid prototyping-to-deployment) and includes batteries like client bindings and operational features (e.g., autobatching/background jobs). The repo appears to have meaningful community adoption (thousands of GitHub stars) and strong integration potential for typical LLM/CV/ASR workloads (e.g., Hugging Face models, common OSS examples), which supports a high (but not “industry-standard framework”) score.",success
https://github.com/pytorch/audio,audio,"TorchAudio is PyTorch’s audio and speech processing library, providing datasets, transforms, and functional utilities for preparing and transforming audio tensors in ML workflows. It includes common feature-extraction and resampling utilities and aims to be a tightly scoped, ML-focused audio toolkit for PyTorch.",2800,pytorch|audio-processing|speech-processing|deep-learning|machine-learning|signal-processing|datasets,9,"This repository provides TorchAudio, an audio/speech data processing library built specifically for PyTorch, including dataset loaders, transforms, and utilities for feature extraction and preprocessing. It is directly applicable to ML workflows for tasks like ASR, speaker recognition, and audio classification, and integrates tightly with PyTorch tensors/autograd for GPU-accelerated pipelines. Community adoption is strong as part of the broader PyTorch ecosystem, making it a high-value dependency for audio ML practitioners, though it is in a maintenance phase with some user-facing features removed in recent versions.",success
https://github.com/scikit-optimize/scikit-optimize,scikit-optimize,"Scikit-Optimize (skopt) is a Python library for sequential model-based (Bayesian) optimization of expensive and noisy black-box functions, exposing a SciPy-like minimize interface. It is built on top of NumPy, SciPy, and scikit-learn and is commonly used for tasks like hyperparameter optimization.",2800,bayesian-optimization|hyperparameter-optimization|machine-learning|black-box-optimization|scikit-learn|python|numerical-optimization,9,"This repository provides scikit-optimize (skopt), a Bayesian/sequential model-based optimization toolkit aimed at minimizing expensive, noisy objective functions, with a SciPy-like API. It is directly applicable to core ML workflows—especially hyperparameter search and tuning of scikit-learn-style models—making it a practical tool for data scientists and ML engineers. It also integrates naturally with the Python scientific stack (NumPy/SciPy/scikit-learn) and has strong community adoption (on the order of ~2.8k GitHub stars), supporting the high relevance score. The only reason it is not a 10 is that it is a specialized optimization library (and the GitHub repository is archived/read-only), rather than a broad, actively evolving cornerstone framework like PyTorch or pandas.",success
https://github.com/tensorflow/ranking,ranking,"TensorFlow Ranking (TF-Ranking) is a TensorFlow-based library for learning-to-rank (LTR). It provides ranking losses (pointwise/pairwise/listwise), ranking metrics (e.g., MRR, NDCG), groupwise scoring, LambdaLoss, and methods for unbiased LTR from biased feedback data.",2800,machine-learning|learning-to-rank|information-retrieval|tensorflow|recommender-systems|ranking-metrics|deep-learning,9,"This repository provides a dedicated Learning-to-Rank library on top of TensorFlow, including standard LTR losses, ranking metrics like MRR/NDCG, groupwise scoring, and LambdaLoss for directly optimizing ranking metrics. It is directly applicable to ML workflows for search, recommendation, and information retrieval, and includes runnable examples and a pip-installable package, making it practical for experimentation and production prototyping. The GitHub project is archived (read-only as of May 21, 2025), which can limit ongoing maintenance and ecosystem evolution, but it remains a highly relevant, purpose-built ML library for ranking tasks.",success
https://github.com/thunlp/UltraChat,UltraChat,"UltraChat is a large-scale, diverse multi-round dialogue dataset and associated resources for training and evaluating chat-oriented large language models (LLMs). The repository also provides materials related to UltraLM (models trained on UltraChat), dataset release notes, and training/inference utilities.",2800,nlp|large-language-models|chat-datasets|instruction-tuning|preference-data|rlhf|model-training|pytorch,9,"This repository’s primary purpose is to provide large-scale multi-round chat data (UltraChat) and supporting artifacts (e.g., UltraLM model releases and scripts) for building chat LLMs. It is directly applicable to ML workflows such as instruction tuning, dialogue modeling, evaluation, and potentially preference learning/feedback-based alignment via related releases (e.g., UltraFeedback and reward/critic models). Community adoption appears strong for an academic dataset/model repo (thousands of GitHub stars), and it offers substantial educational value for understanding data construction and training setups. It is scored 9 (not 10) because it is a high-value dataset/model resource rather than a broadly general-purpose core ML framework with massive industry-wide adoption.",success
https://github.com/werner-duvaud/muzero-general,muzero-general,"A commented and documented educational implementation of the MuZero reinforcement learning algorithm (from the DeepMind paper) designed to be easily adapted to many games and RL environments (e.g., OpenAI Gym). It includes PyTorch models, self-play with MCTS, distributed execution via Ray, TensorBoard monitoring, and example game integrations.",2800,reinforcement learning|MuZero|PyTorch|Monte Carlo Tree Search|Ray|self-play|Atari|OpenAI Gym,9,"This repository provides an end-to-end implementation of MuZero, a core deep reinforcement learning algorithm, including training, self-play, replay buffer, and game/environment adapters, making it directly usable for RL experimentation and learning. It is highly relevant to ML workflows (model training, evaluation, experiment tracking with TensorBoard, distributed runs with Ray) and offers substantial educational value via comments and documentation. Community adoption appears strong for an educational RL implementation (about 2.8k GitHub stars), but it is not an industry-standard foundational library on the scale of PyTorch/TensorFlow, so it scores slightly below a 10.",success
https://github.com/whylabs/whylogs,whylogs,"whylogs is an open-source data logging and profiling library (Python and Java) that generates compact, privacy-preserving dataset “profiles” to monitor data quality, detect drift, validate constraints, and track model/data behavior over time, with optional integration to the WhyLabs observability platform.",2800,mlops|data-observability|data-profiling|data-quality|drift-detection|python|java|monitoring,9,"This repository provides an open-source standard/library for producing statistical profiles of datasets (and related constraints/visualizations) aimed at monitoring data quality and change over time in ML pipelines. It is directly applicable to common ML engineering workflows like training/serving monitoring, drift detection, data validation, and experiment tracking, and it integrates with ecosystem tools and the WhyLabs platform. The project appears widely adopted for an MLOps/observability utility (not a model-training framework), which makes it highly valuable to data scientists/ML engineers but not quite a universal core dependency like a major ML framework.",success
https://github.com/DLR-RM/rl-baselines3-zoo,rl-baselines3-zoo,"RL Baselines3 Zoo is a training framework built on Stable Baselines3 that provides scripts/CLI for training and evaluating reinforcement learning agents, tuning hyperparameters, plotting results, and recording videos. It also includes a collection of tuned hyperparameters and pre-trained agents for common RL environments.",2700,reinforcement learning|stable-baselines3|hyperparameter optimization|optuna|pytorch|benchmarking|experiment tracking,9,"This repository is primarily a reinforcement-learning training and benchmarking framework for Stable Baselines3, offering a practical CLI/workflow for training, evaluation, hyperparameter tuning, and result visualization, plus a library of tuned configs and pre-trained agents. It maps directly to common ML engineering workflows for RL experimentation (repeatable training runs, evaluation, tracking/visualization, and sharing trained models), and is part of the widely used SB3 ecosystem with substantial community adoption (thousands of stars). It is highly valuable for ML practitioners working in RL, though it is less relevant for non-RL data science tasks (e.g., tabular ML pipelines).",success
https://github.com/IDEA-Research/DINO,DINO,"Official implementation of the ICLR 2023 paper ""DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"". Provides code, configs, scripts, and pretrained checkpoints to train/evaluate transformer-based object detectors (DETR-family) on datasets like COCO.",2700,computer vision|object detection|transformers|DETR|PyTorch|deep learning|research code,9,"This repository implements a state-of-the-art end-to-end object detection method (DINO) in the DETR family, intended for training, evaluating, and running inference on standard CV datasets such as COCO. It is directly applicable to ML workflows (model training, evaluation scripts, pretrained checkpoints, and CUDA ops) and is built around common ML tooling (PyTorch). The repo also has strong community adoption signals (thousands of stars) and high educational value for practitioners studying transformer-based detectors, so it merits a high ML/data score.",success
https://github.com/PythonOT/POT,POT,"POT (Python Optimal Transport) is an open-source Python library that implements a broad set of (often differentiable) optimal transport solvers (e.g., Sinkhorn/entropic OT, exact OT/EMD, Gromov-Wasserstein, unbalanced/partial OT) and related tools like barycenters and domain adaptation, with support for multiple array backends (NumPy, PyTorch, JAX, TensorFlow, CuPy).",2700,optimal transport|machine learning|domain adaptation|statistics|scientific computing|python|pytorch,9,"This repository is a full-featured optimal transport library, providing core algorithms (e.g., Sinkhorn, EMD/network simplex, Gromov-Wasserstein, barycenters, unbalanced/partial OT) widely used in modern ML and data analysis. It directly supports ML workflows such as domain adaptation and differentiable OT losses, and offers interoperability with common ML array frameworks (PyTorch/JAX/TensorFlow) that make it practical for research and production prototyping. Its broad algorithm coverage and strong community adoption make it highly valuable for data science and machine learning, though it is more specialized than general-purpose ML frameworks, so it is not a 10.",success
https://github.com/Trusted-AI/AIF360,AIF360,"AI Fairness 360 (AIF360) is an extensible open-source toolkit (Python and R) for detecting, understanding, and mitigating bias in machine learning datasets and models across the AI lifecycle, providing fairness metrics and bias-mitigation algorithms.",2700,machine learning|responsible ai|ai fairness|bias mitigation|fairness metrics|python|r,9,"This repository provides a practical toolkit focused on fairness in ML: it includes a large suite of dataset/model fairness metrics and multiple pre-, in-, and post-processing bias-mitigation algorithms. It is directly applicable to common data science workflows (evaluate fairness, compare mitigations, and integrate into model development pipelines) and supports both Python and R, increasing adoption potential. Given its clear ML-centric purpose, breadth of implemented methods, and substantial community usage (stars/forks), it merits a 9; it stops short of a 10 mainly because it is a specialized subdomain toolkit rather than a general core ML framework.",success
https://github.com/bghira/SimpleTuner,SimpleTuner,"SimpleTuner is a general-purpose fine-tuning and training toolkit for generative diffusion models across image, video, and audio. It includes a web UI and CLI, supports distributed/multi-GPU training, caching and bucketing for efficient dataset handling, and integrates advanced training backends like DeepSpeed and FSDP2 for large-model training.",2700,machine learning|generative ai|diffusion models|model fine-tuning|PyTorch|LoRA|distributed training|MLOps,9,"This repository’s primary purpose is to fine-tune/train diffusion-based generative models (image/video/audio) and manage the end-to-end training lifecycle via a CLI and web UI, which is directly in the core ML training workflow. It supports modern ML engineering needs like multi-GPU/distributed training, accelerator integrations (e.g., DeepSpeed/FSDP2), and techniques commonly used in diffusion fine-tuning such as LoRA/LyCORIS and embedding caching/bucketing. The relatively high GitHub star count indicates meaningful community adoption for diffusion fine-tuning, though it is more specialized than general-purpose ML frameworks, so it is not a universal “10/10” foundational library.",success
https://github.com/dvlab-research/LongLoRA,LongLoRA,"Code and documentation for LongLoRA and LongAlpaca (ICLR 2024 Oral), providing training, evaluation, and inference tooling to extend LLM context length efficiently (including support for LoRA/QLoRA and streaming inference setups).",2700,large language models|long-context|LoRA|QLoRA|instruction tuning|NLP|fine-tuning|evaluation,9,"This repository provides end-to-end tooling (scripts/configs) for long-context LLM fine-tuning and evaluation, centered on the LongLoRA method and the LongAlpaca dataset/models released alongside the paper. It is directly applicable to ML workflows for adapting and benchmarking transformer LLMs with extended context windows, including options to reduce memory via QLoRA and to run streaming-style inference. Community adoption appears strong for a research codebase (thousands of stars), and it has clear educational value as a reference implementation for long-context adaptation techniques. It is not a general-purpose ML framework, but it is highly relevant for practitioners working on LLM training/inference, hence a 9/10.",success
https://github.com/junyanz/interactive-deep-colorization,interactive-deep-colorization,"Deep learning software for interactive colorization of grayscale images using user-provided color hints (clicks/points), based on the SIGGRAPH 2017 “Real-Time User-Guided Image Colorization with Learned Deep Priors” project. Includes Jupyter notebook demos and a full GUI, with support for Caffe (official) and PyTorch backends.",2700,computer vision|image colorization|deep learning|interactive annotation|PyTorch|Caffe|Jupyter notebooks|GUI,9,"This repository provides an end-to-end interactive image colorization system built on deep neural networks (local hints and global hints networks), including pretrained model download scripts, demos, and a GUI application. It is directly useful for ML/CV practitioners for reproducing results, experimenting with user-guided colorization, and integrating learned priors into interactive workflows. Community adoption is strong (2.7k stars) and it has high educational value as an accompanying implementation for a well-known SIGGRAPH paper, though it is more of an application/research codebase than a general-purpose ML framework.",success
https://github.com/langwatch/langwatch,langwatch,"LangWatch is an open LLM Ops platform for observing and improving LLM applications, providing tracing/analytics, evaluations, datasets, and prompt management/optimization. It supports local/self-hosted deployment (e.g., via Docker Compose/Helm) and integrates natively with OpenTelemetry for framework- and provider-agnostic instrumentation.",2700,LLMOps|observability|OpenTelemetry|LLM evaluation|prompt management|datasets|agent frameworks|self-hosted,9,"This repository implements an LLM Ops platform focused on instrumenting LLM/agent systems with tracing (via OpenTelemetry), then using those traces to power analytics, dataset creation, evaluations, and prompt optimization workflows. It is directly applicable to ML/LLM engineering work: teams can monitor production behavior, build/curate datasets from real interactions, and run offline/online evals to compare prompts/pipelines/providers. The strong alignment to LLM development lifecycle (observability + evaluation + datasets + optimization), plus broad ecosystem integrations and deployability, makes it highly valuable for data/ML practitioners, though it is not a general-purpose training framework (hence not a 10).",success
https://github.com/linto-ai/whisper-timestamped,whisper-timestamped,A Python extension for OpenAI Whisper transcription that adds word-level timestamps and per-word/segment confidence scores using alignment based on cross-attention (DTW). It also supports optional Voice Activity Detection (VAD) to reduce hallucinations and improve segment timing on long audio files.,2700,speech-to-text|automatic-speech-recognition|whisper|audio-processing|word-timestamps|python|pytorch,9,"This repository extends OpenAI Whisper to produce word-level timestamps and confidence scores by aligning tokens to audio via cross-attention weights (DTW), enabling higher-fidelity transcripts and subtitle generation. It is directly applicable to ML/audio/NLP workflows (ASR pipelines, dataset labeling, subtitle/time-aligned transcript creation) and integrates cleanly into Python-based model inference with optional VAD pre-processing. The project shows strong community adoption (about 2.7k GitHub stars) and provides practical tooling that ML engineers can drop into production or research pipelines, warranting a high score.",success
https://github.com/patrick-kidger/equinox,equinox,"Equinox is a JAX library for building neural networks (and more general models) using PyTorch-like syntax via callable PyTrees, plus utilities like filtered transformations and PyTree manipulation. It aims to be lightweight and fully interoperable with core JAX and the wider JAX ecosystem rather than a standalone framework.",2700,jax|deep learning|neural networks|differentiable programming|scientific computing|python|pytree,9,"This repository provides a core modeling library for JAX: defining trainable models/modules as PyTrees with a clean, PyTorch-like interface, plus ""filtered"" APIs for JAX transformations and utilities that make advanced JAX workflows easier. It is directly applicable to ML workflows (model definition, training, differentiation, JIT/vmap composition) and is positioned alongside major JAX ecosystem tools (e.g., Optax), making it highly relevant for ML engineers and researchers using JAX. The project shows strong community adoption for a JAX-native library (about 2.7k GitHub stars) and has substantial educational value for learning how to structure JAX models without introducing heavy framework magic. It is not a general-purpose data processing tool (like pandas/Spark), so it falls short of a perfect 10, but it is a high-value ML library for JAX-based modeling.",success
https://github.com/stochasticai/xTuring,xTuring,"xTuring is a Python library for fine-tuning, evaluating, and running private, personalized open-source LLMs on your own data. It provides a simple API for data preparation, training (including LoRA and low-precision INT8/INT4), and inference locally or in a private cloud/VPC.",2700,large language models|llm fine-tuning|nlp|pytorch|lora|quantization|model evaluation|mlops,9,"This repository is primarily an ML tool focused on customizing open-source LLMs end-to-end: dataset handling, fine-tuning, inference, and evaluation (e.g., perplexity). It directly supports common ML workflows for adapting language models to proprietary instruction/data, with practical efficiency features like LoRA and INT8/INT4 quantization and the ability to run locally or in private infrastructure. Its strong applicability to LLM engineering and sizeable community adoption (thousands of GitHub stars) justify a high score, though it is not at the broad, foundational adoption level of core frameworks like PyTorch or TensorFlow.",success
https://github.com/torch-points3d/torch-points3d,torch-points3d,"A PyTorch-based framework for training and evaluating deep learning models on 3D point clouds across common tasks (e.g., classification, segmentation, detection, registration) using configurable pipelines. It builds on PyTorch Geometric and Hydra to provide reproducible experiments, benchmark tooling, and an extensible model/dataset library.",2700,machine learning|deep learning|point clouds|3D computer vision|PyTorch|PyTorch Geometric|LiDAR|semantic segmentation,9,"This repository is primarily an ML framework focused on deep learning for 3D point-cloud data, providing implemented architectures (e.g., PointNet/PointNet++, KPConv, RandLA-Net, VoteNet) plus dataset/task abstractions and training/evaluation scripts. It is directly applicable to ML workflows for 3D vision research and engineering (experiment configuration via Hydra, training pipelines, benchmarks, and dataset support). Community adoption is solid (on the order of ~2.7k GitHub stars) and the project has strong educational value by offering reference implementations and end-to-end examples/notebooks. It is not a general-purpose mainstream framework at PyTorch/TensorFlow scale, but it is highly relevant and practical for point-cloud ML, hence a 9.",success
https://github.com/wzhe06/SparrowRecSys,SparrowRecSys,"SparrowRecSys is an end-to-end deep learning recommender system project (movie recommendation) that includes offline data processing (Spark), model training (TensorFlow), and an online serving layer with a web server/UI for demonstrating recommendations.",2700,recommender systems|deep learning|machine learning|TensorFlow|Apache Spark|feature engineering|model serving|MovieLens,9,"This repository provides an industrial-style recommender system stack, covering offline data processing, feature engineering, deep learning model training, and online serving with a demo UI. It is directly applicable to ML/data workflows for learning and prototyping common recommendation models (e.g., Wide&Deep, DeepFM, DIN, Two-Tower) and related pipelines. Community adoption is fairly strong for a niche educational/engineering repo (thousands of stars), and its breadth makes it highly valuable for ML engineers and data scientists building or studying recommender systems.",success
https://github.com/KupynOrest/DeblurGAN,DeblurGAN,"PyTorch implementation of DeblurGAN for blind motion image deblurring using a conditional GAN (Wasserstein GAN with gradient penalty) plus perceptual loss (VGG-19). Includes scripts for inference (test.py), training (train.py), and dataset preparation utilities for paired image-to-image translation workflows.",2600,computer vision|image deblurring|GAN|PyTorch|image-to-image translation|deep learning|motion blur,9,"This repository provides a working PyTorch implementation of a research GAN architecture specifically intended for an ML computer-vision task: blind motion deblurring (and related image-to-image translation tasks). It is directly applicable to ML workflows because it includes pretrained weights, inference code, and training utilities/dataset tooling that an ML engineer can adapt to custom data. It also has strong community adoption (2.6k GitHub stars) and educational value as a reference implementation of conditional WGAN-GP + perceptual loss for restoration problems.",success
https://github.com/SeldonIO/alibi,alibi,"Alibi is a source-available Python library for machine learning model inspection and interpretability, providing high-quality implementations of local/global and black-box/white-box explanation methods for classification and regression models. It includes explainers such as Anchors, Integrated Gradients, counterfactual methods, ALE/PD, and SHAP variants, with a scikit-learn-like API and optional distributed execution (e.g., via Ray).",2600,machine-learning|model-interpretability|explainable-ai|python|counterfactual-explanations|shap|tensorflow|pytorch,9,"This repository is primarily an explainable AI (XAI) toolkit: it implements multiple established explanation algorithms (e.g., Anchors, Integrated Gradients, counterfactual approaches, ALE/partial dependence, SHAP variants) for inspecting classification/regression models via a consistent Python API. These capabilities are directly applicable in real ML workflows for debugging models, auditing behavior, and communicating model decisions, and it supports common ML stacks (including TensorFlow/Keras and black-box predict functions) plus optional scaling features like distributed execution. Community adoption appears strong for a specialized XAI library (about 2.6k GitHub stars), but it is not a general-purpose training framework—hence a 9 rather than a 10.",success
https://github.com/autodistill/autodistill,autodistill,Autodistill is a modular framework that uses large foundation (base) models to automatically label unlabeled images and then train smaller supervised (target) models for deployment. It provides pluggable base/target model and ontology components to build auto-labeling and model distillation pipelines for computer vision tasks like object detection and instance segmentation.,2600,machine learning|computer vision|data labeling|dataset creation|model distillation|object detection|instance segmentation|python,9,"This repository’s primary purpose is to automate dataset labeling and distill foundation-model knowledge into deployable supervised vision models via a plugin-based pipeline (base model + ontology -> auto-labeled dataset -> target model -> distilled weights). It is directly applicable to ML workflows because it reduces/avoids manual annotation, produces training datasets, and integrates with common CV model families through separate base/target plugins. The repo shows strong community adoption signals (thousands of GitHub stars) and provides clear primitives for assembling practical auto-labeling/training pipelines, making it highly valuable for ML engineers working on custom vision models.",success
https://github.com/dvlab-research/LISA,LISA,"LISA (Large Language Instructed Segmentation Assistant) is a multi-modal LLM-based system for ""reasoning segmentation"": given a natural-language query that may require world knowledge or multi-step reasoning, it produces a segmentation mask and can generate explanatory answers. The repository provides training and inference code plus links to released models/datasets (including LISA++).",2600,computer vision|image segmentation|multimodal LLM|vision-language|deep learning|PyTorch|instruction tuning|reasoning,9,"This repository is primarily an ML research codebase for reasoning-driven image segmentation using large vision-language models, with end-to-end assets (training scripts, inference/demo code) and references to released models/datasets. It is directly applicable to ML workflows in computer vision and multimodal learning (fine-tuning, evaluation, and deployment of segmentation-capable VLMs). Community adoption appears strong for a research repo (on the order of ~2.6k GitHub stars), and it has high educational value for learning how to connect instruction-following LLM behavior with pixel-level segmentation outputs, justifying a 9 rather than a 10.",success
https://github.com/google-deepmind/mctx,mctx,"Mctx is a JAX-native library implementing Monte Carlo Tree Search algorithms (including AlphaZero, MuZero, and Gumbel MuZero) with batch-parallel execution and full JIT support for accelerator-friendly performance.",2600,reinforcement learning|monte carlo tree search|jax|deep reinforcement learning|muzero|alphazero|planning,9,"This repository provides production-quality, JAX-native implementations of core planning/search algorithms (MCTS) used in modern deep reinforcement learning, including MuZero-style policies and a generic search API. It is directly applicable to ML workflows for researchers and engineers building RL agents that combine neural networks with lookahead planning, and it is designed for accelerator use via batched computation and JIT compilation. The repo also has strong educational value by offering clear, configurable reference implementations and example demos/projects. Given its focused purpose in RL and clear community adoption (2.6k stars), it merits a high score, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/knazeri/edge-connect,edge-connect,"EdgeConnect is a two-stage, structure-guided image inpainting system that first predicts missing edges (edge generator) and then completes the image using those edges (image completion network). It provides PyTorch code, training/testing scripts, and pretrained models for common inpainting datasets.",2600,computer vision|image inpainting|deep learning|generative adversarial networks|PyTorch|edge detection,9,"This repository implements a published deep-learning method (EdgeConnect, ICCV 2019) for generative image inpainting using an adversarial edge-learning pipeline, including training and evaluation code. It is directly applicable to ML workflows for research and production prototyping in computer vision (data preparation, model training, inference, and pretrained checkpoints are all supported). The project is widely recognized and used (thousands of GitHub stars), making it educationally valuable and practical for ML engineers working on inpainting or related generative modeling tasks. It’s not a general-purpose ML framework, but it is a strong, end-to-end reference implementation for a well-known CV model, justifying a high score.",success
https://github.com/lucidrains/audiolm-pytorch,audiolm-pytorch,"A PyTorch implementation of Google Research's AudioLM for neural audio generation, including components for neural audio tokenization (SoundStream) and compatibility with Meta's EnCodec. It also adds text-conditioning via classifier-free guidance with T5 to enable text-to-audio / TTS-style workflows beyond the original paper.",2600,machine learning|deep learning|PyTorch|audio generation|text-to-audio|neural codec|transformers,9,"This repository implements state-of-the-art research (AudioLM) for generating audio with language-modeling techniques in PyTorch, and includes practical building blocks like a SoundStream neural codec and EnCodec compatibility for tokenizing audio into discrete codes usable by downstream models. It is directly applicable to ML workflows for training and experimenting with audio generative models (and related tasks like text-to-audio/TTS conditioning), making it highly relevant for ML engineers and researchers. While it is not a broadly adopted foundational framework on the scale of PyTorch itself, its strong research/educational value and usable training code make it a high-impact ML repo.",success
https://github.com/michaelfeil/infinity,infinity,"Infinity is a high-throughput, low-latency REST API (and CLI/Docker runtime) for serving text embeddings and related inference workloads such as reranking and multimodal models (e.g., CLIP/CLAP/ColPali). It focuses on fast production serving via multiple inference backends, dynamic batching, and an OpenAPI/OpenAI-aligned interface.",2600,embeddings|model-serving|inference|FastAPI|NLP|reranking|MLOps|vector-search,9,"This repository provides an inference serving engine/REST API specifically for ML embedding and reranking models, including multi-model orchestration and optimized backends (e.g., PyTorch and ONNX/optimum), which makes it directly useful in real-world ML and RAG pipelines. It is highly applicable to data/ML workflows because it operationalizes embedding generation behind a production-friendly API/CLI and supports GPU/CPU deployments (including Docker images). Community adoption appears strong (≈2.6k GitHub stars) and it integrates well with common ML tooling and deployment patterns, justifying a high (but not foundational-framework-level) score.",success
https://github.com/secretflow/secretflow,secretflow,"SecretFlow is a unified framework for privacy-preserving data intelligence, data analysis, and machine learning. It provides an abstract device layer for cryptographic protocols, a DAG-based device flow layer, algorithm support for horizontally/vertically partitioned data (e.g., federated learning), and workflow capabilities for end-to-end processing and training.",2600,privacy-preserving machine learning|federated learning|secure multi-party computation|homomorphic encryption|differential privacy|trusted execution environment|data analysis,9,"This repository is primarily a privacy-preserving data analysis and machine learning framework, providing core abstractions (devices, DAG/flow execution) and algorithm/workflow layers aimed at real ML and analytics tasks across multiple parties. It is directly applicable to ML/data workflows where data cannot be centralized, supporting techniques like federated learning and other privacy-enhancing technologies (e.g., MPC, HE, DP, and related capabilities). The project shows meaningful community adoption (thousands of GitHub stars) and integrates concepts and components commonly needed in practical privacy-preserving ML systems, making it highly valuable for ML engineers and data scientists working in regulated or multi-organization settings.",success
https://github.com/voxelmorph/voxelmorph,voxelmorph,"VoxelMorph is a learning-based medical image registration library for aligning images via predicted deformation fields, supporting unsupervised training and providing scripts/tutorials and pre-trained models for common registration workflows. It includes TensorFlow and a PyTorch implementation (with the PyTorch interface noted as under active development).",2600,medical imaging|image registration|deep learning|computer vision|PyTorch|TensorFlow|deformable registration|neuroimaging,9,"This repository provides end-to-end deep learning tooling for deformable image registration (predicting warps/deformation fields and training models with unsupervised losses), including training/registration/testing scripts and references to tutorials and pre-trained models. It is directly applicable to ML workflows in medical imaging/neuroimaging (data loading, model training, inference/registration, evaluation) and is widely recognized in the research community for learning-based registration. It does not have the broad, general-purpose adoption of core ML frameworks, but as a domain-specific ML library it is highly valuable for practitioners working on registration and deformation modeling, justifying a score of 9.",success
https://github.com/HypoX64/DeepMosaics,DeepMosaics,"DeepMosaics is a computer-vision project that can automatically remove mosaics (pixelation/censorship) from images and videos, and also add mosaics. It is based on semantic segmentation and image-to-image translation, with scripts, pretrained-model support, and instructions for running and training on custom datasets.",2500,computer vision|deep learning|PyTorch|image-to-image translation|semantic segmentation|video processing|mosaic removal,9,"This repository implements an ML-based pipeline (semantic segmentation + image-to-image translation) for adding/removing mosaics in images and videos, and includes code, pretrained model usage, and guidance for training on your own dataset. It is directly applicable to ML/CV workflows (model inference, dataset creation/training, and deployment-style tooling via scripts/GUI), and it relies on standard ML tooling like PyTorch and related dependencies. Its popularity (thousands of GitHub stars) suggests meaningful community adoption for a specialized CV task, making it highly valuable for practitioners and learners working on restoration, censorship removal, or image-translation problems.",success
https://github.com/KimMeen/Time-LLM,Time-LLM,"Official ICLR 2024 implementation of Time-LLM, a framework that repurposes frozen large language models for time-series forecasting by reprogramming time-series inputs into text-like prototypes and using prompts to guide the LLM’s reasoning, then projecting the transformed representations into forecasts.",2500,time series forecasting|large language models|reprogramming|deep learning|PyTorch|Transformers|prompting|research code,9,"This repository implements Time-LLM, a research framework for performing time-series forecasting by leveraging (largely frozen) LLM backbones via input reprogramming and prompt-based context augmentation, with training/evaluation scripts and datasets instructions. It is directly applicable to ML workflows for time-series forecasting research and experimentation (e.g., running benchmarks, reproducing paper results, adapting to new datasets/backbones) and integrates standard ML tooling such as PyTorch, Hugging Face Transformers, and DeepSpeed. While it is not a general-purpose production library and has more limited “industry-standard” adoption than core frameworks, it is highly valuable for ML practitioners working specifically on time-series foundation models and LLM-based forecasting, justifying a 9/10 score.",success
https://github.com/MaybeShewill-CV/lanenet-lane-detection,lanenet-lane-detection,"An unofficial TensorFlow implementation of the LaneNet deep neural network for real-time lane detection, based on the paper ""Towards End-to-End Lane Detection: an Instance Segmentation Approach"". It includes code to run inference with pretrained weights (TuSimple) and scripts/utilities to prepare data and train/evaluate the model.",2500,computer-vision|lane-detection|autonomous-driving|tensorflow|semantic-segmentation|instance-segmentation|deep-learning,9,"This repository implements an end-to-end deep learning lane-detection model (LaneNet) using TensorFlow, providing training, evaluation, and inference scripts plus pretrained weights for the TuSimple lane dataset. It is directly applicable to ML/computer-vision workflows (dataset preparation, TFRecords generation, model training, and benchmarking) and is a strong educational reference for instance segmentation with discriminative losses in a practical perception task. Community adoption appears solid for a research-implementation repo (thousands of GitHub stars and hundreds of forks), making it useful as a baseline, learning resource, or starting point for custom lane-detection projects.",success
https://github.com/asteroid-team/asteroid,asteroid,"Asteroid is a PyTorch-based audio source separation toolkit for researchers, designed to enable fast experimentation with common datasets and architectures. It includes training recipes to reproduce results from key source-separation papers and provides utilities like PIT loss wrappers and filterbank APIs.",2500,audio source separation|speech processing|machine learning|deep learning|pytorch|research toolkit|signal processing,9,"This repository is primarily a deep learning toolkit for audio source separation, built directly on PyTorch and centered around training and evaluating neural separation models. It is directly applicable to ML workflows via its model implementations, loss/training utilities (e.g., PIT), dataset support, and reproducible experiment recipes. With substantial community adoption (thousands of GitHub stars) and strong educational value for modern separation methods, it rates highly as an ML-focused research/engineering library.",success
https://github.com/automl/Auto-PyTorch,Auto-PyTorch,"Auto-PyTorch is an AutoML toolkit built on PyTorch that automates deep learning pipeline creation by jointly optimizing neural network architectures and training hyperparameters. It primarily targets tabular (classification/regression) and time series forecasting tasks, leveraging SMAC-based optimization, multi-fidelity scheduling, warmstarting/portfolio methods, and ensembling.",2500,automl|pytorch|neural-architecture-search|hyperparameter-optimization|tabular-ml|time-series-forecasting|bayesian-optimization|ensemble-learning,9,"This repository provides a directly usable AutoML/AutoDL system for common ML workflows, notably tabular classification/regression and time series forecasting, built on PyTorch and designed to automate model selection, architecture search, and hyperparameter tuning. It integrates established AutoML techniques (e.g., SMAC optimization, multi-fidelity budgeting, warmstarting/portfolio construction, and ensembling), making it highly applicable for ML engineers and data scientists who want strong baselines with minimal manual tuning. Its GitHub adoption (about 2.5k stars) indicates meaningful community usage, though it is not at the ubiquitous, foundational-framework level of core libraries like PyTorch itself; hence a 9 rather than a 10.",success
https://github.com/deeplearning4j/deeplearning4j-examples,deeplearning4j-examples,"A collection of runnable example projects demonstrating how to use the Eclipse Deeplearning4J ecosystem (DL4J, ND4J/SameDiff, DataVec) for tasks like model training, data pipelines/ETL, distributed training on Spark, and importing models (e.g., ONNX/Keras). The repo is organized as multiple separate Maven projects you can build and run to learn DL4J workflows end-to-end.",2500,deep-learning|machine-learning|java|deeplearning4j|maven|apache-spark|data-pipelines|model-import,9,"This repository’s primary purpose is to provide practical, runnable examples for the Deeplearning4J stack (DL4J for neural networks, DataVec for ML ETL, and related components like SameDiff), including modules for distributed training and model import. It is directly applicable to ML engineering and data science workflows on the JVM by showing end-to-end patterns (data loading/preprocessing, training/evaluation, and integration with tools like Spark). Its strong educational value and broad coverage of common DL4J use cases justify a high score, though it is an examples repository rather than the core framework itself.",success
https://github.com/mdeff/fma,fma,"FMA (Free Music Archive) is an open dataset and accompanying code/notebooks for music information retrieval research, including metadata, precomputed audio features, and baseline models (e.g., genre recognition). The repository documents dataset creation, provides utilities for loading/processing the data, and includes notebooks for analysis and reproducible experiments.",2500,dataset|music-information-retrieval|audio-analysis|machine-learning|deep-learning|jupyter-notebook|python|reproducible-research,9,"This repository primarily provides the widely used FMA (Free Music Archive) dataset for music analysis/MIR, along with Python utilities and Jupyter notebooks for loading data, feature extraction, dataset creation, and baseline genre-recognition experiments. It is directly applicable to ML/data workflows (supervised learning on audio/features, benchmarking, and dataset handling) and has strong educational value via its notebooks and documented train/validation/test setup. While it is not a general-purpose ML framework, it is a high-impact, task-focused ML dataset/resource, which justifies a high score.",success
https://github.com/median-research-group/LibMTL,LibMTL,"LibMTL is an open-source PyTorch-based library for deep multi-task learning (MTL), providing a unified and extensible framework with consistent evaluation utilities and implementations of many state-of-the-art MTL architectures and optimization/weighting strategies.",2500,machine learning|deep learning|multi-task learning|pytorch|optimization|research library|multi-objective learning,9,"LibMTL is purpose-built for machine learning research and practice in deep multi-task learning, offering a unified framework plus numerous implemented MTL methods (architectures and optimization/weighting strategies) to enable fair comparisons and rapid prototyping. It fits directly into typical ML workflows because it is built on PyTorch and provides runnable examples/benchmarks and modular components for extending to new tasks or new MTL algorithms. Community adoption appears solid for a research library (about 2.5k GitHub stars), and it has strong educational/reproducibility value via documentation and a published JMLR paper describing the library. It is not a general-purpose ML framework at the scale of PyTorch/TensorFlow, so it does not warrant a 10, but it is highly relevant and directly useful for MTL-focused ML engineering and research.",success
https://github.com/meijieru/crnn.pytorch,crnn.pytorch,"PyTorch implementation of a Convolutional Recurrent Neural Network (CRNN) for image-based sequence recognition, primarily aimed at scene text recognition (OCR). Includes demo inference with a pretrained model and scripts for dataset preparation and training.",2500,computer-vision|ocr|scene-text-recognition|deep-learning|pytorch|crnn|ctc-loss,9,"This repository provides a practical PyTorch implementation of the CRNN architecture for scene text recognition, including training and inference code plus dataset tooling. It is directly applicable to ML workflows for OCR and sequence recognition, and references standard academic grounding (Shi et al., 2016) with guidance for constructing datasets and training. Community adoption appears strong (about 2.5k stars and hundreds of forks), making it both useful for applied work and educational for understanding CRNN+CTC pipelines.",success
https://github.com/oegedijk/explainerdashboard,explainerdashboard,"A Python library to quickly build and deploy interactive Explainable AI dashboards (Plotly Dash) for scikit-learn–compatible models, including performance analysis, feature importance, SHAP-based explanations, partial dependence, and what-if exploration. Supports exporting dashboards to static HTML and composing multiple dashboards via an ExplainerHub.",2500,explainable-ai|model-interpretability|machine-learning|python|plotly-dash|shap|scikit-learn,9,"This repository provides a ready-to-use framework for creating interactive dashboards that explain and analyze ML models (e.g., SHAP values, permutation importance, partial dependence, and per-prediction explanations) with deployment and export options. It is directly applicable to common data science workflows for model debugging, validation, stakeholder communication, and governance/regulatory needs, and integrates with widely used ML toolchains (scikit-learn and popular gradient boosting libraries). Given its clear ML-specific purpose and strong community adoption (≈2.5k GitHub stars), it merits a high score, though it is not itself a core training framework.",success
https://github.com/scikit-learn-contrib/category_encoders,category_encoders,Category Encoders is a Python library providing scikit-learn-compatible transformers to encode categorical features into numeric representations using many unsupervised and supervised encoding techniques. It supports pandas DataFrames well and is designed to plug directly into sklearn Pipelines/ColumnTransformers for ML preprocessing workflows.,2500,machine learning|data preprocessing|categorical encoding|scikit-learn|python|feature engineering|pandas,9,"This repository implements a broad set of categorical feature encoders (e.g., one-hot, ordinal, hashing, target/leave-one-out, WOE, CatBoost-style) as scikit-learn-style transformers intended for feature engineering and preprocessing. It is directly applicable in day-to-day ML workflows because it integrates cleanly with scikit-learn pipelines and supports common data formats (notably pandas DataFrames). Community adoption appears strong (about 2.5k GitHub stars), and the breadth of encoding methods plus pipeline integration makes it highly valuable for ML practitioners, though it is a focused preprocessing tool rather than a full end-to-end ML framework.",success
https://github.com/young-geng/EasyLM,EasyLM,"EasyLM is a JAX/Flax-based framework for large language models that provides a single codebase for pre-training, fine-tuning, evaluation, and serving. It is designed to scale LLM training across many TPU/GPU accelerators using JAX pjit-based sharding and integrates with Hugging Face transformers/datasets.",2500,large language models|natural language processing|jax|flax|transformers|distributed training|fine-tuning,9,"This repository is primarily an LLM training/finetuning/evaluation/serving framework built specifically for machine learning workflows, with an emphasis on scalable training in JAX/Flax across TPU/GPU setups. It directly supports common LLM engineering tasks (pretraining, finetuning, evaluation, serving) and explicitly targets transformer-based language models (e.g., LLaMA family). Its strong alignment with core ML engineering needs and integration with standard ecosystem tools (Hugging Face) justify a high score, though it is not at the “industry-standard core library” adoption level of PyTorch/TensorFlow.",success
https://github.com/Lightning-AI/torchmetrics,torchmetrics,"TorchMetrics is a PyTorch-native library providing a large collection of machine learning metric implementations with a standardized API, including support for batch-wise accumulation and correct synchronization in distributed/multi-device training. It is designed to reduce evaluation boilerplate and integrates well with PyTorch Lightning workflows.",2400,machine-learning|pytorch|metrics|deep-learning|distributed-training|model-evaluation|pytorch-lightning,9,"This repository provides a comprehensive set of machine learning evaluation metrics implemented in native PyTorch, with APIs that handle stateful accumulation across batches and synchronization across devices for distributed training. It is directly applicable in ML workflows for training and validating models (classification, regression, and domain-specific areas like vision/audio/text), and it is commonly used alongside PyTorch and PyTorch Lightning. Community adoption is strong (thousands of GitHub stars) and the project is well-documented and tested, making it highly valuable to ML engineers and data scientists. It is not a full training framework itself, so it falls just short of a perfect 10.",success
https://github.com/cure-lab/LTSF-Linear,LTSF-Linear,"Official PyTorch implementation of the AAAI 2023 (Oral) paper ""Are Transformers Effective for Time Series Forecasting?"" providing the LTSF-Linear family (Linear, NLinear, DLinear) for long-term time series forecasting, plus scripts/benchmarks and re-implementations of several forecasting Transformers for comparison.",2400,time series forecasting|deep learning|pytorch|long-term forecasting|linear models|transformers|benchmarking,9,"This repository provides end-to-end code (models, experiment scripts, and benchmark setup) for long-term time series forecasting (LTSF), centered on the LTSF-Linear family (Linear/NLinear/DLinear) introduced in the associated AAAI 2023 paper. It is directly applicable to ML workflows (training/evaluation on standard forecasting datasets, reproduction of paper results, and comparison against multiple Transformer-based baselines) and is implemented in PyTorch, making it easy for ML engineers to integrate or extend. Community adoption appears strong for an academic codebase (about 2.4k GitHub stars), and the repo is also positioned as an educational reference for understanding why simple linear baselines can be competitive in LTSF. It is not a general-purpose production library, but it is highly valuable for research, benchmarking, and practical experimentation in time-series ML.",success
https://github.com/google-research/electra,electra,"Reference implementation of ELECTRA, a self-supervised pretraining method for Transformer language models that trains a discriminator to detect replaced tokens instead of generating masked tokens. The repo includes scripts for building pretraining datasets, pretraining models, and fine-tuning on downstream NLP tasks such as GLUE classification, SQuAD QA, and sequence tagging, plus code for the related “Electric” objective.",2400,machine learning|natural language processing|transformers|language model pretraining|TensorFlow|fine-tuning|ELECTRA,9,"This repository is purpose-built for ML: it provides end-to-end code to pre-train ELECTRA Transformer encoders and to fine-tune/evaluate them on common NLP benchmarks (e.g., GLUE and SQuAD). It is directly applicable to ML workflows involving representation learning and downstream task adaptation, and includes dataset-building utilities and training scripts. While it targets an older TensorFlow stack (TF 1.15), the method is widely known and the repo remains highly educational and practically useful for understanding and reproducing ELECTRA-style pretraining.",success
https://github.com/mckinsey/causalnex,causalnex,"CausalNex is a Python library for causal reasoning and “what-if” (counterfactual/interventional) analysis using Bayesian Networks. It supports causal structure learning, incorporating domain knowledge into the graph, fitting probabilistic models, and estimating intervention effects (e.g., via do-calculus).",2400,causal inference|bayesian networks|machine learning|data science|counterfactual analysis|probabilistic modeling|python,9,"This repository provides an end-to-end toolkit for causal modeling workflows centered on Bayesian Networks: learning graph structure from data, refining it with expert knowledge, fitting distributions, and running intervention/what-if analyses. These capabilities are directly applicable to ML/data science projects where causal understanding and decision support matter (beyond correlation-based modeling), and it includes documentation and practical interfaces for data scientists. It also shows notable community adoption (about 2.4k GitHub stars), supporting a high score, though it is more specialized than broad, general-purpose ML frameworks.",success
https://github.com/metarank/metarank,metarank,"Metarank is an open-source, low-code machine learning ranking service for real-time personalization in search and recommendations. It ingests user feedback signals (e.g., clicks/purchases), computes ranking features, and serves reranking models to improve relevance and engagement.",2400,learning-to-rank|search|recommendation-systems|semantic-search|information-retrieval|mlops|scala|real-time-personalization,9,"This repository provides a production-oriented learn-to-rank/personalized ranking service that supports search and recommendation use cases, including feature generation from behavioral signals and model serving for reranking. It is directly applicable to ML/data workflows (ranking, IR, recommender systems, online inference) and is designed to integrate with existing search stacks and cloud-native deployments (e.g., stateless service with Redis-managed state). With substantial community interest (2.4k stars at the time of lookup) and strong practical value for ML engineers building real-time ranking pipelines, it merits a high score, though it is more specialized than general-purpose ML frameworks.",success
https://github.com/microsoft/DialoGPT,DialoGPT,"Microsoft’s DialoGPT repository provides code and pretrained checkpoints for a large-scale GPT-2-based dialogue response generation model trained on Reddit conversations, including scripts for data extraction/preprocessing and model training/evaluation. The repo is noted as no longer maintained and recommends switching to GODEL unless DialoGPT is needed for reproducibility.",2400,natural language processing|dialogue systems|chatbots|transformer models|language modeling|PyTorch|pretrained models|research,9,"This repository contains end-to-end resources for an ML dialogue model (DialoGPT), including pretrained model checkpoints and training/data-prep code built around GPT-2-style transformers. It is directly applicable to ML/NLP workflows for experimenting with conversational response generation, fine-tuning, and benchmarking, and it connects well to the broader ecosystem (e.g., Hugging Face model cards referenced in the README). Although the repo is marked as no longer maintained and superseded by GODEL, it remains a highly valuable research/educational resource for reproducing results and understanding large-scale dialogue pretraining, justifying a high score.",success
https://github.com/PacktPublishing/The-Kaggle-Book,The-Kaggle-Book,"Official code repository for Packt Publishing’s book “The Kaggle Book: Data analysis and machine learning for competitive data science,” containing chapter notebooks and supporting materials for Kaggle-style ML workflows (validation, feature engineering, ensembling, AutoML, CV/NLP, etc.).",2300,machine learning|data science|kaggle|jupyter notebooks|python|feature engineering|model validation|ensembling,9,"This repository provides the hands-on notebooks and code accompanying “The Kaggle Book,” organized by chapter and focused on competitive machine learning practices such as validation design, feature engineering, model tuning, and ensembling. It is directly applicable to ML/data workflows because users can run the notebooks on Kaggle/Colab or locally and reuse the techniques in real projects and competitions. While it is primarily educational rather than a reusable framework/library, it is highly relevant and practical for data scientists aiming to improve modeling skills, which justifies a high score.",success
https://github.com/labmlai/labml,labml,"LabML is an open-source experiment tracking and monitoring toolkit for deep learning that lets you log training metrics, configurations, and metadata (e.g., git commit/hyperparameters) and view them via a self-hosted web/mobile-friendly UI. It also includes hardware monitoring utilities and supports distributed training workflows.",2300,machine learning|deep learning|experiment tracking|MLOps|PyTorch|TensorFlow|monitoring,9,"This repository provides a purpose-built platform for managing and monitoring ML experiments (metric logging, experiment metadata, visualizations, and a server/UI for viewing runs) plus system/hardware monitoring. It directly supports common ML workflows across frameworks (e.g., PyTorch/TensorFlow) and is immediately usable by ML engineers for training runs and reproducibility. With thousands of GitHub stars and dedicated documentation, it shows meaningful adoption and strong educational/practical value, but it is not a foundational ML computation framework itself—so it scores slightly below a 10.",success
https://github.com/opengeos/geoai,geoai,"GeoAI is a Python package that integrates AI/deep learning with geospatial data workflows, covering remote sensing data discovery/download, dataset preparation, model training (classification/detection/segmentation), inference pipelines, and interactive visualization. It also includes QGIS integration via a dedicated plugin to run GeoAI workflows from the desktop GIS.",2300,geospatial|remote sensing|machine learning|deep learning|computer vision|PyTorch|GIS|QGIS,9,"This repository is primarily an ML-for-geospatial toolkit: it provides end-to-end capabilities for geospatial AI workflows including data acquisition (e.g., satellite/aerial imagery), dataset preparation (chips/labels), model training, and inference, plus visualization integrations and a QGIS plugin. It is directly applicable to common ML/DS pipelines for remote sensing computer vision tasks (classification, detection, segmentation) and integrates with major ML frameworks like PyTorch and related model libraries. Its scope and tooling make it highly valuable for practitioners and learners working in geospatial ML, though it is not a general-purpose, industry-standard ML framework at the scale of PyTorch/TensorFlow, which is why it scores 9 rather than 10.",success
https://github.com/refuel-ai/autolabel,autolabel,"Autolabel is a Python library for labeling, cleaning, and enriching text datasets using large language models (LLMs). It supports a config-driven workflow (guidelines + model selection, dry-run prompt preview, then run labeling) and includes tooling to benchmark supported models/prompts.",2300,machine learning|data labeling|LLMs|NLP|synthetic data|data quality|Python|benchmarking,9,"This repository provides an end-to-end, LLM-driven system to automatically label and enrich text datasets, which is a core step in many ML/NLP workflows (training data creation, weak supervision, dataset cleaning, and augmentation). It is directly usable by data scientists and ML engineers via a Python API and simple JSON configs, and it explicitly targets improving labeled data availability/quality for ML. The repo also includes model benchmarking utilities and examples, increasing its practical and educational value. It scores a 9 (not 10) because it is a specialized data-labeling utility rather than a general-purpose, industry-defining ML framework with the broad adoption of foundational libraries.",success
https://github.com/scverse/scanpy,scanpy,"Scanpy is a scalable Python toolkit for analyzing single-cell gene expression (single-cell omics) data. It provides an end-to-end workflow including preprocessing, visualization, clustering, trajectory inference, and differential expression testing, and integrates closely with AnnData.",2300,single-cell|bioinformatics|transcriptomics|data-science|machine-learning|python|anndata|scverse,9,"This repository provides a mature, widely used library for single-cell gene expression data analysis, covering core data-science tasks like preprocessing, dimensionality reduction, clustering, visualization, and statistical testing. It directly supports ML/data workflows in computational biology by enabling scalable analysis pipelines and integrating with standard data structures (AnnData) and tooling. Community adoption is strong (thousands of stars, active development), and it is commonly used in research and production-like analysis settings, justifying a high (but not general-purpose-ML-framework-level) score.",success
https://github.com/OpenDCAI/DataFlow,DataFlow,"DataFlow is a data-centric AI data preparation and training system that uses modular LLM/deep-learning/rule-based operators assembled into reusable pipelines to parse, generate, clean, augment, and evaluate high-quality datasets from noisy sources (e.g., PDFs, plain text, low-quality QA) for domain LLM training (pretraining/SFT/RL) and RAG knowledge-base cleaning.",2200,data-centric ai|data preparation|llm|rag|data pipelines|data quality evaluation|python|data engineering,9,"This repository primarily targets ML data workflows: it provides a unified system of modular operators (including LLM-based operators) and ready-to-use pipelines to transform noisy raw inputs into high-quality training/evaluation data for domain-specific LLM improvement and RAG knowledge-base cleaning. It is directly applicable to data/ML engineering tasks such as dataset generation, data cleaning, and quality scoring, and it ships with documented CLI-driven pipeline scaffolding and multiple built-in pipelines (e.g., text mining, reasoning augmentation, text2sql, KB cleaning). Community adoption appears meaningful (2.2k GitHub stars), but it is not at the ecosystem-defining scale of top-tier frameworks; hence a 9 rather than a 10.",success
https://github.com/feature-engine/feature_engine,feature_engine,"Feature-engine is a Python feature engineering library that provides a wide range of scikit-learn compatible transformers (fit/transform) for tasks like imputation, encoding, discretization, outlier handling, variable transformations, feature creation, scaling, and feature selection.",2200,machine learning|feature engineering|data preprocessing|scikit-learn|python|feature selection|tabular data,9,"This repository implements Feature-engine, a dedicated feature engineering and feature selection library for tabular machine learning workflows, exposing many preprocessing operations as scikit-learn-style transformers that plug directly into pipelines. It is highly applicable for data scientists/ML engineers because it standardizes common transformation steps (e.g., imputers, encoders, outlier cappers, discretisers, selectors) in a reproducible fit/transform API. Community adoption appears strong (2.2k GitHub stars and 334 forks), indicating meaningful usage in the ML/data ecosystem. It’s not a full training framework, but it is a core preprocessing toolkit, which justifies a high (but not maximum) score.",success
https://github.com/isl-org/Open3D-ML,Open3D-ML,"Open3D-ML extends the Open3D library with machine learning tooling for 3D data (e.g., point clouds), including dataset loaders, training/inference pipelines, and pretrained models for tasks such as semantic point cloud segmentation. It supports both PyTorch and TensorFlow integrations and includes utilities like visualization to fit into practical 3D ML workflows.",2200,3d machine learning|point clouds|computer vision|pytorch|tensorflow|semantic segmentation|open3d,9,"This repository is purpose-built for 3D machine learning, providing end-to-end components (datasets, model configs, pipelines, pretrained weights, and examples) for training and inference on point-cloud tasks. It integrates directly with major ML frameworks (PyTorch and TensorFlow) and is usable in real ML engineering workflows (model development, evaluation, and visualization). Its adoption (about 2.2k GitHub stars) indicates meaningful community usage in the 3D vision/ML space, making it highly valuable for ML practitioners working with 3D data.",success
https://github.com/NannyML/nannyml,nannyml,"NannyML is an open-source Python library for post-deployment model monitoring: it estimates model performance without target labels, detects data/model/target drift, and helps connect drift alerts to performance impact for tabular classification and regression use cases.",2100,machine learning|MLOps|model monitoring|data drift|performance estimation|Python|tabular data,9,"This repository provides a dedicated post-deployment ML monitoring toolkit, including target-free performance estimation (e.g., CBPE for classification and DLE for regression) plus drift detection and alerting workflows. It is directly applicable for data scientists and ML engineers operating production tabular models, integrating naturally into monitoring pipelines and notebooks with built-in visualizations and APIs. Community signals (e.g., a large star count for a specialized MLOps library) indicate meaningful adoption and practical value. It’s not a general-purpose training framework, but it is a highly relevant, production-focused ML/data tool, justifying a score of 9.",success
https://github.com/ContinualAI/avalanche,avalanche,"Avalanche is an end-to-end PyTorch-based library for deep continual (lifelong) learning, providing benchmarks, training strategies/algorithms, evaluation metrics, and experiment logging to support fast prototyping and reproducible research workflows.",2000,machine learning|continual learning|lifelong learning|deep learning|PyTorch|benchmarks|evaluation metrics|research framework,9,"This repository provides a full-stack continual learning framework built on PyTorch, including standardized benchmark/data stream generation, modular training strategies (including baselines and state-of-the-art methods), and evaluation/logging utilities. It is directly applicable to ML research and engineering workflows for continual learning experiments (installable as a Python package) and emphasizes reproducibility and rapid prototyping. With substantial community adoption (about 2k GitHub stars and many downstream users), it has high practical and educational value for ML practitioners working in continual/lifelong learning, though it is more specialized than general-purpose ML libraries, so it is scored a 9 rather than a 10.",success
https://github.com/dstackai/dstack,dstack,"dstack is an open-source control plane for provisioning and orchestrating GPU compute to run development, training, and inference workloads across cloud providers, Kubernetes, and on-prem clusters. It provides a server + CLI/API workflow to manage backends, fleets, tasks, services, and dev environments across heterogeneous accelerator hardware.",2000,MLOps|GPU orchestration|model training|model inference|Kubernetes|cloud infrastructure|DevOps,9,"This repository provides an open-source control plane focused on GPU provisioning and orchestration for running ML development, training, and inference jobs across multiple environments (hyperscalers, Kubernetes, and on-prem). It directly supports common ML workflows (jobs/services/dev environments) and emphasizes compatibility with ML hardware accelerators, making it highly applicable for ML engineers and data science teams operationalizing training and deployment. While it is not an ML framework itself, it sits squarely in the MLOps/compute-orchestration layer and is designed to integrate with existing ML tools and frameworks, justifying a high score.",success
https://github.com/JuliaAI/MLJ.jl,MLJ.jl,"MLJ (Machine Learning in Julia) is a Julia machine learning toolbox that provides a common interface and meta-algorithms for selecting, tuning, evaluating, composing, and comparing 200+ machine learning models (from Julia and other languages). It serves as an umbrella package integrating multiple MLJ ecosystem components.",1900,machine learning|data science|Julia|model evaluation|hyperparameter tuning|pipelines|ensemble learning|meta-learning,9,"MLJ.jl is a dedicated machine learning framework/toolbox for Julia, focused on providing a unified interface plus meta-algorithms for end-to-end model selection, composition (pipelines), evaluation, and tuning across a large catalog of models. It is directly applicable to typical ML/data-science workflows (training, validation, benchmarking, model comparison, and automation of tuning) and integrates many models via its ecosystem/umbrella-package design. Its strong community adoption signals (about 1.9k GitHub stars, many releases, and a sizeable contributor base) support a high score, though it is not at the universal-industry-adoption level of the largest cross-language frameworks.",success
https://github.com/WenjieDu/PyPOTS,PyPOTS,"PyPOTS is a Python toolkit for machine/deep learning and data mining on partially-observed (missing-value) multivariate time series, especially real-world/industrial data with NaNs and irregular sampling. It provides unified APIs and implements many state-of-the-art models for tasks such as imputation, forecasting, classification, clustering, and anomaly detection.",1900,machine learning|deep learning|time series|missing data imputation|pytorch|anomaly detection|forecasting,9,"This repository is purpose-built for ML on partially-observed time series, offering a broad collection of modern neural models and workflows for key data-science tasks (imputation, forecasting, classification, clustering, anomaly detection) under missingness. It is directly applicable in ML/data workflows where NaNs/irregular sampling are common, and it emphasizes unified APIs plus documentation/tutorials to make advanced methods usable. Community adoption appears strong for a specialized research/engineering toolkit (≈1.9k GitHub stars), but it is not a foundational, universally adopted platform like PyTorch/Pandas—so a 9 (highly relevant) fits better than a 10.",success
https://github.com/data-infra/cube-studio,cube-studio,"Cube Studio is an open-source, cloud-native, end-to-end ML/AI platform for managing the full algorithm lifecycle, including online notebooks, drag-and-drop pipeline orchestration, distributed training, hyperparameter search, and model inference/serving. It targets enterprise MLOps needs on Kubernetes and supports a wide range of ML frameworks and heterogeneous compute (CPU/GPU/NPU), including domestic/Ascend ecosystems.",1900,MLOps|machine learning platform|Kubernetes|distributed training|pipeline orchestration|notebooks|model serving|LLM fine-tuning,9,"This repository provides a comprehensive cloud-native ML/AI platform (“one-stop” MLOps) covering development (notebooks), workflow/pipeline orchestration, distributed multi-node/multi-GPU training, hyperparameter tuning, and inference services. It directly supports common ML engineer and data science workflows by operationalizing training and deployment on Kubernetes and integrating with multiple ML/distributed frameworks (e.g., PyTorch/TensorFlow and distributed runtimes). While it is more infrastructure/platform than an ML algorithm library, its breadth across the ML lifecycle and clear MLOps focus make it highly valuable for ML/data teams, warranting a 9/10.",success
https://github.com/diffgram/diffgram,diffgram,"Diffgram is an ""AI Datastore"" and training-data platform that combines data storage/cataloging with human supervision (data labeling/annotation) workflows and a UI for managing datasets, schemas, and predictions across many media types. It supports end-to-end annotation and dataset operations (e.g., labeling, QA/workflows, and model-assisted/pre-label tooling) for AI/ML projects.",1900,data annotation|data labeling|computer vision|mlops|dataset management|data catalog|vue.js|kubernetes,9,"This repository provides a full platform for creating and managing training data, including labeling workflows, dataset storage/catalog features, and support for multiple media modalities (image, video, 3D, text, audio, geospatial, etc.). It is directly applicable to ML workflows because training-data creation, curation, and QA are core steps in building reliable models, and Diffgram explicitly targets storing predictions and enabling model-assisted labeling and integrations. Community adoption appears meaningful (about 1.9k GitHub stars) and the project positions itself as a comprehensive alternative to commercial labeling platforms. It is not an ML modeling framework itself, but as a training-data and annotation system it is highly valuable for data science and ML teams, hence a 9/10.",success
https://github.com/feathr-ai/feathr,feathr,"Feathr is an open-source data and AI engineering platform (feature store/feature engineering system) for defining, computing, registering, and serving reusable features from batch and streaming data. It provides Pythonic APIs with Spark/PySpark support, point-in-time-correct joins to prevent data leakage, a feature registry, and integrations for running in cloud environments like Databricks and Azure Synapse.",1900,feature store|feature engineering|machine learning|MLOps|data engineering|Apache Spark|PySpark|Azure,9,"This repository implements Feathr, a production-oriented feature engineering and feature store platform focused on building, computing, registering, and reusing ML features across teams and environments. It directly supports key ML/data workflows such as offline training dataset generation with point-in-time correctness (to reduce leakage) and feature materialization/serving for online inference, using Spark/PySpark and cloud integrations (e.g., Databricks and Azure Synapse). Its strong alignment with end-to-end feature pipelines and operationalization makes it highly valuable for ML engineers and data scientists, though it is not a general-purpose model training framework (hence not a 10).",success
https://github.com/linkedin/greykite,greykite,"Greykite is LinkedIn's forecasting and anomaly detection library, centered on the Silverkite algorithm, providing an end-to-end framework for time series modeling (EDA, preprocessing, feature engineering, model selection via grid search/CV, evaluation, and plotting). It also offers an anomaly detection extension (Greykite AD) that tunes prediction-interval-based alerts using expected alert rates and/or labels.",1900,time series forecasting|anomaly detection|machine learning|Python|scikit-learn|statistics|data science,9,"This repository is primarily a time series forecasting and anomaly detection library, with an end-to-end modeling workflow (templates, feature engineering, cross-validation/backtesting, evaluation, and visualization) designed for practical forecasting problems. It is directly applicable to common ML/data science tasks involving temporal metrics, and it integrates with ML-style estimators (e.g., fitting forecasts via a machine learning model of choice). Its community adoption is solid (about 1.9k GitHub stars) and it provides strong educational value through documented algorithms/components (e.g., Silverkite, changepoint detection, model summaries), justifying a high relevance score rather than a perfect 10 reserved for broadly dominant ecosystem tools.",success
https://github.com/netease-youdao/BCEmbedding,BCEmbedding,"BCEmbedding is NetEase Youdao’s open-source bilingual/crosslingual retrieval package for RAG, providing an EmbeddingModel (dual-encoder) for semantic vector search and a RerankerModel (cross-encoder) for second-stage reranking. It includes evaluation resources and integrations for common RAG frameworks such as LangChain and LlamaIndex.",1900,machine learning|NLP|embeddings|reranking|RAG|semantic search|langchain|llamaindex,9,"This repository provides production-oriented embedding and reranker models aimed directly at retrieval-augmented generation (RAG), enabling semantic search (vector embeddings) and second-stage reranking for better retrieval quality. It is highly applicable to ML/NLP workflows (e.g., building retrievers, search pipelines, and RAG systems) and includes integrations with popular tooling like LangChain and LlamaIndex plus evaluation guidance/benchmarks. Community adoption appears solid (about 1.9k GitHub stars at time of lookup), and the repo is directly usable by practitioners for real-world RAG deployments, justifying a high score but not a 10 since it is not a general-purpose foundational framework on the scale of PyTorch/TensorFlow.",success
https://github.com/AI4Finance-Foundation/FinRL-Meta,FinRL-Meta,"FinRL®-Meta provides dynamic datasets plus modular market environments and benchmarks for data-driven financial reinforcement learning, supporting a training-testing-trading workflow. It includes many plug-and-play market environments, demo/tutorial notebooks, and integrations with common DRL libraries for fair strategy evaluation and reproducibility.",1800,financial reinforcement learning|algorithmic trading|quantitative finance|market simulation|benchmarking|Python|Stable-Baselines3,9,"FinRL-Meta is purpose-built for machine learning, specifically deep reinforcement learning applied to trading and portfolio/market environments, with an emphasis on datasets, environment construction, and reproducible benchmarks. It directly supports common ML workflows (data processing + environment setup + training/testing/trading pipeline) and is designed to compare DRL agents fairly across standardized environments. The repository shows strong community adoption signals (notably a large GitHub star count) and high educational value via demos/tutorials and research-paper benchmarks. It is not a general-purpose ML framework on the scale of PyTorch/TensorFlow, but it is highly valuable within the financial DRL domain.",success
https://github.com/ZhengyaoJiang/PGPortfolio,PGPortfolio,"Implementation of the Policy Gradient Portfolio (PGPortfolio) approach from the paper ""A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem"" (arXiv:1706.10059). It provides a research toolkit for portfolio management, including configurable training/experiments, TensorBoard visualization, and baseline (financial-model-based) portfolio algorithms for comparison.",1800,reinforcement learning|deep learning|algorithmic trading|portfolio optimization|quantitative finance|tensorflow|python,9,"This repository is primarily an ML project: it implements a deep reinforcement learning (policy-gradient) method tailored to financial portfolio management, alongside experiment configuration, training, and evaluation/backtesting utilities. It is directly applicable to ML/data workflows for quantitative finance research (feature/input data handling, model training, hyperparameter tuning, and result analysis via TensorBoard). While it is not a broadly adopted general-purpose ML framework, it has strong educational and practical value for reinforcement-learning-driven trading/portfolio research and includes useful baselines for benchmarking, warranting a high score.",success
https://github.com/moj-analytical-services/splink,splink,"Splink is a Python package for probabilistic record linkage (entity resolution) used to deduplicate and link records across datasets that lack unique identifiers. It implements a Fellegi–Sunter-style linkage model and runs at scale across multiple SQL backends (e.g., DuckDB locally, plus Spark and AWS Athena).",1800,record linkage|entity resolution|deduplication|probabilistic matching|data engineering|python|sql|spark,9,"This repository provides a production-grade probabilistic data linkage system (entity resolution/deduplication) with unsupervised parameter estimation and tooling to generate predictions and clusters. It is directly applicable to common data science workflows (cleaning/merging identity-like datasets, creating analytical “single customer/person views”) and supports scalable execution on DuckDB, Spark, and AWS Athena, which makes it useful from laptop-scale to big-data environments. While it is not a general-purpose ML training framework, it is a highly specialized statistical/ML-adjacent library that solves a core data preparation problem and has strong real-world adoption, justifying a high score.",success
https://github.com/microsoft/responsible-ai-toolbox,responsible-ai-toolbox,"Responsible AI Toolbox is a Microsoft suite of interactive widgets and supporting libraries for model and data exploration/assessment (e.g., responsible AI dashboard, error analysis, interpretability, and fairness) to help teams debug, understand, and monitor ML systems more responsibly. It integrates established OSS components (e.g., Fairlearn and InterpretML) and is commonly used from Jupyter environments via the raiwidgets package.",1700,responsible-ai|machine-learning|model-evaluation|fairness|interpretability|error-analysis|jupyter|python,9,"This repository provides a set of Responsible AI-focused dashboards and widgets (Responsible AI dashboard, Error Analysis, Interpretability, and Fairness) used to assess and debug ML models and datasets in interactive workflows. It directly supports common ML engineering/data science tasks like identifying error cohorts, evaluating group fairness metrics, and explaining predictions, often through Jupyter via the raiwidgets Python package. Its integration with widely used responsible-AI tools (e.g., Fairlearn, InterpretML) and its practical, workflow-oriented UI components make it highly applicable for real-world ML evaluation and governance, warranting a 9/10.",success
https://github.com/google/uncertainty-baselines,uncertainty-baselines,"Uncertainty Baselines (UB) is a Google-maintained collection of high-quality, reproducible baseline implementations for uncertainty estimation and robustness benchmarking in deep learning. It provides modular training pipelines plus dataset/model utilities to compare standard and state-of-the-art methods across common ML tasks.",1600,machine-learning|uncertainty-quantification|robustness|deep-learning|benchmarking|tensorflow|jax|pytorch,9,"This repository’s primary purpose is to provide curated, reproducible baselines and best-practice experiment pipelines for evaluating uncertainty and robustness in deep learning, making it directly usable for ML research and applied model benchmarking. It includes baseline scripts (e.g., CIFAR) and reusable modules for datasets and models, aligning closely with typical ML workflows (training, evaluation, metrics, and reproducibility). Community adoption is solid for a specialized benchmarking library (about 1.6k GitHub stars), and it has strong educational value for learning how to run and compare uncertainty/robustness methods in practice. It’s not a general-purpose framework on the level of PyTorch/TensorFlow, so it’s scored slightly below a 10, but it remains highly valuable for ML practitioners focused on uncertainty and robustness.",success
https://github.com/intelligent-machine-learning/dlrover,dlrover,"DLRover is an automatic distributed deep learning system focused on making large-scale model training on Kubernetes and Ray easier, more stable, and more efficient. It provides fault tolerance, elastic/auto-scaling scheduling, and “Flash Checkpoint” for fast checkpointing and rapid recovery, plus extension libraries for PyTorch and TensorFlow training workflows.",1600,distributed training|deep learning|MLOps|Kubernetes|Ray|fault tolerance|PyTorch|TensorFlow,9,"DLRover’s primary purpose is to automate and harden large-scale distributed deep learning training, targeting production needs like elastic scheduling, fault recovery, and fast checkpoint/restore (Flash Checkpoint), especially for Kubernetes/Ray-based clusters. This is directly applicable to ML engineering workflows for training large models (including LLM-scale training) and integrates with common training stacks (e.g., PyTorch/TensorFlow and distributed strategies like DDP/FSDP/DeepSpeed/Megatron-LM). The repository shows meaningful community adoption (about 1.6k GitHub stars) and provides infrastructure-level capabilities that materially improve training stability and utilization, warranting a high (but not ecosystem-defining) score.",success
https://github.com/mlrun/mlrun,mlrun,"MLRun is an open-source MLOps/AI orchestration platform for building, deploying, and managing continuous ML and generative AI applications across their lifecycle. It integrates with development and CI/CD workflows to automate data pipelines, training pipelines, and scalable online serving with observability.",1600,MLOps|machine learning pipelines|LLMOps|orchestration|Kubernetes|model serving|feature store|observability,9,"This repository provides an end-to-end AI orchestration/MLOps platform that automates core lifecycle steps like data preparation, pipeline execution, deployment/serving, and monitoring for ML and generative AI workloads. It is directly applicable to real-world ML engineering workflows (pipelines, CI/CD integration, deployment, monitoring) rather than being a general-purpose utility. Given its clear ML-first purpose, broad integrations (data stores, execution frameworks, ML frameworks, platforms), and visible community adoption on GitHub, it merits a high relevance score, though it is not at the universal-adoption level of foundational libraries like PyTorch or TensorFlow.",success
https://github.com/ModelOriented/DALEX,DALEX,"DALEX (moDel Agnostic Language for Exploration and eXplanation) provides model-agnostic tools to explore, compare, and explain predictive models via a unified “explainer” wrapper and a set of local/global explainability methods. It targets interpretable ML/XAI workflows primarily in R, with a related Python package included in the repository.",1500,machine learning|explainable AI (XAI)|model interpretability|responsible AI|R package|Python package|model diagnostics,9,"This repository implements DALEX, a model-agnostic explainability framework that wraps trained predictive models and provides multiple local and global explainers for understanding model behavior. It is directly applicable in ML/data-science workflows (classification/regression) to diagnose, compare, and communicate model decisions, and it is positioned explicitly within interpretable ML/XAI and responsible ML practices. The project shows notable community adoption (about 1.5k GitHub stars) and has strong educational value through extensive documentation and references (including JMLR papers), so it merits a high score short of foundational training frameworks.",success
https://github.com/PacktPublishing/Machine-Learning-for-Algorithmic-Trading-Second-Edition_Original,Machine-Learning-for-Algorithmic-Trading-Second-Edition_Original,"Companion code repository for the book ""Machine Learning for Algorithmic Trading (2nd Edition)"" by Packt, containing 150+ Jupyter notebooks and supporting code to source financial/alternative data, engineer features, train ML/DL models (including NLP and deep reinforcement learning), and backtest/evaluate trading strategies.",1500,machine learning|algorithmic trading|quant finance|time series|deep learning|reinforcement learning|NLP|Jupyter notebooks,9,"This repository primarily serves as a hands-on, notebook-driven implementation of machine-learning methods for systematic trading, including data sourcing, feature engineering, model training/tuning, and strategy backtesting/evaluation. It is directly applicable to ML/data workflows because it provides end-to-end examples across supervised/unsupervised learning, deep learning (CNN/RNN), text-based signal extraction, and deep reinforcement learning applied to financial data. While it is not a general-purpose ML framework with massive industry-wide adoption, its breadth of applied ML techniques and extensive educational notebook content make it highly valuable for data scientists and ML engineers working in (or learning) quantitative finance.",success
https://github.com/code-kern-ai/refinery,refinery,"Kern AI's open-source tool for scaling, assessing, and maintaining natural language (NLP) training data in a data-centric workflow. It supports (semi-)automated labeling, data quality analysis/monitoring, and integrates with common NLP stacks (e.g., Hugging Face, spaCy) and vector search (e.g., Qdrant).",1500,machine learning|data-centric ai|nlp|data labeling|training data management|hugging face|spacy|vector search,9,"This repository is primarily built for NLP/ML workflows: creating, managing, and improving labeled text datasets using a data-centric approach (including semi-automated labeling and identifying low-quality subsets). It directly supports day-to-day ML engineering work around training data quality, iteration speed, and dataset monitoring, and it integrates with widely used NLP tooling (Hugging Face and spaCy) plus neural/vector search (Qdrant). While it is not itself a model-training framework, its focus on training data operations makes it highly valuable and broadly applicable to real-world ML pipelines, justifying a high score.",success
https://github.com/lotus-data/lotus,lotus,"LOTUS is a Python framework/query engine for LLM- and embedding-powered data processing over structured and unstructured datasets, offering a Pandas-like DataFrame API with ""semantic operators"" (e.g., semantic filter/join/agg) and execution optimizations for large speedups. It targets robust, accurate AI-based analytics and document processing by optimizing LLM execution plans and providing accuracy/quality guarantees against reference methods.",1500,llm|data-processing|pandas|dataframe|document-processing|embeddings|rag|query-engine,9,"This repository provides an LLM-powered data processing/query engine with a Pandas-like API, aimed directly at transforming and analyzing datasets (structured and unstructured) using semantic operators such as semantic filtering, joining, and aggregation. It is highly applicable to ML/data workflows (RAG pipelines, document ETL/extraction, evaluation/LLM-judge analyses, and semantic analytics) and emphasizes optimized execution and robustness/accuracy guarantees, which are key concerns for production data/ML teams. Community adoption appears meaningful (on the order of ~1.5k GitHub stars), and the project is accompanied by documentation, examples, and a corresponding Python package distribution, supporting integration into real-world DS/ML stacks. It is not a general-purpose ML training framework like PyTorch, but it is a strong, specialized data/LLM processing system, warranting a high score.",success
https://github.com/pixeltable/pixeltable,pixeltable,"Pixeltable is an open-source Python library that provides declarative, incremental data infrastructure for building multimodal AI applications. It unifies storage, transformation, indexing/retrieval (including vector search), and AI orchestration via a table + computed-columns interface.",1500,machine learning|data infrastructure|multimodal AI|vector search|python|data engineering|LLM orchestration,9,"This repository implements Pixeltable, a Python-first declarative table system designed specifically for multimodal AI workloads, including incremental computation, built-in model/inference integration (e.g., LLM/vision/embeddings), and vector indexing for retrieval. It is directly applicable to ML engineering and data workflows because it replaces/combines common AI stack components (storage, ETL-style transforms, orchestration, and vector DB functionality) into one programmable interface. Community adoption appears meaningful (about 1.5k GitHub stars) and the project has clear docs and a packaged distribution (PyPI releases), indicating practical usability. It is not a general-purpose ML training framework, but it is highly relevant infrastructure for building and operating AI applications, justifying a 9/10.",success
https://github.com/skrub-data/skrub,skrub,"skrub (formerly dirty_cat) is a Python library for doing machine learning with dataframes, focusing on preprocessing and feature engineering for heterogeneous tabular data. It provides scikit-learn compatible tools (e.g., vectorization/pipelines) and utilities for assembling/joining tables (including fuzzy joins) to go from messy tables to model-ready features.",1500,machine learning|data preprocessing|feature engineering|tabular data|dataframes|scikit-learn|pandas|polars,9,"This repository is a dedicated ML/data-science library aimed at turning real-world (often messy/heterogeneous) dataframes into features suitable for tabular machine learning, with scikit-learn compatible components and end-to-end pipeline helpers. It directly targets core steps in ML workflows—preprocessing, encoding/vectorization, and table assembly (including fuzzy joining of imperfect keys)—so it is immediately usable by data scientists and ML engineers. The project shows meaningful community adoption (on the order of ~1.5k GitHub stars) and maintains comprehensive documentation and examples, which increases practical and educational value. It is not a full model-training framework like PyTorch/TensorFlow, but as a high-leverage preprocessing/feature-engineering toolkit for tabular ML it merits a high score.",success
https://github.com/sb-ai-lab/LightAutoML,LightAutoML,"LightAutoML (LAMA) is a fast, customizable Python AutoML framework by Sber AI Lab for automatic machine learning model creation. It offers ready-to-use presets and building blocks to construct end-to-end ML pipelines (including preprocessing, feature generation, model training, tuning, and reporting) across tabular, text, image, and time-series use cases.",1400,automl|machine-learning|data-science|tabular-modeling|feature-engineering|hyperparameter-optimization|python,9,"This repository is an AutoML framework intended specifically for building ML models with minimal code, providing presets and configurable pipeline components (preprocessing, feature engineering, model selection/ensembling, tuning, and reports). It is directly applicable to common ML workflows for classification/regression and includes practical examples/tutorials that support learning and integration into real projects. The GitHub popularity (about 1.4k stars) suggests meaningful community adoption, but it is not at the near-universal adoption level of foundational libraries (e.g., PyTorch/Pandas), so it scores slightly below a 10.",success
https://github.com/skforecast/skforecast,skforecast,"Skforecast is a Python library for time series forecasting using machine learning models. It wraps any scikit-learn-compatible estimator to provide forecasting workflows (single and multi-series), feature engineering, backtesting/validation, and model selection/tuning utilities.",1400,time series forecasting|machine learning|python|scikit-learn|feature engineering|model selection|backtesting,9,"This repository provides a dedicated time-series forecasting framework built around machine-learning estimators that follow the scikit-learn API, enabling users to turn regression/classification-style models into forecasters. It is directly applicable to common ML/data workflows (training, validation/backtesting, feature engineering, and hyperparameter tuning) and integrates well with widely used ML libraries (e.g., scikit-learn and popular gradient-boosting frameworks). The project also shows meaningful community adoption (notably its GitHub star count) and offers strong educational value via documentation and examples, justifying a high relevance score.",success
https://github.com/zama-ai/concrete-ml,concrete-ml,"Concrete ML is an open-source privacy-preserving machine learning (PPML) framework that lets data scientists run ML inference (and some workflows) on encrypted data using Fully Homomorphic Encryption (FHE). It provides scikit-learn-like built-in models and conversion tooling (e.g., PyTorch to FHE) built on top of Zama’s Concrete stack.",1400,privacy-preserving machine learning|fully homomorphic encryption|FHE|machine learning|scikit-learn|PyTorch|ONNX,9,"This repository’s primary purpose is to enable privacy-preserving ML by compiling/transforming models so they can run with Fully Homomorphic Encryption (FHE), allowing inference on encrypted inputs without exposing sensitive data. It is directly applicable to ML engineers and data scientists because it offers ML-oriented APIs (scikit-learn-like estimators) plus pathways for importing/custom models (e.g., via PyTorch/ONNX) into an FHE-compatible execution workflow. While it is a specialized niche compared to mainstream training frameworks, it is still a highly relevant, practical ML tool with clear integration into common ML ecosystems and substantial community interest (≈1.4k GitHub stars).",success
https://github.com/aeon-toolkit/aeon,aeon,"Aeon is an open-source Python toolkit for time series machine learning, providing scikit-learn-compatible estimators and algorithms for tasks such as time series classification, clustering, and forecasting, with efficient implementations (e.g., via numba).",1300,time series|machine learning|deep learning|python|scikit-learn|forecasting|classification|clustering,9,"This repository provides a dedicated, scikit-learn-compatible toolkit focused on time series machine learning, covering core ML tasks like classification, clustering, and forecasting, and aims to include state-of-the-art algorithms with efficient implementations. It is directly applicable to ML/data science workflows because it offers ready-to-use estimators, documented examples, and installation via standard Python packaging, making it straightforward to integrate into existing pipelines. Its sizable community interest (on the order of ~1.3k GitHub stars) and breadth of time-series functionality make it highly valuable for ML practitioners, though it is not a general-purpose, industry-dominating ML framework at the scale of PyTorch/TensorFlow—hence a 9 rather than 10.",success
https://github.com/logicalclocks/hopsworks,hopsworks,"Hopsworks is a data-intensive AI platform (real-time AI lakehouse) that provides a Python-centric Feature Store plus MLOps capabilities to develop, govern, and serve features, training data, and models. It supports running as a standalone feature store and integrates with major cloud environments and third-party ML platforms.",1300,feature-store|mlops|machine-learning-platform|data-engineering|model-serving|lakehouse|kubernetes,9,"This repository implements Hopsworks, a full ML platform centered around a Feature Store and MLOps (feature pipelines, training pipelines, model governance and serving). It is directly applicable to ML/data workflows because it helps teams build and manage reusable features/training datasets and operationalize models across environments, and it explicitly targets real-time/batch ML production use cases. Community adoption appears solid (around 1.3k GitHub stars), and the platform integrates with common cloud/ML ecosystems, making it highly valuable for ML engineers and data teams, though it is not a general-purpose ML framework like PyTorch (hence not a 10).",success
https://github.com/sintel-dev/Orion,Orion,Orion is a Python machine learning library for unsupervised time series anomaly detection. It provides verified end-to-end anomaly detection pipelines that can be fit on time series data and used to detect and score anomalous intervals for review.,1300,machine learning|time series|anomaly detection|unsupervised learning|python|data science|automl,9,"This repository is explicitly a machine learning library focused on unsupervised time series anomaly detection, providing ready-to-use and benchmarked pipelines (e.g., autoencoders, GAN-based methods) for detecting anomalous patterns in signals. It is directly applicable to common ML/data workflows involving monitoring, forecasting-adjacent analytics, and anomaly triage, and includes tutorials, documentation, and a pip-installable package for practical adoption. While it is not a general-purpose ML framework on the scale of PyTorch/TensorFlow, it is highly relevant and purpose-built for a core ML task (time-series anomaly detection), warranting a high score.",success
https://github.com/uxlfoundation/scikit-learn-intelex,scikit-learn-intelex,Extension for Scikit-learn (scikit-learn-intelex) is a performance accelerator that speeds up scikit-learn training and inference (often 10–100x) on CPU and supported GPU setups by patching scikit-learn or providing drop-in accelerated implementations under a separate module.,1300,machine learning|scikit-learn|python|model acceleration|cpu optimization|gpu acceleration|oneapi,9,"This repository provides Intel/UXL’s Extension for Scikit-learn, which accelerates existing scikit-learn estimators and workflows via patching (e.g., patch_sklearn()) or direct use of accelerated equivalents. It is directly applicable to typical ML/data science pipelines because it targets core scikit-learn operations (training and inference) while preserving the familiar scikit-learn API and enabling CPU/GPU execution options. It has clear practical utility for ML engineers seeking faster experimentation/production inference without rewriting models, and it shows meaningful community adoption for a specialized performance layer, justifying a high (but not foundational-framework-level) score.",success
https://github.com/DeepWisdom/AutoDL,AutoDL,"An end-to-end automated deep learning framework designed to train competitive classifiers with no human intervention, supporting multiple data modalities (image, video, audio, text, and tabular) and multi-label/multi-class settings. It is published as the 1st-place solution for the AutoDL Challenge at NeurIPS and includes ingestion/scoring programs and sample submissions/data for the competition workflow.",1200,automl|deep-learning|multimodal-ml|classification|neural-architecture-search|hyperparameter-optimization|competition-code|python,9,"This repository provides a fully automated model-training pipeline targeting real-world supervised learning problems (especially multi-label classification) across several modalities, making it directly applicable to ML workflows. It includes competition-style ingestion/scoring components and a library of model approaches spanning classical ML through deep learning, which is valuable for practitioners and learning-by-example. While it is highly ML-focused and moderately adopted (not a general-purpose industry standard like PyTorch), its clear AutoML purpose, multimodal scope, and practical end-to-end setup justify a high score.",success
https://github.com/xorbitsai/xorbits,xorbits,"Xorbits is an open-source computing framework for scaling Python data science and machine learning workloads from a single machine (multi-core/GPU) to large clusters. It provides API-compatible integrations with familiar libraries like pandas/NumPy and supports ML workflows including preprocessing, tuning, training, and serving.",1200,distributed-computing|data-science|machine-learning|pandas|numpy|python|scalable-systems|ml-infrastructure,9,"This repository implements a distributed computing framework aimed directly at scaling data science and ML workloads, covering the end-to-end lifecycle from data preprocessing through training/tuning to model serving. It is highly applicable to ML/data workflows because it offers a familiar, largely API-compatible Python experience (notably pandas/NumPy) and integrates with common ML libraries, enabling users to scale existing code with minimal changes. While it is not itself a model library like PyTorch, it is strong ML/data infrastructure with clear practitioner utility and meaningful community adoption (1.2k GitHub stars), justifying a high score.",success
https://github.com/NVIDIA-Merlin/NVTabular,NVTabular,"NVTabular is an NVIDIA Merlin feature engineering and preprocessing library for tabular data, built to efficiently transform very large (terabyte-scale) datasets—especially for deep-learning recommender systems—by accelerating data processing on GPUs (e.g., via RAPIDS/Dask-cuDF).",1100,feature-engineering|data-preprocessing|tabular-data|recommender-systems|gpu-acceleration|rapids|dask|nvidia-merlin,9,"This repository provides a dedicated feature-engineering and preprocessing framework for tabular datasets, with an emphasis on scaling ETL/transform pipelines to very large data sizes and accelerating them on NVIDIA GPUs. It is directly applicable to ML workflows because it prepares training and inference-ready features (notably for recommender systems) and integrates into the broader NVIDIA Merlin ecosystem. The score is high due to its clear ML/data focus, practical utility for ML engineers working on large-scale tabular/recsys pipelines, and its strong alignment with production-oriented preprocessing needs (including reuse of transformations for inference).",success
https://github.com/WecoAI/aideml,aideml,"AIDE ML is an LLM-driven machine-learning engineering agent that uses an agentic tree-search process to iteratively draft, debug, benchmark, and improve ML code to optimize a user-defined evaluation metric. It provides a Python package plus utilities like a CLI, HTML tree visualizer, and a Streamlit UI for experimenting with and extending the AIDE algorithm.",1100,machine learning|data science|LLM agents|AutoML|MLOps|Python|CLI tools|Streamlit,9,"This repository implements AIDE ML, an LLM-guided agent that performs iterative, metric-driven exploration in the space of code to automatically produce and improve ML solutions for a dataset (including benchmarking and debugging along the way). It is directly applicable to ML/data workflows because it is designed to generate end-to-end ML pipelines from natural-language goals and metrics, and includes practical tooling (CLI, UI, visualization) to run experiments. While it is not a foundational library with PyTorch/TensorFlow-scale adoption, it is highly relevant for ML engineering automation, agent research, and rapid prototyping of ML baselines, warranting a high score.",success
https://github.com/cleanlab/cleanvision,cleanvision,"CleanVision is a Python library for auditing image datasets by automatically detecting common data quality issues (e.g., blurry, under/over-exposed, low-information, grayscale, odd size/aspect ratio, and duplicate/near-duplicate images) and generating reports to help improve computer vision data before model training.",1100,computer vision|data quality|dataset auditing|data-centric AI|data validation|deep learning|python,9,"This repository provides a dedicated data-centric computer vision tool (CleanVision) to automatically find and report image-quality issues like blur, exposure problems, and duplicates in image datasets, which are common failure modes in real-world ML pipelines. It is directly applicable to ML workflows as a pre-training dataset audit step, and it also integrates into cleanlab’s broader dataset-auditing ecosystem (e.g., used for image-specific issue detection). With substantial community adoption (about 1.1k GitHub stars) and clear documentation/tutorials, it is highly valuable for ML practitioners, though it is more specialized (dataset QA) than core training frameworks.",success
https://github.com/jankrepl/deepdow,deepdow,"DeepDow is a Python (PyTorch) framework for portfolio optimization with deep learning, designed to learn asset allocations end-to-end in a single forward pass. It provides differentiable building blocks (feature-extraction layers, allocation layers, losses, and data loaders) and integrates tools like differentiable convex optimization and experiment tracking.",1100,portfolio-optimization|deep-learning|pytorch|quant-finance|time-series|convex-optimization|machine-learning,9,"This repository is primarily an ML-focused toolkit for end-to-end learning of portfolio allocation policies, combining forecasting/feature extraction with differentiable optimization-style allocation layers. It is directly applicable to ML/data workflows in quantitative finance (time-series modeling, custom losses like Sharpe ratio/drawdown, experiment tracking via mlflow/tensorboard, and differentiable convex optimization via cvxpylayers). While it is not a general-purpose ML framework, it is a highly relevant, specialized library with meaningful community adoption for its niche (notably ~1.1k GitHub stars), warranting a high score but not a 10 due to narrower scope and ecosystem impact compared to core ML stacks.",success
https://github.com/run-house/kubetorch,kubetorch,"Kubetorch is a Pythonic interface for running and distributing ML/AI workloads on Kubernetes, enabling fast iteration (hot redeploy/caching), reproducible execution, and programmatic fault handling without writing Kubernetes YAML. It includes a Python client plus a Kubernetes deployment (via Helm/operator) and supports heterogeneous/distributed workloads (e.g., training, inference, data processing, evaluation).",1100,kubernetes|machine-learning|mlops|distributed-computing|pytorch|ray|infrastructure,9,"This repository provides an ML-focused, PyTorch-like Python API for launching, scaling, and operating AI workloads on Kubernetes, including features aimed at ML developer velocity (1–2s iteration), reproducibility, and robust fault handling. It is directly applicable to common ML workflows (distributed training, batch processing, online inference, evaluation) and integrates with common ecosystem components like Kubernetes/Helm and mentions compatibility with tools like Ray. While it is not a modeling library, it is highly valuable MLOps/ML infrastructure tooling for teams running real workloads, warranting a high score, though it is not at the universal-adoption level of core frameworks (so not a 10).",success
https://github.com/zinggAI/zingg,zingg,"Zingg is a scalable, ML-based entity/identity resolution and deduplication tool (data mastering) designed to link and unify records that refer to the same real-world entity across one or many data sources. It supports deterministic and probabilistic (fuzzy) matching and includes interactive/active-learning-driven training for building matching models with small labeled samples.",1100,entity-resolution|identity-resolution|deduplication|record-linkage|data-quality|active-learning|apache-spark|java-scala,9,"This repository implements an ML-driven entity resolution/identity resolution system for deduplication and building unified entity views (“data mastering”) at scale, including interactive labeling with active learning and both deterministic and fuzzy matching. It is directly applicable to common data engineering and data science workflows (customer 360, KYC/AML, data quality, record linkage) and is designed to scale to large datasets (Spark-oriented). While it is not a general-purpose ML framework, its primary purpose is a core data/ML task (entity resolution) and it provides end-to-end tooling (data access, labeling, model building, and matching), which justifies a high relevance score.",success
https://github.com/maxpumperla/deep_learning_and_the_game_of_go,deep_learning_and_the_game_of_go,"A Python-based machine learning framework and accompanying code samples for the book ""Deep Learning and the Game of Go"" (Manning). It builds Go-playing agents ranging from classic game AI through deep learning and reinforcement learning approaches, including implementations inspired by AlphaGo and AlphaGo Zero.",1036,machine learning|deep learning|reinforcement learning|game AI|Go (board game)|Python|neural networks|AlphaGo/AlphaGo Zero,9,"This repository is explicitly an end-to-end ML framework for building Go-playing bots, and it includes educational, runnable implementations spanning supervised learning, RL, and AlphaGo/AlphaGo Zero-style methods. It is directly applicable to ML workflows (data preparation for Go games, model training/inference, and RL experimentation) and is structured to support learning via examples tied to the associated book. While it is not a broadly adopted general-purpose ML framework like PyTorch, it has strong educational value and meaningful community adoption for a specialized domain (Go + deep learning), justifying a high score.",success
https://github.com/RexYing/gnn-model-explainer,gnn-model-explainer,"Reference implementation of GNNExplainer (NeurIPS 2019), an approach for generating explanations for Graph Neural Networks by learning feature- and edge-masks that highlight influential subgraphs and node features. Includes scripts to train GCN/GAT-style models, run the explainer, and visualize/export explanations (TensorBoard, Jupyter, D3).",1000,graph neural networks|model explainability|interpretable machine learning|PyTorch|PyTorch Geometric|graph machine learning|NeurIPS paper implementation,9,"This repository implements GNNExplainer, a widely cited method for explaining predictions of graph neural networks by producing node-feature and edge/subgraph importance masks. It is directly applicable to ML workflows involving GNNs (training models, generating explanations, and visualizing outputs) and supports multiple datasets/benchmarks used in the paper. While it is more of a research/reference codebase than a production-ready library, it has clear educational value and meaningful community adoption for graph-ML interpretability, justifying a high (but not maximum) score.",success
https://github.com/mlr-org/mlr3,mlr3,"mlr3 is an R package providing efficient, object-oriented building blocks for machine learning workflows (tasks, learners, resampling, measures, etc.). It is the next-generation successor to the mlr package and serves as the core of the broader mlr3 ecosystem of extension packages.",1000,machine learning|R|mlr3|model training|resampling|hyperparameter tuning|MLOps|data science,9,"This repository contains the core {mlr3} R package, which provides a unified, object-oriented framework for defining datasets as tasks, applying learners, and running standard ML evaluation procedures like resampling. It is directly applicable to day-to-day data science and ML workflows in R and forms the foundation for a large ecosystem of related packages (e.g., learners, tuning, pipelines, visualization). The score is 9 (not 10) because it is a major ML workflow framework in R with strong community adoption, but it is not a general cross-language industry-standard at the scale of tools like PyTorch/TensorFlow.",success
https://github.com/bigscience-workshop/promptsource,promptsource,"PromptSource is a toolkit for creating, sharing, and using natural-language prompt templates for NLP datasets. It includes a prompt collection (P3) and tooling/API plus a Streamlit-based GUI for authoring and inspecting prompts applied to Hugging Face Datasets.",,machine learning|natural language processing|prompt engineering|huggingface-datasets|dataset tooling|streamlit|python|jinja-templates,9,"This repository provides a prompt templating toolkit and accompanying prompt library (P3) used to transform dataset examples into natural-language inputs/targets, which is central to modern NLP workflows (prompting, zero-/few-shot evaluation, instruction tuning, and dataset preprocessing). It integrates directly with the Hugging Face Datasets ecosystem via a Python API and also offers a Streamlit GUI for prompt creation and analysis, making it immediately useful to ML practitioners working with text datasets. Community adoption appears strong for a research/tooling repo (thousands of GitHub stars shown, plus widespread association with BigScience/P3 prompting), but it is not a general-purpose ML framework on the scale of core libraries, so it falls slightly short of a 10.",success
https://github.com/databricks/dbrx,dbrx,"Official Databricks repository with minimal reference code, example scripts, and links/resources for running inference and fine-tuning the DBRX large language model (MoE) via common tooling (e.g., Hugging Face/LLM Foundry) and inference engines (e.g., vLLM, TensorRT-LLM). It includes a reference model implementation file (modeling_dbrx.py) and configuration examples for fine-tuning (full + LoRA).",,large language model|generative ai|llm-inference|mixture-of-experts|fine-tuning|huggingface|pytorch,9,"This repository is directly focused on ML: it provides code examples and resources for using Databricks' DBRX large language model, including reference model code and practical inference/fine-tuning entry points. It is highly applicable to ML engineering workflows (serving/inference, model experimentation, and fine-tuning via LLM Foundry and integrations like vLLM/TensorRT-LLM), but it is not a general-purpose framework on the scale of PyTorch/TensorFlow and the repo itself is intentionally minimal with many capabilities delegated to external projects and Hugging Face. Given its direct relevance to LLM usage and integration, strong educational value for DBRX specifically, and likely broad interest among practitioners, it merits a high (but not maximal) score.",success
https://github.com/yzhao062/pyod,pyod,"PyOD (Python Outlier Detection) is a Python library for anomaly/outlier detection on multivariate data, providing a unified scikit-learn-like API across a large collection of classical and deep learning detectors. It includes utilities for model evaluation, thresholding/contamination handling, acceleration via ensembles (e.g., SUOD), and optional PyTorch-based deep models.",,anomaly detection|outlier detection|machine learning|python|scikit-learn|pytorch|unsupervised learning|deep learning,9,"This repository’s primary purpose is to provide a comprehensive, production-usable toolbox for outlier/anomaly detection, offering many algorithms (classical and deep learning) behind a consistent sklearn-style interface. It is directly applicable to core ML/data workflows such as data cleaning, fraud/abuse detection, monitoring, and robust modeling, and it integrates naturally with common Python ML stacks (NumPy/SciPy/scikit-learn and optional PyTorch). Its long-running ecosystem presence, documentation, and breadth of implemented detectors make it highly valuable for practitioners and researchers, meriting a 9 (highly relevant ML tool, though not at the general-purpose “industry standard” level of foundational libraries like PyTorch/Pandas).",success
https://github.com/dair-ai/Prompt-Engineering-Guide,Prompt-Engineering-Guide,"A curated prompt engineering knowledge base with guides, papers, lessons, and notebooks covering prompt engineering, context engineering, retrieval-augmented generation (RAG), and AI agents, with a companion web version at promptingguide.ai.",68900,prompt engineering|large language models|generative AI|RAG|AI agents|NLP|education,8,"This repository is primarily an educational and reference guide that aggregates practical techniques, lessons, and resources for working effectively with LLMs, including prompting patterns, RAG, and agent/tool-use workflows. While it is not a core ML framework or dataset, it is directly applicable to modern ML/AI engineering work (especially LLM application development) and is widely adopted by the community, as indicated by its very large GitHub star count. Its high educational value and practical guidance for designing, evaluating, and operationalizing LLM prompts and RAG pipelines justify a strong score, but it falls short of a 9–10 because it is mainly documentation/resources rather than a production-grade ML library or platform.",success
https://github.com/pathwaycom/pathway,pathway,"Pathway is a Python ETL/live data processing framework for building batch+streaming pipelines, real-time analytics, and live LLM/RAG applications. It provides a Python API executed by a scalable Rust engine (incremental computation) and includes connectors and utilities for production deployment (e.g., Docker/Kubernetes) and integrations with ML libraries.",56500,stream processing|data engineering|real-time analytics|etl|llm|rag|python|rust,8,"This repository provides a production-oriented live data/ETL framework that supports incremental stream processing and real-time analytics, plus dedicated tooling for building LLM pipelines and RAG systems. It is directly applicable to many ML/data workflows (continuous feature/embedding pipelines, streaming ETL, real-time retrieval + generation, and data connectors), and it integrates naturally with Python ML ecosystems while relying on a high-performance Rust execution engine. It is not a core model-training framework, but it is highly valuable for building and operating data/LLM pipelines end-to-end, which justifies a high (but not maximum) score.",success
https://github.com/FoundationAgents/OpenManus,OpenManus,"OpenManus is an open-source Python framework for building and running general-purpose LLM agents from the terminal, with configurable LLM backends and optional browser automation. It also includes an MCP-based tool mode and an (unstable) multi-agent flow runner, plus an optional DataAnalysis agent for analysis/visualization tasks.",52400,llm-agents|agentic-ai|python|mcp|tool-use|browser-automation|data-analysis,8,"This repository provides an agent framework centered on LLM-driven task execution (including tool use via an MCP mode and a multi-agent flow runner), making it directly useful for building agentic ML applications. It is relevant to ML/data workflows because it can orchestrate LLM calls and tools, and it explicitly includes a DataAnalysis agent aimed at data analysis and visualization tasks. While it is not a core ML training framework (and its community adoption, though strong in stars, is narrower than foundational ML libraries), it is highly applicable for practical LLM/agent prototyping and integration work, justifying an 8/10.",success
https://github.com/mem0ai/mem0,mem0,"Mem0 is a universal memory layer for AI assistants/agents that stores, retrieves, and updates long-term memories (e.g., user preferences and prior interactions) to enable more personalized, context-aware conversations. It provides developer-friendly SDKs/APIs and supports integration with multiple LLMs and vector store backends for hosted or self-hosted deployments.",45200,llm|ai-agents|rag|agent-memory|vector-database|python|typescript,8,"This repository’s primary use case is providing long-term memory for LLM-powered agents by extracting/storing memories and retrieving relevant items at inference time, which is a common component of modern agentic/RAG systems. It is directly applicable to ML/LLM engineering workflows because it plugs into agent applications to improve personalization, latency, and token usage via memory retrieval rather than full-context prompting. Its high GitHub star count indicates strong community adoption in the LLM/agent ecosystem, and it includes practical examples and integrations (e.g., SDKs and vector store support) that make it useful in production ML applications. It’s not a core model-training framework, but it is a highly relevant enabling layer for applied LLM systems, hence an 8/10.",success
https://github.com/apache/airflow,apache/airflow,"Apache Airflow is an open-source platform for programmatically authoring, scheduling, and monitoring workflows (DAGs). It provides a rich web UI, extensible operator/provider ecosystem, and integrations for orchestrating data pipelines and other automated jobs.",43800,workflow orchestration|data engineering|data pipelines|ETL/ELT|MLOps|Python,8,"This repository is Apache Airflow, a widely used workflow orchestration system for defining, scheduling, and monitoring DAG-based pipelines. It is highly relevant to ML/data workflows because it is commonly used to orchestrate ETL/ELT, feature pipelines, model training/inference jobs, and related automation, and it integrates broadly with data platforms via providers. It is not an ML framework itself (it does not provide model algorithms/training primitives), but its adoption and integration potential in production data/ML stacks justify a high score.",success
https://github.com/streamlit/streamlit,streamlit,"Streamlit is an open-source Python framework that turns Python scripts into interactive web apps for data exploration, dashboards, reports, and chat/LLM apps. It provides a simple API for UI widgets, layout, charts, and data display, with easy local running and optional deployment via Streamlit Community Cloud.",43000,python|data-apps|data-visualization|dashboarding|web-development|ml-ops|llm-apps,8,"This repository implements Streamlit, a Python-first framework for quickly building interactive web applications around data, analytics, and ML demos (e.g., dashboards, data exploration tools, and LLM/chat apps). It is not a model-training framework itself, but it is highly practical for ML/data workflows because it is widely used to prototype, demo, and share results, and it integrates well with common Python data/ML libraries (pandas, NumPy, scikit-learn, PyTorch/TensorFlow via user code). Its large community adoption and strong fit for communicating and operationalizing analytics/ML outputs justify a high (but not perfect) score.",success
https://github.com/apachecn/ailearning,ailearning,ApacheCN 的 AI 学习/实战资料仓库，覆盖数据分析、机器学习实战与线性代数等内容，并包含部分 PyTorch、NLTK、TensorFlow 2 等相关教程与示例，配套提供在线阅读站点。,41900,machine learning|data analysis|education|python|pytorch|tensorflow|nlp,8,该仓库主要定位为中文 AI/数据分析/机器学习的学习与实战资料集合，包含多章节学习文档、示例代码与配套资源链接，并提供在线阅读入口。它对数据科学与机器学习工作流的直接“落地工具”属性不强（不是训练框架或MLOps系统），但作为系统化学习与复现实战案例的资料库，教育价值与可复用性较高。社区采用度也较好（GitHub 显示约 41.9k Stars、11.6k Forks），因此综合评为 8/10。,success
https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap,Deep-Learning-Papers-Reading-Roadmap,"A curated reading roadmap of influential deep learning papers, organized to guide learners from foundational history and core methods to specialized application areas. The repository primarily consists of an extensive README with categorized paper links, plus a small helper script for downloading papers.",39400,deep learning|machine learning|paper reading list|research roadmap|education|literature survey,8,"This repository is an educational, curated roadmap of deep learning papers rather than a software library, dataset, or training framework. It is highly relevant to ML workflows for researchers and practitioners because it helps structure learning and literature review across core DL topics and applications. Community adoption is strong (tens of thousands of stars), indicating it is widely used as a reference. It scores an 8 because its value is high for ML learning and research orientation, but it is not directly executable infrastructure or tooling for building/deploying models.",success
https://github.com/QuivrHQ/quivr,quivr,"Quivr is an opinionated Retrieval-Augmented Generation (RAG) framework (“second brain”) for integrating GenAI into applications, letting you ingest files and query them with LLMs using configurable workflows. It supports multiple LLM providers (e.g., OpenAI/Anthropic/Mistral and local models) and multiple vector stores (e.g., PGVector, Faiss), with extensibility for custom parsers and tools.",38800,retrieval-augmented-generation|LLM|NLP|vector-database|python|generative-ai|document-ingestion,8,"This repository primarily provides an opinionated RAG “core” (the backend brain behind Quivr) that ingests documents, builds embeddings/vector indexes, and orchestrates retrieval + generation workflows across multiple LLM providers and vector stores. It is directly applicable to ML/data workflows for building LLM-powered knowledge bases, document Q&A, and internal assistants, and it exposes configurable pipelines (e.g., YAML-defined workflows) that are useful for experimentation and integration. While it is not a model-training framework, it is highly relevant infrastructure for production LLM applications and applied NLP, which justifies a high (but not maximum) score.",success
https://github.com/chatchat-space/Langchain-Chatchat,Langchain-Chatchat,"Langchain-Chatchat (formerly Langchain-ChatGLM) is an open-source, offline-deployable RAG and agent application built with LangChain, integrating local/hosted LLMs (e.g., ChatGLM/GLM-4-Chat, Qwen2, Llama3) to provide knowledge-base Q&A via FastAPI APIs and a Streamlit WebUI.",37000,LLM|RAG|LangChain|agents|knowledge base|FastAPI|Streamlit|vector database,8,"This repository provides an end-to-end RAG and agent application for building knowledge-base question answering and tool-using chat systems on top of LangChain, with support for multiple open-source LLMs, embedding models, and vector databases. It is directly useful for ML/LLM engineering workflows (document ingestion, chunking, embedding, retrieval, prompting, serving, and a WebUI), though it is more of an application framework than a model-training library. Strong community adoption (tens of thousands of GitHub stars) and broad model/database integration make it highly valuable for practitioners building LLM-enabled data products, justifying a score of 8/10.",success
https://github.com/pola-rs/polars,polars,"Polars is an extremely fast DataFrame library and analytical query engine written in Rust. It supports both eager and lazy execution with query optimization, streaming execution for larger-than-RAM datasets, and has APIs for Python, Rust, Node.js, R, and SQL.",36900,dataframes|data-engineering|analytics|rust|python|apache-arrow|lazy-execution|query-engine,8,"This repository implements Polars, a high-performance DataFrame and analytical query engine (eager + lazy) with query optimization and streaming execution, primarily aimed at fast data manipulation and analytics. It is highly applicable to ML/data workflows because it is commonly used for feature engineering, ETL, data cleaning, and preprocessing prior to model training, and it integrates well with Arrow-based data ecosystems and Python tooling. While it is not an ML framework itself (no model training/inference core), its direct utility in preparing and processing large datasets and its strong community adoption in data engineering justify a high score rather than a perfect 10.",success
https://github.com/duckdb/duckdb,duckdb,"DuckDB is a high-performance, in-process analytical (OLAP) SQL database designed to be fast, portable, and easy to embed. It supports a rich SQL dialect (e.g., window functions, complex types) and integrates with tools like Python/R and data formats like CSV and Parquet.",35200,sql|database|analytics|olap|embedded-database|data-engineering|parquet,8,"This repository implements DuckDB, an embedded analytical SQL database optimized for local/interactive analytics and fast querying over common data formats (e.g., CSV and Parquet). It is highly applicable to data science workflows because it integrates directly with Python and data tools (notably pandas) and can serve as a fast query engine for feature extraction, exploratory analysis, and dataset preparation. While it is not an ML training framework itself, it is widely adopted in the data community as core analytics infrastructure and integrates cleanly into ML pipelines, justifying a high (but not maximum) score.",success
https://github.com/BerriAI/litellm,litellm,"LiteLLM is a Python SDK and proxy server (AI gateway) that lets you call 100+ LLM provider APIs using an OpenAI-compatible (or native) interface. It also provides operational features such as cost tracking, logging, guardrails, and load balancing across providers like OpenAI, Azure, AWS Bedrock, Vertex AI, Anthropic, Cohere, and more.",33500,LLM|OpenAI-compatible API|AI gateway|MLOps|observability|cost tracking|proxy server|Python,8,"This repository provides an OpenAI-compatible SDK and production proxy/gateway to unify access to many LLM providers and models, focusing on routing, reliability, and operational controls (logging, guardrails, load balancing, and spend tracking). It is highly applicable to ML/LLM engineering workflows because it simplifies model/provider integration and adds MLOps-style governance and observability for LLM usage. It is not a model training framework or data-processing library, but it is a strong enabling layer for deploying and operating LLM-powered applications at scale, which justifies a high (but not maximum) score.",success
https://github.com/lutzroeder/netron,netron,"Netron is a visualizer/viewer for neural network, deep learning, and machine learning model files. It supports many popular model formats (e.g., ONNX, TensorFlow Lite, PyTorch, Keras, Core ML) via a web app, desktop apps, and a Python package.",32200,machine-learning|deep-learning|model-visualization|onnx|pytorch|tensorflow-lite|keras|coreml,8,"This repository provides a widely used tool to inspect and visualize trained ML model graphs and metadata across many frameworks and file formats, making it directly useful in day-to-day ML engineering workflows. It doesn’t train models or build datasets, but it significantly improves model debugging, architecture review, interoperability checks, and communication by providing a clear visual representation. Strong community adoption (tens of thousands of GitHub stars) and broad format support make it highly relevant for ML practitioners, though it’s not a core training/inference framework—hence an 8/10 rather than a 9–10/10.",success
https://github.com/khoj-ai/khoj,khoj,"Khoj is an open-source, self-hostable “AI second brain” that lets you chat with local or hosted LLMs and get answers grounded in your documents and/or the web. It provides semantic search and agent/automation features and can be accessed from clients like browser apps and editor integrations (e.g., Obsidian/Emacs).",32100,LLM|RAG|semantic search|personal knowledge base|AI agents|MLOps|self-hosted|Python,8,"Khoj’s primary purpose is to run a personal AI assistant that performs retrieval-augmented generation (RAG) over your content (PDF/Markdown/Notion/etc.) and can also use web information, which is directly relevant to modern ML application workflows. For data scientists and ML engineers, it’s useful as an end-to-end reference implementation for embeddings + vector storage (via Postgres/pgvector), LLM integration (local or API-compatible servers), and building agentic features and automations. It’s not a general-purpose ML framework for training models, but it is highly applicable for deploying LLM-powered knowledge assistants and experimentation with RAG/agents, meriting a high (but not max) score.",success
https://github.com/microsoft/Data-Science-For-Beginners,Data-Science-For-Beginners,"A Microsoft-authored, project-based data science curriculum organized as a 10-week, 20-lesson course. It includes lesson materials with instructions, quizzes, assignments, and solutions, plus supporting assets (datasets, examples, and a quiz app).",31800,data science|education|curriculum|python|data visualization|statistics|machine learning,8,"This repository is primarily an educational curriculum for learning data science fundamentals through a structured 10-week, 20-lesson program with hands-on projects, quizzes, and assignments. It directly supports ML/data workflows by teaching core concepts and practical skills (working with data, visualization, lifecycle topics) rather than providing a production ML framework or tool. Community adoption is strong for a learning resource (tens of thousands of GitHub stars), and it is highly useful for onboarding and self-study, which justifies a high—but not maximum—score.",success
https://github.com/academic/awesome-datascience,awesome-datascience,"A curated, “awesome list”-style collection of Data Science learning materials, tools, and references, organized into sections like training resources, algorithms, ML/deep learning ecosystems, visualization, and datasets. It serves as a guided starting point for learning and applying data science concepts to real-world problems.",28100,data science|machine learning|deep learning|learning resources|awesome list|datasets|model evaluation,8,"This repository is primarily a curated index of data science and machine learning resources (courses, tutorials, algorithms, tool ecosystems like PyTorch/TensorFlow/Keras, evaluation/monitoring links, and datasets), rather than an executable library. It is highly relevant to ML/data workflows as a discovery and learning hub—useful for selecting tools, finding training materials, and locating references commonly used by practitioners. Community adoption appears strong (tens of thousands of GitHub stars), indicating broad utility. It earns an 8/10 because it is highly valuable educationally and as a resource map, but it is not a core production framework or tool used directly in pipelines.",success
https://github.com/TauricResearch/TradingAgents,TradingAgents,"TradingAgents is an open-source, multi-agent LLM financial trading research framework that models a trading firm workflow (analysts, researchers, trader, risk management, portfolio manager) to collaboratively analyze market data and produce simulated trading decisions. It provides both a CLI and a Python package, and integrates with external data sources (e.g., yfinance and Alpha Vantage) and LLM APIs (e.g., OpenAI).",27700,llm|multi-agent-systems|algorithmic-trading|quant-finance|langgraph|python|backtesting|market-data,8,"This repository provides a multi-agent LLM framework specifically aimed at financial market analysis and (simulated) trading decision-making, with modular agent roles (fundamental/sentiment/news/technical analysis, debate, trading, risk, portfolio approval) and a runnable CLI/package interface. It is highly relevant to ML/data workflows because it operationalizes LLM-based agent orchestration over market/news/fundamental data sources and can be used as a research scaffold for experimentation, evaluation, and pipeline integration. While it is not a general-purpose ML training framework and its core value depends on external APIs/data access, its strong domain focus, clear architecture, and significant community adoption (high star count) justify an 8/10.",success
https://github.com/HumanSignal/labelImg,labelImg,"LabelImg is a desktop (Qt) graphical image annotation tool for drawing object bounding boxes and exporting labels in common computer-vision dataset formats such as PASCAL VOC (XML), YOLO, and CreateML. The HumanSignal fork is archived (read-only) and notes that ongoing efforts have shifted to the broader Label Studio community tool.",24600,computer vision|image annotation|data labeling|bounding boxes|dataset creation|python|qt,8,"This repository provides an interactive GUI tool used to label images with bounding boxes and export annotations in widely used ML training formats (PASCAL VOC, YOLO, CreateML), making it directly useful for creating computer-vision datasets. It is strongly relevant to ML/data workflows because labeling and ground-truth creation are core steps in supervised CV model training and evaluation. Community adoption appears high (tens of thousands of GitHub stars), but the repo is archived and no longer actively developed, which slightly reduces its practical value versus maintained labeling platforms (e.g., Label Studio).",success
https://github.com/wesm/pydata-book,pydata-book,"Official companion repository for Wes McKinney’s book ""Python for Data Analysis"" (3rd Edition), containing chapter-by-chapter Jupyter/IPython notebooks plus datasets and examples used throughout the book.",24100,data science|python|pandas|numpy|jupyter notebooks|data analysis|teaching materials,8,"This repository primarily provides educational notebooks, datasets, and code examples that accompany the book ""Python for Data Analysis"" and teach practical data manipulation and analysis workflows in Python (notably with pandas and NumPy). While it is not an ML framework or modeling library itself, it is highly applicable to day-to-day data science work because it covers foundational skills needed to prepare, clean, explore, and transform data before modeling. Its strong community adoption and broad use as a learning resource for Python data analysis make it especially valuable for data scientists and ML practitioners, hence a high (but not maximal) score.",success
https://github.com/lukasmasuch/best-of-ml-python,best-of-ml-python,"A curated, ranked “best-of” list of machine learning libraries in Python, organized into many ML/data categories and updated weekly. Projects are ranked using an automatically computed project-quality score derived from GitHub and package-manager metrics.",23000,machine learning|python|awesome-list|curated-list|ml-libraries|data science|open source,8,"This repository is primarily a curated, automatically ranked directory of Python machine learning and data-related open-source projects (not a framework/library itself). It is highly applicable to ML/data workflows because it helps practitioners discover and evaluate tools across key areas (frameworks, NLP, vision, time series, MLOps, interpretability, etc.) and provides structured metadata and contribution mechanisms (e.g., via projects.yaml). It has substantial community adoption (tens of thousands of GitHub stars) and strong educational value as a map of the ML Python ecosystem, but it is not a direct runtime dependency or core tooling like an ML framework—hence an 8/10 rather than 9–10.",success
https://github.com/sinaptik-ai/pandas-ai,pandas-ai,"PandasAI is a Python library that lets you query and analyze data (e.g., SQL databases and files like CSV/Parquet) using natural language via LLMs, enabling conversational data exploration and chart generation with RAG-style capabilities.",23000,data analysis|python|pandas|LLM|RAG|natural language interface|SQL|data visualization,8,"This repository provides a conversational layer over common data sources (DataFrames, SQL, CSV/Parquet) using LLMs, enabling users to ask questions in natural language and receive computed results and even generated plots. It is directly applicable to data science workflows for exploratory data analysis and rapid insight generation, and it integrates with LLM tooling (e.g., via a LiteLLM adapter shown in the README). The project also appears to have strong community adoption (about 23k GitHub stars), which supports a high score, but it is not itself a model training framework, so it’s not a 10.",success
https://github.com/ScrapeGraphAI/Scrapegraph-ai,Scrapegraph-ai,"ScrapeGraphAI is a Python web-scraping library that uses LLMs and a graph-based pipeline to extract structured information from websites and local documents (e.g., HTML, XML, JSON, Markdown) based on a natural-language prompt. It provides multiple “graph” pipelines (e.g., single-page, multi-page via search, script generation) and supports both API-based and local LLMs.",22200,web scraping|LLM|data extraction|Python|document parsing|automation|agents,8,"This repository’s primary purpose is AI-assisted information extraction: users specify what to extract in natural language and the library builds scraping pipelines using an LLM plus graph logic. It is directly applicable to ML/data workflows because it can automate dataset creation, web-to-structured-data extraction, and ingestion from semi-structured documents, and it integrates with common LLM ecosystems (including local model runtimes). The strong community adoption signal (large GitHub star count) and the focus on LLM-driven extraction make it highly relevant, though it is not a core model-training framework—hence an 8/10 rather than a 9–10.",success
https://github.com/vanna-ai/vanna,vanna,"Vanna is an LLM-powered text-to-SQL and data insights framework that lets users chat with SQL databases and receive answers as streamed UI components (SQL, tables, charts, summaries). It provides a production-ready backend (e.g., FastAPI integration), an embeddable web chat component, and enterprise-focused features like user-aware permissions and row-level security.",22200,text-to-sql|llm|agentic-retrieval|data-analytics|sql|fastapi|data-visualization|chat-ui,8,"This repository focuses on converting natural-language questions into SQL and delivering data insights (tables, charts, summaries) via an LLM-driven, agentic workflow, which is directly useful for analytics and BI-style data science work. It is highly applicable for data teams building NL-to-SQL interfaces over warehouses/databases and integrates with common LLM providers and databases, plus includes a ready-to-embed web UI and production server patterns. While it is not a model-training framework, it is strongly ML-adjacent infrastructure for applied LLM + data workflows with significant community adoption (22.2k stars), justifying a high score but not a perfect 10.",success
https://github.com/PrefectHQ/prefect,prefect,"Prefect is an open-source workflow orchestration framework for building resilient data pipelines in Python. It helps teams productionize scripts into observable workflows with features like scheduling, retries, caching, and event-driven automation, monitored via a self-hosted server or Prefect Cloud.",21300,workflow orchestration|data pipelines|data engineering|MLOps|Python|ETL|observability,8,"This repository provides Prefect, a Python-based workflow orchestration system primarily used to build, schedule, and monitor data pipelines and automated workflows. It is highly applicable to ML/data workflows because teams commonly use orchestrators like Prefect to run ETL/ELT jobs, feature pipelines, training/evaluation runs, and batch inference with retries, scheduling, and observability. While it is not an ML framework itself, it integrates well into MLOps and data platform stacks and is widely adopted in the data engineering ecosystem, justifying a high (but not maximum) score.",success
https://github.com/RasaHQ/rasa,rasa,"Rasa Open Source is an open-source machine learning framework for building text- and voice-based conversational assistants, providing components for NLU (understanding user messages) and dialogue management, plus integrations to messaging channels. The repository is currently in maintenance mode, with Rasa positioning “Hello Rasa” and its CALM engine as the future direction for building AI agents.",21000,conversational-ai|nlp|chatbots|dialogue-management|nlu|python|machine-learning|llm-agents,8,"This repository implements Rasa Open Source, a widely used framework for building conversational AI systems, including ML-driven NLU pipelines and dialogue policies for managing conversations. It is directly applicable to ML workflows for training and deploying intent/entity models and conversation policies, and it integrates with common conversational AI tooling and channels. However, because the project is explicitly in maintenance mode and Rasa is steering new development toward Hello Rasa/CALM, its forward-looking educational and integration value is somewhat reduced versus actively evolving core ML frameworks, so it scores high but not maximal.",success
https://github.com/letta-ai/letta,letta,"Letta (formerly MemGPT) is a platform for building stateful AI agents with persistent memory that can learn and self-improve over time. It provides an API and client SDKs (Python/TypeScript) to create agents, manage memory blocks/tools, and run them across multiple model providers (e.g., OpenAI, Anthropic, Gemini).",20600,llm-agents|agent-framework|memory|rag|python|typescript|api|developer-platform,8,"This repository focuses on building and operating stateful LLM agents with long-term/persistent memory, which is a common need in applied ML systems (agentic workflows, tool use, retrieval/memory, and multi-turn applications). It is directly useful to ML engineers building production LLM apps because it provides an API and SDKs for creating and managing agents, memory blocks, and integrations across model providers. The project shows strong community adoption (20.6k GitHub stars) and offers significant practical/educational value for agent architectures and memory-driven LLM applications, but it is not a core model-training framework—hence an 8 rather than 9–10.",success
https://github.com/EthicalML/awesome-production-machine-learning,awesome-production-machine-learning,"A curated “awesome list” of open-source tools and resources for production machine learning, covering areas like deployment/serving, monitoring, orchestration, data pipelines, experiment tracking, and safety/privacy. It functions as a categorized directory to help ML engineers choose and navigate MLOps tooling.",19900,machine learning|MLOps|production ML|deployment|model monitoring|data pipelines|experiment tracking|awesome-list,8,"This repository is primarily a curated catalog of production ML/MLOps tools (deployment, monitoring, orchestration, feature stores, experiment management, etc.), rather than a runnable ML library itself. It is highly applicable to real-world ML/data workflows because it helps practitioners discover and evaluate tooling across the production lifecycle, and it shows strong community adoption (high star count). It scores below 9–10 because it doesn’t directly provide executable ML functionality; its main value is as a well-organized reference and learning/selection aid for ML engineering.",success
https://github.com/1Panel-dev/MaxKB,MaxKB,"MaxKB is an open-source platform for building enterprise-grade AI agents and knowledge-base Q&A systems. It provides RAG pipelines (document upload/crawling, splitting, vectorization), an agentic workflow engine with MCP tool-use, multi-model support (private and public LLMs), and multimodal I/O for rapid integration into business systems.",19800,RAG|LLM|agentic-workflows|knowledge-base|chatbot|LangChain|Django|pgvector,8,"This repository’s primary purpose is to build and deploy enterprise AI agents and knowledge-base Q&A applications, centered around Retrieval-Augmented Generation (RAG) and workflow orchestration. It is directly applicable to ML/LLM workflows because it operationalizes document ingestion, chunking, embedding/vector storage, retrieval, and LLM integration, and supports multiple model providers plus MCP tool-use for agent behaviors. While it is not a model-training framework, it is highly valuable for applied LLM engineering (RAG/agents) and production deployment, which justifies a high score rather than a perfect 10.",success
https://github.com/Avaiga/taipy,taipy,"Taipy is a Python framework for turning data and AI/ML algorithms into production-ready web applications. It provides UI generation plus data integration, pipeline orchestration, scenario/what-if analysis, scheduling, and operational tooling (CLI, deployment scripts, monitoring).",19000,python|data-science|mlops|data-engineering|workflow-orchestration|data-visualization|web-app-framework|pipeline-orchestration,8,"This repository provides Taipy, a Python framework aimed at data scientists and ML engineers to build data/AI-driven web apps, with built-in workflow/pipeline orchestration, scenario (what-if) management, scheduling, and deployment/ops helpers. It is not an ML training library itself, but it directly supports common ML/data workflows by helping productionize analytics/ML pipelines and expose them through interactive applications. The strong relevance to productionizing data/AI work (plus notable community traction indicated by its star count and usage) justifies a high but not maximum score.",success
https://github.com/bytedance/deer-flow,deer-flow,"DeerFlow is a community-driven “Deep Research” framework that combines LLMs with tools such as web search, web crawling, and Python code execution to produce enriched research outputs (e.g., reports with images) and optionally generate derivative content like podcasts. It also supports integrations like MCP services and offers a web UI for interactive usage.",19000,llm|ai-agents|deep-research|web-search|web-crawling|langchain|langgraph|mcp,8,"This repository primarily provides an LLM-powered research/agent framework that orchestrates language models plus external tools (search, crawling, Python execution) to automate multi-step research and generate structured outputs like comprehensive reports and related media. It is directly applicable to ML/AI engineer and data-science workflows for knowledge acquisition, rapid prototyping of agentic pipelines, and integrating tool-using LLM systems (including MCP). While it is not a model training library, it is highly relevant for applied LLM systems, agent orchestration, and research automation, and it shows meaningful community adoption (≈19k GitHub stars at time of lookup).",success
https://github.com/spotify/luigi,luigi,"Luigi is a Python package for building and running complex batch data pipelines as dependency graphs of tasks. It provides dependency resolution, workflow management, failure handling, and a web-based visualizer, with integrations commonly used for Hadoop and other data systems.",18600,data engineering|workflow orchestration|data pipelines|batch processing|python|hadoop|ETL,8,"Luigi’s primary purpose is orchestrating long-running batch workflows by defining tasks and their dependencies in Python, with scheduling/monitoring via a central server and a visualizer. This maps directly onto data engineering and ML workflows (e.g., ETL/feature pipelines, running training/evaluation jobs, coordinating Hadoop/Spark/DB tasks), even though it is not an ML framework itself. It is widely adopted (high star count and longstanding usage) and integrates well into production data/ML platforms, making it highly valuable for ML/data teams as an orchestration layer rather than a modeling tool.",success
https://github.com/marimo-team/marimo,marimo,"marimo is a reactive notebook for Python that stores notebooks as pure .py files, automatically re-running dependent cells to keep outputs consistent. It supports first-class SQL, can execute notebooks as scripts, and can deploy notebooks as interactive apps in a modern editor.",18300,python|notebooks|data-science|data-visualization|sql|reproducible-research|interactive-apps|developer-tools,8,"This repository provides a reactive Python notebook environment designed for reproducible, git-friendly workflows, with built-in interactivity and the ability to run notebooks as scripts or deploy them as apps. It’s highly applicable to ML/data workflows because notebooks are a primary medium for exploration, experimentation, reporting, and lightweight app-style sharing of analyses, and marimo emphasizes reproducibility and dependency-aware execution. While it’s not an ML framework itself (no model training/inference primitives), it directly supports common data science needs (interactive exploration, SQL querying, and sharing/deployment), warranting a high but not maximum score.",success
https://github.com/eosphoros-ai/DB-GPT,DB-GPT,"DB-GPT is an open-source AI-native data application development framework that combines agents with AWEL (Agentic Workflow Expression Language) to build LLM-powered data apps. It provides capabilities such as RAG-based knowledge applications, natural-language interaction with multiple data sources (GBI), multi-model management, and Text2SQL optimization/fine-tuning workflows.",17900,LLM|RAG|agents|workflow-orchestration|text-to-sql|generative-business-intelligence|data-app-framework|python,8,"DB-GPT is primarily a framework for building AI-native data applications, focusing on LLM-centric capabilities like RAG, Text2SQL, multi-agent collaboration, and workflow orchestration (AWEL). It is directly applicable to ML/data workflows because it helps teams connect LLMs to enterprise data sources, build retrieval/knowledge systems, and operationalize natural-language analytics and data assistants. The project shows meaningful community adoption (large GitHub star count) and strong integration potential with model providers and data backends, but it is not a core training framework on the level of foundational ML libraries—hence an 8 rather than 9–10.",success
https://github.com/arc53/DocsGPT,DocsGPT,"DocsGPT is an open-source private AI platform for building agents/assistants and enterprise search over your documents and web content. It supports document ingestion/analysis across many formats, deep research tooling, multi-model (cloud or local) LLM support, source-cited answers, and integrations/API connectivity for actionable agents.",17600,RAG|LLM|enterprise search|document analysis|information retrieval|agent framework|NLP|Python,8,"DocsGPT’s primary use case is building and deploying LLM-powered agents and enterprise search experiences over private corpora (documents, URLs, and other sources) with citations and integrations, which is directly aligned with modern ML application patterns like RAG and LLM ops. It is highly applicable to ML/data workflows for retrieval, indexing, evaluation/QA over knowledge bases, and building AI assistants that interact with data sources. The repository shows strong community adoption (tens of thousands of stars) and integrates with multiple model providers and local inference options, making it practical for ML engineers. It is not a core training framework (like PyTorch), but it is a high-value applied ML system for productionizing LLM + retrieval solutions.",success
https://github.com/microsoft/CNTK,CNTK,"Microsoft Cognitive Toolkit (CNTK) is an open-source deep learning framework for defining neural networks as computational graphs, supporting common architectures (DNNs, CNNs, RNNs/LSTMs) with automatic differentiation and scalable training across GPUs and servers. The repository includes the core engine plus docs, tutorials, examples, and pretrained models.",17600,deep learning|machine learning framework|neural networks|computer vision|NLP|distributed training|ONNX|GPU acceleration,8,"This repository is a full deep-learning toolkit/framework (CNTK) used to build and train neural networks via a computation-graph approach, with features like automatic differentiation and multi-GPU/distributed training. It is directly applicable to ML workflows (model development, training, exporting to ONNX) and provides substantial educational value through tutorials, examples, and pretrained models. However, it is no longer under active feature development (the repo notes CNTK 2.7 as the last main release), which reduces its practical adoption for new projects compared to currently dominant frameworks—so it scores highly but not at the very top.",success
https://github.com/ujjwalkarn/Machine-Learning-Tutorials,Machine-Learning-Tutorials,"A topic-wise curated “awesome list” of machine learning and deep learning tutorials, articles, courses, and other learning resources, organized by subject area (e.g., statistics, model validation, deep learning, NLP, computer vision). It serves as an index to external educational material rather than a code library.",17400,machine learning|deep learning|data science|educational resources|awesome-list|nlp|computer vision,8,"This repository is primarily an educational, curated collection of links to ML/DL tutorials, courses, and references across many core topics (statistics, validation, deep learning, NLP, CV, etc.). It is highly relevant to ML/data workflows as a learning and reference hub, but it is not a runnable framework, dataset, or tooling that can be directly integrated into pipelines. The project shows strong community adoption (high star count) and broad educational value, which supports a high score, but the lack of executable ML tooling keeps it below 9–10.",success
https://github.com/TransformerOptimus/SuperAGI,SuperAGI,"SuperAGI is a developer-first open-source autonomous AI agent framework for building, managing, and running concurrent agents with extensible toolkits (including a marketplace) and a GUI. It supports integrations such as multiple vector databases and provides telemetry to monitor and optimize agent performance.",17000,autonomous agents|LLM orchestration|agent framework|MLOps|vector databases|Python|developer tools,8,"This repository provides an open-source framework to create and operate autonomous AI agents, including a GUI, toolkits/marketplace extensions, and operational features like action controls and performance telemetry. It is highly relevant to ML/LLM workflows because it helps engineers orchestrate LLM-driven agents, integrate vector databases for retrieval-augmented behaviors, and deploy/manage agents in more production-like setups. It is not a core ML training library, but it is directly applicable to modern ML engineering and LLM application development, and its strong GitHub adoption (17k stars) supports an 8/10 score.",success
https://github.com/google/adk-python,adk-python,"Agent Development Kit (ADK) is an open-source, code-first Python framework for building, evaluating, and deploying AI agents. It provides a modular toolkit for orchestrating agent workflows (including multi-agent systems), integrating tools (e.g., custom functions, OpenAPI, MCP tools), and deploying to environments like Cloud Run or Vertex AI Agent Engine.",17000,ai agents|agent orchestration|llm tooling|python|gemini|vertex ai|mcp|evaluation,8,"This repository is primarily an agent framework: it helps developers build and orchestrate LLM-driven agents and multi-agent systems, including tooling integration, evaluation workflows, and deployment patterns. It is directly applicable to ML/LLM engineering workflows (agentic apps, tool use, evaluation, and operationalization) even though it is not a model-training library. Community adoption appears strong (high star and fork counts), and the repo’s focus on evaluation and deployment increases its practical value for applied ML teams building production agent systems.",success
https://github.com/onyx-dot-app/onyx,onyx,"Onyx is an open-source, self-hostable AI chat platform that works with any LLM (hosted or self-hosted) and can run airgapped. It includes advanced features such as agents, web search, RAG (hybrid search + knowledge graph), MCP/actions, deep research workflows, and connectors to 40+ knowledge sources.",17000,generative-ai|llm|rag|information-retrieval|enterprise-search|chat-ui|agents|mcp,8,"This repository provides a production-oriented AI chat and enterprise search platform centered on LLM applications, including RAG, agents, web search, and extensive data connectors. It is highly relevant to ML/data workflows because it focuses on retrieval, indexing, and orchestration around LLMs (a common applied-ML pattern) rather than core model training. It also supports integrations and deployment options (Docker/Kubernetes/Terraform) that make it practical for ML engineering and internal knowledge-base/assistant use cases. It is scored an 8 (highly relevant) because it is a strong applied LLM/RAG system, but it is not a foundational ML framework for training models.",success
https://github.com/tensorflow/tensor2tensor,tensor2tensor,"Tensor2Tensor (T2T) is a TensorFlow-based library of deep learning models and dataset/problem definitions (e.g., Transformer, ResNet, image/text/audio tasks) with command-line tools for data generation and training (t2t-datagen, t2t-trainer). The repository is archived (read-only) and deprecated in favor of Trax, but remains usable for running and reproducing older research code.",16900,machine learning|deep learning|TensorFlow|NLP|computer vision|speech recognition|sequence-to-sequence,8,"This repository provides a substantial collection of deep learning models and standardized dataset/problem wrappers plus training/data-generation tooling, making it directly applicable to ML research workflows (training, evaluation, reproduction of published baselines). It has strong educational value for understanding classic architectures (notably early Transformer implementations) and end-to-end experimentation patterns around datasets and hyperparameters. However, it is explicitly deprecated and the repo was archived on July 7, 2023, which reduces its practical value for new production work despite its still-large community footprint (16.9k stars).",success
https://github.com/harvard-edge/cs249r_book,cs249r_book,"Open-source learning stack for AI/ML systems engineering: the source for the “Machine Learning Systems” textbook plus hands-on components like TinyTorch, labs, and hardware kits for deploying and benchmarking models on real devices.",16600,machine learning systems|mlops|edge ai|deep learning|education|benchmarking|pytorch,8,"This repository contains the full educational stack behind the “Machine Learning Systems” textbook, including the book source and practical modules like TinyTorch, labs, and hardware kits focused on building and deploying ML systems. It is strongly relevant to ML/data workflows because it teaches end-to-end engineering concerns (benchmarking, deployment constraints, systems tradeoffs) and provides runnable code/labs rather than only prose. While it is not a production ML framework with broad industry adoption, its applied curriculum and tooling make it highly valuable for learning and prototyping ML systems concepts, justifying a score of 8/10.",success
https://github.com/ipython/ipython,ipython,"IPython (Interactive Python) is an enhanced interactive shell for Python focused on productive interactive computing, providing rich introspection, tab completion, history, and an extensible system of magic commands. It can be embedded in other Python programs and integrates with debugging/profiling tools, while notebook/Qt console components are now part of Jupyter.",16600,python|interactive-computing|repl|jupyter-ecosystem|developer-tools|scientific-computing,8,"This repository provides IPython, a widely used interactive Python shell that improves exploratory programming via introspection, rich tab completion, persistent history, and powerful magic commands. It is not an ML framework itself, but it is central to day-to-day data science and ML workflows for experimentation, debugging, profiling, and interactive analysis, and it underpins much of the broader Jupyter ecosystem usage patterns. Due to its extremely high adoption in the ML/data community and strong workflow integration value (even without providing ML algorithms), it merits a high relevance score but not a 9–10 reserved for core ML/data processing/training libraries.",success
https://github.com/argoproj/argo-workflows,argo-workflows,"Argo Workflows is an open-source, Kubernetes-native workflow engine (implemented as Kubernetes CRDs) for orchestrating multi-step and highly parallel jobs where each step runs as a container, supporting both step-based and DAG-based workflows.",16300,Kubernetes|workflow orchestration|DevOps|CI/CD|MLOps|data pipelines|container-native|cloud native,8,"This repository provides a Kubernetes-native workflow orchestration engine for defining and running container-based pipelines, including DAG-structured workflows and highly parallel jobs. It is directly applicable to ML/data workflows because it is commonly used to orchestrate training, preprocessing, batch inference, and other compute-intensive data processing on Kubernetes, and it integrates well with containerized ML tooling and artifact storage backends. While it is not an ML library itself, its strong fit for MLOps/data pipeline execution and broad adoption in cloud-native environments justify a high (but not maximum) score.",success
https://github.com/xming521/WeClone,WeClone,"An end-to-end toolkit for creating a “digital avatar” from personal chat history by exporting and preprocessing chat logs, fine-tuning an LLM (including optional image-modal fine-tuning), and deploying it as a chatbot (e.g., Telegram/Discord/Slack). It includes privacy filtering and supports LoRA/QLoRA-style fine-tuning workflows.",16200,llm-fine-tuning|chatbot|data-preprocessing|synthetic-persona|lora|multimodal|telegram,8,"WeClone’s primary purpose is to build a personalized conversational model (“digital avatar”) by turning chat exports into a training dataset, running preprocessing (including PII removal), fine-tuning an LLM (LoRA/QLoRA and optional image-modal support), and deploying inference via demo/UI or server endpoints. This is directly applicable to ML workflows involving dataset construction, supervised fine-tuning, and lightweight deployment of LLMs. It also shows meaningful community traction (16.2k stars), increasing its practical and educational value for applied LLM fine-tuning and data preparation, though it’s specialized to persona/chat-history use cases rather than a general-purpose ML framework.",success
https://github.com/Kanaries/pygwalker,pygwalker,"PyGWalker is a Python library for exploratory data analysis that turns a pandas (and similar) DataFrame into an interactive, Tableau-like visual analytics UI inside environments like Jupyter. It supports drag-and-drop chart building and interactive exploration, with options aimed at scaling computation (e.g., DuckDB-backed) and integrating into common app/notebook workflows.",15600,data visualization|exploratory data analysis|python|jupyter|pandas|interactive analytics|duckdb,8,"This repository primarily provides an interactive visual analytics layer for DataFrame-based exploratory data analysis (EDA), effectively bringing a Tableau-style workflow into Python notebooks and related environments. It is directly useful in data science workflows for understanding distributions, relationships, data quality issues, and feature exploration prior to modeling, and it appears to have strong community adoption (15.6k GitHub stars). While it is not an ML training/inference framework itself, its tight fit with common DS tooling and its focus on EDA/visual exploration make it highly valuable for ML/data work, warranting an 8/10.",success
https://github.com/akfamily/akshare,akshare,"AKShare is a Python library that provides a unified, easy-to-use interface for fetching a wide range of financial and economic data. It focuses on simplifying access to market datasets (e.g., stocks and other instruments) so analysts can retrieve data quickly with minimal code.",15200,python|financial-data|quantitative-finance|data-collection|data-analysis|economics|pandas,8,"This repository primarily provides programmatic access to financial and economic datasets via a Python API, which is a foundational need in many ML/data science pipelines (data acquisition and feature building). While it is not an ML modeling framework itself, it is directly applicable for preparing training/validation datasets for time-series forecasting, factor research, and other quantitative workflows, typically integrating naturally with pandas-based stacks. The project also shows strong community adoption (high GitHub stars/forks), increasing its practical value for ML/data practitioners. The score is not higher because it focuses on data interfaces rather than model training, evaluation, or MLOps capabilities.",success
https://github.com/jupyterlab/jupyterlab,jupyterlab,"JupyterLab is an extensible, next-generation web-based interactive computing environment for Project Jupyter, combining notebooks, terminals, text editor, file browser, and rich outputs in a single UI. It supports a powerful extension system (source and prebuilt extensions) distributed via npm, PyPI/conda, and other package managers.",15000,data science|interactive computing|jupyter|notebooks|web application|typescript|python|developer tools,8,"This repository provides JupyterLab, a widely adopted interactive development environment for computational notebooks and data-centric workflows, integrating editors, terminals, file management, and rich output rendering in the browser. While it is not an ML framework itself, it is a core tool used daily by data scientists and ML engineers to explore data, prototype models, run experiments, and visualize results. Its strong ecosystem of extensions and broad community adoption in ML/data workflows justify a high score, though it remains primarily an IDE/platform rather than a library for model training or data processing.",success
https://github.com/LlamaFamily/Llama-Chinese,Llama-Chinese,"A Chinese-language community repository for the Llama model ecosystem that aggregates learning resources and provides practical guides, scripts, and examples for training, fine-tuning, quantization, deployment, and evaluation of Llama-family LLMs (including Chinese-focused workflows).",14800,large-language-models|llama|NLP|fine-tuning|pretraining|quantization|inference-serving|MLOps,8,"This repository is centered on the Llama LLM ecosystem for Chinese users, combining curated learning materials with hands-on assets such as training/fine-tuning scripts and deployment/acceleration guidance (e.g., Docker, llama.cpp, vLLM/TensorRT-LLM-style serving topics). It directly supports common ML workflows—data preparation, model training and LoRA fine-tuning, quantization, evaluation, and inference deployment—making it practically useful for ML engineers working with LLMs. Its large visible community adoption (about 14.8k GitHub stars) indicates strong interest and reuse. I scored it an 8 (highly relevant) because it’s clearly ML-focused and workflow-oriented, though it is more of a community hub/tooling collection than a single foundational ML framework.",success
https://github.com/dagster-io/dagster,dagster,"Dagster is a cloud-native orchestration platform for building, running, and observing data assets and pipelines using Python. It provides a declarative programming model, integrated lineage/observability, and tooling (including a web UI) to support the full data development lifecycle from local dev to production.",14700,data orchestration|data engineering|data pipelines|MLOps|workflow orchestration|Python|observability|data lineage,8,"This repository implements Dagster, a production-grade data orchestration system focused on defining and maintaining data assets (tables/datasets) and also supports machine learning assets like models. It is highly applicable to ML/data workflows as an orchestration and observability layer (scheduling, dependency management, lineage, and operational monitoring) rather than a model-training framework itself. Because it is widely used in modern data stacks and integrates well with common data/ML tools, it earns a high score, but not a 10 since its primary purpose is orchestration/infrastructure instead of core ML algorithms.",success
https://github.com/microsoft/data-formulator,data-formulator,"Data Formulator is a Microsoft Research prototype for AI-powered data exploration and visualization, combining a visual interface with natural-language and agent-driven workflows. It supports loading data from multiple sources (files, databases, screenshots/text extraction) and generating/inspecting transformations, formulas, and code to produce rich charts and shareable reports.",14700,data visualization|AI agents|data exploration|analytics|LLM tooling|typescript|python,8,"This repository provides an AI-assisted data exploration and visualization system (Microsoft Research) that helps analysts load data from diverse sources and use LLM-powered agents to formulate transformations and generate charts and reports. It is strongly aligned with data-science workflows (EDA, data cleaning/transformation, charting, reporting) and includes integrations for multiple model providers (e.g., OpenAI/Azure/Ollama/Anthropic via LiteLLM) and data backends/connectors. While it is not a model-training framework, it is highly useful as a practical data/analytics tool that can accelerate common DS tasks, which justifies a high (but not maximum) score.",success
https://github.com/scipy/scipy,scipy,"SciPy is an open-source Python library for scientific computing that provides efficient numerical routines built on NumPy arrays, including modules for statistics, optimization, integration, linear algebra, Fourier transforms, signal and image processing, and ODE solvers.",14300,scientific computing|numerical methods|statistics|optimization|signal processing|linear algebra|python,8,"This repository contains the core SciPy library, a foundational scientific-computing toolkit in Python that offers robust numerical algorithms (e.g., optimization, linear algebra, integration, statistics, and signal processing). While it is not an end-to-end machine learning framework, it is heavily used in ML/data science workflows for preprocessing, statistical testing, numerical optimization, and scientific modeling, and it underpins parts of the broader Python scientific ecosystem. Its very large user base and ecosystem integration make it highly valuable for data work, but it scores below core ML frameworks because it does not focus on model training APIs, deep learning, or MLOps.",success
https://github.com/visenger/awesome-mlops,awesome-mlops,"A curated “awesome list” of MLOps resources, organized into categories like workflow management, feature stores, data engineering, deployment/serving, monitoring, infrastructure, papers, and learning materials. It serves as a reference hub for practitioners looking for tools, guides, courses, and community links related to operating ML systems in production.",13500,MLOps|machine learning engineering|production ML|model deployment|ML monitoring|data engineering|DevOps,8,"This repository is primarily a curated catalog of MLOps references (tools, guides, courses, papers, and communities) rather than an executable library, so it doesn’t directly provide code for training/serving models. However, it is strongly aligned with real-world ML/data workflows (deployment, feature stores, monitoring, and infrastructure) and is directly useful for ML engineers and data scientists designing production ML systems. Its community adoption appears high (13.5k GitHub stars), indicating broad utility as an educational and navigational resource. The score is 8/10 because it’s highly relevant to ML operations and learning, but it’s not a core ML/data framework or standalone tool used directly in pipelines.",success
https://github.com/Canner/WrenAI,WrenAI,"WrenAI is an open-source GenBI (Generative BI) agent that lets users query databases in natural language and automatically generates accurate SQL (text-to-SQL) and visualizations (text-to-chart), producing AI-powered BI insights, summaries, charts, and reports. It supports multiple databases and integrates with many LLM providers to embed “talk to your data” experiences via API.",13400,generative-ai|business-intelligence|text-to-sql|nlp|llm|data-analytics|data-visualization|semantic-layer,8,"This repository provides a production-oriented GenBI system that translates natural-language questions into SQL, generates charts/reports, and adds a semantic layer (MDL) to improve correctness and governance across multiple databases and LLM backends. It is highly relevant to data science and analytics workflows because it operationalizes text-to-SQL and BI insight generation on top of real data warehouses/databases, and can be embedded via API for data products. It’s not a general-purpose ML training framework, but it is a strong applied AI/data tool with substantial real-world usefulness and notable community adoption (13.4k stars) in the data/BI space.",success
https://github.com/pandas-profiling/pandas-profiling,ydata-profiling,"YData Profiling (formerly pandas-profiling) generates automated data-quality and exploratory data analysis (EDA) reports for Pandas and Spark DataFrames in one line of code, with export options like HTML and JSON. It includes type inference, univariate/multivariate statistics, correlation and missingness analysis, and specialized support for time-series and text profiling.",13200,data profiling|exploratory data analysis|data quality|pandas|pyspark|python|jupyter,8,"This repository provides an automated profiling and EDA report generator (formerly pandas-profiling) that summarizes dataset structure, distributions, correlations, missing data patterns, and data-quality warnings for Pandas and Spark DataFrames. It is directly applicable to ML/data workflows as a fast first-step for understanding features, detecting leakage/quality issues, and producing shareable reports (HTML/JSON) used in analysis and pipeline validation. While it is not a model-training framework, it is widely used as a practical, reusable component in real-world data science projects, which justifies a high (but not maximum) score.",success
https://github.com/MorvanZhou/tutorials,tutorials,"A collection of Python and machine learning tutorials (largely in Chinese), including example code for core ML libraries and related topics such as TensorFlow, PyTorch, scikit-learn, reinforcement learning, NumPy/Pandas, and Matplotlib.",12800,machine learning|python|deep learning|reinforcement learning|tensorflow|pytorch|scikit-learn|numpy,8,"This repository is primarily an educational/tutorial codebase focused on machine learning and data-processing topics, with many subfolders dedicated to common ML frameworks (TensorFlow, PyTorch, Keras, Theano) and core data tools (NumPy, Pandas, Matplotlib). It is directly useful for learning and prototyping ML/data workflows via runnable examples rather than providing a reusable production library or pipeline system. Its strong community adoption (notably a large star count) and broad coverage of foundational ML/data concepts justify a high score, but it’s not a core industry framework or MLOps tool, so it doesn’t reach 9–10.",success
https://github.com/kmario23/deep-learning-drizzle,deep-learning-drizzle,"A curated collection of deep learning, machine learning, reinforcement learning, computer vision, NLP, and related lecture courses/resources, organized in a structured README with links to course pages and videos.",12800,deep learning|machine learning|reinforcement learning|computer vision|natural language processing|learning resources|lecture collection|education,8,"This repository primarily serves as a curated index of high-quality ML/DL/RL/CV/NLP lecture courses and learning materials rather than a code library. It is highly relevant to ML/data workflows for upskilling, onboarding, and referencing foundational-to-advanced topics, but it does not directly provide datasets, reusable model code, or tooling for training/deployment. Community adoption appears strong for an educational resource (12.8k stars), supporting a high score, though not a 9–10 since it is not a core ML framework or production tool.",success
https://github.com/tangyudi/Ai-Learn,Ai-Learn,"A Chinese-language AI learning roadmap and resource collection, organizing roughly 200 hands-on ML/AI cases and projects with supporting materials (code, datasets via cloud links, slides, and a companion textbook PDF). It covers Python fundamentals, math, data analysis/mining, machine learning, deep learning, and applied CV/NLP with frameworks like PyTorch and TensorFlow.",12500,artificial intelligence|machine learning|deep learning|data analysis|data mining|computer vision|natural language processing|python,8,"This repository is primarily an educational AI/ML roadmap and curated practice hub, with a large set of practical projects spanning ML, data analysis/mining, deep learning, CV, and NLP, plus references to common tooling (NumPy/Pandas/Matplotlib) and frameworks (PyTorch/TensorFlow/Keras/Caffe). It is directly useful for learners and practitioners looking for structured study paths and hands-on exercises, though it is not a single reusable ML library or production tool. Community adoption appears strong for a learning resource (notable star/fork counts), which supports a high score, but it falls short of a 9–10 because it’s not a widely adopted core framework or standardized workflow tool. ",success
https://github.com/RUCAIBox/LLMSurvey,LLMSurvey,"The official repository for the survey paper ""A Survey of Large Language Models"", providing a curated and regularly updated collection of LLM-related papers, resources, timelines, model lists, and supplementary materials (e.g., prompts and experiment notes).",12100,large language models|natural language processing|LLM survey|research literature|prompting|machine learning resources,8,"This repository primarily curates and organizes research papers, resources, and structured knowledge (timelines, model lists, and topic-organized reading lists) around large language models, aligned to the accompanying survey paper. It is highly relevant to ML/NLP workflows as a discovery and reference hub for methods (pretraining, instruction tuning, evaluation, prompting) and for staying oriented in the LLM literature, though it is not a core training framework or a data-processing library. Community adoption is strong (high star count), and the educational/reference value is substantial for researchers and practitioners, which supports a high score but not a perfect 10 due to limited direct tooling/code for production ML pipelines.",success
https://github.com/GibsonAI/Memori,Memori,"Memori is an open-source, SQL-native memory layer for LLM applications and AI agents that stores, retrieves, and injects relevant context across conversations. It integrates with common LLM providers and works with standard SQL databases (e.g., SQLite/Postgres/MySQL) to provide structured long-term and short-term memory.",11600,LLM|AI agents|agent memory|RAG|knowledge graph|Python|SQL databases|MLOps,8,"This repository provides a practical memory layer for LLM apps/agents, including attribution, sessioning, background “augmentation” to create memories, and SQL-backed querying of stored conversation/entity facts and knowledge-graph-like structures. It is directly applicable to ML/LLM engineering workflows because it solves a common production problem (persistent, queryable agent memory and context injection) and integrates with major LLM providers and frameworks. While it is not a model-training framework or core data science library, it is highly relevant for building LLM systems (RAG/memory, retrieval, and context management), which justifies a high (but not perfect) score.",success
https://github.com/Olow304/memvid,memvid,"Memvid is a serverless, single-file memory layer for AI agents that packages data, embeddings, search indexes, and metadata into a portable .mv2 file to enable fast local retrieval (hybrid lexical + semantic) without running external databases or complex RAG infrastructure.",11600,rag|ai-agents|vector-search|information-retrieval|embedding|rust|mcp|offline-first,8,"This repository provides an infrastructure-free memory and retrieval layer designed for AI agents, offering persistent local storage plus fast hybrid search (lexical BM25 + vector similarity) inside a single portable file. It is directly applicable to ML/LLM workflows (RAG, agent memory, knowledge bases) and includes SDK/CLI tooling intended for integration into agent frameworks and applications. While it is not a model-training library, it meaningfully supports practical ML/LLM systems by handling ingestion, indexing, and retrieval, which justifies a high (but not ""core framework"") score.",success
https://github.com/datahub-project/datahub,datahub,"DataHub is an open-source metadata platform (data catalog) for discovering, governing, and managing metadata across the modern Data & AI stack. It includes a web UI and backend services plus connectors/ingestion tooling to integrate metadata from many systems into a unified metadata graph.",11400,data-catalog|metadata-management|data-governance|data-discovery|data-engineering|data-lineage|data-observability|MLOps,8,"This repository provides a full-featured metadata platform (catalog) used to index, search, and govern datasets, pipelines, and related assets across a company’s data and AI ecosystem, including a UI, backend services, and ingestion/connectors. It is highly relevant to ML/data workflows because it supports discovery of training data and features, tracking lineage and ownership, and integrating metadata from common data/analytics tools—capabilities that are central to data science enablement and MLOps governance. It is not itself a model-training or ML framework, but it is widely adopted infrastructure for managing data/AI assets, which justifies a high (but not maximal) score.",success
https://github.com/dive-into-machine-learning/dive-into-machine-learning,dive-into-machine-learning,"A curated, hands-on guide to learning machine learning using Python and Jupyter Notebooks, compiling notebooks, courses, and links to high-quality learning resources. It also points to tooling options (local and cloud) and related topics like responsible/ethical ML and MLOps.",11400,machine learning|data science education|python|jupyter notebooks|curated resources|scikit-learn|responsible ai,8,"This repository is primarily an educational, curated roadmap for learning machine learning with Python/Jupyter, linking to notebooks, tutorials, and practical exercises rather than providing a single deployable ML library. It is highly relevant to ML/data workflows because it helps learners and practitioners quickly find hands-on resources and common tooling (e.g., Jupyter, scikit-learn, numpy/pandas), making it directly useful for skill-building and onboarding. Community adoption is strong (11.4k stars), but it is not a core production framework or data pipeline tool, so it scores below 9–10. The repo is archived (read-only), which slightly reduces ongoing integration potential and freshness, but the educational value remains high.",success
https://github.com/hoya012/deep_learning_object_detection,deep_learning_object_detection,"A curated paper list and reference hub for deep learning–based object detection, including a chronological bibliography (2014–2020), links to implementations, and summary figures/tables of major detectors and benchmarks.",11400,computer vision|object detection|deep learning|paper list|literature review|survey|research resources,8,"This repository is primarily a curated research resource: it compiles and organizes deep learning object detection papers by year, includes a performance table, and links to code/implementations, making it useful for literature review and model selection. It directly supports ML workflows (research, benchmarking awareness, and educational onboarding into object detection), but it is not itself a training framework/library or a dataset/tooling package. Community adoption is strong (11.4k stars), indicating high practical/educational value, though its last noted content update is dated 2020-09-22, which limits ‘state-of-the-art’ currency. Overall, it’s highly relevant for ML practitioners and students as a reference, but not a core production ML tool.",success
https://github.com/Chainlit/chainlit,chainlit,"Chainlit is an open-source Python framework for quickly building production-ready conversational AI apps with a built-in web UI. It helps developers create chat-based LLM applications, integrate tools/services (e.g., OpenAI, LangChain, LlamaIndex, vector DBs), and run/share them via a streamlined developer workflow.",11300,conversational-ai|llm|python|chat-ui|openai|langchain|llamaindex|web-development,8,"This repository provides a Python framework and UI layer for building conversational AI/LLM applications, focusing on rapidly shipping chat experiences and agent/tool interactions rather than model training. It is highly applicable to ML/AI product workflows (LLM app prototyping, evaluation via human-in-the-loop conversations, tool-calling UX, and integration with ecosystems like LangChain/LlamaIndex and LLM providers). While it is not a core data science library for data processing or training, it is widely relevant for deploying and iterating on LLM-powered applications, justifying a high (but not maximum) score.",success
https://github.com/apple/turicreate,turicreate,"Turi Create is a Python-based toolkit for building custom machine learning models with a simple, task-focused API (e.g., image classification, object detection, recommendations, text classification). It supports working with common data modalities and can export trained models to Core ML for deployment in Apple-platform apps.",11200,machine learning|python|coreml|computer vision|recommender systems|natural language processing|model training,8,"This repository provides an end-to-end ML toolkit aimed at quickly training practical models (recommendation, classification, object detection, etc.) and exporting them to Core ML for on-device deployment. It is directly applicable to ML workflows because it includes data structures/utilities, model training APIs, and deployment export capabilities used by data scientists and ML engineers. However, it was archived on Dec 21, 2023 (read-only), and its stated Python support is older, which reduces its current integration and adoption potential versus actively maintained ML frameworks; hence an 8 rather than a 9–10.",success
https://github.com/statsmodels/statsmodels,statsmodels,"Statsmodels is a Python library for statistical modeling and econometrics, providing descriptive statistics plus estimation and inference for many statistical models. It includes regression (OLS/GLM), discrete choice models, time series/state space models, survival analysis, multivariate methods, statistical tests, and example datasets.",11200,statistics|econometrics|python|time-series|regression|bayesian-modeling|statistical-inference|data-science,8,"This repository is a widely used Python package focused on statistical modeling and econometrics, offering a broad set of classical modeling and inference tools (e.g., GLM, discrete models, state space/time series, survival analysis, and hypothesis testing). It is directly applicable to data science workflows for exploratory analysis, inference, forecasting, and model diagnostics, and is commonly used alongside NumPy/SciPy/Pandas. It is not primarily a modern end-to-end machine learning training framework (like PyTorch/TensorFlow), but it is highly valuable for applied statistics and interpretable modeling, which justifies a high (but not maximal) score.",success
https://github.com/great-expectations/great_expectations,great_expectations,"GX Core (Great Expectations) is an open-source Python framework for data quality: defining, running, and sharing “Expectations” (unit-test-like checks) on data. It supports validating data, generating documentation from validation results, and integrating into modern data workflows.",11100,data-quality|data-validation|data-engineering|python|etl|mlops,8,"This repository provides Great Expectations (GX Core), a widely used data quality and validation framework centered around defining reusable expectations (tests) for datasets and producing validation results and documentation. It is directly applicable to ML/data workflows because data scientists and ML engineers rely on it to catch schema/drift/anomaly issues before training, during feature pipeline runs, and in production monitoring/CI. It integrates naturally with common data stacks (via Python and GX integrations), and its strong community adoption (11.1k GitHub stars as of the repository page) indicates significant real-world usage. It scores an 8 (highly relevant) because it is a core enabling tool for reliable ML/data pipelines, even though it is not a model training framework itself.",success
https://github.com/dataelement/bisheng,bisheng,"BISHENG is an open LLM DevOps platform for building and operating enterprise GenAI applications, providing capabilities such as workflow orchestration, RAG, agents, unified model management, evaluation, SFT, dataset management, observability, and enterprise system management. It includes a Docker-based deployment and is oriented toward complex, production enterprise scenarios.",10900,llmops|generative-ai|rag|agents|workflow-orchestration|enterprise-ai|model-management|observability,8,"This repository provides an enterprise-focused LLM DevOps platform for developing and operating GenAI applications, including workflow orchestration, RAG, agent support, model management, evaluation, SFT, and dataset management. These features align directly with common ML/LLM engineering workflows (building retrieval pipelines, running evaluations, managing models/datasets, and deploying/monitoring systems). It earns an 8 because it is highly relevant to ML/LLM application development and operations, but it is more of a platform layer (MLOps/LLMOps) than a core ML training framework with ubiquitous industry adoption.",success
https://github.com/rushter/MLAlgorithms,MLAlgorithms,"A collection of minimal, clean, from-scratch implementations of common machine learning algorithms in Python, intended for learning how the algorithms work internally. Includes runnable examples and implementations spanning classic ML methods and basic deep learning models using NumPy/SciPy (and autograd).",10900,machine learning|machine-learning-algorithms|deep learning|python|numpy|neural networks|educational,8,"This repository provides readable, from-scratch implementations of a broad set of ML algorithms (e.g., linear/logistic regression, SVM, random forests, clustering, dimensionality reduction, boosting, and some neural-network models) along with example entry points to run them. It’s highly relevant to ML/data workflows for education, prototyping, and understanding algorithm internals, but it’s not positioned as a production-grade library (e.g., lacks the maturity, optimization, and ecosystem integration of mainstream frameworks). Community adoption appears strong for an educational repo (about 10.9k stars), supporting its usefulness for learning and reference. As a result, it scores high for educational value and ML relevance, but not a 9–10 due to limited production and integration focus.",success
https://github.com/fastai/numerical-linear-algebra,numerical-linear-algebra,"Free online textbook and course materials (primarily Jupyter notebooks) for fast.ai’s Computational Linear Algebra course, focused on practical matrix computations with acceptable speed and accuracy. Includes application-driven lessons (e.g., topic modeling with NMF/SVD, robust PCA for background removal, compressed sensing) using Python tooling such as NumPy, scikit-learn, Numba, and PyTorch.",10700,linear algebra|numerical computing|data science education|jupyter notebooks|python|pytorch|numpy|scikit-learn,8,"This repository is an educational, code-first set of Jupyter notebooks (a free online textbook) for learning computational/numerical linear algebra through real data-oriented applications like topic modeling (NMF/SVD), robust PCA, PageRank, and compressed sensing. While it is not an ML framework or production library, it directly supports ML/data workflows by teaching core linear-algebra techniques and implementations commonly used in ML (decompositions, regression solvers, randomized SVD concepts) with standard Python data/ML tools (NumPy, scikit-learn, PyTorch, Numba). Its strong educational value and clear relevance to foundational ML/data methods justify a high score, tempered because it is primarily course content rather than a reusable software package.",success
https://github.com/HKUDS/AI-Trader,AI-Trader,"AI-Trader is an agentic trading benchmark/arena where multiple AI models autonomously research markets, generate trade decisions, and compete on real (or replayed) market data across NASDAQ 100, SSE 50, and major cryptocurrencies. It provides an MCP tool-driven architecture, live dashboard/leaderboard, performance analytics, and a framework for contributors to submit new trading agents/strategies via PRs.",10600,algorithmic trading|llm agents|multi-agent systems|reinforcement learning|quantitative finance|backtesting|model context protocol (MCP)|python,8,"This repository implements an AI-agent trading benchmark where LLM-based agents use tools (via an MCP-style toolchain) to retrieve market information, decide trades, and are evaluated in a controlled competition setting (including historical replay with anti-look-ahead controls). It is directly relevant to ML/data workflows for financial modeling and agent evaluation because it provides a structured environment, agent framework, and evaluation/analytics concepts that can be used to test and compare model-driven trading behavior. It has strong community adoption signals (notably a large GitHub star count) and meaningful educational value for building/evaluating tool-using agents in finance, but it is not a general-purpose foundational ML library on the scale of core frameworks—hence an 8 rather than 9–10.",success
https://github.com/colmap/colmap,colmap,"COLMAP is a general-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline for 3D reconstruction from ordered or unordered image collections, offering both a GUI and command-line interface. It includes an end-to-end workflow for feature extraction/matching, sparse reconstruction, and dense reconstruction, with optional GPU acceleration and Python bindings (PyCOLMAP).",10600,computer vision|3D reconstruction|structure-from-motion|multi-view stereo|photogrammetry|SLAM|C++|python bindings,8,"This repository provides COLMAP, a widely used 3D computer vision/photogrammetry system for reconstructing camera poses and 3D geometry from image collections via SfM and MVS, with both GUI and CLI workflows. While it is not a model-training framework, it is highly relevant to ML/data workflows because it generates and processes core geometric data products (poses, sparse/dense point clouds, meshes) commonly used in robotics, AR/VR, NeRF/3D vision pipelines, dataset creation, and evaluation. The strong community adoption and availability of Python bindings (PyCOLMAP) make it easy to integrate into data science pipelines and automate preprocessing at scale, justifying a high (but not maximum) score.",success
https://github.com/chiphuyen/stanford-tensorflow-tutorials,stanford-tensorflow-tutorials,"Code examples and assignments for Stanford CS20: ""TensorFlow for Deep Learning Research"" (primarily TensorFlow 1.x era), covering core deep learning workflows and topics like NLP and chatbots. The repository is archived (read-only) and intended mainly for instructional use.",10400,machine learning|deep learning|tensorflow|tensorflow-1.x|course materials|NLP|education,8,"This repository provides educational code examples and assignments for Stanford’s CS20 course on using TensorFlow for deep learning research, including practical implementations across common ML topics (e.g., NLP and chatbots). It is directly useful to ML practitioners as reference implementations and learning material, but it is not a production-ready library/tool and is archived, with much of the content tied to older TensorFlow 1.x versions. Its strong community adoption (10.4k stars) and high instructional value justify a high score, tempered by its age and limited integration with modern TF2/Keras-first workflows.",success
https://github.com/modin-project/modin,modin,"Modin is a drop-in replacement for pandas that accelerates pandas workflows by distributing computation across all CPU cores (and potentially a cluster) via execution engines like Ray, Dask, or MPI (through unidist). It aims to speed up and scale DataFrame operations with minimal code changes (often just changing the import).",10300,data engineering|dataframes|pandas|distributed computing|parallel computing|ray|dask|python,8,"This repository provides Modin, a pandas-compatible DataFrame library focused on scaling and accelerating tabular data processing by using distributed/parallel execution engines (e.g., Ray and Dask). It is directly applicable to data science and ML workflows because many pipelines start with pandas-based ETL, feature engineering, and dataset preparation that can become CPU/memory bottlenecks at larger data sizes. While it is not an ML training framework itself, it integrates naturally into ML stacks by making core data-wrangling steps faster with minimal code changes, which is why it merits a high (but not maximum) score.",success
https://github.com/microsoft/agent-lightning,agent-lightning,"Agent Lightning is a training framework for improving AI agents (including multi-agent systems) with minimal or near-zero code changes by tracing agent interactions and applying learning algorithms such as reinforcement learning, automatic prompt optimization, and supervised fine-tuning.",10200,agentic-ai|reinforcement-learning|llm|mlops|agent-frameworks|prompt-optimization|python,8,"This repository provides an end-to-end ""trainer"" for AI agents, capturing prompts/tool calls/rewards as structured traces and using them to optimize agent behavior via RL and other learning approaches, while integrating with popular agent frameworks (e.g., LangChain, AutoGen, CrewAI, OpenAI Agent SDK). It is directly applicable to ML workflows focused on agent training, evaluation, and iteration loops (including prompt/policy updates) and includes examples/docs to operationalize these pipelines. Community adoption appears strong for a research/agent-training tool (10.2k GitHub stars), but it is more specialized than general-purpose ML frameworks; hence an 8 rather than 9–10.",success
https://github.com/alexjc/neural-doodle,neural-doodle,"Implements Semantic Style Transfer to turn simple annotated doodles (semantic masks) plus optional content images into stylized artworks, and also supports related tasks like texture synthesis and image analogy generation via a Python script (doodle.py) that leverages deep neural networks.",9900,deep-learning|computer-vision|neural-style-transfer|semantic-segmentation-masks|image-synthesis|texture-synthesis|python,8,"This repository provides an end-to-end implementation of Semantic Style Transfer (""Neural Doodle""), using a deep neural network approach to generate new images from style/content inputs and optional semantic annotations, primarily via the doodle.py script. It is directly useful for ML/computer-vision experimentation and education around style transfer, texture synthesis, and optimization-based image generation, and includes examples, parameters, and workflow guidance. While it is a strong applied ML project with substantial community interest (about 9.9k stars), it is archived (read-only since Jan 2, 2021) and is not a modern, actively maintained framework, which limits integration and long-term production use—keeping it below a 9-10 score.",success
https://github.com/satellite-image-deep-learning/techniques,techniques,"A curated, exhaustive overview of deep learning techniques for satellite and aerial imagery, organized by task (e.g., classification, segmentation, object detection, change detection, time series, SAR, and foundation models). It primarily serves as a reference index of models, architectures, and related resources for remote sensing computer vision.",9900,remote sensing|satellite imagery|aerial imagery|deep learning|computer vision|segmentation|object detection|foundation models,8,"This repository is a highly ML-focused reference collection: it catalogs deep learning approaches and resources specifically for satellite/aerial image analysis across many core tasks (classification, segmentation, detection, change detection, SAR, etc.). It is directly useful in ML workflows as a starting point for model selection and literature/tool discovery, though it is more of a curated index than a runnable training framework or dataset. Its large community adoption (thousands of stars) and breadth make it valuable for learning and for rapidly orienting ML engineers in remote-sensing CV, justifying an 8/10 rather than a 9–10 reserved for full-featured libraries/frameworks. ",success
https://github.com/OpenMined/PySyft,PySyft,"PySyft (by OpenMined) enables “remote data science” by letting data scientists run statistical analysis and machine learning on data hosted in remote “Datasites” without directly accessing or copying the underlying private data. It provides a Python client/server workflow (including Jupyter usage) and supports executing Python code (including third‑party libraries) within governed, privacy-preserving environments.",9800,privacy-preserving machine learning|federated learning|secure data science|remote execution|data governance|python|jupyter,8,"PySyft is primarily built to enable privacy-preserving data science and machine learning by allowing compute to run where sensitive data resides (via Datasite servers) instead of moving data to the analyst. This is highly relevant to ML/data workflows for teams working with regulated or confidential datasets, since it supports executing Python-based analysis/ML (including third-party libraries) through a client/server model commonly used in notebooks. While it is not a general-purpose ML training framework like PyTorch, it provides important infrastructure for governed, remote, privacy-aware ML and analytics, and has substantial community adoption for the PPML space (notably a large GitHub star count).",success
https://github.com/tflearn/tflearn,tflearn,"TFLearn is a modular deep learning library that provides a higher-level API on top of TensorFlow, aimed at speeding up experimentation while staying transparent and compatible with TensorFlow graphs. It includes reusable layers, optimizers, metrics, training helpers, and examples for common neural network architectures.",9600,deep learning|machine learning|tensorflow|neural networks|python|high-level API|model training,8,"This repository provides a high-level deep learning API built on top of TensorFlow, enabling faster prototyping and training of neural network models (e.g., CNNs, LSTMs, RNNs) with built-in layers, optimizers, metrics, and training utilities. It is directly applicable to ML workflows for model definition and training, and includes tutorials/examples that add educational value. Community adoption appears solid (about 9.6k GitHub stars), but it is not a dominant modern standard compared to today’s most common frameworks, which is why it scores below a 9–10.",success
https://github.com/sloria/TextBlob,TextBlob,"TextBlob is a Python library for simplified natural language processing (NLP), providing an easy API for tasks like part-of-speech tagging, noun phrase extraction, sentiment analysis, tokenization, and basic text classification. It builds on NLTK and pattern to offer common text-processing features with minimal boilerplate.",9500,python|nlp|natural-language-processing|sentiment-analysis|text-processing|nltk|pattern,8,"This repository provides a high-level NLP toolkit for common text analytics tasks (e.g., sentiment analysis, POS tagging, noun phrase extraction, tokenization, and simple classifiers) aimed at making NLP workflows straightforward in Python. It is directly useful in data science for quick baseline text features, exploratory analysis, and prototyping, and it integrates with well-known NLP foundations like NLTK and pattern. While it is not a modern deep-learning training framework, it remains highly relevant as a practical NLP utility library with strong community adoption (as indicated by its star count).",success
https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow,Reinforcement-learning-with-tensorflow,"A collection of simple, code-first reinforcement learning tutorials implemented in TensorFlow, covering classic tabular methods and modern deep RL algorithms (e.g., DQN variants, policy gradients, actor-critic, A3C, DDPG, PPO), with example experiments and OpenAI Gym usage.",9400,reinforcement learning|tensorflow|deep reinforcement learning|tutorials|OpenAI Gym|DQN|policy gradient|actor-critic,8,"This repository is primarily an educational reinforcement learning codebase: it provides implementations and walkthrough-style examples for many widely used RL algorithms (tabular and deep RL), largely in Python/TensorFlow, and includes practical experiment demos and Gym-based environments. It is directly applicable for ML practitioners who want reference implementations, learning material, or a starting point for RL experimentation, though it is not a production-grade framework with standardized APIs comparable to major RL libraries. Community adoption appears solid (thousands of stars), and the breadth of covered algorithms makes it highly valuable for learning and prototyping, justifying a high (but not maximal) score.",success
https://github.com/The-Pocket/PocketFlow,PocketFlow,"Pocket Flow is a minimalist (~100-line) LLM application framework built around a graph abstraction for composing agent/workflow/RAG patterns without heavy dependencies or vendor lock-in. It provides tutorials and examples (chat, structured output, workflows, agents, RAG, streaming, multi-agent, etc.) and can be installed via pip or copied directly as source.",9400,llm|agent-framework|rag|workflow-orchestration|python|multi-agent-systems|prompt-engineering|ai-app-development,8,"PocketFlow is an LLM framework focused on building agentic applications using a lightweight graph-based abstraction, with many practical examples (agents, workflows, RAG, streaming, structured outputs). It is directly applicable to common ML/AI engineering workflows—especially LLM app development, orchestration, and retrieval-augmented generation—but it is not a general-purpose data science library (e.g., for data wrangling, classical ML training, or analytics). Its strong relevance to modern LLM engineering plus notable community adoption (high GitHub stars) supports a high score, though it is less central than core ML frameworks or data processing stacks.",success
https://github.com/gorse-io/gorse,gorse,"Gorse is an open-source recommendation system engine written in Go. It provides REST APIs, AutoML for choosing recommendation models, and supports single-node training with distributed prediction plus a dashboard for management and monitoring.",9300,recommender-systems|machine-learning|collaborative-filtering|information-retrieval|golang|distributed-systems|rest-api|mlops,8,"This repository is a production-oriented recommender system engine (not just a library) that ingests users/items/interactions and trains recommendation models automatically, then serves recommendations via REST APIs. It is directly applicable to ML/data workflows for building and operating recommendation pipelines, including data ingestion, model training, offline/online recommendation, and evaluation/monitoring capabilities. While it is more focused on deploying recommendation services than on general-purpose ML research/training, its end-to-end recommender functionality and distributed serving make it highly valuable for ML engineers and data teams implementing recommenders at scale.",success
https://github.com/voicepaw/so-vits-svc-fork,so-vits-svc-fork,"A fork of so-vits-svc (SoftVC VITS Singing Voice Conversion) that adds real-time voice conversion, a GUI and unified CLI, easier installation via pip, and other usability/training improvements. The repository is marked as no longer maintained, with updates largely limited since Spring 2023.",9200,voice-conversion|singing-voice-conversion|speech-audio|deep-learning|pytorch|real-time|vits,8,"This repository provides an end-to-end deep-learning system for voice/singing voice conversion (SVC), including training and inference workflows plus real-time conversion tooling, which is directly applicable to ML audio model development and experimentation. It integrates common ML components (e.g., PyTorch-based training/inference and feature/pitch extraction choices like HuBERT/ContentVec and CREPE) and is usable by ML practitioners to train models on custom datasets. The project has substantial community adoption (thousands of stars), but it is explicitly no longer maintained, which reduces its practical value for current production use and limits long-term integration potential; hence a high but not top score.",success
https://github.com/zyddnys/manga-image-translator,manga-image-translator,"A one-click manga/image translation tool that detects text in images, performs OCR + machine translation, and can also remove the original text and re-typeset the translated text back into the image. It supports local/batch usage plus web and API modes, with optional GPU acceleration and Docker deployment.",9200,computer vision|OCR|image translation|machine translation|PyTorch|inpainting|web API|Docker,8,"This repository is an end-to-end vision + language pipeline for translating text embedded in images (notably manga), combining text detection, OCR, translation, and post-processing like inpainting and typesetting. It is directly applicable to ML workflows because it orchestrates multiple ML components and supports GPU usage and containerized deployment, making it useful for practitioners integrating CV/NLP models into products or batch pipelines. It also has strong community adoption (≈9.2k GitHub stars at the time of lookup) and includes resources like notebooks and a training-related directory, giving it practical and educational value. It is scored 8/10 rather than 9–10 because it is primarily an application/product pipeline rather than a general-purpose ML framework or foundational library with broad industry-standard adoption.",success
https://github.com/infinitered/nsfwjs,nsfwjs,"Client-side NSFW/indecent image content detection using TensorFlow.js. Provides a simple API to load bundled (or self-hosted) models and classify images into five categories (Drawing, Hentai, Neutral, Porn, Sexy) in the browser or in JavaScript environments.",8800,machine-learning|computer-vision|tensorflow-js|nsfw-detection|image-classification|javascript|browser,8,"This repository is a JavaScript library focused on running a pre-trained image classification model for NSFW detection using TensorFlow.js, making it directly applicable to ML-powered content moderation workflows. It’s particularly useful for ML engineers and product teams who need an off-the-shelf classifier that runs on-device/in-browser, and it includes multiple bundled model options plus guidance for hosting your own model assets. While it is not a general-purpose training framework or a dataset, it is highly relevant as a practical inference-time ML component and is widely adopted (as indicated by its star count and community activity).",success
https://github.com/poloclub/cnn-explainer,cnn-explainer,"An interactive, web-based visualization system for teaching how Convolutional Neural Networks (CNNs) work by letting users explore layers, activations, and learned features. It includes a live demo site and code for running the explainer locally, with a companion directory showing how the example CNN (Tiny-VGG) is trained.",8800,machine learning|deep learning|computer vision|cnn|interactive visualization|visual learning|svelte,8,"This repository’s primary purpose is to help users understand CNNs through interactive visual explanations rather than to serve as a production training/inference library. It is highly relevant to ML education and model interpretability/visualization workflows (useful for teaching, demos, and understanding CNN internals), and it includes an example model/training code (Tiny-VGG). However, it is less directly applicable as a drop-in tool for typical ML engineering pipelines compared with core frameworks or MLOps tooling, which is why it scores below 9–10.",success
https://github.com/fengdu78/Data-Science-Notes,Data-Science-Notes,"A collection of data science study notes and curated resources, primarily in Jupyter notebooks, covering fundamentals from math and Python through NumPy/Pandas/SciPy, visualization, scikit-learn, machine learning, deep learning, and feature engineering.",8500,data science|machine learning|deep learning|python|jupyter notebook|scikit-learn|pandas|feature engineering,8,"This repository is an educational set of data-science notes and collected materials organized by core topics (math, Python, NumPy/Pandas/SciPy, visualization, scikit-learn, ML, DL, and feature engineering). It directly supports ML/data workflows by providing structured learning content and practical notebook-based references for commonly used tools and concepts, rather than being a production library or framework. Its strong community adoption (8.5k stars) and broad coverage make it highly valuable for learning and reference, but it scores below 9–10 because it is not a core ML framework/tool used as a dependency in production systems.",success
https://github.com/vaexio/vaex,vaex,"Vaex is a high-performance Python library providing lazy, out-of-core DataFrames (Pandas-like) for exploring, visualizing, and processing very large tabular datasets using Apache Arrow/NumPy techniques. It emphasizes memory-mapped/zero-copy access, fast aggregations/groupbys, joins, and interactive workflows (e.g., Jupyter) on datasets up to billions of rows.",8500,dataframes|data-engineering|big-data|out-of-core-processing|apache-arrow|data-visualization|python|machine-learning,8,"This repository implements Vaex, an out-of-core/lazy DataFrame engine designed to efficiently explore and compute statistics/aggregations over massive tabular datasets, with strong performance and memory efficiency features (memory mapping, zero-copy, lazy expressions). It is directly useful in data science workflows as a Pandas-like alternative for large data, and it also advertises ML-oriented usage (e.g., feature engineering via expressions and ML integration guidance). While it is not a model-training framework itself, it materially improves data loading, transformation, and exploratory analysis steps that precede modeling, making it highly valuable for ML/data practitioners. The substantial GitHub adoption (8.5k stars) supports the high—but not “core ML framework”—score.",success
https://github.com/apache/beam,apache/beam,"Apache Beam is a unified programming model and set of SDKs for building batch and streaming data processing pipelines. It includes multiple language SDKs and runners to execute pipelines on distributed backends such as Flink, Spark, and Google Cloud Dataflow.",8400,data engineering|stream processing|batch processing|distributed systems|ETL|Apache Flink|Apache Spark|Google Cloud Dataflow,8,"This repository provides Apache Beam, a widely used framework for defining and running large-scale batch and streaming data pipelines across multiple execution engines. It is strongly relevant to ML/data workflows because it is commonly used for data ingestion, transformation, feature engineering, and building production data pipelines that feed model training and inference systems. While it is not an ML training framework itself, its portability across runners and broad adoption in data engineering make it highly valuable to ML engineers and data scientists working in production environments. The score reflects high applicability and ecosystem integration for ML/data pipelines, but not being a core model-training library.",success
https://github.com/nebuly-ai/optimate,optimate,"OptiMate is a legacy (no longer actively maintained) collection of open-sourced libraries from Nebuly AI aimed at optimizing AI model performance and costs. It includes tools for inference acceleration and hardware-aware optimization (Speedster), Kubernetes GPU-cluster utilization/cost optimization (Nos), and LLM fine-tuning/RLHF optimization tooling (ChatLLaMA).",8400,machine-learning|deep-learning|llm|model-optimization|inference-optimization|kubernetes|gpu,8,"This repository’s primary purpose is to provide practical tooling to optimize AI/ML workloads—covering inference speed/cost optimization (Speedster), GPU-cluster utilization optimization on Kubernetes (Nos), and LLM fine-tuning/alignment optimization (ChatLLaMA). These capabilities map directly onto common ML engineering and MLOps workflows (deployment, serving efficiency, and LLM training/finetuning efficiency), making it highly applicable for ML practitioners. The score is not higher mainly because the repo is explicitly marked as legacy and not actively maintained, which reduces reliability and long-term integration potential despite strong relevance and notable community adoption (8.4k stars).",success
https://github.com/firmai/financial-machine-learning,financial-machine-learning,"A curated, continuously updated list of practical tools, libraries, and applications for financial machine learning and quantitative finance. It organizes links/repos by topic (e.g., trading, deep learning/RL) and tracks metadata like activity/status and star counts.",8300,financial machine learning|quantitative finance|algorithmic trading|reinforcement learning|deep learning|curated list|Python,8,"This repository primarily serves as a curated and actively maintained directory of financial ML/data-science tools and applications, rather than a single executable ML library. It is highly relevant to ML/data workflows because it helps practitioners discover and compare financial ML repos (including deep learning and reinforcement learning trading stacks) and provides organized entry points by topic with tracked repo metadata. Community adoption appears strong (thousands of GitHub stars), and its educational value is high as a map of the ecosystem, but integration potential is indirect since most value comes from the external linked projects rather than code in this repo itself.",success
https://github.com/google/trax,trax,"Trax is an end-to-end deep learning library focused on clear code and speed. It provides model implementations (e.g., Transformer, Reformer, ResNet), supervised training utilities, and reinforcement learning algorithms, designed to run on CPUs/GPUs/TPUs and usable from Python or the command line.",8300,deep learning|machine learning|neural networks|NLP|transformers|reinforcement learning|Python|TPU,8,"This repository is a full deep learning framework/library (Trax) that includes model architectures (e.g., Transformer/Reformer) and training/decoding utilities, plus reinforcement learning algorithms, making it directly applicable to ML engineering and research workflows. It also integrates with common ML data sources (e.g., TensorFlow Datasets/Tensor2Tensor bindings mentioned in the README) and supports common accelerators (CPU/GPU/TPU), which increases its practical utility for training and experimentation. However, the GitHub repo is archived and read-only as of Oct 31, 2025, which reduces ongoing adoption and integration potential compared with actively maintained major frameworks—hence an 8 rather than 9–10.",success
https://github.com/jupyterhub/jupyterhub,jupyterhub,"JupyterHub is a multi-user server for Jupyter that spawns, manages, and proxies individual single-user notebook/server instances. It provides authentication, user/server management, and an admin REST API for running Jupyter environments for teams, classes, or research groups.",8200,jupyter|jupyterhub|jupyter-notebook|jupyterlab|multi-user|devops|python|infrastructure,8,"This repository provides JupyterHub, an orchestration layer that authenticates users and spawns/manages separate Jupyter notebook/server instances behind a proxy, aimed at shared environments (classes, data science teams, research/HPC groups). While it is not an ML library itself, it is highly applicable to ML/data workflows because it is commonly used to deliver and manage Jupyter-based data science environments for many users, often integrating with scalable infrastructure and admin automation via its REST API. The strong adoption in the Jupyter ecosystem and its direct usefulness for running collaborative data platforms justify a high score, but it is not a core ML framework, so it is not a 9–10.",success
https://github.com/zilliztech/GPTCache,GPTCache,"GPTCache is a Python library for building a semantic cache for LLM queries to reduce latency and API costs by reusing prior LLM responses via exact and similarity-based matching. It integrates with popular LLM app frameworks (e.g., LangChain and llama_index) and also provides a server/docker option for language-agnostic usage.",7900,LLM|semantic caching|RAG|LangChain|LlamaIndex|vector database|Python,8,"This repository’s primary purpose is to cache LLM inputs/outputs using semantic (similarity-based) matching so repeated or near-duplicate prompts can be served without re-calling an LLM, improving speed and reducing inference/API spend. It is highly applicable to ML/LLM engineering workflows (especially production LLM apps and RAG systems) and integrates directly with common LLM tooling like LangChain/llama_index, making adoption straightforward. While it is not a model-training framework, it is an important piece of LLM application infrastructure/MLOps for serving and cost control, which justifies a high (but not maximum) ML/data relevance score.",success
https://github.com/exadel-inc/CompreFace,CompreFace,"CompreFace is a free, open-source, self-hosted face recognition system that provides a REST API (and UI) for face recognition/identification and related tasks like verification, detection, landmarks, mask detection, head pose, age, and gender estimation. It is designed to be easy to deploy via Docker/docker-compose on CPU or GPU without requiring prior ML expertise.",7600,computer-vision|face-recognition|facial-detection|machine-learning|rest-api|docker|self-hosted|biometrics,8,"This repository provides a production-ready, containerized facial recognition platform with a REST API and UI for common vision/biometric capabilities (recognition, verification, detection, and multiple face-related plugins). It is highly relevant to ML/DS workflows because ML engineers can deploy it as an inference service and integrate it into applications and pipelines without building models from scratch, though it is not primarily a training/research framework. Community adoption appears strong for an open-source application (thousands of GitHub stars) and its integration-first design (APIs, SDKs, Docker) makes it practical for applied ML and MLOps use cases, supporting an 8/10 score.",success
https://github.com/MingchaoZhu/DeepLearning,DeepLearning,"An educational repository providing mathematical derivations, principle-level explanations, and NumPy-based from-scratch implementations aligned with the book ""Deep Learning"" (Goodfellow, Bengio, Courville). It includes PDFs (Chinese/English book versions and a continuously updated companion document) plus corresponding reference code.",7500,deep learning|machine learning|educational|numpy|from-scratch|mathematical derivations|computer vision|natural language processing,8,"This repository is primarily an educational deep learning resource: it re-explains concepts from the Deep Learning textbook with detailed derivations and provides source-level implementations mainly using Python/NumPy rather than frameworks like PyTorch/TensorFlow. It is directly useful for ML learners and practitioners who want to understand algorithms and training mechanics at an implementation level, and it includes substantial written material (PDF chapters) plus code. While it is not a production ML framework or MLOps tool, its strong learning value and breadth of covered topics (optimization, CNNs, sequence modeling, etc.) make it highly valuable for data science and ML study and prototyping.",success
https://github.com/firmai/industry-machine-learning,industry-machine-learning,"A curated, community-contributed catalog of applied machine learning and data science resources (primarily Python/Jupyter notebooks and libraries) organized by industry verticals such as finance, healthcare, manufacturing, and government.",7400,machine learning|data science|awesome-list|Jupyter notebooks|Python|industry applications|curated resources,8,"This repository is primarily an ""awesome list"" style directory that aggregates applied ML/data-science notebooks, tools, and references across many industries rather than a single runnable library or framework. It is highly relevant to ML/data workflows because it helps practitioners discover domain-specific datasets, notebooks, and libraries they can directly use or learn from, and it has substantial community adoption (7.4k stars). It scores below 9–10 because it is not itself a core ML tool (e.g., a training framework or production pipeline), but it remains very valuable for educational and practical discovery in applied ML.",success
https://github.com/QuivrHQ/MegaParse,MegaParse,"MegaParse is a Python-based document/file parsing toolkit optimized for LLM ingestion with a focus on minimizing information loss. It supports parsing common formats like PDF, DOCX, and PPTX (and more per README), and can run as a library or as an API service.",7300,llm|document-parsing|pdf|docx|pptx|ocr|python|data-extraction,8,"MegaParse’s primary purpose is to convert documents (e.g., PDFs, Word, PowerPoint) into representations that are well-suited for LLM ingestion while preserving as much structure/content as possible (tables, TOC, headers/footers, images). This is directly applicable to ML/data workflows like RAG pipelines, dataset creation from enterprise documents, and preprocessing for downstream NLP/LLM tasks, and it even includes a vision/multimodal parsing mode that relies on LLM/VLM providers. It is not an ML training framework itself, but it is a high-leverage data-preparation component for LLM applications, and the sizable GitHub adoption (7.3k stars) supports a high relevance score.",success
https://github.com/hybridgroup/gocv,gocv,"Go (Golang) bindings for OpenCV 4+ that enable computer vision and image/video processing in Go applications. It also includes optional support for OpenCV DNN, CUDA acceleration, OpenCV Contrib modules, and OpenVINO integration.",7300,computer vision|opencv|golang|image processing|video processing|deep learning inference|cuda|openvino,8,"This repository provides Go bindings to OpenCV (4 and beyond), enabling core computer-vision workflows like image/video I/O, processing, and feature/camera operations, with additional options for DNN inference, CUDA acceleration, and OpenVINO. It’s highly relevant to ML/data workflows because it can be used directly to build vision data pipelines (capture/ETL, preprocessing, augmentation) and to run model inference via OpenCV’s DNN module, especially in production Go services. It’s not a full model-training framework, but its practical utility for CV data handling and deployment plus strong community adoption (7.3k stars) justify a high score.",success
https://github.com/zilliztech/deep-searcher,deep-searcher,"DeepSearcher is an open-source “deep research”/agentic RAG toolkit written in Python that combines LLMs and vector databases (e.g., Milvus/Zilliz Cloud) to search, evaluate, and reason over private/local data to produce accurate answers and longer reports. It supports loading local documents (and optional website loading), configurable LLM/embedding providers, and vector DB-backed retrieval for enterprise knowledge/Q&A scenarios.",7300,agentic-rag|retrieval-augmented-generation|llm|vector-database|milvus|enterprise-search|information-retrieval|python,8,"This repository provides an agentic RAG/deep-research pipeline that connects LLMs with embeddings and vector databases to answer questions and generate comprehensive reports from private/local corpora, which is directly aligned with common ML/DS knowledge-base and research workflows. It includes practical components data scientists/ML engineers use in production (document ingestion/loading, embeddings, vector DB storage/retrieval, multi-LLM provider configuration, and query/report generation). Community adoption appears strong for a focused tool (thousands of GitHub stars and active ecosystem references), but it is not a core training framework like PyTorch—hence an 8 rather than 10.",success
https://github.com/WangRongsheng/awesome-LLM-resources,awesome-LLM-resources,"A curated, continuously updated “awesome list” collecting high-quality resources related to large language models (LLMs), covering areas like data processing, fine-tuning, inference, evaluation, RAG/knowledge bases, agents, and multimodal models.",7200,large language models|NLP|generative AI|RAG|LLM fine-tuning|LLM inference|agents|multimodal,8,"This repository is primarily a curated index of tools, papers, tutorials, and references across the LLM ecosystem (including data processing, fine-tuning, inference, evaluation, RAG, and agents). While it is not an executable ML library itself, it is highly actionable for ML practitioners because it aggregates many directly usable tools and learning resources for building and operating LLM systems. Community adoption appears strong (thousands of stars and hundreds of forks), increasing its practical value as a navigation hub. It scores an 8 because it is highly relevant and broadly useful for ML/data workflows, but it is fundamentally a resource list rather than a core framework or pipeline that you integrate as a dependency.",success
https://github.com/instillai/machine-learning-course,machine-learning-course,"An educational machine learning course in Python with tutorials and example code covering ML basics, supervised/unsupervised learning, and deep learning topics (e.g., regression, trees, clustering, CNNs, RNNs). It includes documentation (ReadTheDocs) and a structured set of lessons plus corresponding code.",7100,machine learning|python|scikit-learn|deep learning|supervised learning|unsupervised learning|education,8,"This repository is primarily an educational machine learning course, providing Python-based tutorials and code examples for common ML algorithms and deep learning concepts. It is directly useful for learning and practicing ML workflows (reading lessons, running example implementations, and adapting code patterns), though it is not a production ML framework or pipeline tool. Community adoption appears solid for an educational repo (thousands of GitHub stars and many forks), but its main value is instructional rather than being a widely-integrated industry library, which is why it scores 8 instead of 9–10.",success
https://github.com/thunlp/WantWords,WantWords,"WantWords is an open-source online reverse dictionary system that returns candidate words semantically matching a natural-language description (e.g., to solve tip-of-the-tongue or word-finding needs). It includes a web service implementation and uses a multi-channel reverse-dictionary model with downloadable pretrained models/data.",7100,nlp|natural-language-processing|reverse-dictionary|information-retrieval|pytorch|django|web-application,8,"This repository implements a reverse-dictionary NLP system (given a textual description, retrieve semantically matching words) and provides the code to run it as an online service, along with links to download pretrained models and data. It is directly applicable to ML/NLP workflows for semantic retrieval, language assistance tools, and as a reference implementation of the associated research model. The score is high because it is explicitly ML/NLP-focused, includes pretrained artifacts, and has strong community adoption (7.1k GitHub stars), though it is a specialized application rather than a general-purpose ML framework.",success
https://github.com/SerpentAI/SerpentAI,SerpentAI,"Serpent.AI is a Python-based, plugin-driven game agent framework for building AI/bot agents that can learn to play video games you own by treating them as sandbox environments. It provides tooling and modules (e.g., for vision/input automation) to support experimentation with approaches like reinforcement learning and computer vision.",7000,reinforcement learning|game AI|machine learning|computer vision|python|agent framework|automation,8,"This repository is primarily a framework for creating game-playing agents, explicitly positioned as a tool for Machine Learning & AI research and experimentation (especially reinforcement learning and vision-based agents). It is directly applicable to ML workflows where the “environment” is a real game (screen capture + action execution), offering a structured, plugin-based way to build, run, and iterate on agents. While it is not a general-purpose data science library and the repository is archived/read-only (archived Aug 23, 2022), it remains highly relevant educationally and practically for ML practitioners exploring game agents and custom RL environments.",success
https://github.com/EutropicAI/Final2x,Final2x,"Final2x is a cross-platform (Windows/macOS/Linux) desktop tool for image super-resolution (upscaling) using deep-learning-based backends, with support for custom models. It provides an easy-to-use GUI for running super-resolution workflows and distributing packaged releases.",6900,computer vision|image super-resolution|image processing|PyTorch|Electron|TypeScript|Vue 3|cross-platform desktop app,8,"This repository provides an end-user application for AI-based image super-resolution, a core computer-vision task, and it explicitly integrates ML tooling/backends (notably PyTorch) for inference and model usage. It’s directly applicable to ML/CV workflows for upscaling images and experimenting with different super-resolution models (including custom models), though it is more of a packaged application than a general-purpose training framework. Its strong community adoption (thousands of GitHub stars) and practical utility for CV practitioners justify a high score, but it falls short of a 9–10 because it’s not a foundational ML library/framework with broad training/research extensibility.",success
https://github.com/likedan/Awesome-CoreML-Models,Awesome-CoreML-Models,"A curated “awesome list” of machine learning models available in Apple Core ML format, aimed at helping iOS/macOS/tvOS/watchOS developers quickly find, download, and try pre-trained models (with links to demos and references). It also includes supporting assets like a generated README and a JSON index of model entries.",6900,coreml|ios|machine-learning|model-zoo|computer-vision|nlp|swift|apple-ecosystem,8,"This repository’s primary purpose is to catalog and organize many ready-to-use Core ML models (plus links to downloads, demos, and references) for Apple platforms, functioning like a model zoo/awesome list. It is highly relevant to applied ML workflows for on-device inference, prototyping, benchmarking, and education—especially for ML engineers and app developers deploying models to iOS/macOS. It’s not a training framework or data pipeline tool, but it is directly useful for model selection and deployment experiments, and its strong community adoption (thousands of stars) supports a high score.",success
https://github.com/vladmandic/sdnext,sdnext,"SD.Next is an all-in-one web UI for running AI generative image and video workflows, focused on diffusion-based generation (e.g., Stable Diffusion) with broad model and hardware backend support. It includes an installer/updater, multiple UI modes, queue management, and built-in tools for text/image/batch/video processing plus captioning/interrogation features.",6900,generative-ai|stable-diffusion|diffusion-models|computer-vision|webui|pytorch|video-generation|model-inference,8,"This repository primarily provides a production-oriented WebUI and runtime for diffusion model inference (and related workflows like captioning/interrogation), enabling end users and ML practitioners to run and manage generative image/video pipelines across many backends (CUDA/ROCm/DirectML/OpenVINO/ONNX, etc.). It is highly applicable to ML workflows for model serving, experimentation, and prompt-based generation, but it is not a general-purpose training framework or data pipeline library. Strong community adoption and broad integrations make it valuable for applied ML and generative AI operations, warranting an 8/10 rather than a 9–10 reserved for foundational ML frameworks.",success
https://github.com/yenchenlin/DeepLearningFlappyBird,DeepLearningFlappyBird,"Implements a Deep Q-Network (DQN) deep reinforcement learning agent that learns to play Flappy Bird from raw pixel input. Includes the Flappy Bird game environment, training script, and pretrained checkpoints/logs for experimentation.",6800,reinforcement learning|deep q-learning|deep learning|tensorflow|computer vision|pygame,8,"This repository is primarily an applied deep reinforcement learning project: it trains a convolutional Deep Q-Network on image frames (raw pixels) to control an agent in the Flappy Bird environment. It is directly useful for ML workflows as a reference implementation of DQN, including preprocessing (grayscale/resize/frame stacking), replay memory, epsilon-greedy exploration, and training code in TensorFlow. While it is older (e.g., references TensorFlow 0.7) and not a general-purpose library, it has strong educational value and notable community adoption (thousands of GitHub stars), which justifies a high but not top-tier score.",success
https://github.com/traceloop/openllmetry,openllmetry,"OpenLLMetry is an open-source observability toolkit for GenAI/LLM applications built on OpenTelemetry. It provides OpenTelemetry-compatible instrumentations for LLM providers, vector databases, and popular LLM frameworks, plus a Traceloop SDK to simplify setup and export traces/metrics to existing observability backends.",6700,LLM observability|OpenTelemetry|tracing|MLOps|LLM instrumentation|vector databases|Python SDK,8,"This repository focuses on observability for LLM/GenAI applications via OpenTelemetry, offering ready-made instrumentations for major LLM providers (e.g., OpenAI/Anthropic), vector databases (e.g., Pinecone/Qdrant/Weaviate), and frameworks (e.g., LangChain/LlamaIndex), along with a Python SDK to initialize tracing. It is highly relevant to ML/data workflows because production ML/LLM systems need monitoring, tracing, debugging, and performance/cost visibility across model calls and retrieval components. While it is not a modeling/training library, it is directly applicable to building and operating LLM-powered data products, and its strong community adoption (thousands of GitHub stars) supports a high score.",success
https://github.com/vespa-engine/vespa,vespa,"Vespa is an open-source, distributed serving engine for AI + data applications that supports large-scale retrieval, filtering/aggregation, and multi-phase ranking (including deploying ML models in the query path) for use cases like search, recommendations, and hybrid (text + vector) retrieval.",6700,search engine|vector database|information retrieval|recommendation systems|ranking|MLOps/inference serving|distributed systems|Java,8,"This repository contains the core Vespa engine, a production-grade platform used to store, retrieve, and rank data with support for hybrid retrieval and advanced ranking pipelines. It is highly relevant to ML/data workflows because it serves as the online inference and retrieval layer for systems like semantic search and RAG, and it supports model-driven ranking (e.g., via ONNX/XGBoost) directly in the serving path. While it is not a model-training framework, it is a critical component for deploying and operating ML-powered retrieval/ranking in production at scale, and it has meaningful adoption in modern AI search stacks.",success
https://github.com/datawhalechina/fun-rec,fun-rec,"FunRec is a beginner-friendly, comprehensive tutorial for learning recommender systems, covering theory, core algorithms (recall/ranking/reranking), engineering practice, and interview preparation, with an accompanying online book.",6600,recommender systems|machine learning|deep learning|tensorflow|education|recommendation algorithms|python,8,"This repository is primarily an educational guide for recommender systems, including conceptual explanations and practical engineering-oriented content, which makes it directly relevant to ML practitioners working on recommendation. It relates strongly to ML/data workflows because recommender systems are a major applied ML domain involving model training (e.g., deep models like Wide & Deep), embeddings, feature engineering, and evaluation. Community adoption appears strong for a learning resource (about 6.6k GitHub stars), supporting its utility and reach. It scores an 8 (highly relevant) because it is not a general-purpose ML framework itself, but it is a substantial, practically-oriented learning resource focused on core ML recommendation methods.",success
https://github.com/microsoft/presidio,presidio,"Presidio is an open-source data protection and de-identification SDK for detecting and anonymizing sensitive data (PII/PHI) across text, images, and structured data. It supports NLP-based entity recognition, pattern/rule-based detectors, and customizable redaction/masking/anonymization pipelines deployable via Python, Docker, and Kubernetes.",6600,data-privacy|PII-detection|data-anonymization|NLP|named-entity-recognition|Python|spaCy|transformers,8,"This repository provides practical tooling to detect and de-identify sensitive entities (PII/PHI) using a mix of ML (NER via spaCy/transformers or external models) and rule/pattern-based recognition, plus anonymization/redaction operators. It is highly applicable to ML/data workflows where privacy-preserving preprocessing is required (e.g., preparing datasets for analytics/model training, governance, compliance, and safe data sharing), including support for text, images (including DICOM), and structured processing (e.g., PySpark). It earns an 8 (highly relevant) because it is a widely adopted, production-oriented privacy/PII framework that integrates directly into DS/ML pipelines, though it is not itself a general-purpose model training framework.",success
https://github.com/ml5js/ml5-library,ml5-library,"ml5.js is a JavaScript library that makes machine learning approachable in the browser for artists, creative coders, and students. It provides easy-to-use ML models and algorithms on top of TensorFlow.js, along with examples, tutorials, and educational resources.",6600,machine learning|javascript|web development|tensorflow.js|creative coding|browser-based ML|education,8,"This repository is the main source code for ml5.js, a browser-focused JavaScript ML library built on top of TensorFlow.js, designed to make using pretrained ML models and common ML tasks accessible to non-experts. It is directly applicable to ML workflows for prototyping and deploying interactive ML experiences in the browser (e.g., client-side inference), though it is not primarily a training framework or data pipeline tool. Its extensive examples/tutorials and strong community adoption in creative coding and education increase its practical and educational value. The score reflects high relevance to applied ML (especially inference and teaching) but not being a core industry-standard training/data-engineering backbone like PyTorch/TensorFlow proper.",success
https://github.com/NLPchina/ansj_seg,ansj_seg,"Ansj is a Java-based Chinese NLP library focused on fast, accurate Chinese word segmentation. It also provides features like Chinese name recognition, part-of-speech tagging, user-defined dictionaries, keyword extraction, and automatic summarization, using approaches described as n-gram + CRF + HMM in the README.",6500,natural language processing|Chinese NLP|word segmentation|Java|tokenization|CRF|HMM|part-of-speech tagging,8,"This repository implements core Chinese NLP preprocessing—especially Chinese tokenization/segmentation—and includes additional text-mining utilities like keyword extraction and summarization, which are directly useful in many ML/NLP pipelines. While it is not a model-training framework, segmentation is a foundational step for feature engineering and downstream tasks (classification, search, clustering) and the project appears widely adopted (thousands of GitHub stars). Because it provides practical, production-oriented NLP processing rather than end-to-end ML training or MLOps tooling, it fits best as a highly relevant supporting library rather than a core ML framework, hence an 8/10.",success
https://github.com/axa-group/nlp.js,nlp.js,"NLP.js is a Node.js natural-language processing library aimed at building chatbots/bots, providing intent classification (NLU), named-entity recognition, sentiment analysis, and language detection. It supports many languages and offers a modular plugin/pipeline architecture with optional integrations (e.g., BERT-based language support and bot connectors).",6500,natural language processing|NLU|chatbots|named entity recognition|sentiment analysis|JavaScript|Node.js,8,"This repository provides an end-to-end NLP toolkit for building conversational systems in Node.js, including intent classification, NER, sentiment analysis, and language detection, plus a manager layer for training and running multi-language bots. It is directly applicable to ML/data workflows for text understanding (training intent models, extracting structured entities from text, and evaluating/serving NLP pipelines), even though it is more application-oriented than a general-purpose research framework. Community adoption appears strong (about 6.5k GitHub stars), and the feature set and integrations (e.g., BERT-based support mentioned in the README and modular packages published under node-nlp) increase practical utility, justifying a high (but not top-tier) score.",success
https://github.com/codertimo/BERT-pytorch,BERT-pytorch,"A PyTorch implementation of Google AI's 2018 BERT (Bidirectional Encoder Representations from Transformers) with an emphasis on a simple, annotated codebase. It includes tooling/CLI for building a vocabulary from a corpus and pre-training a BERT-style language model using masked language modeling and next sentence prediction.",6500,natural language processing|pytorch|transformers|bert|language modeling|pretraining,8,"This repository provides an end-to-end PyTorch implementation of BERT pre-training (masked language modeling and next sentence prediction), plus practical scripts/CLI commands to build vocabularies and train models from text corpora. It is directly applicable to ML/NLP workflows for learning, experimentation, and custom pretraining, though it is not the dominant production-standard implementation compared to widely adopted libraries (e.g., Hugging Face Transformers). The strong educational value and solid community interest (thousands of stars) justify a high score, but the presence of more modern, heavily maintained alternatives keeps it below a 9–10.",success
https://github.com/run-llama/rags,rags,"RAGs is a Streamlit app that lets you build a retrieval-augmented generation (RAG) pipeline over a data source (e.g., local file or web page) using natural-language instructions, then chat with the generated RAG agent over that data. It is built with LlamaIndex and supports configuring LLM/embedding choices and key RAG parameters (top-k, chunk size, summarization, etc.).",6500,retrieval-augmented-generation|llm|llamaindex|streamlit|chatbot|information-retrieval|embeddings|openai,8,"This repository provides a ready-to-run UI application for constructing and querying RAG pipelines, including retrieval and optional summarization tools, with configurable parameters and model providers. It is directly applicable to common ML/NLP workflows (building “chat over your data” systems) and integrates with popular LLM/embedding backends (e.g., OpenAI and local Hugging Face embeddings) via LlamaIndex. Its focus is practical RAG system creation rather than model training, but it is highly valuable for ML engineers and data scientists implementing LLM-powered knowledge assistants, and it shows strong community adoption (thousands of GitHub stars).",success
https://github.com/TencentQQGYLab/AppAgent,AppAgent,"AppAgent is an LLM-based multimodal agent framework that operates Android smartphone apps via visual understanding of screenshots and human-like interactions (tap/swipe) executed through ADB. It can learn an app either by autonomous exploration or from human demonstrations, building a reusable knowledge base to complete future tasks without backend/app-instrumentation access.",6400,multimodal agents|LLM|mobile automation|android|GUI agents|computer vision|ADB,8,"This repository provides a practical framework for building and running multimodal LLM agents that perceive mobile GUIs from screenshots and decide concrete actions (taps/swipes) to accomplish user tasks, including a learning phase that builds a knowledge base for reuse. It is strongly relevant to ML workflows because it operationalizes vision-language models (e.g., GPT-4V-style models and alternatives like Qwen-VL) in an agent loop, and it also releases an evaluation benchmark used in testing, which can be useful for research and experimentation. While it is not a general-purpose ML training library like PyTorch, it is highly applicable to ML research/engineering on GUI agents, tool-using agents, and multimodal evaluation, and it has notable community adoption (6.4k stars).",success
https://github.com/microsoft/nlp-recipes,nlp-recipes,"Microsoft’s archived collection of NLP best practices, end-to-end example Jupyter notebooks, and reusable utility functions for building common NLP solutions (e.g., classification, NER) with modern approaches such as transformer-based models.",6400,natural language processing|machine learning|deep learning|transformers|jupyter notebooks|python|hugging face,8,"This repository provides practical NLP examples and best-practice guidance, largely via Jupyter notebooks and accompanying Python utility code aimed at building real-world text/language solutions. It is directly applicable to ML workflows (training/fine-tuning models for common NLP tasks) and has clear educational value for data scientists and ML engineers. However, it is archived (read-only as of Nov 16, 2023) and is not a foundational, widely-adopted core framework like PyTorch/TensorFlow, which lowers the score slightly despite strong relevance.",success
https://github.com/poloclub/transformer-explainer,transformer-explainer,"An interactive, browser-based visualization tool for learning how Transformer-based LLMs (e.g., GPT) work by running a live GPT-2 model in the browser and showing internal computations (e.g., attention, MLP) and next-token prediction behavior in real time.",6400,machine learning|NLP|transformers|LLM|interactive visualization|explainable AI|web app,8,"This repository primarily provides an educational, interactive visualization of Transformer internals and runs a live GPT-2 model directly in the browser for hands-on exploration. While it is not a training framework or a production MLOps tool, it is highly relevant to ML/NLP workflows as a practical learning and debugging aid for understanding attention, embeddings, and token sampling behavior. Its strong educational value and substantial community adoption (thousands of GitHub stars) justify a high score, though it scores below 9–10 because it is not a core industry library for model development or deployment.",success
https://github.com/scikit-image/scikit-image,scikit-image,"scikit-image is an open-source Python library for image processing and computer vision, providing a wide range of algorithms for filtering, segmentation, feature extraction, morphology, and related tasks, with strong documentation and community support.",6400,python|image-processing|computer-vision|scientific-computing|numpy|scipy|data-science,8,"This repository implements scikit-image, a widely used Python toolkit for classical image processing and computer vision workflows (e.g., segmentation, filtering, morphology, feature extraction). It is highly applicable to data science and ML pipelines as a preprocessing/feature-engineering layer for image data, and it integrates naturally with the broader Scientific Python stack (NumPy/SciPy). It is not a model-training framework itself, but its adoption and direct utility for preparing and analyzing image datasets justify a high (but not maximum) score.",success
https://github.com/SkalskiP/courses,courses,"A curated collection of links to courses and learning resources in Artificial Intelligence, organized across topics like deep learning, NLP, computer vision, MLOps, transformers, and generative AI. The repo serves as an AI learning hub with a README-based catalog and community contributions.",6300,artificial intelligence|machine learning|deep learning|natural language processing|computer vision|generative AI|MLOps|education,8,"This repository’s primary purpose is educational: it curates and organizes high-quality AI/ML courses and resources (e.g., deep learning, NLP, computer vision, transformers, generative AI) into a single, navigable catalog. While it is not a software library, dataset, or framework directly used in production ML workflows, it is highly valuable for data scientists and ML engineers for structured learning and skill development. Its strong community adoption (6.3k stars) indicates broad usefulness and credibility as a learning reference.",success
https://github.com/SmirkCao/Lihang,Lihang,"A study/companion repository for Li Hang’s book 《统计学习方法》(Statistical Learning Methods, 2nd edition), containing notes, code, notebooks, reference-material download scripts, and supplementary indexes/errata to support learning the algorithms in the book.",6300,machine learning|statistical learning|educational|python|jupyter-notebook|notes|algorithms,8,"This repository is primarily an educational companion to a core machine-learning textbook, organizing chapter-by-chapter materials (notes, code, and notebooks) around widely used statistical learning algorithms. It maps directly to common ML workflows for learning and experimenting with classical methods (e.g., classification, probabilistic models, and related foundations), making it highly useful for learners and practitioners refreshing fundamentals. While it is not a production ML framework or MLOps tool and its adoption is more educational than industry-standard tooling, its practical examples and structured coverage provide strong value for data science/ML study and prototyping.",success
https://github.com/lavague-ai/LaVague,LaVague,"LaVague is an open-source Large Action Model framework for building AI web agents that turn natural-language objectives into executable browser actions. It provides a World Model + Action Engine architecture and can generate/execute automation code via drivers like Selenium, Playwright, or a Chrome extension, with additional tooling such as LaVague QA for turning Gherkin specs into tests.",6300,ai-agents|web-automation|llm|rag|selenium|playwright|python,8,"This repository’s primary use case is building LLM-powered web agents that plan and execute multi-step browser workflows by converting objectives into instructions and then into automation code (e.g., Selenium/Playwright). It is strongly relevant to ML workflows because it operationalizes LLMs (and often RAG-style retrieval over web content) for agentic automation, and includes evaluation/testing utilities (e.g., test runner/benchmarking and QA tooling). It’s not a core ML training framework, but it is highly applicable for ML engineers building agents, automation, and applied LLM systems, with meaningful community adoption (6.3k stars).",success
https://github.com/ufoym/deepo,deepo,"Deepo is a framework for assembling and generating Docker images (via a Dockerfile generator) for deep learning research environments, with modular components and automatic dependency/version compatibility handling (e.g., CUDA/cuDNN/Python/PyTorch/TensorFlow). The repository also provides pre-built images for common ML setups, but it was archived on January 29, 2023 and is no longer maintained.",6300,deep learning|docker|ml-environment|devops|gpu-computing|cuda|dockerfile-generator|reproducible-research,8,"This repository’s primary purpose is to help users quickly set up reproducible deep learning environments by generating best-practice Dockerfiles from modular “lego-like” components and providing ready-to-use images. It directly supports ML workflows because it targets common DL stacks (CUDA/cuDNN plus major frameworks) and reduces environment setup friction for training and experimentation. Community adoption appears strong (6.3k GitHub stars), but the repo is archived (read-only since Jan 29, 2023) and explicitly not maintained, which reduces practical value for modern stacks. Given its direct ML applicability but maintenance status, a score of 8/10 is appropriate.",success
https://github.com/thtrieu/darkflow,darkflow,"Darkflow is a TensorFlow-based implementation/port of the Darknet YOLO object detection models, enabling users to load pre-trained Darknet weights, run real-time inference, and retrain/fine-tune YOLO using TensorFlow workflows. It also supports exporting models (e.g., constant graph definitions) for deployment scenarios such as mobile.",6200,machine learning|computer vision|object detection|YOLO|TensorFlow|Darknet|model deployment,8,"This repository focuses on real-time object detection/classification by translating Darknet YOLO models to TensorFlow and providing tooling to load weights, run inference, and retrain/fine-tune models, which is directly applicable to common ML/computer-vision workflows. It is strongly ML-centric and useful for practitioners working with YOLO-style detectors, including model conversion and deployment-oriented export capabilities. Community adoption appears solid (thousands of stars/forks), but it targets older TensorFlow-era workflows (e.g., TensorFlow 1.x noted in the README), which reduces modern integration value compared to current mainstream CV stacks—hence an 8 rather than 9–10.",success
https://github.com/tyiannak/pyAudioAnalysis,pyAudioAnalysis,"pyAudioAnalysis is a Python library for audio analysis tasks including audio feature extraction (e.g., MFCCs, spectrograms, chromagrams), audio classification/regression, and both supervised and unsupervised segmentation (e.g., speaker diarization). It provides both a Python API and command-line tooling for common audio ML workflows.",6200,audio-analysis|audio-signal-processing|machine-learning|feature-extraction|audio-classification|audio-segmentation|speaker-diarization|python,8,"This repository is primarily an audio ML/data-science toolkit: it focuses on extracting engineered audio features and training/evaluating models for tasks like classification, regression (e.g., emotion recognition), and segmentation (including diarization). It is directly applicable to ML workflows that involve audio datasets, offering ready-to-use utilities, examples, and CLI wrappers that can accelerate prototyping and experimentation. Community adoption appears strong for a niche audio library (thousands of GitHub stars), but it is not a general-purpose, industry-standard core framework on the scale of PyTorch/TensorFlow, which keeps it below 9–10.",success
https://github.com/apache/hudi,apache/hudi,"Apache Hudi is an open data lakehouse platform and table format that enables upserts/deletes, incremental processing, indexing, and transactional writes on data stored in open formats on cloud/object storage. It integrates with engines like Spark and Flink to ingest, manage, and query large-scale datasets efficiently.",6100,data engineering|data lakehouse|data lake|table format|apache spark|apache flink|incremental processing|upserts,8,"This repository implements Apache Hudi, a production-grade data lakehouse table format/platform focused on managing large analytical datasets with capabilities like upserts/deletes, indexing, schema evolution, and incremental queries. While it is not an ML framework, it is highly applicable to ML/data workflows because it improves dataset reliability, freshness, and efficient incremental feature/label updates used in pipelines and feature engineering. It is widely adopted in data engineering ecosystems (notably Spark/Flink), making it valuable infrastructure for ML platforms and MLOps, hence an 8/10 rather than a 10/10.",success
https://github.com/microsoft/TaskWeaver,TaskWeaver,"TaskWeaver is a code-first LLM agent framework focused on planning and executing data analytics tasks by translating user requests into executable code and orchestrating extensible plugins. It preserves both chat and code-execution state (including in-memory data such as pandas DataFrames) to support iterative, stateful analytics workflows.",6100,llm-agents|data-analytics|python|pandas|agent-framework|plugins|code-generation|observability,8,"TaskWeaver is primarily built to enable LLM-powered agents to perform data analytics by generating and executing Python code in a stateful, notebook-like manner while coordinating user-defined plugins, which directly targets common data/ML engineering workflows. It is highly applicable for data scientists who want an agent that can manipulate structured data (e.g., pandas DataFrames), run analyses iteratively, and integrate domain-specific logic via plugins and examples. It is not itself a model-training framework, but it is a strong “agentic analytics” layer that can sit on top of ML/data tooling, making it very valuable for applied DS/ML automation and experimentation.",success
https://github.com/szad670401/HyperLPR,HyperLPR,"HyperLPR (HyperLPR3) is a high-performance Chinese license plate recognition (LPR) framework providing end-to-end plate detection and recognition with cross-platform support (Python, C/C++, Android, iOS, Linux/Mac) and optional WebAPI service deployment.",6100,computer vision|license plate recognition|OCR|deep learning|ONNX Runtime|OpenCV|FastAPI,8,"This repository implements an end-to-end license plate recognition system (detection + recognition) and provides practical interfaces such as a Python package (installable via pip), CLI samples, and a REST/WebAPI service, making it directly usable in ML-powered CV applications. It is strongly related to ML workflows because it wraps trained models and runtime inference tooling (e.g., ONNX Runtime/OpenCV) for production-style deployment across platforms, which is valuable for applied ML engineers. However, it appears to provide limited training data and only partial/older training code due to data privacy constraints, so it is more focused on inference/deployment than on model development or dataset curation. Its substantial community adoption (thousands of GitHub stars/forks) further supports a high score, but not a perfect 10 because it is a specialized application library rather than a general-purpose ML framework.",success
https://github.com/tiny-dnn/tiny-dnn,tiny-dnn,"tiny-dnn is a header-only, dependency-free (core) deep learning framework in C++14 aimed at running and embedding neural networks on limited compute environments such as embedded/IoT devices. It provides common layers, activation functions, loss functions, and optimizers, with optional acceleration via CPU vectorization/parallelism and optional OpenCL-related backends.",6000,deep learning|machine learning|C++|neural networks|embedded systems|inference|model training,8,"This repository is a C++14 deep learning framework (header-only) that lets users build, train, and run neural networks, with a focus on portability and suitability for constrained/embedded environments. It is directly applicable to ML workflows for engineers who need lightweight C++ deployment/inference (and potentially training) without heavyweight dependencies, and it has meaningful community adoption (notably thousands of GitHub stars). The score is not higher primarily because the project’s README indicates it may be abandoned and its last prominently listed “What’s New” entries are from 2016, which can limit practical integration in modern ML stacks despite its educational and embedded-focused value.",success
https://github.com/aiwaves-cn/agents,agents,"Agents is an open-source framework for building data-centric, self-evolving autonomous language agents. It supports agent learning and evaluation via a symbolic-learning approach that treats agent pipelines like computational graphs and optimizes prompts/tools using language-based loss and backpropagation-style updates.",5900,llm|autonomous agents|agent learning|prompt optimization|multi-agent systems|NLP|evaluation,8,"This repository provides a framework for training and evaluating autonomous language agents, including a symbolic-learning workflow that introduces language loss, backpropagation-like “language gradients,” and prompt/tool updates. It is directly applicable to ML/NLP workflows for building and iterating on LLM-based agent systems, and includes learning/evaluation support (Agents 2.0). It appears to have meaningful community adoption (about 5.9k GitHub stars) and solid educational value for understanding agent optimization concepts, but it is more specialized than core, broadly used ML foundations (e.g., PyTorch), so it does not merit a 10.",success
https://github.com/chainer/chainer,chainer,"Chainer is a Python-based deep learning framework for building and training neural networks, featuring define-by-run (dynamic) computational graphs and automatic differentiation. It supports GPU acceleration via CUDA/cuDNN through CuPy and includes high-level, object-oriented APIs plus examples and tooling.",5900,deep learning|machine learning|neural networks|python|autograd|gpu|cuda,8,"This repository implements Chainer, a full deep learning framework (dynamic computational graphs / define-by-run) used to build, train, and run neural network models, with GPU acceleration via CUDA/cuDNN through CuPy. It is directly applicable to ML workflows (model definition, training loops, autodiff, and deployment/inference), and includes substantial ecosystem components (examples, docs, related submodules like ChainerMN/ChainerX). The score is 8 (highly relevant) because it is clearly an ML framework, but its practical impact today is reduced by being in maintenance-only mode and having its latest release dated June 29, 2022 rather than being a current mainstream default choice.",success
https://github.com/gorgonia/gorgonia,gorgonia,"Gorgonia is a Go library for building and running machine learning models using computation graphs, with automatic differentiation and support for executing numerical operations efficiently (including GPU/CUDA-related components). It provides primitives and examples for constructing neural networks and other differentiable programs in Go.",5900,machine learning|deep learning|go|autodiff|computational graph|neural networks|cuda,8,"This repository is an ML framework for Go, centered around defining computation graphs and performing automatic differentiation to train models, which makes it directly applicable to core ML workflows (model definition, forward/backward passes, optimization). It is less dominant than mainstream Python ecosystems (e.g., PyTorch/TensorFlow) and has comparatively smaller community adoption, but it remains a substantial, purpose-built ML tool in the Go ecosystem with clear educational and practical value for implementing ML in Go. The presence of graph-based primitives, autodiff, and CUDA-related code indicates a focus on efficient model training/inference rather than peripheral utilities, justifying a high (but not top-tier) score.",success
https://github.com/cocoindex-io/cocoindex,cocoindex,CocoIndex is an ultra-performant data transformation framework for AI with a Rust core engine and a Python developer interface. It supports incremental processing to keep sources and targets in sync and provides built-in data lineage/observability for transformation steps.,5800,data-engineering|data-pipelines|mlops|llm|rag|vector-database|rust|python,8,"This repository provides a framework to define AI-oriented dataflows (e.g., building vector indexes, knowledge graphs, and other transformation pipelines) with incremental recomputation and lineage/observability, making it directly applicable to production ML/LLM data preparation. It is strongly related to ML/data workflows as a reusable pipeline/indexing layer for RAG and context engineering, rather than a model-training framework. The score is high because it targets ML/AI data transformation and indexing needs and includes performance- and production-focused features (incremental processing, Rust core), but it’s not a foundational ML library with ubiquitous adoption on the level of major frameworks.",success
https://github.com/tensortrade-org/tensortrade,tensortrade,"TensorTrade is an open-source Python reinforcement-learning framework for building, training, evaluating, and deploying algorithmic trading agents. It provides a modular, extensible trading environment and integrates with common ML/data tooling (e.g., NumPy/Pandas, Gym-style environments, and deep learning libraries) to support experimentation and robust trading pipeline development.",5800,reinforcement learning|algorithmic trading|quantitative finance|python|gym-environment|backtesting|tensorflow,8,"This repository’s primary purpose is to support reinforcement learning for algorithmic trading by offering composable components (environments, action/reward schemes, data/feature pipelines, execution simulation) and examples for training/evaluating agents. It is directly applicable to ML/data workflows for time-series/market data experimentation, agent training, and reproducible backtesting-like evaluation loops. While it is highly relevant for applied RL research/education in finance, its community adoption appears moderate rather than ecosystem-defining compared to core ML libraries, and production use is explicitly cautioned as beta—so it scores below 9–10.",success
https://github.com/owid/covid-19-data,owid/covid-19-data,"Repository for Our World in Data’s COVID-19 dataset and the pipeline used to compile it, including country-level metrics (cases, deaths, hospitalizations, testing, etc.) and supporting scripts. Note: the repository’s GitHub-hosted datasets are no longer updated since 19 August 2024; OWID now points users to their data catalog and documentation for current COVID data access.",5700,public-health|covid-19|epidemiology|open-data|data-engineering|data-pipelines|python,8,"This repository primarily provides a widely used, cleaned, cross-country COVID-19 time-series dataset plus the scripts/pipeline used to produce it, making it directly useful for analytics, forecasting, and modeling workflows. It’s not an ML framework, but it is a high-value ML/data input because it standardizes and aggregates many signals into analysis-ready files and has broad adoption across the data science community. The score is reduced slightly because the GitHub dataset is explicitly no longer updated after 19 August 2024, so ongoing ML projects should use OWID’s catalog/API for the latest data instead.",success
https://github.com/google/seq2seq,seq2seq,"A general-purpose encoder–decoder (seq2seq) framework built on TensorFlow for building models such as machine translation, text summarization, conversational modeling, and image captioning. The repository is archived (read-only) and served as the codebase used in Google's ""Massive Exploration of Neural Machine Translation Architectures"" work.",5600,machine learning|deep learning|natural language processing|sequence-to-sequence|machine translation|tensorflow|encoder-decoder,8,"This repository provides a TensorFlow-based seq2seq encoder-decoder framework intended for training and experimenting with common ML sequence modeling tasks like machine translation, summarization, dialogue, and captioning. It is directly applicable to ML workflows for model development/training and has meaningful community adoption (thousands of stars), plus strong educational value as a reference implementation linked to a notable NMT architecture exploration paper. However, because it was archived on Dec 29, 2022 and is tied to older TensorFlow-era patterns, its practical usefulness for modern production work is somewhat reduced versus actively maintained contemporary frameworks.",success
https://github.com/idealo/imagededup,imagededup,"imagededup is a Python package for finding exact and near-duplicate images in a collection. It supports multiple perceptual hashing methods and a CNN-based approach, and includes utilities for generating image encodings, evaluating deduplication quality with ground truth, and visualizing duplicates.",5600,computer vision|image deduplication|perceptual hashing|deep learning|python|data quality|similarity search,8,"This repository provides practical tooling to detect exact and near-duplicate images using perceptual hashing (AHash/PHash/DHash/WHash) and convolutional neural networks, plus evaluation and plotting utilities. Duplicate detection is a common data-cleaning and dataset-curation step in ML workflows (e.g., removing leakage/duplicates in training data and maintaining image catalogs), making it directly applicable to data science work. It is reasonably well-adopted (thousands of GitHub stars) and offers educational value by exposing multiple approaches (hashing vs. CNN embeddings). It is not a general-purpose ML framework, but it is a strong, focused utility for ML/data quality tasks, justifying an 8/10.",success
https://github.com/kyegomez/swarms,swarms,"Swarms is an enterprise-focused, production-ready multi-agent orchestration framework for building and running LLM-powered agents and agent swarms (sequential, concurrent, hierarchical, graph-based, and MoA-style workflows). It provides agent abstractions, workflow orchestration utilities, and integrations/protocol support aimed at deploying multi-agent systems at scale.",5600,multi-agent-systems|llm|agent-orchestration|python|ai-agents|workflow-orchestration|mcp,8,"This repository is primarily an LLM agent and multi-agent orchestration framework (agents, swarm architectures like sequential/concurrent/graph workflows, and a router to run different swarm types), making it directly applicable to building ML/AI applications that rely on foundation models. It is strongly relevant to ML engineering workflows (agentic pipelines, tool-using LLM apps, evaluation-style multi-step workflows), though it is not a core model-training or data-processing library like PyTorch/Spark. The repo shows significant community adoption (about 5.6k GitHub stars) and includes extensive examples and integrations/protocols (e.g., MCP), supporting practical integration into real ML/AI systems.",success
https://github.com/airweave-ai/airweave,airweave,"Airweave is an open-source context retrieval layer for AI agents that connects to apps, productivity tools, databases, and document stores, turning their contents into searchable knowledge bases. It exposes search via a REST API or MCP and handles auth, extraction, embedding, and serving for agent-facing retrieval.",5500,retrieval-augmented generation|agent tooling|semantic search|data connectors|MCP|vector search|API,8,"This repository provides an end-to-end context retrieval system that ingests data from many third-party sources and serves it through an agent-friendly interface (REST API and MCP), effectively powering RAG-style applications. It is directly applicable to ML/LLM workflows because it focuses on data extraction, embedding-backed indexing, and semantic/hybrid search for downstream agent/query use. While it is not a model training framework, it is a core enabling component for production LLM applications and data-to-agent retrieval pipelines, justifying a high (but not maximal) score.",success
https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models,awesome-pretrained-chinese-nlp-models,"A curated “awesome” list of high-quality publicly available Chinese pretrained NLP models, covering classic PLMs (e.g., BERT/RoBERTa variants) as well as modern LLMs and multimodal Chinese models, with links to downloads, papers, and related resources.",5500,natural language processing|chinese nlp|pretrained-models|large-language-models|multimodal|awesome-list|huggingface,8,"This repository’s primary purpose is to catalog Chinese pretrained language models (including LLMs and multimodal models) and point users to model downloads, papers, and project pages, making it directly useful for model selection and benchmarking in ML/NLP workflows. It is not a training framework or dataset itself, but it significantly reduces discovery time and provides structured pointers to widely used resources (e.g., Hugging Face links and model tables). Community adoption appears solid for an “awesome list” style repo (thousands of stars), which boosts its practical and educational value. I rated it an 8 because it is highly relevant to ML/NLP practitioners, but it is primarily a curated index rather than a core tool/library used in production pipelines.",success
https://github.com/tensorflow/rust,rust,"Idiomatic Rust language bindings for TensorFlow via the TensorFlow C API, including tooling to download prebuilt TensorFlow libraries or compile TensorFlow from source when needed. Provides Rust crates and examples to build and run TensorFlow graphs (with optional GPU support via features).",5500,machine learning|tensorflow|rust|ffi|bindings|gpu|deep learning,8,"This repository provides Rust bindings to TensorFlow, enabling ML engineers and developers to load/build graphs and run TensorFlow computation from Rust. It is highly relevant to ML workflows because it directly interfaces with a major ML framework (TensorFlow) and supports common needs like using prebuilt C libraries or compiling TensorFlow, plus optional GPU enablement. While it is not a training framework in itself (it wraps TensorFlow rather than replacing it), it is directly applicable for integrating TensorFlow inference/training capabilities into Rust services and systems, justifying a high but not maximal score.",success
https://github.com/wb14123/seq2seq-couplet,seq2seq-couplet,"A TensorFlow-based seq2seq (sequence-to-sequence) project for generating Chinese couplets (对对联). It includes training code, BLEU evaluation, and a small server/Docker setup to run a trained model as a web service.",5500,machine-learning|deep-learning|nlp|seq2seq|tensorflow|text-generation|chinese-language,8,"This repository implements a sequence-to-sequence neural model (in TensorFlow) to generate Chinese couplets, including training scripts and BLEU-based evaluation, which makes it directly relevant to NLP model development workflows. It’s useful for ML practitioners as a reference implementation for seq2seq text generation and for learning how to train/serve such models (including a simple server and Dockerfiles). While it has solid educational and practical value, it is not a widely adopted general-purpose ML framework/tool, so it scores below top-tier libraries.",success
https://github.com/TaskingAI/TaskingAI,TaskingAI,"TaskingAI is an open-source BaaS platform for developing and deploying LLM-based agents, providing a unified API over many model providers plus a web console to manage tools, RAG systems, assistants, and conversation history. It supports self-hosting (e.g., via Docker), modular integrations/plugins, and scalable production deployment workflows.",5400,LLM|AI agents|RAG|MLOps|backend-as-a-service|FastAPI|OpenAI-compatible API|plugins-tools,8,"This repository provides an end-to-end platform for building and operating LLM-powered agents, including unified model access across providers, tool/plugin integration, and built-in Retrieval-Augmented Generation (RAG) capabilities, exposed via APIs and a management UI. It is directly applicable to ML/LLM engineering workflows (agent orchestration, tool use, RAG configuration, deployment, and multi-tenant operation) and can be used as infrastructure for production AI applications rather than as a pure research/training library. I scored it an 8 because it is highly relevant to practical ML/LLM application development and deployment, but it is not a core model-training framework nor a ubiquitous industry-standard like PyTorch/TensorFlow.",success
https://github.com/flashlight/flashlight,flashlight,"Flashlight is a fast, flexible standalone machine learning library written in C++ with a core tensor/autograd/neural-network stack and domain packages/apps for speech, vision, and text (e.g., ASR, image classification, object detection, and language modeling). It emphasizes performance and modifiability, and uses ArrayFire by default for tensor computation/backends.",5400,machine learning|deep learning|C++|autograd|tensor library|speech recognition|computer vision|NLP,8,"This repository provides a full C++ machine learning framework (tensors, neural network modules, automatic differentiation) along with end-to-end application code for multiple ML domains, including automatic speech recognition, vision tasks, and language modeling. It is directly applicable to ML engineering workflows—especially for researchers/engineers who need high-performance C++ training/inference and want to modify internal components (kernels, tensor backends, etc.). Community adoption appears solid (thousands of GitHub stars) but it is less universally adopted than the most common Python-first ecosystems, which is why it scores below 9–10. Overall, it is a highly relevant ML repo with strong educational and practical value for performance-focused ML systems work.",success
https://github.com/Kodezi/Chronos,Chronos,"Kodezi Chronos is a debugging-first language model for repository-scale code understanding and automated bug fixing. This repository primarily contains the research paper, benchmarks, evaluation artifacts, and supporting documentation; the model itself is proprietary and accessible via Kodezi OS.",5300,large language models|code intelligence|automated debugging|program repair|retrieval-augmented generation|software engineering benchmarks|MLOps,8,"This repository documents a debugging-first LLM system (Chronos) and includes research materials such as benchmarks, evaluation results, and reference implementations related to automated software bug fixing. It is highly relevant to ML/data workflows for practitioners working on LLM evaluation, agentic coding, retrieval systems, and software-engineering benchmarks (e.g., SWE-bench Lite), but it is not a fully open model training/inference repo since the model access is proprietary via Kodezi OS. The strong benchmarking/evaluation focus and substantial community interest (high GitHub stars) make it valuable for ML research and experimentation, even if direct reuse for training or deployment is limited.",success
https://github.com/modelscope/FunClip,FunClip,"FunClip is an open-source, locally deployable AI video clipping tool that performs speech recognition on videos (via FunASR/Paraformer models), lets users select text segments or speakers, and exports the corresponding clips and SRT subtitles. It also supports LLM-assisted “smart clipping” (e.g., Qwen/GPT-series) through a Gradio-based UI for interactive clipping workflows.",5300,audio speech recognition|video clipping|ASR|speaker diarization|LLM|gradio|python|multimodal,8,"This repository provides an end-to-end application for ML-powered video clipping using automatic speech recognition (FunASR/Paraformer) plus optional speaker recognition/diarization and LLM-based extraction of clip timestamps. It is directly applicable to ML/data workflows involving media analytics (transcription, segmentation, subtitle generation, speaker-based filtering) and can be integrated into downstream datasets/annotation or content-processing pipelines. Community adoption appears strong (5.3k stars) and the project has practical educational value for combining ASR outputs, timestamps, and UI-driven postprocessing into a usable tool. I rated it 8/10 because it is highly relevant to applied ML (especially speech/video), but it is more of an application/workflow tool than a general-purpose ML framework with broad industry-standard adoption.",success
https://github.com/AgentOps-AI/agentops,agentops,"AgentOps is a Python SDK and open-source platform for observability of AI agents, providing session replays, debugging/analytics, and LLM cost tracking. It integrates with popular LLM providers and agent frameworks (e.g., OpenAI Agents SDK, CrewAI, LangChain, AG2/AutoGen) and supports self-hosting of the dashboard/backend.",5200,MLOps|LLM observability|agent monitoring|LLM cost tracking|AI agents|Python SDK|LangChain|OpenAI Agents SDK,8,"This repository provides observability tooling for AI agents, including session replays, step-by-step execution analytics, debugging instrumentation via decorators/spans, and LLM cost management. It is highly relevant to ML/LLM engineering workflows because it helps teams monitor, evaluate, and operate agentic systems in production and integrates directly with major agent frameworks and LLM ecosystems. It does not primarily provide model training or datasets, but it is strong MLOps/LLMOps infrastructure with practical, direct applicability for ML engineers deploying agent-based applications, which supports an 8/10 score.",success
https://github.com/ashnkumar/sketch-code,sketch-code,"SketchCode is a deep learning project that converts hand-drawn website wireframes/mockups into working HTML code. It uses a Keras/TensorFlow image-captioning-style architecture, with scripts for downloading data/pretrained weights, running single/batch conversion, training, and BLEU-based evaluation.",5200,deep learning|computer vision|image captioning|keras|tensorflow|html generation|code generation|wireframe-to-code,8,"This repository implements an end-to-end deep learning pipeline to generate HTML from images of hand-drawn web mockups, which directly fits ML workflows (model training, inference scripts, and evaluation). It is strongly ML-focused (Keras/TensorFlow, image captioning approach) and provides pretrained weights and data-download scripts, making it directly usable for experimentation and learning. While it is a proof-of-concept and somewhat narrow in scope (limited generalization and focused on a specific task/domain), it still offers high educational and practical value for applied computer vision + sequence generation tasks, so it merits a high (but not top-tier) score.",success
https://github.com/dataease/SQLBot,SQLBot,"SQLBot is an open-source conversational analytics (ChatBI) system that uses large language models plus RAG to translate natural-language questions into SQL and return data insights and visualizations. It is designed to be easy to deploy and integrate (e.g., web embedding / popup embedding / MCP calling) while supporting workspace isolation and fine-grained data permissions.",5200,text-to-sql|llm|rag|conversational-analytics|chatbi|data-visualization|business-intelligence|docker,8,"This repository provides a production-oriented system for conversational data analysis: users ask questions in natural language and the system generates SQL using LLMs enhanced with retrieval-augmented generation (RAG), then presents results (including charts). It is highly relevant to data workflows because it directly connects LLM/NLP capabilities to querying structured databases, with deployment and integration options that fit real analytics environments. While it is not a general-purpose ML training framework, it is a strong applied LLM+data product (Text-to-SQL, analytics automation) with notable adoption (5.2k stars), justifying a high but not maximum score.",success
https://github.com/sql-machine-learning/sqlflow,sqlflow,"SQLFlow is a compiler that translates an extended SQL dialect (with ML/AI clauses) into an Argo Workflow that runs distributed on Kubernetes, enabling model training, prediction, evaluation, explanation, custom jobs, and mathematical programming directly from SQL. It supports multiple SQL engines (e.g., MySQL/MariaDB, TiDB, Hive, MaxCompute) and ML toolkits including TensorFlow/Keras and XGBoost.",5200,machine learning|MLOps|SQL|Kubernetes|Argo Workflows|workflow orchestration|compiler|TensorFlow,8,"This repository provides an end-to-end system that lets users express ML tasks (train/predict/evaluate/explain) in an extended SQL syntax, compiling them into Kubernetes-native Argo workflows for scalable execution. It is directly applicable to ML/data workflows by bridging databases and model training/inference pipelines, integrating with common SQL engines and ML frameworks like TensorFlow/Keras and XGBoost. Its focus is strongly ML/data oriented and operationally practical for teams that want SQL-driven ML pipelines, though it is not a general-purpose ML library with the broad industry ubiquity of major frameworks, so it lands below a 9–10.",success
https://github.com/volcano-sh/volcano,volcano,"Volcano is a cloud-native batch system for Kubernetes (a CNCF project) that provides a high-performance scheduler plus job/queue management for batch and HPC workloads. It enables running AI/ML and big-data frameworks on Kubernetes with features like gang scheduling, priority/preemption, and advanced resource/queue controls.",5200,kubernetes|batch-scheduling|hpc|cloud-native|ml-infrastructure|gpu-scheduling|big-data|golang,8,"This repository implements Volcano, a Kubernetes-native batch/HPC scheduler and job management system aimed at reliably running large-scale compute workloads (including AI training and big-data processing) with capabilities like queue management and advanced scheduling policies. It is not an ML library itself, but it is directly useful in ML/data workflows as infrastructure for orchestrating and scheduling distributed training and data processing jobs on Kubernetes clusters. Given its explicit focus on AI/big-data/HPC use cases, broad framework integrations, and strong community adoption (thousands of GitHub stars), it merits a high infrastructure-relevance score rather than a perfect 10 reserved for core ML frameworks.",success
https://github.com/google/tf-quant-finance,tf-quant-finance,"TF Quant Finance is a high-performance quantitative finance library built on TensorFlow, providing differentiable and accelerator-friendly implementations of foundational math (e.g., random/quasi-random generation, optimization), mid-level numerical methods (e.g., SDE/PDE tools), and pricing/calibration utilities for common models. The repository is archived and no longer maintained, with guidance to fork if continued development is needed.",5100,quantitative finance|TensorFlow|automatic differentiation|Monte Carlo simulation|derivatives pricing|stochastic processes|numerical methods,8,"This repository provides TensorFlow-based, differentiable building blocks and end-to-end examples for quantitative finance (simulation, numerical solvers, and pricing/calibration), making it directly useful for ML engineers and data scientists working on differentiable finance, risk, or model calibration workflows. It integrates tightly with the TensorFlow ecosystem (and leverages autodiff and hardware acceleration), which increases its practical applicability for gradient-based methods and scalable computation. However, the repo is archived and no longer maintained, which reduces its integration reliability and community momentum compared with actively maintained ML/data libraries, so it falls short of a 9–10.",success
https://github.com/humphd/have-fun-with-machine-learning,have-fun-with-machine-learning,"A hands-on beginner guide that walks through building an image-classification project (dolphins vs. seahorses) using convolutional neural networks, including dataset creation, training, evaluation, and improving accuracy via fine-tuning pretrained models. The guide focuses on practical use of Caffe and NVIDIA DIGITS rather than ML theory.",5100,machine learning|deep learning|computer vision|image classification|convolutional neural networks|caffe|nvidia-digits|tutorial,8,"This repository is primarily an educational, hands-on machine learning walkthrough for training and deploying an image classifier using a CNN, including steps like creating an image dataset, training from scratch, testing on unseen images, and fine-tuning pretrained networks (e.g., AlexNet/GoogLeNet). It is directly relevant to ML workflows (dataset preparation, model training/evaluation, transfer learning), but it is not a general-purpose ML library/framework itself and relies on older tooling (Caffe/DIGITS). Community adoption is decent as a tutorial/reference (about 5.1k GitHub stars), but its practical integration into modern stacks may be limited compared to current PyTorch/TensorFlow-centric resources. ([github.com](https://github.com/humphd/have-fun-with-machine-learning))",success
https://github.com/katanaml/sparrow,sparrow,"Sparrow is a Python-based system for structured data extraction from documents (images/PDFs) and for “instruction calling” using ML/LLMs including vision LLMs. It provides multiple pipelines/backends (e.g., MLX on Apple Silicon, Ollama, vLLM, Docker, Hugging Face), schema-validated JSON outputs, and includes a web UI plus API/CLI for integrating document processing into applications.",5100,document-ai|data-extraction|vision-llm|llm|ocr|python|structured-data|mlops,8,"This repository’s primary use case is extracting structured JSON data from unstructured documents (PDFs/images) using vision-capable LLM pipelines, exposed via API/CLI and supported by a web UI. That makes it directly applicable to common ML/data workflows like document understanding, invoice/receipt parsing, table extraction, and downstream analytics/ETL into databases. It also supports multiple inference backends (e.g., MLX, Ollama, vLLM) and schema-based validation, which increases integration potential in real-world ML systems. It scores an 8 (highly relevant) because it is a practical ML document-processing tool with notable adoption (thousands of GitHub stars), though it is not a general-purpose core ML framework.",success
https://github.com/treeverse/lakeFS,lakeFS,"lakeFS is an open-source data version control system (“Git for data”) that turns object storage into a Git-like repository with branching, commits, merges, and rollbacks. It enables reproducible, atomic, versioned operations for data lakes and integrates with common data frameworks while supporting S3-compatible storage (including AWS S3, Azure Blob Storage, and Google Cloud Storage).",5100,data version control|data engineering|data lake|object storage|MLOps|ETL|Go,8,"This repository provides a Git-like version control layer for data stored in object storage, enabling branching, committing, merging, and rollback workflows for data lakes. It is highly relevant to ML/data workflows because reproducibility, safe experimentation (isolated branches), and auditability are common pain points in model training and data pipeline development. While it is not an ML framework itself, it is a strong enabling infrastructure tool for data science teams and MLOps/data platform engineering, with broad integration potential across modern analytics and processing engines.",success
https://github.com/Nyandwi/machine_learning_complete,machine_learning_complete,"An educational “Complete Machine Learning Package” containing 30+ (notably 35) Jupyter notebooks covering Python for ML, NumPy/Pandas, data visualization, data preparation, classical ML with scikit-learn, deep learning with TensorFlow/Keras, computer vision, NLP, and an MLOps guide.",5000,machine learning|data science|education|jupyter notebooks|python|scikit-learn|tensorflow|mlops,8,"This repository is primarily an educational collection of curated notebooks that teach practical ML/data concepts end-to-end (Python basics, data manipulation, visualization, preprocessing, classical ML, deep learning, CV, NLP, and MLOps). It’s directly applicable for learning, onboarding, and as a reference for common workflows and tooling, though it is not a reusable production library or framework. Community adoption appears strong for an educational repo (about 5k stars and 832 forks at the time of review). Given its breadth and hands-on learning value but limited integration as a drop-in tool, an 8/10 best fits.",success
https://github.com/hadley/r4ds,r4ds,"Source repository for the book ""R for Data Science"", containing the Quarto (.qmd) manuscripts, code, data, and assets used to build the website/book about doing data science with R and the tidyverse (data import, tidying, transformation, visualization, and communication).",5000,r|data-science|education|tidyverse|data-wrangling|data-visualization|quarto,8,"This repository is the full source for ""R for Data Science"", a widely used practical guide for working with data in R (importing, cleaning/tidying, transforming, visualizing, and communicating results). While it is not an ML framework and doesn’t provide model-training infrastructure, it is directly applicable to most ML/data workflows because it teaches core data preparation and exploratory analysis skills that precede modeling. It has strong educational value and broad community adoption as a standard reference for data work in R, which justifies a high (but not maximal) score.",success
https://github.com/javascriptdata/danfojs,danfojs,"Danfo.js is a Pandas-inspired JavaScript library for data analysis, providing Series/DataFrame data structures for manipulating structured data with built-in IO (CSV/JSON/Excel), indexing, groupby, joins, plotting, and preprocessing utilities. It integrates with TensorFlow.js by supporting conversion to tensors for ML workflows in Node.js and the browser.",5000,data analysis|dataframes|javascript|typescript|tensorflow.js|data preprocessing|data visualization|node.js,8,"This repository provides a high-level, Pandas-like DataFrame/Series toolkit for JavaScript, aimed at data manipulation, preprocessing, IO, and analysis tasks. It is directly applicable to ML/data workflows because it supports common data-wrangling operations and integrates with TensorFlow.js tensors, enabling smoother transitions from tabular data preparation to model training/inference in JS. While it is not itself an ML training framework, its tight coupling with TensorFlow.js and breadth of data-processing features make it highly valuable for JS-based data science. Its visible community adoption (about 5k GitHub stars) supports an 8/10 rating rather than a lower, purely “utility” score.",success
https://github.com/man-group/dtale,dtale,"D-Tale is a web-based interactive explorer for pandas data structures, combining a Flask backend with a React frontend to view and analyze DataFrames (and related pandas objects). It integrates with Python/IPython and Jupyter to support exploratory data analysis features like filtering, summaries, correlations, charts, and more.",5000,exploratory-data-analysis|pandas|data-visualization|python|flask|react|jupyter,8,"This repository provides an interactive, browser-based UI for exploring and analyzing pandas data structures, aimed primarily at accelerating exploratory data analysis (EDA) workflows. It is directly useful to data scientists because it integrates with Python/IPython and notebooks and offers common EDA operations (e.g., summaries, correlations, charts, missing/outlier analysis) on tabular data. While it is not a model-training framework, it is highly applicable in ML/data workflows as a front-end for inspecting datasets and features before modeling, and it has meaningful adoption (thousands of GitHub stars).",success
https://github.com/transcranial/keras-js,keras-js,"Keras.js is a JavaScript library for running pre-trained Keras neural network models in the browser, with GPU acceleration via WebGL (and CPU-only execution in Node.js). The project includes demos and documentation but is no longer actively maintained (the author recommends TensorFlow.js instead).",5000,machine-learning|deep-learning|keras|tensorflow|javascript|webgl|browser-inference,8,"This repository provides an ML inference runtime: it loads and executes Keras models client-side in the browser with WebGL acceleration, and can also run in Node.js (CPU-only). That makes it directly applicable to ML engineering workflows focused on deploying trained models to the web (especially for interactive demos and privacy-preserving on-device inference). However, it is explicitly no longer active/updated and targets older Keras compatibility, which reduces its practical value today despite strong historical adoption (about 5k GitHub stars).",success
https://github.com/K-Dense-AI/claude-scientific-skills,claude-scientific-skills,"An MIT-licensed collection of 139 ready-to-use “scientific skills” that extend Claude/Claude Code with documented, multi-step research workflows and integrations across domains like bioinformatics, cheminformatics, clinical research, and general data analysis/visualization. The repo includes per-skill documentation (e.g., SKILL.md), examples, and integration guides to help Claude use scientific databases and Python tooling effectively.",4900,machine learning|data science|bioinformatics|cheminformatics|scientific-workflows|claude|python|research-automation,8,"This repository provides a large catalog of prebuilt scientific “skills” intended to turn Claude into a more capable research assistant by giving it structured workflows, examples, and integrations with scientific databases and Python packages. It is directly applicable to ML/data workflows because it covers common DS/ML tasks (data analysis, visualization, modeling, and domain-specific pipelines in biology/chemistry/medicine) and references widely used tools (e.g., scikit-learn, PyTorch Lightning, RDKit, Scanpy). While it is not itself a core ML framework, its practical, workflow-oriented skill library and strong adoption signal (4.9k stars) make it highly valuable for ML/data practitioners, justifying an 8/10 rather than a 9–10 reserved for foundational, broadly-standardized toolchains.",success
https://github.com/kelvins/awesome-mlops,awesome-mlops,"A curated “awesome list” of MLOps tools and resources, organized by MLOps lifecycle areas (e.g., AutoML, CI/CD for ML, data validation, feature stores, model serving, experiment tracking, and workflow orchestration). It serves as a directory to discover and compare tools across the end-to-end machine learning production stack.",4900,MLOps|machine learning|DevOps|data engineering|model deployment|ML pipelines|experiment tracking|awesome-list,8,"This repository is an “awesome list” that aggregates and categorizes a wide range of MLOps tools and learning resources rather than providing a single executable library. It is highly relevant to ML/data workflows because it maps directly to common production ML needs (data management/validation, feature stores, drift detection, lifecycle tracking, serving, and orchestration) and is immediately useful for tool selection and ecosystem discovery. Its community adoption appears strong (about 4.9k GitHub stars), increasing its practical value, but it scores below a 9–10 because it is primarily a curated index rather than a core ML framework used directly in training/inference.",success
https://github.com/INTERMT/Awesome-PyTorch-Chinese,Awesome-PyTorch-Chinese,"A curated Chinese-language “awesome list” aggregating PyTorch learning resources, including tutorials/manuals, video courses, recommended papers/books, and practical project links for NLP and computer vision.",4700,pytorch|deep-learning|machine-learning|awesome-list|education|nlp|computer-vision|chinese-resources,8,"This repository is primarily a curated collection of PyTorch learning materials and links (tutorials, videos, NLP/CV practice projects, paper/book recommendations), aimed at helping learners and practitioners find high-quality resources in Chinese. It is highly relevant to ML workflows because PyTorch is a core deep learning framework and the linked materials support model building, training, and applied projects. However, it is not a direct ML tool/library or dataset itself (it’s a resource index), so it scores slightly below “core tooling” repos despite strong educational value and community adoption (thousands of stars).",success
https://github.com/esimov/pigo,pigo,"Pigo is a fast, lightweight face detection library written in pure Go, with additional capabilities for pupil/eye localization and facial landmark point detection. It also includes a bundled CLI tool and supports WebAssembly demos for real-time detection.",4700,computer vision|face detection|facial landmarks|pupil detection|golang|wasm|cli,8,"This repository provides computer-vision detection components (face detection, eye/pupil localization, and facial landmark detection) implemented as a Go library plus a command-line tool, targeting fast inference without OpenCV/C++ bindings. It’s directly useful in ML/data workflows for preprocessing and annotation (e.g., detecting faces/landmarks before downstream analysis), even though it is not a model-training framework. Its strong adoption (about 4.7k GitHub stars) and practical examples (including WASM real-time demos) increase its value for applied ML/vision engineering, but it is less central than full ML frameworks, so it scores below 9–10.",success
https://github.com/xlang-ai/OpenAgents,OpenAgents,"OpenAgents is an open-source, full-stack platform for using and hosting real-world language agents via a chat-based web UI. It provides three primary agents: a Data Agent for Python/SQL-based data analysis, a Plugins Agent integrating 200+ third-party tools, and a Web Agent for autonomous web browsing (via a Chrome extension).",4700,llm-agents|agent-framework|data-analysis|tool-using-agents|web-browsing-automation|full-stack-web-app|python|nlp,8,"This repository is a practical framework and demo platform for LLM-powered agents, including a dedicated Data Agent that can write/execute Python/SQL and perform common data tasks (search/handle/manipulate/visualize). It is directly applicable to ML/data workflows as a starting point for building tool-using agents that operate on datasets, code, and external tools, and it includes an end-to-end product-style UI plus local deployment for experimentation. Community adoption appears strong (thousands of GitHub stars), but it is not a core ML training framework and is more oriented toward agent applications/integration than novel modeling, which is why it scores below 9–10.",success
https://github.com/accord-net/framework,accord-net/framework,"Accord.NET is an archived scientific computing framework for .NET providing machine learning, computer vision/image processing, statistics, and related algorithms with a unified API for training and using models. It includes core math/statistics components plus higher-level ML and imaging modules and was merged with AForge.NET to provide a consolidated toolkit.",4600,machine learning|computer vision|.NET|C#|statistics|scientific computing|image processing,8,"This repository implements a broad, practical set of machine learning, statistics, and computer-vision algorithms for the .NET ecosystem, including APIs for training models (e.g., Learn(x,y)) and applying them (e.g., Transform/Decide). It is directly useful for ML/data workflows in C#/.NET (model training, evaluation, classical CV pipelines), and has significant historical adoption (thousands of stars), but it is archived and read-only (archived Nov 19, 2020), limiting ongoing maintenance and modern ML integration. Because it is a full-featured ML/CV library yet no longer actively developed, it scores high for relevance but below actively maintained core ML frameworks.",success
https://github.com/instillai/deep-learning-roadmap,deep-learning-roadmap,"A curated “roadmap”/kick-starter of deep learning resources, organized into categories such as papers (by model/core/application areas), datasets, courses, books, blogs, tutorials, and frameworks to help learners and researchers find targeted references quickly.",4600,deep learning|machine learning|roadmap|educational resources|papers|datasets|computer vision|natural language processing,8,"This repository is primarily an educational, curated index of deep learning resources (papers, datasets, courses, books, tutorials, and frameworks) rather than an executable ML library or tool. It is highly relevant to ML/data workflows because it helps practitioners and learners discover foundational references and datasets across key subdomains (e.g., CNNs, RNNs, generative models, NLP, speech). The score is 8 (highly relevant) due to strong educational value and practical resource aggregation, but it is not a direct training/inference framework or pipeline tool used in production workflows.",success
https://github.com/kyegomez/tree-of-thoughts,tree-of-thoughts,"A plug-and-play Python implementation of the Tree of Thoughts (ToT) prompting/search approach for deliberate problem solving with large language models, including agents that explore and prune reasoning branches (e.g., DFS) to improve solution quality.",4600,machine learning|llm|prompting|reasoning|agentic ai|python|search algorithms,8,"This repository provides an implementable Tree of Thoughts framework (e.g., TotAgent and a DFS-style ToT agent) to run structured multi-branch reasoning workflows over LLM calls, rather than being a general-purpose application. It is highly relevant to ML/LLM engineering because it directly supports building and experimenting with reasoning/search strategies (DFS, planned BFS/Monte Carlo) that can be integrated into agent pipelines and evaluation workflows. Community adoption appears solid (thousands of GitHub stars), and it has strong educational value for understanding ToT-style reasoning algorithms. It is not a core training framework like PyTorch, but it is a practical, ML-adjacent tool for LLM reasoning experimentation and prototyping.",success
https://github.com/nateraw/stable-diffusion-videos,stable-diffusion-videos,A Python package and pipelines for generating videos with Stable Diffusion by interpolating/morphing through latent space between multiple text prompts (optionally syncing interpolation to audio for music videos). It includes example scripts/notebooks and a simple UI for creating prompt-walk videos.,4600,stable-diffusion|diffusion-models|generative-ai|text-to-image|video-generation|huggingface-diffusers|python,8,"This repository provides tooling (a Stable Diffusion “walk” pipeline) to generate prompt-interpolated image sequences and compile them into videos, including optional beat-synced interpolation using an audio file. It is highly relevant to ML workflows for generative AI practitioners because it wraps model inference and video generation in a reusable package with scripts/notebooks, making it directly applicable for experimentation and content generation. While it is not a training framework or data pipeline, it is a practical ML application built on widely used diffusion tooling (e.g., Hugging Face diffusers) and has strong community adoption (thousands of stars), justifying a high score but not a perfect 10.",success
https://github.com/okfn-brasil/serenata-de-amor,serenata-de-amor,"Operação Serenata de Amor is an open civic-tech project that uses artificial intelligence to analyze Brazilian public officials’ reimbursement expenses and flag suspicious spending. This repository hosts the core components, including Rosie (the AI/analysis pipeline) and Jarbas (the web interface to explore expenses and suspicions).",4600,civic tech|open data|machine learning|data analysis|government spending oversight|python|web application,8,"This repository’s primary purpose is data-centric: it ingests and analyzes public spending datasets and applies AI-driven heuristics/models to detect potentially suspicious reimbursements, then publishes results through a public-facing interface. It is directly applicable to ML/data workflows (data ingestion/cleaning, feature extraction, anomaly/suspicion detection, dataset publishing) and has strong educational value as a real-world end-to-end civic-data project. It’s not a general-purpose ML framework with broad industry adoption, but it is a substantial applied ML/data product with meaningful community traction (thousands of GitHub stars), justifying a high score rather than a perfect 10.",success
https://github.com/astorfi/TensorFlow-World,TensorFlow-World,"A curated collection of simple, ready-to-use TensorFlow tutorials with accompanying source code and documentation, organized by topic areas (basics, classic ML, and neural networks). The repo links to expanded explanations via its GitHub wiki and hosted docs.",4500,machine learning|deep learning|TensorFlow|tutorials|neural networks|computer vision|education,8,"This repository’s primary purpose is educational: it provides structured TensorFlow tutorials with runnable example code and documentation covering fundamentals through neural-network topics. It is directly useful to ML practitioners and learners for understanding TensorFlow workflows and implementing common models, though it is not a production-grade library or MLOps tool. Community adoption appears solid for an educational repo (on the order of ~4.5k GitHub stars), which supports its ongoing usefulness. I rated it an 8 because it is highly relevant to ML learning and prototyping, but it is not a core industry framework or widely-used production dependency.",success
https://github.com/CLUEbenchmark/CLUEDatasetSearch,CLUEDatasetSearch,"A curated, searchable collection of Chinese and English NLP datasets organized by task (e.g., NER, QA, sentiment analysis, text classification, matching, summarization, MT, knowledge graphs, corpora, reading comprehension). The repo backs an online dataset-search page and stores dataset metadata (links, update time, provider, description, keywords, category, and related papers).",4400,natural language processing|datasets|dataset catalog|chinese nlp|benchmark resources|data curation|information retrieval,8,"This repository’s primary purpose is to curate and publish a searchable directory of NLP datasets (Chinese-focused with some English datasets), including structured metadata and links for many common NLP tasks. It is directly useful for ML/data workflows because it speeds up dataset discovery, comparison, and sourcing for experiments, benchmarking, and education, even though it is not a training framework or modeling library. Community adoption appears strong (thousands of GitHub stars and hundreds of forks), indicating it’s a widely referenced resource for dataset discovery. I rated it 8/10 because it is highly relevant to ML practice as a data resource index, but it doesn’t itself provide models, pipelines, or programmatic dataset APIs at the level of core ML tooling.",success
https://github.com/DistrictDataLabs/yellowbrick,yellowbrick,"Yellowbrick is a Python library of visual diagnostic tools (""Visualizers"") that extends the scikit-learn API to support human-guided model selection. It integrates with scikit-learn workflows and uses matplotlib to visualize steps like feature analysis, model evaluation, and tuning.",4400,machine-learning|data-visualization|scikit-learn|matplotlib|model-selection|python|ml-diagnostics,8,"This repository provides a dedicated ML visualization/diagnostics library (Yellowbrick) built specifically to help practitioners analyze features, evaluate models, and steer model selection. It is directly applicable in day-to-day data science workflows because its Visualizers follow the scikit-learn estimator/pipeline style and generate interpretable plots via matplotlib. The project shows strong community adoption (thousands of GitHub stars and broad packaging/distribution via PyPI/conda), and it has solid educational value because the visual tools make common ML issues (e.g., bias/variance tradeoffs, class imbalance, feature correlation) easier to understand. I scored it an 8 (highly relevant) because it is not a core training framework like PyTorch/TensorFlow, but it is a widely useful, purpose-built companion for ML model development and evaluation.",success
https://github.com/IDSIA/sacred,sacred,"Sacred is a Python tool for configuring, organizing, logging, and reproducing computational experiments. It provides configuration management, a CLI for running parameterized variants, and observer backends (e.g., MongoDB) to record configs, dependencies, results, and metadata for experiment tracking.",4400,machine learning|experiment tracking|reproducibility|mlops|python|configuration management|mongodb,8,"This repository provides an experiment management framework focused on reproducibility and systematic tracking of runs (parameters, results, dependencies, and environment metadata). It is directly applicable to ML/data science workflows because it streamlines running hyperparameter variants, logging outputs, and persisting run artifacts/metadata via observers (commonly used with MongoDB). While it is not an ML algorithm library itself, its practical utility for organizing and reproducing ML experiments and its established adoption make it highly relevant, earning an 8/10.",success
https://github.com/MorvanZhou/Tensorflow-Tutorial,Tensorflow-Tutorial,"A Chinese-language TensorFlow (primarily TensorFlow 1.x-era, 2017) tutorial code repository covering basics and multiple neural network architectures (e.g., CNN, RNN, autoencoders, DQN, GAN), with accompanying video/text lessons referenced from the author’s site.",4400,machine learning|deep learning|TensorFlow|neural networks|tutorial|computer vision (CNN)|reinforcement learning (DQN)|generative models (GAN),8,"This repository is primarily an educational collection of TensorFlow tutorial implementations spanning foundational TF concepts and a range of common deep learning models (classification/regression, CNN/RNN/autoencoder, DQN, GAN). It is directly relevant to ML workflows as runnable reference code for learning and prototyping classic architectures, but it appears oriented toward older TensorFlow (2017/TF1-style) patterns, which reduces direct production applicability today compared with modern TF2/Keras-first practices. Community adoption is solid (about 4.4k stars), indicating it has been widely used as a learning resource, supporting a high (but not top-tier) ML/data usefulness score.",success
https://github.com/pytorch/serve,serve,"TorchServe is a model serving framework for deploying, scaling, and managing PyTorch models in production. It provides HTTP/REST (and related management/metrics) APIs, model archiving tools (MAR), multi-model serving, and Docker/Kubernetes deployment support, but the repository is now archived and under limited maintenance.",4400,pytorch|model-serving|mlops|inference|deployment|docker|kubernetes|torchserve,8,"This repository implements TorchServe, a dedicated serving system for PyTorch inference, including packaging models into archives (MAR), exposing inference/management endpoints, and supporting production deployment patterns (e.g., Docker/Kubernetes). It is directly applicable to ML engineering workflows for turning trained PyTorch models into scalable inference services, and it has meaningful community adoption (thousands of GitHub stars). However, the repo is archived (Aug 7, 2025) and marked as ""Limited Maintenance"" with no planned updates or security patches, which reduces its practical value for new production deployments despite its strong ML relevance.",success
https://github.com/Azure/MachineLearningNotebooks,MachineLearningNotebooks,"A large collection of Jupyter/Python notebooks demonstrating machine learning and deep learning workflows using the Azure Machine Learning (AzureML) Python SDK (primarily SDK v1). The repository is marked as deprecated in favor of AzureML SDK v2 sample notebooks, and is not expected to receive ongoing updates.",4300,azure-machine-learning|azureml-sdk|machine-learning|deep-learning|jupyter-notebooks|mlops|python,8,"This repository’s primary purpose is to provide hands-on Azure Machine Learning notebooks covering common ML tasks (environment setup, data access, training, evaluation, and deployment) using the AzureML Python SDK. It is directly applicable to ML/data workflows for teams using AzureML and has strong educational value due to its breadth of examples and notebook-based format. However, it is explicitly deprecated for AzureML SDK v1 and points users to v2 samples instead, which reduces its “current best practice” value despite remaining a useful reference; therefore it earns a high but not top score.",success
https://github.com/mljar/mercury,mercury,"Mercury is an open-source framework for turning Jupyter/Python notebooks into interactive web apps (and dashboards/presentations) by adding widgets directly in the notebook, with automatic cell re-execution and options like code hiding and export to PDF/HTML.",4300,jupyter|python|data-apps|dashboarding|notebook-to-webapp|data-visualization|interactive-widgets|ml-tools,8,"This repository’s primary purpose is to publish Jupyter notebooks as interactive web applications by adding Mercury widgets in Python and running them via a Mercury server. It is highly applicable to ML/data workflows because many data scientists build analyses and model demos in notebooks and need a lightweight way to share interactive results with non-technical stakeholders without rebuilding a full web frontend. While it is not a model-training framework itself, it integrates well with common DS/ML libraries (e.g., pandas, scikit-learn, visualization tools) and has strong community adoption (about 4.3k GitHub stars), justifying a high relevance score but not a perfect 10.",success
https://github.com/zuruoke/watermark-removal,watermark-removal,"A machine-learning image inpainting project for removing watermarks from images, aiming to produce outputs that are visually indistinguishable from the original (ground-truth) image. It is inspired by contextual-attention and gated-convolution inpainting approaches and provides scripts for running watermark removal using pre-trained checkpoints.",4300,computer vision|image inpainting|watermark removal|deep learning|tensorflow|python|generative models,8,"This repository implements an ML-based computer vision workflow (image inpainting) specifically aimed at watermark removal, including code and instructions to run inference using provided/pretrained checkpoints. It is directly applicable to ML/CV practitioners for experimentation, benchmarking, or adapting inpainting techniques (contextual attention, gated convolution) to related restoration tasks. While it appears to be a single-project implementation (not a general-purpose framework) and depends on older TensorFlow versions, its clear ML focus and substantial community interest (thousands of stars) make it highly relevant, hence an 8/10.",success
https://github.com/cs230-stanford/cs230-code-examples,cs230-code-examples,"A collection of Stanford CS230 deep learning code examples in both PyTorch and TensorFlow, covering computer vision and natural language processing (NLP) project templates and tutorials organized by framework and domain.",4200,deep learning|machine learning education|pytorch|tensorflow|computer vision|natural language processing|tutorials,8,"This repository provides structured, educational deep learning code examples for Stanford CS230, with implementations in PyTorch and TensorFlow spanning vision and NLP. It is directly applicable to ML workflows as a starting point for model training projects, including reusable project structure and example code patterns. While it is not a broadly adopted production framework, it has strong educational value and practical relevance for ML practitioners building or learning end-to-end training code, justifying a high (but not maximum) score.",success
https://github.com/Moataz-Elmesmary/Data-Science-Roadmap,Data-Science-Roadmap,"A free, self-learning data science roadmap (""from A to Z"") that curates learning resources and a structured study path across beginner, intermediate, and advanced phases (including statistics, programming, machine learning, deep learning, and deployment/interview prep).",4100,data science|machine learning|learning roadmap|statistics|python|data engineering|deep learning|career guidance,8,"This repository is primarily an educational roadmap that organizes the data science learning journey into phases (beginner/intermediate/advanced) and links out to many free/paid resources and guides. It is strongly relevant to ML/data workflows because it directly targets the skill-building path for data scientists (statistics, programming, ML/DL, and deployment), but it is not a software library or tool that you would integrate into production pipelines. The community adoption appears solid for an educational repo (about 4.1k GitHub stars), supporting a high educational value score even though direct workflow integration is limited.",success
https://github.com/ModelEngine-Group/nexent,nexent,"Nexent is an open-source, zero-code platform for generating and running AI agents from natural-language instructions (no manual orchestration or drag-and-drop flows). It is built around the MCP tool ecosystem and includes capabilities for agent control/multi-agent collaboration, data processing (including OCR and structured extraction), knowledge-base management with traceability/citations, and multimodal interaction.",4100,ai-agents|agent-platform|llm|mcp|rag|knowledge-base|data-processing|multimodal,8,"This repository provides a full agent platform that turns natural language into runnable (including multimodal) agent workflows and integrates tools via the MCP ecosystem, positioning it directly in the LLM/agent tooling space. It includes data-processing and knowledge-base features (e.g., handling many file formats, OCR/table extraction, and citation/traceability), which are highly relevant to common ML/RAG workflows. While it is not a foundational ML training framework, it is strongly applicable to practical ML engineering (agentic apps, RAG, tool integration, and data ingestion), and it shows notable community adoption (≈4.1k stars).",success
https://github.com/aws/aws-sdk-pandas,aws-sdk-pandas,"AWS SDK for pandas (also known as awswrangler) is a Python library that integrates pandas with AWS data services, enabling easy reading/writing of datasets and running queries across services like S3 (Parquet/CSV/JSON/Excel), Athena, Glue, Redshift, Timestream, and more.",4100,python|pandas|aws|data-engineering|data-lake|etl|athena|s3,8,"This repository provides a production-grade Python toolkit (awswrangler) that connects pandas workflows to core AWS analytics and storage services (notably S3, Athena, Glue, Redshift, and others), streamlining common data ingestion, query, and dataset management tasks. It is highly applicable to ML/data workflows because it covers the “data access + feature/label extraction” layer used before model training, and it integrates well into typical Python data stacks. While it is not an ML framework (no model training/inference APIs), its widespread use for AWS-based data pipelines and its direct utility for preparing and moving large datasets makes it strongly valuable for data science and ML engineering.",success
https://github.com/google-deepmind/learning-to-learn,learning-to-learn,"TensorFlow (TF1-era) reference implementation of DeepMind's “Learning to Learn” work, training a learned optimizer (meta-optimizer) that can optimize other models/tasks. Includes scripts to train and evaluate the learned optimizer on toy quadratics and image-classification problems like MNIST and CIFAR-10.",4100,machine learning|meta-learning|learned optimizers|deep learning|tensorflow|research code|optimization,8,"This repository implements a learned optimizer (“learning to learn”) in TensorFlow, providing training/evaluation scripts and example tasks (quadratic functions, MNIST, CIFAR-10) that demonstrate meta-optimization workflows. It is directly relevant for ML researchers/engineers interested in optimization and meta-learning, and it has meaningful community adoption (thousands of stars) as a canonical reference implementation. However, it targets older dependencies (TensorFlow >= 1.0 and Sonnet >= 1.0) and is primarily research-oriented rather than a drop-in modern production tool, which slightly limits practical integration today.",success
https://github.com/orchest/orchest,orchest,"Orchest is an open-source platform for building and running data pipelines via a visual UI while writing pipeline steps directly in Python, R, or Julia using notebooks and scripts. It supports dependency-managed environments, scheduled/partial pipeline runs (jobs), project versioning with Git, and long-lived services during pipeline execution; however, the maintainers note the project is no longer actively developed and recommend Apache Airflow as an alternative.",4100,data pipelines|workflow orchestration|MLOps|notebooks|ETL|data engineering|Python,8,"This repository provides a workflow/pipeline orchestration platform aimed at building data pipelines through a UI while authoring steps in notebooks/scripts, making it directly usable for ETL, feature engineering, and ML experiment pipelines. It fits well into ML/data workflows (pipeline authoring, scheduling, environment management, services) and includes example projects like model training/comparison and PySpark usage. While it’s highly relevant to data science infrastructure, the stated lack of active development reduces its practical long-term value and community momentum versus actively maintained orchestrators, so it scores below top-tier MLOps/orchestration staples.",success
https://github.com/pydata/xarray,xarray,"Xarray is a Python library for working with labeled N-dimensional arrays and datasets, providing dimension/coordinate-aware operations, alignment, grouping, and metadata handling. It is designed for scientific/array data (notably netCDF) and integrates with tools like NumPy and Dask for efficient and parallel computation.",4100,scientific-computing|data-analysis|multidimensional-arrays|netcdf|numpy|dask|python,8,"This repository provides xarray, a widely used data-structure and analytics library for labeled N-dimensional data (common in geoscience, climate, and other scientific domains) with pandas-like ergonomics and strong interoperability with NumPy and netCDF-based workflows. It is highly relevant to ML/data workflows for feature engineering, spatiotemporal data preprocessing, and scalable array computation (especially when combined with Dask), though it is not itself a model-training framework. Its broad adoption in the scientific Python ecosystem and practical utility for real-world multi-dimensional datasets justify a high score, but not a 10 because it is more of a core data handling layer than an end-to-end ML framework.",success
https://github.com/quantopian/alphalens,alphalens,"Alphalens is a Python library for performance analysis of predictive (alpha) stock factors. It helps users generate “tear sheets” with key statistics and plots (e.g., returns, information coefficient, turnover, grouped analysis) and integrates well with Zipline and Pyfolio workflows.",4100,python|quantitative-finance|factor-investing|algorithmic-trading|financial-data-analysis|jupyter-notebooks|pandas|data-visualization,8,"This repository provides a purpose-built toolkit for analyzing predictive signals (“alpha factors”) in equities by computing forward returns, factor quantiles, and producing standardized tear sheets with plots and diagnostics. It is directly applicable to data science workflows in systematic trading and financial ML, especially for feature/signal evaluation, backtest research, and factor selection. While it is not a model-training framework, it is a highly useful, widely adopted analysis layer (notably with Zipline/Pyfolio ecosystems) for evaluating ML-derived or statistical factors, justifying a high but not maximum score.",success
https://github.com/PINTO0309/PINTO_model_zoo,PINTO_model_zoo,"A model zoo that collects many pretrained ML models and provides versions that have been converted between multiple deployment frameworks and runtimes (e.g., TensorFlow, PyTorch, ONNX, OpenVINO, TFJS, TF-TRT, TFLite including INT8, EdgeTPU, and CoreML). It is primarily used as a reference and source of ready-to-use converted models for inference across platforms.",4000,machine learning|model zoo|model conversion|onnx|tensorflow-lite|openvino|edge ai,8,"This repository’s primary purpose is to host a large collection of pretrained models that have been inter-converted across common ML frameworks and edge-deployment runtimes, making it directly useful for inference, benchmarking, and deployment workflows. It is highly relevant to ML engineers and applied data scientists who need model format interoperability (e.g., ONNX/OpenVINO/TFLite/EdgeTPU/CoreML) rather than training code or datasets. The community adoption appears strong based on the repository’s star count and breadth of included models, but it is less of a core ML library/framework and more of a curated asset collection, so it falls short of a 9–10.",success
https://github.com/jphall663/awesome-machine-learning-interpretability,awesome-machine-learning-interpretability,"A maintained, curated “awesome list” of practical resources related to responsible machine learning and interpretability, including governance/policy guidance, education materials, incident tracking, benchmarks/datasets, and open-source responsible AI tooling.",4000,machine learning interpretability|responsible AI|AI governance|model explainability|fairness and bias|ML resources|awesome-list,8,"This repository is a curated, actively maintained collection of resources for responsible ML and interpretability (including guidance, education, incident/critique resources, and technical tools like benchmarks and datasets). It is highly relevant to ML/data workflows because it helps practitioners select methods, frameworks, software packages, and references for explaining models and meeting responsible AI requirements, though it is not itself an implementation library. Community adoption appears strong for a curated list (thousands of stars and hundreds of forks), and its educational and reference value for ML engineers/data scientists is high. I assigned an 8/10 because it is broadly and directly useful for ML practice, but it is more of a meta-resource hub than a core tool used in production pipelines.",success
https://github.com/junyanz/iGAN,iGAN,"Reference implementation of iGAN (interactive GAN) from the ECCV 2016 paper ""Generative Visual Manipulation on the Natural Image Manifold"", providing an interactive UI that turns user strokes/constraints into photorealistic images in real time using GAN/DCGAN-based generative models.",4000,machine learning|deep learning|generative adversarial networks|computer vision|interactive image generation|theano|python,8,"This repository implements an interactive image generation system (iGAN) built on GAN/DCGAN models, including scripts to run an editing UI and to generate images from constraint maps (color/edge constraints). It is directly relevant to ML workflows for generative modeling and as an educational/reference codebase for manipulating a learned image manifold, but it is older (Python 2 + Theano, PyQt4) and not a modern training framework. Community adoption is strong for a research repo (thousands of stars), yet integration into current pipelines is limited compared to contemporary PyTorch/TensorFlow implementations, leading to a high but not top-tier score.",success
https://github.com/minivision-ai/photo2cartoon,photo2cartoon,"A portrait photo-to-cartoon stylization project that uses a GAN-based unpaired image translation approach (built on ideas from U-GAT-IT) to convert real face photos into a more realistic “cartoon” style while preserving identity via a face-ID loss. The repo provides pretrained weights plus scripts for preprocessing, testing (PyTorch and ONNX), and training.",4000,computer vision|image-to-image translation|GAN|portrait stylization|pytorch|onnx|face recognition,8,"This repository implements an ML model pipeline for portrait cartoonization using GAN-based unpaired image translation with additional components (face alignment/segmentation and an identity-preserving loss). It is directly useful for ML/CV practitioners who want to run inference, fine-tune, or study an end-to-end stylization system, and it includes pretrained weights and ONNX inference support. Community adoption appears strong for a niche CV model (on the order of ~4k GitHub stars), but it is not a foundational/general ML framework and uses relatively older dependency versions, which slightly limits modern integration—hence an 8/10 rather than 9–10.",success
https://github.com/snipsco/snips-nlu,snips-nlu,"Snips NLU is an open-source Python Natural Language Understanding library for intent classification and slot/entity extraction, producing structured, machine-readable parses from user text for chatbots and voice assistants.",4000,natural-language-processing|NLU|intent-classification|entity-extraction|slot-filling|chatbots|python,8,"This repository provides an end-to-end NLU engine (training + inference) focused on intent detection and slot filling, which are core applied NLP/ML tasks used in conversational AI systems. It is directly useful for ML practitioners to train models on labeled NLU datasets and to run parsers that output structured predictions (intents and extracted entities/slots). While it is not a general-purpose ML framework, it is a substantial ML application library with clear educational and practical value for building and evaluating NLU pipelines, hence a high (but not maximum) score.",success
https://github.com/stumpy-dev/stumpy,stumpy,"STUMPY is a Python library for scalable modern time-series analysis built around efficient matrix profile computation. It supports common time-series data mining tasks like motif/pattern discovery, anomaly (discord) detection, segmentation, and streaming analysis, with options for distributed execution (e.g., via Dask).",4000,time series|matrix profile|anomaly detection|pattern mining|data mining|python|distributed computing|dask,8,"This repository provides STUMPY, a specialized time-series data mining library focused on fast matrix profile algorithms, enabling tasks like motif discovery, anomaly/discord detection, segmentation, and summarization for time-series data. These capabilities are directly useful in ML/data workflows for feature discovery, monitoring, and exploratory analysis on sequential signals. It is not a full model-training framework, but it is highly applicable as a core analytical primitive for time-series ML and has strong community adoption (thousands of GitHub stars), supporting the high score.",success
https://github.com/NervanaSystems/neon,neon,"Intel® Nervana™'s reference deep learning framework focused on high performance across hardware backends (CPU/MKL and GPU), providing a Python-based API, common neural-network layers, and example models/tutorials. The repository has been archived (read-only) and is discontinued by Intel (no longer maintained).",3900,deep learning framework|machine learning|neural networks|python|CPU optimization (MKL)|GPU acceleration|model zoo,8,"This repository is a full deep learning framework (training/inference library) with support for common layers (e.g., convolutional nets and RNN variants) plus tutorials and example scripts, making it directly applicable to ML model development workflows. It is highly relevant to ML engineers/data scientists as an end-to-end framework, including performance-oriented backends (notably CPU MKL optimization) and a model zoo. However, community adoption is limited compared to modern mainstream frameworks and the project was archived/discontinued (archived Jan 3, 2023), reducing its practical value for current production use—hence an 8 rather than 9–10.",success
https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials,Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials,"A curated, multi-topic collection of tutorials and learning resources for AI, deep learning, and machine learning, organized across frameworks (e.g., PyTorch, TensorFlow, scikit-learn) and applied domains (e.g., NLP, computer vision, healthcare, climate/energy). It functions primarily as an educational index of materials rather than a single runnable library/package.",3900,machine learning|deep learning|artificial intelligence|tutorials|pytorch|tensorflow|scikit-learn|nlp,8,"This repository is primarily an educational, curated set of ML/AI/deep learning tutorials and reference materials, covering major ML frameworks and topics (e.g., PyTorch, TensorFlow, scikit-learn, and domain areas like NLP/computer vision). It is directly useful to data scientists and ML engineers as a learning path and reference index, but it is not a cohesive tool/library that plugs into production workflows. Its large star and fork counts indicate meaningful community adoption for learning/discovery, which supports a high (but not maximal) score.",success
https://github.com/getzep/zep,zep,"Zep is an end-to-end context engineering platform for AI agents that ingests chat history, business data, documents, and app events, then assembles relationship-aware context for LLMs with low-latency retrieval. This repository primarily contains examples, integrations (e.g., LangChain, LlamaIndex, AutoGen), and supporting tools, with legacy Community Edition code housed under a legacy folder.",3900,llm|ai-agents|rag|knowledge-graph|agent-memory|context-engineering|langchain|llamaindex,8,"The repository centers on building production-ready AI agent context/memory via Graph RAG and temporal knowledge-graph-based retrieval, which is directly applicable to modern LLM/agent workflows. While it is not a model-training framework, it is highly valuable for ML engineering in practice because it addresses core problems in retrieval, memory, and context assembly and includes integrations/examples for common agent stacks. Community adoption appears strong (around 3.9k GitHub stars), indicating meaningful usage and interest in the ML/LLM ecosystem.",success
https://github.com/googlecreativelab/teachable-machine-v1,teachable-machine-v1,Teachable Machine v1 is a browser-based experiment from Google Creative Lab that lets users explore machine learning by training simple classifiers live in the browser with no coding required. It is built with TensorFlow.js and includes a local development workflow (Yarn-based) for building and running the web app.,3900,machine learning|tensorflow.js|browser-based ML|interactive education|web application|javascript,8,"This repository provides the source code for Teachable Machine v1, an educational, interactive web app that demonstrates training and using ML models directly in the browser (no-code) using TensorFlow.js. It’s highly relevant to ML learning and prototyping (especially client-side ML), but it’s not a general-purpose training framework or production MLOps tool. Its strong educational value and clear ML focus justify a high score, while its archived status and app-specific scope keep it below the top-tier (10) category.",success
https://github.com/dongrixinyu/JioNLP,JioNLP,"A Python library for Chinese NLP preprocessing and parsing, providing a large set of practical utilities (e.g., time semantic parsing, location/address parsing, text cleaning and regex extraction, keyphrase extraction, and data augmentation). It aims to be accurate, efficient, and easy to use for building Chinese-language NLP pipelines.",3800,NLP|Chinese NLP|text preprocessing|information extraction|time parsing|data augmentation|Python,8,"JioNLP is primarily a Chinese NLP preprocessing/parsing toolkit that offers many pipeline-ready components (text cleaning, regex-based extraction, time/location parsing, and augmentation) that directly support dataset preparation and feature engineering in ML workflows. While it is not a model training framework, it meaningfully accelerates real-world ML and data tasks by standardizing and enriching text inputs before modeling, and it includes functionality used in common NLP production pipelines. Its visible community adoption (about 3.8k GitHub stars) suggests it is a well-known utility library in the Chinese NLP ecosystem, supporting an 8/10 score rather than a perfect 10 reserved for core ML frameworks. ",success
https://github.com/gee-community/geemap,geemap,"geemap is a Python package for interactive geospatial analysis and visualization using Google Earth Engine (GEE) inside Jupyter-based environments. It provides interactive mapping (built on ipyleaflet/ipywidgets), utilities for exploring and exporting Earth Engine data, and tools such as JavaScript-to-Python conversion to help users move from the GEE Code Editor to Python workflows.",3800,geospatial|google-earth-engine|remote-sensing|jupyter|data-visualization|gis|python,8,"This repository primarily targets geospatial data science workflows by enabling interactive access to Google Earth Engine’s large-scale raster/vector datasets and providing tools for visualization, export, and analysis directly in Python notebooks. While it is not an ML framework itself, it materially supports ML/data pipelines by simplifying data acquisition, preprocessing, exploratory analysis, and even includes capabilities like image classification and accuracy assessment within an Earth Engine-centric workflow. Its strong community adoption (thousands of GitHub stars) and notebook-first ergonomics make it highly practical for data scientists working with Earth observation and environmental analytics, justifying a high (but not core-ML) score.",success
https://github.com/justmarkham/scikit-learn-videos,scikit-learn-videos,"A collection of Jupyter notebooks that accompany the “Introduction to Machine Learning with scikit-learn” video series by Data School. The repo provides the code, examples, and supporting materials used across a 10-part scikit-learn tutorial curriculum.",3800,machine learning|scikit-learn|python|jupyter notebooks|education|model evaluation|cross-validation,8,"This repository is an educational set of Jupyter notebooks aligned to a structured video series teaching core machine learning workflows using scikit-learn (including training, evaluation, cross-validation, and grid search). It is highly relevant for data science learning and can be directly used as runnable examples or a starting point for ML experiments, though it is not a production-grade library or framework. Its strong community adoption (thousands of GitHub stars) and focused ML curriculum make it particularly valuable for practical learning and reference, justifying an 8/10.",success
https://github.com/LazyAGI/LazyLLM,LazyLLM,"LazyLLM is an Apache-2.0 licensed low-code framework for building and deploying multi-agent LLM applications, offering modular workflows to assemble agents/tools, support RAG pipelines, and iterate via data feedback and optimization. It targets production use with unified interfaces across online/local models and common inference/fine-tuning and database backends.",3700,LLM|multi-agent|agentic-workflows|RAG|low-code|MLOps|Python,8,"LazyLLM is primarily an LLM application framework focused on quickly composing multi-agent systems (including chatbots and retrieval-augmented generation pipelines) and supporting iterative improvement through data feedback and fine-tuning. This is directly applicable to ML/DS workflows for prototyping and deploying LLM-powered products, especially where orchestration, tool use, and RAG are needed. Its relatively strong GitHub adoption (~3.7k stars) and emphasis on deployment/integration across model providers and infrastructure make it highly relevant, though it is not a foundational training library like PyTorch/TensorFlow—hence an 8 rather than a 9–10.",success
https://github.com/MemTensor/MemOS,MemOS,"MemOS is an open-source “memory operating system” for LLM-based AI agents that provides long-term memory storage, retrieval, and updating to improve contextual recall and personality consistency across sessions. It offers a unified memory API and (in MemOS 2.0) adds knowledge-base management, multimodal memory (images/documents), tool memory, feedback/correction controls, and an enterprise-oriented architecture (e.g., Redis Streams scheduling and DB optimizations).",3700,llm|ai-agents|rag|long-term-memory|memory-augmented-generation|model-context-protocol|python,8,"This repository provides a practical framework for building LLM agents with persistent, queryable long-term memory, including retrieval, updating, and newer knowledge-base and multimodal memory features. It is directly applicable to ML/LLM product workflows (agentic RAG, personalization, conversational memory, evaluation) and includes infrastructure patterns that ML engineers commonly need when productionizing agents. While it is not a general-purpose ML training framework, its core value is squarely in LLM systems, memory-augmented generation, and agent tooling, making it highly relevant for applied ML/LLM engineering use cases.",success
https://github.com/Netflix/maestro,maestro,"Maestro is Netflix’s general-purpose workflow orchestrator that provides a managed workflow-as-a-service (WaaS) for scheduling and running large-scale workflows and jobs. It is designed to be highly scalable and extensible, supporting diverse data and ML platform use cases and offering APIs/SDKs for workflow definition and execution.",3700,workflow orchestration|data engineering|MLOps|distributed systems|Java|Spring Boot|Kubernetes,8,"This repository implements a production-grade workflow orchestrator (WaaS) used for scheduling and executing large volumes of workflows/jobs, including Data/ML workflows, at Netflix. It is directly applicable to ML/data workflows as orchestration infrastructure for pipelines (scheduling, triggering, dependency management) and includes interfaces like REST APIs plus a Python SDK client for creating/pushing workflows. While it is not an ML modeling library itself, it is strongly relevant to MLOps/data-platform operations and therefore merits a high score for ML/data usefulness.",success
https://github.com/UnicomAI/wanwu,wanwu,"Wanwu (China Unicom Yuanjing Wanwu Agent Platform) is an enterprise-grade, multi-tenant AI agent development platform for building intelligent agents, workflows, and RAG applications, with integrated model lifecycle/management capabilities. It aims to provide a secure, extensible, commercially friendly full-stack solution for enterprise AI application development.",3700,ai-agents|llm|rag|agent-platform|workflow-orchestration|model-management|enterprise-ai|multi-tenant,8,"This repository provides an end-to-end platform for developing and operating LLM-powered applications, including AI agents, workflow orchestration, and RAG/enterprise knowledge base capabilities. It is directly applicable to ML/data workflows because it supports model access/management and production patterns (e.g., RAG pipelines and tool integrations) that data/ML teams commonly need to ship LLM features. While it is not a core ML training framework, its strong relevance to applied LLM engineering and enterprise deployment makes it highly valuable for many ML/DS practitioners. The relatively strong visible adoption on GitHub (thousands of stars) supports the high score.",success
https://github.com/MrForExample/ComfyUI-3D-Pack,ComfyUI-3D-Pack,"A comprehensive custom-node suite for ComfyUI that adds 3D asset generation and processing workflows (mesh/UV texture/3D Gaussian Splatting, etc.), integrating modern 3D reconstruction and generation approaches like NeRF/3DGS and multiple third-party models.",3600,ComfyUI|custom-nodes|3D-generation|3D-reconstruction|NeRF|Gaussian-splatting|diffusion-models|computer-vision,8,"This repository primarily provides ComfyUI nodes and workflows for ML-based 3D generation/reconstruction, including pipelines that depend on state-of-the-art research models (e.g., NeRF/3D Gaussian Splatting and related image-to-3D approaches) and integrates model-weight downloads and GPU tooling. It is directly applicable to ML/vision practitioners working on generative 3D content and can be used in practical production-style pipelines (image/text-to-3D, multi-view processing, mesh/texture baking, visualization). While it is not a general-purpose ML framework, its strong alignment with modern generative 3D methods and noticeable GitHub adoption make it highly valuable for applied ML workflows, hence an 8/10.",success
https://github.com/MrGemy95/Tensorflow-Project-Template,Tensorflow-Project-Template,"A best-practice TensorFlow deep learning project template that provides a clean folder structure and OOP-based abstractions (base model/trainer, data loader, logger, configs) to speed up starting new training projects.",3600,machine learning|deep learning|TensorFlow|project template|MLOps|training pipeline|software architecture,8,"This repository is a reusable template/architecture for TensorFlow projects, providing standardized components like base model and trainer classes, data loading, configuration management, and logging to help structure training pipelines. It is directly applicable to ML engineering workflows because it accelerates project setup and encourages maintainable patterns for model training and experimentation. It shows substantial community adoption (thousands of GitHub stars), but it is not itself a novel ML algorithm/library, so it scores slightly below core ML frameworks.",success
https://github.com/PeterH0323/Streamer-Sales,Streamer-Sales,Streamer-Sales（销冠）是一个“卖货主播”LLM 大模型项目：根据商品特点生成能激发购买意愿的直播带货解说文案，并提供从数据生成/微调到部署的完整工程化方案。项目还集成推理加速（LMDeploy）、RAG 检索增强、TTS/ASR、Agent 网络查询、数字人生成，以及 Vue 前端 + FastAPI 后端 + Docker Compose 部署。,3600,large language models|fine-tuning|RAG|text-to-speech|speech-to-text|agentic-ai|FastAPI|Vue,8,该仓库核心目标是构建并落地一个面向电商直播场景的 LLM（卖货主播）系统，覆盖数据生成流程、指令微调、推理部署与应用端到端集成（含 RAG、Agent、ASR/TTS、数字人等）。它对 ML/数据工作流的直接价值较高：提供了可复用的微调与应用落地范式，并展示了多模态/检索增强/推理加速的组合式工程实践。社区采用度（stars/ forks）也较高，且具备较强的教学与参考价值，因此评分为 8（高度相关但并非通用型核心基础框架级别）。,success
https://github.com/gusye1234/nano-graphrag,nano-graphrag,"A small, easy-to-modify (“easy-to-hack”) Python implementation of GraphRAG that provides graph-based retrieval plus naïve RAG, with async APIs and pluggable components for LLMs, embeddings, vector stores, and graph storage (e.g., OpenAI/Azure/Bedrock/Ollama; FAISS/hnswlib/milvus-lite; NetworkX/Neo4j).",3600,retrieval-augmented generation|GraphRAG|LLMs|NLP|knowledge graphs|vector databases|Python,8,"This repository implements GraphRAG end-to-end: it ingests text, extracts entities/relations to build a graph, computes communities and reports, and supports multiple query modes (global/local/naive) with async methods and configurable prompts and chunking. It is directly applicable to ML/NLP workflows for building RAG systems and experimentation with graph-based retrieval, and it integrates with common LLM/embedding backends and storage options (e.g., OpenAI/Azure/Bedrock/Ollama; FAISS/hnswlib; NetworkX/Neo4j). Community adoption appears solid (about 3.6k GitHub stars at time of lookup), but it’s not a foundational, industry-standard framework on the level of major ML libraries, so it scores below 9–10.",success
https://github.com/mcmonkeyprojects/SwarmUI,SwarmUI,"SwarmUI (formerly StableSwarmUI) is a modular, extensible web-based UI for AI media generation, focused on high performance and “power tools” accessibility. It supports multiple AI image models (e.g., Stable Diffusion and others) and also supports AI video generation workflows, with additional modalities planned.",3600,generative-ai|stable-diffusion|image-generation|video-generation|web-ui|comfyui-workflows|dotnet,8,"SwarmUI is primarily a production-oriented interface and workflow layer for running and managing generative AI model inference (not a model-training library). It’s highly applicable to ML workflows for practitioners who generate images/video with diffusion and related models, providing tooling, extensibility, and integrations that streamline experimentation and deployment-like usage. Its community adoption appears solid (thousands of GitHub stars) and it offers practical educational value for understanding and operating modern gen-AI pipelines and UI-driven workflows. It scores below a 9–10 because it’s not a foundational ML framework or data-processing library, and its core value is orchestration/UI rather than novel ML methods or training infrastructure.",success
https://github.com/pytorch/text,pytorch/text,"TorchText is a PyTorch companion library that provides datasets, text preprocessing transforms, vocabulary utilities, and pretrained NLP models to build language-processing pipelines. The repository is archived (read-only as of Sep 10, 2025) and its README notes development has stopped, with torchtext 0.18 (April 2024) as the last stable release.",3600,pytorch|torchtext|natural-language-processing|text-preprocessing|datasets|deep-learning|python,8,"This repository implements TorchText, which supplies core NLP building blocks for PyTorch workflows: dataset iterators, tokenization/text transforms, vocab utilities, and pretrained models. These components are directly applicable to ML/data science tasks involving text (training/evaluating NLP models, building input pipelines, and experimenting with standard datasets), and it has meaningful community adoption as part of the PyTorch ecosystem. However, because the repo is archived and the project’s development is stated as stopped (last stable release in April 2024), its forward-looking integration potential and long-term maintainability are reduced, keeping it below a top-tier score.",success
https://github.com/skyzh/tiny-llm,tiny-llm,"An educational codebase (with an accompanying book) that teaches how to build LLM inference serving on Apple Silicon using MLX, progressively implementing core components (e.g., attention, RoPE, KV cache, continuous batching, flash attention) to form a simplified “tiny vLLM” around Qwen/Qwen2 models.",3600,llm-inference|llm-serving|mlx|apple-silicon|vllm|qwen2|python|systems-engineering,8,"This repository is primarily a hands-on course for building and optimizing an LLM inference/serving stack (a simplified vLLM-like system) on Apple Silicon, centered on Qwen2-style transformer inference. It is highly relevant to ML engineering workflows because it focuses on practical inference components (attention/KV cache/batching/flash attention/quantization) and serving performance, though it is not a general-purpose training framework or data pipeline tool. Community adoption appears solid for an educational project (thousands of stars), and its educational value for understanding LLM inference systems is strong, justifying a high (but not max) ML/data score.",success
https://github.com/Michael-A-Kuykendall/shimmy,shimmy,"Shimmy is a lightweight, Python-free local inference server (single binary) that exposes OpenAI-compatible API endpoints for running LLMs locally. It supports GGUF and SafeTensors models with features like auto model discovery and hot model swapping.",3500,llm-inference|openai-api-compatible|local-ai|rust|gguf|safetensors|model-serving|generative-ai,8,"This repository provides an OpenAI-API compatible server for local LLM inference, focusing on easy, dependency-free deployment (single Rust binary) and support for common local-model formats like GGUF and SafeTensors. It is directly applicable to ML/LLM workflows for local serving, tool integration, and offline/private inference, making it valuable for ML engineers and applied data/AI practitioners. While it is not a training framework or general-purpose data-science library, it is a strong MLOps/model-serving utility with clear relevance to deploying and integrating LLMs in practical systems.",success
https://github.com/SkalskiP/make-sense,make-sense,"makesense.ai is a free, browser-based image labeling/annotation tool for preparing computer-vision datasets. It supports multiple annotation types (e.g., rectangles, polygons) and exports labels to common formats like YOLO, VOC XML, COCO JSON, and others, with optional in-browser AI-assisted labeling via TensorFlow.js integrations.",3500,computer vision|data labeling|image annotation|dataset preparation|tensorflow.js|react|typescript|yolo,8,"This repository provides a practical, end-to-end tool for creating labeled image datasets, a core prerequisite workflow for training and evaluating computer-vision models. It is directly applicable to ML work because it supports common annotation types and exports to widely used training formats (e.g., YOLO and COCO), and it also includes AI-assisted labeling integrations (e.g., YOLOv5/TF.js) to speed up annotation. Community adoption appears solid (thousands of GitHub stars and hundreds of forks), and it has strong educational value for understanding annotation formats and labeling workflows. It is not a model-training framework itself, but it is highly valuable infrastructure for ML dataset creation, justifying an 8/10.",success
https://github.com/business-science/ai-data-science-team,ai-data-science-team,"A Python library of specialized AI agents for common data science workflows, plus a flagship Streamlit app (AI Pipeline Studio) that helps build visual, reproducible pipelines for tasks like data loading, cleaning, EDA, visualization, modeling, and evaluation.",3500,data-science|machine-learning|ai-agents|generative-ai|python|streamlit|mlflow|h2o,8,"This repository provides an agent-based data science toolkit and a Streamlit application (AI Pipeline Studio) aimed directly at accelerating end-to-end data workflows (EDA, wrangling, feature engineering, modeling, predictions) with reproducible pipelines. It integrates with common ML/data tooling (notably MLflow and H2O) and supports LLM backends such as OpenAI and local models via Ollama, making it directly applicable to modern DS/ML workflows. Community adoption appears solid (about 3.5k GitHub stars), though it’s labeled Beta with potential breaking changes, which slightly reduces production readiness versus mature core frameworks. Overall, it is highly relevant to ML/data work as an applied workflow/productivity layer rather than a foundational ML framework.",success
https://github.com/wzhe06/Reco-papers,Reco-papers,"A curated, continuously updated collection of classic recommendation system papers, learning materials, and industry write-ups, organized by topics such as retrieval/reranking, deep learning recommender systems, embeddings, evaluation, and RL for recommendation.",3500,recommender systems|paper list|machine learning|deep learning|information retrieval|ranking|reinforcement learning,8,"This repository is primarily a curated bibliography/resource hub for recommender systems, listing influential papers and practical references organized by sub-area (e.g., retrieval & rerank, deep learning recsys, embeddings, evaluation, and reinforcement learning in recommendation). It is highly relevant to ML/data workflows because it helps practitioners and researchers discover foundational and modern recsys methods to study and implement, though it is not itself an ML library or dataset. Community adoption appears strong for a reading list (3.5k stars and 814 forks), indicating broad educational and reference value. I scored it an 8 because it’s highly useful for ML learning and research direction-setting, but offers limited direct “drop-in” tooling compared with frameworks or pipelines.",success
https://github.com/catalyst-team/catalyst,catalyst,"Catalyst is a PyTorch-based framework for accelerated deep learning research and development, focused on reproducibility and rapid experimentation. It provides a structured training pipeline (e.g., runners/callbacks) with common features like metrics tracking, early stopping, and checkpointing to reduce boilerplate training-loop code.",3400,deep learning|PyTorch|training framework|MLOps|experiment tracking|computer vision|reproducible research,8,"This repository is primarily a deep learning R&D framework built on PyTorch, aimed at speeding up model development with reusable training abstractions (runners/callbacks) and built-in pipeline features like metrics, checkpointing, and early stopping. It is directly applicable to ML workflows for training and evaluating neural networks, and includes examples/utilities that reduce common engineering overhead for practitioners. While it is not as universally adopted as the largest ML frameworks, it is clearly an ML-first toolkit with meaningful community usage (thousands of stars), which justifies a high (but not maximum) score.",success
https://github.com/databricks/koalas,koalas,Koalas implements the pandas DataFrame API on top of Apache Spark to let users write pandas-like code that can scale to distributed Spark workloads. The repository is deprecated/maintenance-mode because the pandas API on Spark is officially included in PySpark starting with Apache Spark 3.2.,3400,apache-spark|pandas|dataframes|distributed-computing|big-data|python|data-science|pyspark,8,"Koalas provides a pandas-compatible DataFrame interface backed by Apache Spark, enabling scalable data wrangling and feature preparation using familiar pandas idioms. This is highly applicable to data science and ML workflows (ETL, exploratory analysis, preprocessing) and has strong adoption signals (thousands of GitHub stars and common usage in Spark-centric environments). It is not an ML framework itself (no model training/inference core), and it is now maintenance-mode since equivalent functionality moved into PySpark, which slightly reduces its forward-looking utility—hence an 8/10 rather than 9–10.",success
https://github.com/jaymody/picoGPT,picoGPT,"A deliberately minimal implementation of GPT-2 inference written in plain NumPy, focused on showcasing the full forward pass in a very small amount of code. It includes GPT-2 weight/tokenizer download & loading utilities plus a simple CLI script for greedy text generation, but does not include training or advanced sampling features.",3400,machine-learning|deep-learning|nlp|transformers|gpt-2|large-language-models|numpy|python,8,"This repository provides a tiny, educational GPT-2 implementation in NumPy, including model definition, weight loading, tokenization, and a runnable text-generation script (inference). It is highly relevant to ML workflows for learning and experimentation with transformer internals, but it is not intended for production use (slow NumPy implementation) and explicitly lacks training code and modern sampling options. Community interest appears strong (thousands of GitHub stars), which boosts its educational and reference value for ML practitioners, but limited feature depth and lack of integration with common ML frameworks keep it below a 9–10.",success
https://github.com/ownthink/Jiagu,Jiagu,"Jiagu is a Chinese NLP toolkit trained on large-scale corpora that provides common text processing and analysis features such as Chinese word segmentation, POS tagging, named entity recognition, sentiment analysis, keyword extraction, text summarization, text clustering, new word discovery, and basic knowledge-graph relation extraction.",3400,natural language processing|chinese nlp|tokenization|named entity recognition|sentiment analysis|keyword extraction|text summarization|knowledge graph,8,"This repository is primarily an applied NLP library focused on Chinese-language text understanding tasks (segmentation, POS, NER, sentiment, summarization, clustering, and relation extraction). It is directly useful in ML/data workflows for preprocessing and feature extraction, rapid prototyping, and baseline modeling on Chinese text corpora, with a simple Python API and pip installation. While it is not a general-purpose ML framework and may have limited extensibility compared to larger ecosystems, its scope is squarely ML/NLP and it shows substantial community adoption (thousands of GitHub stars), justifying a high relevance score.",success
https://github.com/pashpashpash/vault-ai,vault-ai,"OP Vault is a Go backend + React frontend app that lets you upload documents (e.g., PDF/txt/epub/docx) and then ask questions answered using retrieval over your uploaded content via OpenAI embeddings and a Pinecone vector database (""OP Stack""). It provides long-term “memory” by chunking documents, embedding them, storing them in Pinecone, and returning answers with supporting file/context references.",3400,retrieval-augmented-generation|vector-database|pinecone|openai-api|document-question-answering|golang|react,8,"This repository implements a practical RAG-style document QA system: it ingests user files, extracts/chunks text, generates embeddings with OpenAI, stores them in Pinecone, and uses similarity search to assemble context for answering questions. That makes it directly applicable to ML/data workflows around semantic search, knowledge-base Q&A, and LLM app prototyping, even though it’s more of an application/template than a general-purpose ML library. It has clear educational value for understanding end-to-end embedding pipelines and vector search integration, and notable community adoption (3.4k GitHub stars).",success
https://github.com/ucbepic/docetl,docetl,"DocETL is an agentic, LLM-powered system for building and running data processing/ETL pipelines focused on complex document processing. It includes an interactive UI playground (DocWrangler) for iterative prompt/pipeline development and a Python package to execute production pipelines via CLI or Python.",3400,LLM|document processing|ETL|data pipelines|prompt engineering|Python|interactive UI,8,"This repository provides an LLM-centric ETL/pipeline framework aimed at transforming and extracting structured data from unstructured documents, with both a UI (DocWrangler) and a Python package for production execution. It is directly applicable to ML/data workflows where LLMs are used for document understanding, information extraction, and automated data preparation. While it is not a model-training framework, it is highly relevant for modern data/AI engineering pipelines that operationalize LLMs for data processing, justifying a high score.",success
https://github.com/X-D-Lab/LangChain-ChatGLM-Webui,LangChain-ChatGLM-Webui,"A Web UI built with LangChain and ChatGLM-6B (and related LLMs) for question answering over a local knowledge base. It supports uploading documents (e.g., txt/docx/md/pdf) and uses embedding models to enable retrieval-augmented chat grounded in your own files.",3300,large language models|LLM applications|RAG|LangChain|ChatGLM|embeddings|knowledge base QA|web UI,8,"This repository is primarily an applied LLM/RAG project: it provides a web interface and pipelines to ingest local documents, embed/split them, and answer questions grounded in that content via LangChain and ChatGLM-family models. It is directly useful for ML engineers and data practitioners building retrieval-augmented generation systems (document QA, internal knowledge assistants) and demonstrates practical integration with embedding models and LLM backends. It is not a model-training framework, but it is highly relevant to real-world ML application development and has meaningful community adoption (thousands of GitHub stars), justifying a high (but not maximum) score.",success
https://github.com/helblazer811/ManimML,ManimML,ManimML is a Python library built on the Manim Community edition to create animations and visualizations of common machine-learning concepts (especially neural network architectures) from code. It provides reusable visualization primitives and higher-level abstractions so users can focus on explaining ML ideas rather than building custom animation tooling from scratch.,3300,machine-learning|data-visualization|animations|manim|python|deep-learning|neural-networks,8,"This repository provides a purpose-built toolkit for programmatically animating machine learning concepts—most notably neural network structures and forward-pass-style animations—using Manim Community, with examples like convolutional and feed-forward layers. It is directly useful in ML/data workflows for education, presentations, documentation, and research communication (e.g., quickly generating consistent visuals of architectures and mechanisms). While it is not a training/inference framework or an MLOps/data pipeline tool, it has clear ML-focused functionality and meaningful community adoption (multi-thousand GitHub stars), which justifies a high relevance score but not a perfect 10.",success
https://github.com/krzjoa/awesome-python-data-science,awesome-python-data-science,"A curated “awesome list” of Python tools and libraries for data science, organized by topics such as machine learning, deep learning, NLP, visualization, data manipulation, deployment, and more.",3300,data science|machine learning|deep learning|python|NLP|computer vision|time series|awesome-list,8,"This repository is primarily a curated catalog of Python data science and machine learning software, with sections spanning ML, deep learning (PyTorch/TensorFlow/JAX), NLP, CV, visualization, data manipulation, and deployment. It is directly useful in ML/data workflows as a discovery and reference resource for selecting libraries and tooling across the stack, though it is not itself an executable framework or library. Community adoption appears solid (about 3.3k GitHub stars), indicating practical value and visibility. Given its strong educational and practical utility but indirect “tooling” nature (not a standalone ML system), a score of 8/10 is appropriate.",success
https://github.com/shankarpandala/lazypredict,lazypredict,"Lazy Predict is a Python library that quickly trains and compares many baseline scikit-learn models for classification and regression with minimal code, returning a leaderboard-style summary of metrics. It also supports categorical encoders, optional cross-validation/timeouts, and MLflow experiment tracking integration.",3300,machine learning|python|scikit-learn|automl|model benchmarking|classification|regression|mlflow,8,"This repository provides a low-code way to fit and evaluate 40+ baseline ML models for classification and regression, producing comparative metrics and (optionally) predictions, which is directly useful for rapid ML prototyping and baseline selection. It integrates well with common ML workflows via scikit-learn compatibility and optional MLflow tracking, plus supports multiple categorical encoding strategies and cross-validation/timeouts. Community adoption appears strong (about 3.3k GitHub stars) and it has clear educational value for quickly seeing how many standard models perform on a dataset. It’s scored 8 (highly relevant) because it’s a practical ML productivity/benchmarking tool, though it’s not a full AutoML/hyperparameter-optimization framework.",success
https://github.com/tensorforce/tensorforce,tensorforce,"Tensorforce is an open-source deep reinforcement learning (RL) framework built on TensorFlow, providing modular components and ready-to-use agents for training and deploying RL policies across common environments (e.g., Gym). The repository includes examples, benchmarks, environment adapters, and a CLI workflow, though the README notes the project is no longer maintained.",3300,reinforcement learning|deep reinforcement learning|tensorflow|python|rl-agents|openai-gym,8,"This repository is primarily a machine learning library focused on deep reinforcement learning, offering agent implementations, training utilities, and integrations with popular RL environments, making it directly usable in ML workflows. It has meaningful community adoption (3.3k GitHub stars) and strong educational value for understanding and applying RL algorithms in TensorFlow. However, the README explicitly states the project is not maintained any longer, which lowers its practical value for production use and long-term integration compared with actively maintained RL frameworks.",success
https://github.com/unitycatalog/unitycatalog,unitycatalog,"Unity Catalog is an open, multimodal catalog and governance system for Data & AI assets (e.g., tables, files, functions, AI models). It provides open APIs (including OpenAPI), an OSS server implementation, and compatibility with Hive Metastore and Apache Iceberg REST catalog APIs so multiple engines and formats can discover and govern assets consistently.",3300,data catalog|data governance|metadata management|lakehouse|data engineering|apache iceberg|delta lake|openapi,8,"This repository implements an open, universal catalog for data and AI assets with a server, APIs, and tooling (including a CLI) aimed at organizing and governing datasets and AI artifacts across engines and formats. It is highly relevant to ML/data workflows because catalogs and governance are foundational for discoverability, lineage/metadata, access control, and operationalizing datasets and models in production pipelines. While it is not an ML training/inference library, it directly supports end-to-end ML platform needs (data/model registry-like capabilities and cross-engine interoperability), making it a strong infrastructure component for data science and ML engineering.",success
https://github.com/xinghaochen/awesome-hand-pose-estimation,awesome-hand-pose-estimation,"A curated “awesome list” collecting research papers, datasets, benchmarks/evaluation resources, and related materials for hand pose estimation and tracking (including yearly conference/journal paper lists and dataset links). It also includes an evaluation folder with guidance on performance evaluation for hand pose estimation.",3300,computer vision|hand pose estimation|3D pose estimation|deep learning|research papers|datasets|awesome-list,8,"This repository is primarily a curated index of hand pose estimation/tracking resources (papers, datasets, and evaluation/benchmarking information), rather than a training or inference codebase. It is highly relevant to ML workflows because it helps practitioners discover datasets, compare methods, and navigate the literature for model development and evaluation. Community adoption appears strong for a niche research list (about 3.3k GitHub stars), increasing its utility as a reference. I scored it an 8 (highly relevant) because it’s very useful for ML research and data selection, but it doesn’t directly provide a core ML framework, pipeline, or model implementation.",success
https://github.com/OpenGVLab/InternGPT,InternGPT,"InternGPT (iGPT) is an open-source interactive multimodal demo platform for showcasing and orchestrating AI models, enabling users to interact with chatbots and vision tools via pointing actions (click/drag/draw) plus natural language. It integrates multiple vision-language capabilities such as multimodal chat, segmentation, interactive image editing, and model/tool demos (e.g., DragGAN, ImageBind, SAM).",3200,multimodal ai|vision-language|computer vision|LLM tools|interactive demo platform|gradio|image editing|segmentation,8,"This repository provides a runnable platform and reference implementation for building interactive multimodal AI demos that combine LLM-driven dialogue with vision tools and pointing-based user instructions. It is directly relevant to ML workflows because it demonstrates practical integration/orchestration of vision-language models and tools (e.g., segmentation, interactive editing, multimodal generation) in an end-user application. Its community adoption is solid (thousands of GitHub stars), and it has strong educational value for engineers learning how to wire together LLMs + CV models into a cohesive system. It scores below 9–10 mainly because it is a demo/system integration project rather than a foundational ML library or broadly adopted production framework.",success
https://github.com/astorfi/Deep-Learning-Roadmap,Deep-Learning-Roadmap,"A curated, organized roadmap of deep learning resources for researchers and developers, including papers (by model/type/application), datasets, courses, books, blogs, tutorials, and frameworks.",3200,deep learning|machine learning|educational resources|research papers|datasets|roadmap|computer vision|NLP,8,"This repository is primarily a curated knowledge base/roadmap that organizes deep learning learning and research resources (papers, datasets, courses, books, tutorials, and frameworks) into an easy-to-navigate structure. While it is not a library/tool you would import into an ML pipeline, it is directly useful for ML practitioners to discover canonical papers, benchmark datasets, and learning material, making it highly applicable for study, literature review, and project planning. It also shows strong community adoption (3.2k stars) and high educational value, which justifies a high (but not tool-level) score.",success
https://github.com/aurelio-labs/semantic-router,semantic-router,"Semantic Router is a Python library that performs fast, embedding-based intent recognition/routing for LLMs and agents by comparing queries in semantic vector space to example utterances (“routes”), enabling quick tool/prompt/agent selection without LLM classification calls.",3200,LLM tooling|semantic routing|embeddings|NLP|agent orchestration|Python|vector search,8,"This repository provides an embedding-driven routing layer that classifies/dispatches user inputs to routes (e.g., tools, prompts, agents) using semantic similarity rather than slower LLM generations, and includes integrations with popular embedding providers and vector databases. It is directly applicable to ML/LLM application workflows (agent/tool orchestration, intent detection, prompt/tool gating) and is packaged for practical use (PyPI install, documented quickstart). While it is not a model-training framework, it is highly relevant infrastructure for deploying ML/LLM systems and improving latency/cost/robustness in production routing, justifying a high (but not “core framework”) score.",success
https://github.com/microsoft/lida,lida,"LIDA is a Python library that uses large language models to automatically generate data visualizations and data-faithful infographics from datasets. It treats visualizations as code and supports workflows like summarization, goal generation, visualization generation/editing/explanation, and evaluation/repair across multiple charting libraries and LLM providers.",3200,data visualization|LLM|generative AI|Python|EDA|infographics|visualization code generation,8,"This repository provides an LLM-driven system for summarizing datasets, generating analysis goals, and producing executable visualization code (plus editing, explanation, and repair), making it directly useful in exploratory data analysis and automated reporting workflows. It is highly relevant to data science because it targets common DS tasks (EDA, chart recommendation/generation) and integrates with multiple LLM providers and visualization libraries, including an optional UI/Web API for interactive use. While it is not a general-purpose ML training framework, its practical applicability to data workflows and meaningful community adoption (stars) justify a high score rather than a perfect 10.",success
https://github.com/migueldeicaza/TensorFlowSharp,TensorFlowSharp,"TensorFlowSharp provides .NET (C# and F#) bindings to TensorFlow by exposing TensorFlow’s low-level C API as a strongly-typed .NET API, primarily for loading and running existing TensorFlow models (and optionally training) from .NET applications. The repository is archived (read-only as of Aug 11, 2025) and the README recommends TensorFlow.NET for an actively maintained, higher-level alternative.",3200,machine learning|tensorflow|.NET|C#|F#|bindings|model inference,8,"This repository’s primary purpose is to let .NET applications execute TensorFlow workloads by providing a strongly-typed wrapper over the TensorFlow C API, making it directly useful for ML inference (and some training) in production .NET environments. It is tightly aligned with ML/data workflows because it enables loading saved graphs/models and running them against application data without using Python. The score is not higher mainly because it is a low-level binding (more cumbersome than high-level ML APIs) and the repo is archived as of Aug 11, 2025, which reduces ongoing utility and integration freshness despite solid adoption (about 3.2k stars).",success
https://github.com/neuralmagic/deepsparse,deepsparse,"DeepSparse is a sparsity-aware deep learning inference runtime optimized for running neural networks efficiently on CPUs (e.g., ONNX-based inference for NLP and computer vision). The repository has been archived and, per the maintainers, the community version was deprecated and stopped receiving updates/support as of June 2, 2025.",3200,machine learning|model inference|CPU inference|sparse models|ONNX|performance optimization|NLP|computer vision,8,"This repository provides an ML-focused inference runtime (not a general-purpose library), specifically targeting fast CPU execution with sparsity-aware optimizations and integrations around ONNX and common ML workloads (NLP/CV). It is directly applicable to ML engineering workflows for deploying and serving models on CPU hardware and is reasonably adopted (thousands of GitHub stars). However, because the repo is archived and the community editions were deprecated on June 2, 2025 with no further updates/support, its practical value for new production use is reduced, keeping it below a 9–10.",success
https://github.com/spark-notebook/spark-notebook,spark-notebook,"Spark Notebook is an open-source, web-based notebook environment for interactive and reproducible data science and data engineering with Scala and Apache Spark. It supports mixing Scala code, SQL, markup, JavaScript, and interactive/reactive visualizations, with notebook isolation via separate JVMs/SparkSessions.",3200,apache spark|scala|notebooks|data engineering|data science|big data|interactive computing|visualization,8,"This repository provides a full interactive notebook application purpose-built for working with Apache Spark using Scala, enabling exploratory analysis, SQL querying, and interactive visualization in a collaborative web UI. It is directly applicable to data science and ML workflows because Spark is widely used for large-scale data processing and feature engineering, and the notebook format supports experimentation and reproducibility. While it is not itself an ML framework, it is a strong enabler for building and prototyping Spark-based ML pipelines (e.g., via Spark MLlib and JVM ML libraries), so it merits a high relevance score but not a 9–10 reserved for core ML libraries.",success
https://github.com/yusugomori/DeepLearning,DeepLearning,"A multi-language deep learning tutorial/implementation repository providing classic neural network and unsupervised deep learning models (e.g., RBM/DBN, denoising autoencoders, MLP, dropout MLP), with code in Python, C, C++, Java, Scala, and Go. It serves primarily as educational reference implementations, with CNN work referenced on a separate development branch.",3200,deep learning|machine learning|neural networks|restricted boltzmann machine (RBM)|deep belief networks (DBN)|autoencoders|educational|multi-language,8,"This repository provides reference implementations of foundational deep learning models (RBM/CRBM, DBN/CDBN, denoising autoencoders/SdA, MLP/dropout, and related components) across multiple programming languages, making it a strong educational and implementation resource. It is directly relevant to ML workflows for understanding/training classic architectures, though it is not a modern end-to-end training framework (e.g., PyTorch/TensorFlow ecosystem) and appears more tutorial-oriented than production-focused. Community adoption is solid (thousands of stars), but its primary value today is learning and studying core deep learning methods rather than being a widely integrated ML engineering tool.",success
https://github.com/fbdesignpro/sweetviz,sweetviz,"Sweetviz is an open-source Python library for exploratory data analysis (EDA) that generates a self-contained HTML report with high-density visualizations, summary statistics, and feature/target relationships. It can also compare datasets (e.g., train vs. test) and compute mixed-type associations (numeric, categorical, and categorical-numeric).",3100,python|exploratory-data-analysis|data-visualization|pandas|html-reporting|dataset-comparison|statistics,8,"This repository provides an automated EDA/reporting tool focused on understanding datasets, feature distributions, missingness, correlations/associations, and relationships to a target variable, producing a shareable HTML report. It fits directly into common data science workflows for initial data understanding, feature inspection, and train/test comparison before modeling. While it is not an ML training framework, it is highly useful for ML practitioners during data preparation and validation, and it appears reasonably adopted (3.1k GitHub stars).",success
https://github.com/i-am-bee/beeai-framework,beeai-framework,"BeeAI Framework is an open-source toolkit for building production-ready intelligent agents and multi-agent systems in Python or TypeScript. It provides unified LLM provider backends, agent tooling, workflows/orchestration, RAG support, memory, observability, and server/protocol integrations (e.g., MCP, A2A).",3100,ai-agents|multi-agent-systems|llm|rag|python|typescript|agent-orchestration|mcp,8,"This repository is primarily an agent framework for building autonomous and multi-agent applications, with first-class support in Python and TypeScript, unified LLM backends, built-in tools, workflows, and serving/protocol integrations. It is highly relevant to ML/LLM engineering workflows because it directly supports RAG, tool-use, agent orchestration, and integration with multiple model providers—common building blocks for modern applied NLP/LLM systems. It is not a model-training framework (so it’s not a 9–10), but it is a strong, directly usable framework for building and deploying LLM-powered systems and agentic applications, which warrants an 8.",success
https://github.com/icip-cas/PPTAgent,PPTAgent,"PPTAgent is an autonomous agentic framework for generating PowerPoint presentations from source documents using a reflective, edit-based workflow that leverages reference slides for structure and design. It also includes PPTEval, a multi-dimensional evaluation framework covering content, design, and coherence.",3100,LLM|agentic-ai|presentation-generation|document-to-slides|NLP|MCP|python,8,"This repository provides an LLM-driven agent framework to automatically generate slide decks (PPTX) from documents, including a web demo and tooling for research/design agents and an agent sandbox environment. It is strongly related to ML workflows because it operationalizes LLM-based agents for document understanding, structured content planning, and multimodal/design-oriented generation, and it ships an evaluation framework (PPTEval) aligned with ML benchmarking needs. Community adoption appears solid for a research-codebase (about 3.1k stars), suggesting meaningful interest, though it is not a general-purpose ML library like a core framework. I scored it an 8 because it is highly relevant to applied ML/NLP and agentic systems work, but its scope is specialized (presentation generation) rather than broadly reusable across many ML tasks.",success
https://github.com/ml-tooling/opyrator,opyrator,"Opyrator turns Python functions (including ML inference code) into production-ready microservices with an auto-generated HTTP API (FastAPI/OpenAPI) and interactive web UI (Streamlit). It supports packaging and sharing services as self-contained executables or Docker images, leveraging Pydantic and Python type hints for schema-driven I/O.",3100,machine learning|MLOps|model serving|microservices|FastAPI|Streamlit|Pydantic|OpenAPI,8,"This repository is primarily aimed at productizing Python functions—commonly ML inference functions—by generating both an HTTP API (FastAPI/OpenAPI) and an interactive UI (Streamlit), making it a practical model-serving and demo-deployment tool. It directly supports ML workflows such as wrapping models behind typed inputs/outputs, rapidly exposing inference endpoints, and containerizing deployments (Docker). While it is not a training framework or data-processing library, its focus on deployment/serving and its significant community adoption (3.1k stars) make it highly valuable for ML engineers and data scientists shipping models.",success
https://github.com/nidhaloff/igel,igel,"Igel is a no-code machine learning tool (CLI-first) that trains, evaluates, and uses ML models from YAML/JSON configurations instead of handwritten code. It targets fast prototyping and supports common ML tasks (e.g., regression/classification/clustering), preprocessing, cross-validation, and some AutoML-style workflows.",3100,machine learning|no-code|AutoML|scikit-learn|CLI|model training|data preprocessing,8,"This repository’s primary purpose is to let users train/test/serve machine-learning models without writing code, using YAML/JSON configuration files and a CLI-driven workflow. It is directly applicable to ML/data workflows for quick experimentation, baseline modeling, and evaluation (including preprocessing and cross-validation), and it explicitly targets common supervised/unsupervised tasks. While it is not a foundational ecosystem library with massive industry adoption, it is strongly ML-focused and practical for prototyping, which supports a high (but not maximum) score.",success
https://github.com/parrt/dtreeviz,dtreeviz,"dtreeviz is a Python library for decision tree visualization and model interpretation. It generates rich visual explanations for trees and tree-based models, and supports multiple ML frameworks via adaptor objects (e.g., scikit-learn, XGBoost, LightGBM, Spark MLlib, and TensorFlow).",3100,machine learning|model interpretability|decision trees|data visualization|python|scikit-learn|xgboost|lightgbm,8,"This repository provides a specialized visualization and interpretability toolkit for decision trees and tree-based models, producing explanatory plots such as tree visualizations and prediction-path explanations. It directly supports common ML libraries (including scikit-learn, XGBoost, LightGBM, Spark MLlib, and TensorFlow), making it practical for many real-world ML workflows focused on structured/tabular data. Its relevance is high because model understanding and explanation are core needs in applied ML, and the project shows meaningful adoption (thousands of GitHub stars). It is not a full training framework or pipeline system, so it scores slightly below core ML frameworks, but remains highly valuable for ML practitioners.",success
https://github.com/seungeunrho/minimalRL,minimalRL,"A collection of minimal, single-file PyTorch implementations of classic reinforcement learning algorithms (e.g., REINFORCE, Actor-Critic, DQN, PPO, DDPG, A3C, ACER, A2C, SAC, V-trace). The code is intentionally short (roughly ~100–150 lines per algorithm) and uses a fixed Gym environment (CartPole-v1) to focus on understanding core RL logic.",3100,reinforcement learning|deep reinforcement learning|pytorch|gymnasium/openai-gym|educational|policy gradients|value-based rl,8,"This repository provides concise PyTorch reference implementations of foundational reinforcement learning algorithms, aimed primarily at learning and rapid experimentation rather than production deployment. It is directly useful for ML practitioners and students who want to understand/verify algorithm mechanics or bootstrap small RL experiments, but it is not a full-featured training framework (limited environment scope and minimal infrastructure). Community adoption appears strong for an educational RL codebase (thousands of GitHub stars), and the repo integrates with common ML tooling (PyTorch + Gym), justifying a high (but not framework-level) score.",success
https://github.com/Cartucho/mAP,mAP,"Python implementation to evaluate object detection / recognition results using the PASCAL VOC 2012 mean Average Precision (mAP) metric. It parses ground-truth and detection-result text files, computes per-class AP from precision/recall curves (IoU threshold 0.5), and reports overall mAP; optional scripts help convert outputs from common toolchains (e.g., YOLO).",3000,computer vision|object detection|evaluation-metrics|mean-average-precision|pascal-voc|python,8,"This repository is a focused evaluation tool for computer vision models, implementing the widely used PASCAL VOC 2012 mAP/AP calculation (including IoU-based matching and precision/recall integration). It is directly applicable in ML workflows for benchmarking and comparing object detectors, and includes practical guidance/scripts for preparing inputs from common detection pipelines. Community adoption appears strong (about 3k GitHub stars), and it has educational value because it documents the mAP computation steps clearly; however, it is not a full training/inference framework, so it’s slightly below core-ecosystem tools.",success
https://github.com/CodeRayZhang/Movie_Recommend,Movie_Recommend,"A Spark-based movie recommendation system (“懂你”) that includes a web movie site, an admin management system, a Python/Scrapy crawler for collecting movie data, and a big-data recommendation pipeline built on a Hadoop/Spark ecosystem (with Kafka/Flume/Hive/MySQL) to generate and serve personalized recommendations.",3000,recommender systems|Apache Spark|big data|collaborative filtering|ALS|Hadoop ecosystem|Kafka|Java,8,"This repository’s primary purpose is building an end-to-end movie recommendation platform: data collection (crawler), a user-facing website and admin portal, and a Spark-based recommendation pipeline that processes user behavior and writes recommendations back to MySQL for serving. It directly relates to ML/data workflows by implementing a scalable recommender approach (including ALS-style collaborative filtering) and integrating common data engineering components (Hadoop/Hive, Kafka/Flume) typically used in production data pipelines. It has strong educational value for learning how to operationalize recommender systems in a big-data stack, but it is not a general-purpose ML library/framework and is relatively application-specific despite notable GitHub adoption (thousands of stars).",success
https://github.com/edtechre/pybroker,pybroker,"PyBroker is a Python framework for building and backtesting algorithmic trading strategies, with first-class support for machine-learning-driven models. It provides a fast NumPy/Numba-accelerated backtesting engine, data-source integrations (e.g., Alpaca, Yahoo Finance, AKShare), walkforward analysis, and performance metrics (including bootstrap-based metrics) with caching and parallelization.",3000,algorithmic trading|backtesting|quant finance|machine learning|python|time series|numba|walkforward analysis,8,"This repository is primarily an algorithmic trading and backtesting framework that explicitly targets ML-powered trading strategies, including model training hooks and walkforward analysis. It is directly applicable to ML/data workflows involving time-series feature engineering, supervised learning for signals, and robust evaluation via backtests and bootstrap metrics. While it is not a general-purpose ML framework, it integrates common data-science tooling patterns (data ingestion, feature/indicator computation, model training, evaluation) and is meaningfully adopted (thousands of GitHub stars), justifying a high but not top-tier score.",success
https://github.com/hegelai/prompttools,prompttools,"PromptTools is an open-source, self-hostable toolkit for experimenting with, testing, and evaluating prompts, LLMs, and vector databases via code, notebooks, and a local/hosted playground. It supports running prompt experiments across multiple model providers and assessing retrieval performance across popular vector DBs.",3000,LLMs|prompt-engineering|evaluation|MLOps|Python|vector-databases|RAG|Streamlit,8,"This repository provides developer-facing tooling to systematically run and compare prompt/model configurations and to evaluate vector database retrieval—both common needs in modern LLM and RAG workflows. It is directly applicable to ML engineering practice (prompt evaluation, model/provider comparison, retrieval evaluation) and integrates with many widely used LLM APIs and vector databases, plus provides notebook and playground interfaces for rapid experimentation. While it is not a model-training framework, it is highly relevant to applied ML/LLM development and evaluation, warranting a high (but not maximal) score.",success
https://github.com/maciejkula/spotlight,spotlight,"Spotlight is a PyTorch-based library for building and experimenting with recommender systems, supporting both shallow factorization models and deep sequential recommendation models. It includes multiple loss functions, representation modules, evaluation helpers, and dataset utilities (e.g., MovieLens and synthetic generators) to speed up prototyping.",3000,machine learning|recommender systems|PyTorch|deep learning|collaborative filtering|ranking|sequential recommendation,8,"This repository is a dedicated machine learning library focused on training and evaluating recommender models (factorization and deep sequential architectures) using PyTorch, with ready-to-use components for losses, representations, and metrics. It is directly applicable to ML workflows for recommendation and ranking, and also provides dataset loaders/generators that support rapid experimentation. Community adoption appears solid (on the order of ~3k GitHub stars), making it a practical and educational resource for ML engineers working on recommender systems, though it is not a general-purpose, industry-dominant framework on the scale of PyTorch or TensorFlow.",success
https://github.com/noahshinn/reflexion,reflexion,"Research code, demos, and experiment logs for the NeurIPS 2023 paper “Reflexion: Language Agents with Verbal Reinforcement Learning,” where LLM agents improve via textual self-reflection stored in memory instead of weight updates. Includes runnable notebooks/scripts and logged runs for tasks like HotPotQA reasoning, AlfWorld decision-making, programming, and WebShop-style environments.",3000,llm-agents|reinforcement-learning|self-reflection|prompting|agentic-workflows|NLP|research-code,8,"This repository implements and demonstrates the Reflexion framework from a NeurIPS 2023 paper, focused on improving LLM-based agents through verbal feedback/self-reflection and an episodic memory buffer. It is directly relevant to ML workflows for agent research and experimentation (reasoning, sequential decision-making, and coding tasks) and provides runnable setups and logged results for multiple benchmarks/environments. While it is more research/experiment oriented than a general-purpose production library, it is highly educational and practically useful for ML engineers working on LLM agents and evaluation, justifying a high score.",success
https://github.com/raghakot/keras-vis,keras-vis,"Neural network visualization and debugging toolkit for Keras models, providing techniques like activation maximization, saliency maps, and class activation maps (CAM), with support for N-dimensional image inputs.",3000,machine learning|deep learning|keras|model interpretability|visualization|computer vision|saliency maps|class activation maps,8,"This repository provides practical interpretability/visualization utilities (e.g., activation maximization, saliency maps, class activation maps) specifically for Keras neural network models. It directly supports common ML debugging and explainability workflows, especially in computer vision, and includes example code to apply these techniques. While it is not a full ML framework, it is a specialized, highly relevant toolkit for understanding and diagnosing trained models, with meaningful community adoption (on the order of ~3k GitHub stars).",success
https://github.com/vectara/hallucination-leaderboard,hallucination-leaderboard,"A public leaderboard from Vectara that ranks LLMs by how often they hallucinate when summarizing documents, using Vectara's Hallucination Evaluation Model (HHEM). The repo publishes methodology, evaluation prompt, and periodically updated results for factual consistency vs. hallucination rate.",3000,LLM evaluation|hallucination detection|benchmarking|NLP|summarization|leaderboard|RAG evaluation,8,"This repository’s primary purpose is to evaluate and compare LLMs for factual consistency (hallucination rate) on a summarization task using Vectara’s HHEM model, and to publish an ongoing leaderboard of results. It is directly relevant to ML/NLP workflows for model selection, quality evaluation, and safety/groundedness benchmarking, especially for summarization and RAG-style applications. While it is not a general-purpose ML framework, it provides strong practical and educational value around LLM evaluation methodology and results, making it highly useful for ML engineers and data scientists who need reliable evaluation signals.",success
https://github.com/yangjianxin1/GPT2-chitchat,GPT2-chitchat,"A Chinese chitchat (open-domain dialogue) chatbot project built on GPT-2 using Hugging Face Transformers, including training, preprocessing, and interactive inference scripts. It also includes decoding strategies (e.g., temperature, top-k, nucleus sampling) and an MMI-inspired variant for response generation/reranking.",3000,natural language processing|chatbot|dialogue generation|gpt-2|transformers|pytorch|chinese nlp,8,"This repository provides an end-to-end implementation for training and running a Chinese GPT-2-based dialogue model, including data preprocessing, model training, and interactive chatting scripts. It is directly applicable to ML/NLP workflows (fine-tuning and inference for conversational generation) and integrates with common ML tooling like PyTorch and Hugging Face Transformers. While it is not a general-purpose ML framework and its community adoption is modest compared to major libraries, it offers strong practical and educational value for conversational NLP and text generation, justifying a high (but not maximum) score.",success
https://github.com/BayesWitnesses/m2cgen,m2cgen,"m2cgen (Model 2 Code Generator) transpiles trained machine-learning/statistical models into native source code with zero runtime dependencies. It supports generating code in many languages (e.g., C, Java, Go, JavaScript, C#, R, etc.) for a range of common model types (linear models, trees/forests, boosting, SVMs, and more).",2900,machine-learning|model-deployment|code-generation|model-serialization|python|scikit-learn|xgboost|lightgbm,8,"This repository’s primary purpose is ML model deployment: it converts trained models into standalone native code so predictions can run without ML libraries in the target environment. It directly supports common ML workflows by enabling lightweight inference/embedding models in production systems (including multiple languages and popular model libraries like scikit-learn, XGBoost, and LightGBM). Community adoption appears solid (on the order of thousands of GitHub stars), and it has strong practical value for inference portability and edge/embedded use cases, though it is not a training framework and appears less actively maintained recently.",success
https://github.com/Conchylicultor/DeepQA,DeepQA,"A TensorFlow-based implementation of the seq2seq RNN chatbot described in the paper “A Neural Conversational Model,” with tooling to train/test on multiple dialogue corpora and an optional web interface for chatting with trained models.",2900,machine-learning|deep-learning|nlp|chatbot|tensorflow|seq2seq|rnn,8,"DeepQA is primarily an ML/NLP project that implements a sequence-to-sequence RNN conversational model (chatbot) in TensorFlow, including training and interactive testing workflows. It directly supports ML experimentation by providing data loaders for multiple dialogue corpora (e.g., Cornell Movie Dialogs, OpenSubtitles, Ubuntu Dialogue Corpus) and typical model-development tooling (training flags, TensorBoard logging). While it is older (TensorFlow 1.x-era) and not a modern production chatbot framework, it remains highly relevant for learning and prototyping classic seq2seq conversational models and dataset preparation pipelines.",success
https://github.com/IntelLabs/nlp-architect,nlp-architect,"NLP Architect is an open-source, model-oriented Python library from Intel AI Lab that provides deep-learning NLP/NLU models, utilities, and CLI workflows for training and inference across tasks like NER, dependency parsing, intent/slot extraction, sentiment, language modeling, and transformer-based models. The repository is archived and marked discontinued/read-only (archived Nov 8, 2022).",2900,natural language processing|natural language understanding|deep learning|python|transformers|pytorch|tensorflow|model training,8,"This repository provides a collection of implementable NLP/NLU deep-learning models (including transformer-based classifiers) plus supporting utilities, dataset loaders, and command-line procedures for training and inference, making it directly applicable to common ML workflows in NLP. It has meaningful community adoption (on the order of thousands of GitHub stars), and its examples/tutorials add educational value for practitioners learning model training and evaluation. However, it is archived/discontinued (read-only since Nov 8, 2022), which reduces practical integration value for current production use due to maintenance/security concerns; hence an 8 rather than a 9.",success
https://github.com/Tencent/PocketFlow,PocketFlow,"PocketFlow is an automatic model compression framework that helps compress and accelerate deep learning models with minimal human effort by searching hyper-parameters to meet target compression/acceleration ratios. It supports common compression techniques (e.g., pruning, sparsification, quantization, and distillation) and is aimed at producing efficient models for deployment, including on mobile devices.",2900,model-compression|deep-learning|tensorflow|quantization|pruning|knowledge-distillation|reinforcement-learning|mobile-deployment,8,"This repository’s primary purpose is ML-focused: it provides an AutoML-style framework to compress and speed up neural networks via channel pruning, weight sparsification, quantization, and distillation, with RL-based hyper-parameter optimization. It is directly applicable to ML engineering workflows for deploying efficient models (especially on resource-constrained devices) and includes documentation and examples for common vision backbones. It is not as universally adopted as major mainstream frameworks, but it offers substantial educational and practical value for model optimization and deployment, justifying a high (but not maximum) score.",success
https://github.com/easy-tensorflow/easy-tensorflow,easy-tensorflow,"A collection of simple, comprehensive TensorFlow tutorials, each pairing detailed Jupyter Notebook explanations (.ipynb) with corresponding Python source code (.py). The repo is organized into topic-based folders covering setup, TensorFlow basics, and common neural network architectures (e.g., CNNs, RNNs), plus tools like TensorBoard.",2900,machine learning|deep learning|tensorflow|tutorials|jupyter notebooks|neural networks|computer vision|tensorboard,8,"This repository’s primary purpose is educational: it provides end-to-end TensorFlow tutorials with both narrative notebooks and runnable Python code across core deep learning topics (basics, logistic regression, feed-forward networks, autoencoders, CNNs, RNNs, and TensorBoard). It directly supports ML workflows by helping practitioners learn model implementation and training patterns in TensorFlow, though it is not a production framework or MLOps tool. Community adoption appears solid for an educational repo (about 2.9k GitHub stars), indicating meaningful usage for learning and reference. I rated it an 8 because it is highly relevant to ML/deep learning learning and prototyping, but not a widely adopted core industry library at the level of major frameworks.",success
https://github.com/explosion/thinc,thinc,"Thinc is a lightweight deep learning library providing a type-checked, functional-programming API for composing and training models. It supports interoperability by wrapping models/layers from frameworks like PyTorch, TensorFlow, and MXNet, and includes an integrated configuration system for model and hyperparameter definitions.",2900,deep learning|machine learning|python|functional programming|model composition|pytorch integration|tensorflow integration|type checking,8,"This repository implements Thinc, a deep learning library focused on composing, configuring, and training neural models via a functional, strongly-typed API, with utilities for optimizers, schedules, backends, and an integrated config/registry system. It is directly applicable to ML workflows because it can serve as a standalone toolkit for model development/training or as an interface layer that wraps external frameworks (notably PyTorch and TensorFlow) within a unified API. Its close relationship to widely used NLP tooling from Explosion (e.g., spaCy) and its practical examples (MNIST, transformers tagger, distributed training with Ray) make it valuable for ML engineers and researchers, though it is not as universally adopted as top-tier general frameworks like PyTorch itself.",success
https://github.com/jisungk/deepjazz,deepjazz,Deep learning–based jazz music generation project that trains a 2-layer LSTM on a provided MIDI file and then generates new jazz sequences. Built with Keras + Theano and includes MIDI preprocessing utilities (via music21) and a generator script to train/run the model.,2900,machine learning|deep learning|music generation|LSTM|RNN|Keras|Theano|MIDI,8,"This repository is an end-to-end example of training and using a sequence model (2-layer LSTM/RNN) to generate music from MIDI, including preprocessing and generation code, making it directly relevant to ML workflows. It has strong educational value for sequence modeling and creative AI, and provides runnable training scripts and data handling (MIDI parsing) that ML practitioners can adapt. While it’s no longer actively developed and relies on older frameworks (Keras + Theano), it remains a clearly ML-first project with meaningful adoption/visibility (thousands of stars).",success
https://github.com/Charmve/computer-vision-in-action,computer-vision-in-action,"An interactive, “closed-loop” computer vision learning platform (Chinese e-book + source code + runnable notebooks) focused on deep learning–based vision tasks such as classification and related architectures. It provides an online book site plus Jupyter/Colab/Binder/Docker-friendly materials so learners can run and modify examples end-to-end.",2800,computer vision|deep learning|PyTorch|Jupyter Notebook|educational|interactive notebooks|courseware|MLOps (lightweight),8,"This repository is primarily an applied computer vision/deep learning learning platform that pairs a Chinese e-book with runnable code and notebooks, aiming for hands-on, end-to-end experimentation (e.g., via Jupyter/Colab/Binder and Docker). It is directly relevant to ML workflows because it contains practical implementations, training/fine-tuning examples, and supporting project structure (datasets/models/notebooks) that ML engineers can reuse or adapt. Community adoption is solid (about 2.8k GitHub stars at the time of lookup), and the educational value is high, but it is not a foundational industry framework on the level of core ML libraries—hence an 8 rather than 9–10.",success
https://github.com/Dicklesworthstone/llm_aided_ocr,llm_aided_ocr,"A Python-based pipeline that converts scanned PDFs to images, runs Tesseract OCR, then uses an LLM (local via llama.cpp or cloud via OpenAI/Anthropic) to correct OCR errors and optionally output clean Markdown with quality assessment and logging.",2800,optical character recognition|computer vision|natural language processing|large language models|pdf processing|tesseract|python,8,"This repository’s primary purpose is to improve OCR quality for scanned PDFs by post-processing Tesseract output with an LLM, including chunking, optional Markdown formatting, and an LLM-based quality assessment step. It directly supports common ML/data workflows for document ingestion, dataset creation/cleaning, and downstream NLP tasks by producing cleaner text from noisy scans. It also demonstrates practical LLM integration patterns (local inference via llama_cpp and API-based providers, plus async chunk processing), which increases its applied ML engineering value. While it’s not a general-purpose ML framework or widely adopted core library, it is a highly relevant, ready-to-use tool for document/LLM-enabled data pipelines, justifying an 8/10.",success
https://github.com/mars-project/mars,mars,"Mars is a tensor-based unified framework for large-scale data computation that scales familiar Python APIs (NumPy, pandas, scikit-learn) from a single machine to distributed execution. It provides parallel/distributed tensors, dataframes, and ML utilities, plus integrations with common ML libraries.",2800,distributed computing|data processing|numpy|pandas|scikit-learn|machine learning|python,8,"This repository implements Mars, a large-scale computation framework that offers NumPy-like tensors, pandas-like dataframes, and scikit-learn-like APIs that can execute in parallel and in distributed settings. It is directly applicable to ML/data workflows because it targets common data-science primitives (arrays, dataframes, and ML estimators) and supports executing Python functions remotely/parallel. Mars also explicitly integrates with popular ML tools (e.g., TensorFlow, PyTorch, XGBoost, LightGBM), making it useful as a scalable execution layer for end-to-end data pipelines. It scores 8 (highly relevant) because it is a practical data/ML compute framework, though it is not as universally adopted as the dominant ecosystems (e.g., Spark/Dask/Ray) and is more of a scalable computation layer than a standalone model-training framework.",success
https://github.com/zzw922cn/Automatic_Speech_Recognition,Automatic_Speech_Recognition,"An end-to-end automatic speech recognition (ASR) system implemented in TensorFlow, supporting Mandarin and English. It includes training/evaluation scripts and data-preprocessing utilities for common ASR corpora (e.g., TIMIT, LibriSpeech, WSJ) and implements models such as DeepSpeech2-style architectures.",2800,automatic speech recognition|speech recognition|deep learning|TensorFlow|audio processing|NLP|DeepSpeech2,8,"This repository provides an end-to-end ASR training and evaluation codebase in TensorFlow, including model implementations (e.g., DeepSpeech2) plus feature extraction and dataset preparation workflows for popular speech corpora. It is directly applicable to ML workflows for speech modeling (data preprocessing, training loops, evaluation) and has meaningful community adoption (thousands of GitHub stars), making it useful both for practitioners and for learning classic ASR pipelines. It is not a broadly used industry-standard framework today and appears oriented around older TF1-era tooling, so it falls short of a 9–10 score despite being highly relevant to ML.",success
https://github.com/NVlabs/MUNIT,MUNIT,"Official NVIDIA (NVlabs) implementation of MUNIT (Multimodal UNsupervised Image-to-image Translation), a GAN-based method for multimodal unsupervised image-to-image translation (ECCV 2018) that can generate diverse outputs by disentangling content and style. The repository includes training/testing scripts, configs, and example translation results, but the codebase is marked as no longer maintained.",2700,machine learning|deep learning|computer vision|generative adversarial networks|image-to-image translation|PyTorch,8,"This repository provides a research-grade implementation of a well-known generative modeling approach (MUNIT) for multimodal unsupervised image-to-image translation, including code and configuration to train and run GAN models on image datasets. It is directly applicable to ML workflows for experimentation, reproduction of ECCV 2018 results, and as a baseline/reference for domain translation tasks. Community adoption is solid (~2.7k stars), but practical production use is limited by the project being explicitly unmaintained and by its research-oriented setup; nonetheless it remains highly valuable for learning and prototyping in generative CV.",success
https://github.com/cloud-annotations/cloud-annotations,cloud-annotations,"Cloud Annotations is a fast, collaborative open-source image annotation tool for teams and individuals, designed to label images for computer vision workflows (e.g., object detection). It includes a web app/server architecture and related tooling for creating and managing annotations.",2700,image-annotation|computer-vision|machine-learning|data-labeling|object-detection|typescript|tensorflow,8,"This repository provides an end-to-end image annotation/labeling tool, which is a core step in preparing training datasets for computer vision models (e.g., detection). It is directly applicable to ML/data workflows by enabling teams to create and manage labeled image datasets used for model training and evaluation. While it is not an ML training framework itself and its latest release appears to be from 2020, it still offers high practical value for dataset creation, a critical dependency in many ML projects.",success
https://github.com/datachain-ai/datachain,datachain,"DataChain is a Python-based AI data warehouse for transforming, analyzing, versioning, and incrementally processing unstructured/multimodal data (images, audio, video, PDFs, text) directly in external object storage (e.g., S3/GCS) without duplicating data, while tracking/querying metadata in an internal database. It provides a dataframe-like API for analytics plus ETL primitives (including applying ML/LLMs) and features like delta and retry processing for efficient, scalable pipelines.",2700,data engineering|ETL|multimodal data|unstructured data|data versioning|python|MLOps|LLM pipelines,8,"This repository provides a Python framework positioned as an 'AI-data warehouse' focused on ETL, analytics, versioning, and incremental processing for large-scale unstructured/multimodal datasets stored in cloud/object storage. It directly supports ML/data workflows by enabling dataset creation, enrichment (including applying models and LLMs), and scalable analytics through a dataframe-like API, which makes it immediately useful for data scientists and ML engineers working with real-world media and document corpora. While it is not a model-training framework itself, its core value is in data preparation/management and pipeline execution for ML, and it shows meaningful community adoption (thousands of GitHub stars), justifying a high (but not max) score.",success
https://github.com/freedmand/semantra,semantra,"Semantra is a CLI tool that builds a private, local semantic search index over your text and PDF documents, then launches a local web UI for interactive meaning-based querying. It supports different embedding backends/models (including a local model by default, with optional OpenAI embeddings) and is designed for fast, configurable search over personal document collections.",2700,semantic-search|NLP|embeddings|document-search|Python|CLI|local-web-app,8,"This repository provides an end-to-end semantic document search workflow (document ingestion, embedding generation, similarity-based retrieval, and a web interface for exploration), which is directly applicable to many ML/data tasks involving unstructured text and PDFs. It is clearly ML-driven (embeddings and model selection are core features), and it can be integrated into data-science workflows for literature review, qualitative research, and internal knowledge search. While it is not a general-purpose ML framework, it is a highly practical applied NLP tool with meaningful adoption signals (thousands of GitHub stars), justifying a high score.",success
https://github.com/georgia-tech-db/evadb,evadb,"EvaDB is a database system and SQL query engine for building AI-powered applications over both structured and unstructured data. It lets you connect to multiple data sources and run/fine-tune ML and foundation models (e.g., Hugging Face, OpenAI, YOLO) via SQL with AI-centric query optimizations like caching, batching, and parallelism.",2700,ai database|sql|data engineering|machine learning|llm integration|computer vision|nlp,8,"This repository provides EvaDB, a database/SQL layer designed specifically to bring AI model inference and some model training workflows directly into SQL queries across diverse data sources. It is strongly aligned with ML/data workflows because it integrates pretrained models (including LLMs and vision models), supports bringing custom models via functions, and includes AI-focused query optimizations (caching/batching/parallelism) that matter in production data + ML systems. It is not a general-purpose ML training framework with massive industry adoption, but it is highly applicable for data/ML engineers building AI-powered data applications and pipelines, earning an 8/10. The repo is archived (read-only as of Oct 15, 2025), which slightly reduces ongoing practical value but does not diminish its conceptual/architectural relevance.",success
https://github.com/kaonashi-tyc/zi2zi,zi2zi,"A TensorFlow (v1-era) conditional GAN project for learning and transferring East Asian character/font styles (e.g., Chinese, Japanese, Korean) from one typeface to another, inspired by pix2pix and augmented with category embeddings and additional losses. It includes scripts to render fonts to images, package datasets, train models, and run inference/interpolation for style generation.",2700,generative-adversarial-networks|conditional-gan|image-to-image-translation|font-style-transfer|computer-vision|tensorflow|deep-learning,8,"This repository implements a conditional GAN pipeline (pix2pix-style) to perform image-to-image translation for character glyph/style transfer, including training and inference code plus data preprocessing scripts for building datasets from fonts. It is directly applicable to ML workflows involving generative modeling and style transfer, and it provides a concrete, end-to-end example of dataset preparation, model training, and inference. While it appears to rely on older dependencies (Python 2.7 and TensorFlow 1.x), it remains highly educational and practically useful for GAN-based image translation experiments, especially in font/glyph generation. The relatively strong GitHub adoption (thousands of stars) supports a high relevance score, though it is not a broad, general-purpose ML framework.",success
https://github.com/microsoft/pai,pai,"Open Platform for AI (OpenPAI) is a resource scheduling and cluster management platform for AI workloads, providing features like job submission/monitoring, user and storage management, and Kubernetes-based cluster operations for running distributed training on heterogeneous hardware (CPU/GPU/FPGA/InfiniBand). The repository is archived and read-only (archived June 6, 2024) and is in a stable/no-major-features-planned mode.",2700,MLOps|cluster management|resource scheduling|Kubernetes|distributed training|GPU computing|AI platform,8,"This repository implements OpenPAI, a full-stack AI platform focused on sharing and managing compute resources and running end-to-end training pipelines (including distributed jobs) on Kubernetes-based clusters. It is highly relevant to ML engineering and MLOps workflows because it directly supports multi-tenant AI job scheduling, heterogeneous accelerator management, and operational tooling around training. The score is not a 9–10 mainly because the repo is archived/read-only and in stable mode with no major new features planned, which reduces forward-looking adoption and integration momentum compared to actively maintained core ML frameworks.",success
https://github.com/naiveHobo/InvoiceNet,InvoiceNet,"InvoiceNet is a deep learning-based system for extracting structured information (e.g., vendor name, invoice date/number, totals) from invoice documents (PDF/JPG/PNG). It includes a GUI for viewing documents, preparing labeled training data, training custom models, and running extraction/prediction workflows.",2700,machine-learning|deep-learning|document-ai|invoice-processing|information-extraction|ocr|tensorflow|gui,8,"This repository provides an end-to-end ML application for document information extraction from invoices, including data preparation scripts, training code, and a GUI-based trainer/extractor workflow. It is directly relevant to ML/data workflows (document AI, OCR + structured field extraction) and can be used by ML engineers to train custom models on their own labeled invoice datasets. While it has meaningful community adoption (~2.7k stars) and strong educational value for applied document extraction, its utility depends on having suitable labeled invoice data and it is specialized to the invoice domain rather than being a general-purpose ML framework.",success
https://github.com/rmurai0610/MASt3R-SLAM,MASt3R-SLAM,"Official implementation of “MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors” (CVPR 2025). It provides a GPU-accelerated pipeline for real-time dense SLAM and 3D reconstruction, with scripts for running demos and evaluations on common SLAM datasets and live RealSense input.",2700,computer vision|SLAM|3D reconstruction|dense mapping|PyTorch|CUDA|robotics,8,"This repository implements a research-grade dense SLAM system that leverages learned 3D reconstruction priors (via MASt3R) to produce real-time tracking and dense 3D mapping. It is strongly relevant to ML/data workflows because it uses deep learning components (PyTorch + pretrained checkpoints) and supports standardized datasets (e.g., TUM-RGBD, EuRoC) that are commonly used for training/evaluation and benchmarking. While it is not a general-purpose ML framework, it is directly usable for ML-driven perception/reconstruction experiments and for generating/consuming 3D scene data, which justifies a high (but not maximal) score.",success
https://github.com/spiceai/spiceai,spiceai,"Spice is a portable, accelerated SQL query, search, and LLM-inference engine written in Rust for building data-grounded AI apps and agents. It exposes multiple standard interfaces (e.g., SQL/ODBC/JDBC/Arrow Flight, OpenAI-compatible APIs, Iceberg REST catalog, and MCP) and supports data federation, acceleration/materialization, and hybrid (text + vector) search.",2700,data engineering|sql query engine|data federation|vector search|RAG|LLM inference|Rust|Apache Arrow,8,"This repository provides a production-oriented runtime that unifies data access (federated SQL over databases/warehouses/lakes), search (including vector and full-text), and LLM inference behind standard APIs, positioning it directly in the critical path of many modern AI applications. It’s highly applicable to ML/LLM workflows such as RAG and agent systems by enabling grounded retrieval, hybrid search, and OpenAI-compatible serving, plus integration via MCP. While it is not a model-training framework, it is a strong enabling layer for data-centric AI systems and MLOps-style deployment patterns, which merits a high (but not maximal) score.",success
https://github.com/AI4Finance-Foundation/FinRL-Trading,FinRL-Trading,"FinRL Trading Platform v2.0 is a modular Python quantitative trading platform that supports data acquisition/processing, ML-based strategy development, professional backtesting, and live (paper/live) execution via Alpaca. It includes an end-to-end tutorial notebook demonstrating the full workflow from data fetching to deployment.",2600,quantitative-finance|algorithmic-trading|machine-learning|backtesting|portfolio-optimization|python|alpaca-api,8,"This repository provides an end-to-end quantitative trading workflow in Python, including multi-source data ingestion (e.g., Yahoo/FMP/WRDS), feature engineering, ML-based stock selection strategies, a backtesting engine, and live trading execution via Alpaca. It is directly applicable to ML/data workflows because it operationalizes dataset collection, model-driven signal generation, and evaluation (backtests/benchmarks) in a reusable architecture with runnable examples. Community adoption is solid (about 2.6k GitHub stars), and the included tutorial notebook and modular components make it educational and easy to integrate into research pipelines. It’s not a general-purpose ML framework, but it is highly valuable for applied ML in systematic trading, hence an 8/10.",success
https://github.com/alibaba/pipcook,pipcook,"Pipcook is an open-source machine learning platform/framework for JavaScript/Web developers, providing a pipeline system and tooling to train, evaluate, and package ML models for use from Node.js/JavaScript. It includes modular pipeline components and a bridge that enables calling Python ML libraries from the JavaScript runtime.",2600,machine learning|MLOps|pipeline orchestration|Node.js|JavaScript|Python bridge|model training,8,"This repository provides a JavaScript-focused ML engineering framework: a pipeline abstraction (datasets, training, validation, deployment) plus CLI tooling to train models and produce consumable outputs (e.g., packaged artifacts usable from JS). It is directly applicable to ML workflows for teams that want to build/train and serve models from Node.js and to integrate Python’s ML ecosystem (e.g., NumPy, scikit-learn, TensorFlow) via a JS↔Python bridge. It scores an 8 (highly relevant) because it is explicitly built for end-to-end ML pipelines and integration, though it is not a dominant mainstream ML framework on the level of PyTorch/TensorFlow and appears more niche to JS-centric ML use cases.",success
https://github.com/blmoistawinde/HarvestText,HarvestText,"HarvestText is a Python toolkit for text mining and preprocessing (with a focus on unsupervised/weakly-supervised methods) that supports tasks like text cleaning, segmentation, new word discovery, sentiment analysis, named entity recognition/linking, keyword extraction, summarization, and syntax-based information extraction.",2600,natural language processing|text mining|text preprocessing|chinese nlp|information extraction|sentiment analysis|entity linking|python,8,"This repository provides a practical NLP/text-mining toolkit with many features directly used in data science workflows, including preprocessing, weakly-supervised sentiment analysis, entity recognition/linking, keyword extraction, summarization (e.g., TextRank), and relation/knowledge extraction. It is clearly oriented toward analyzing real-world text corpora (especially Chinese), making it broadly applicable for exploratory text analytics and feature engineering. Its community adoption appears solid (2.6k GitHub stars), but it is not a general-purpose model-training framework like PyTorch/TensorFlow, which keeps it below a 9–10.",success
https://github.com/dmlc/gluon-nlp,gluon-nlp,"GluonNLP is an NLP toolkit for Apache MXNet/Gluon that provides utilities for loading and processing text data, plus modular APIs and pretrained models to train and deploy NLP models (with optional integrations like TVM for inference and AWS SageMaker).",2600,natural language processing|deep learning|machine learning|MXNet|Gluon|pretrained models|text processing|model inference,8,"This repository is a dedicated NLP toolkit (GluonNLP) focused on practical ML workflows such as dataset loading/preprocessing, model training APIs, and a pretrained model zoo. It is directly applicable to data science/ML engineering tasks in NLP and includes tooling (e.g., CLI dataset utilities) and deployment-oriented integrations (e.g., TVM experimental inference, SageMaker integration). Its relevance is somewhat reduced by ecosystem dependency (MXNet/Gluon) and the repository being archived (read-only), but it remains a strong, purpose-built ML/NLP codebase with substantial historical community adoption (2.6k stars).",success
https://github.com/lucidrains/big-sleep,big-sleep,"A Python CLI and library for text-to-image generation that optimizes a BigGAN image to match a text prompt using OpenAI CLIP guidance. It provides a `dream` command plus an `Imagine` API for advanced prompt control (e.g., multiple prompts, negative prompts, saving progress/best images).",2600,machine learning|generative ai|text-to-image|computer vision|pytorch|clip|gan,8,"This repository implements a practical text-to-image generation workflow by combining CLIP as a semantic guidance model with BigGAN as the image generator, exposed via both a command-line tool and a Python API. It is directly applicable to ML experimentation and prototyping in generative modeling (prompt-guided image synthesis) and is educational for understanding CLIP-guided optimization and GAN-based generation. While it is not a general-purpose ML framework and is more of a specific application/tool than broad infrastructure, it remains highly relevant to ML practitioners interested in generative methods and CLIP-based guidance.",success
https://github.com/om-ai-lab/OmAgent,OmAgent,"OmAgent is a Python library/framework for building multimodal language agents (text, image, video, audio) with a simple interface while hiding orchestration and scaling complexity. It provides a graph-based workflow engine, memory abstractions, support for VLMs and video processing, and example projects like video QA agents and a mobile personal assistant.",2600,multimodal agents|LLM|VLM|agent framework|reinforcement learning|workflow orchestration|computer vision|Python,8,"OmAgent’s primary purpose is to help developers and researchers build and deploy multimodal AI agents, including support for vision-language models, video understanding, and device (mobile) integration, with a graph-based workflow orchestration and memory system. This is directly applicable to ML engineering workflows for prototyping agentic applications and multimodal pipelines, and it includes practical demos (e.g., VQA/video QA, mobile assistant) plus support for local model deployment options. While it is not a core training framework like PyTorch nor a dedicated data-processing library, it is highly relevant for building ML-powered agent systems and multimodal applications, warranting a high (but not maximal) score.",success
https://github.com/spcl/graph-of-thoughts,graph-of-thoughts,"Official implementation of ""Graph of Thoughts: Solving Elaborate Problems with Large Language Models"". It provides a Python framework to model complex problem-solving as a Graph of Operations executed by an LLM, and can emulate related paradigms like Chain-of-Thought (CoT) and Tree-of-Thought (ToT).",2600,large-language-models|llm-orchestration|prompt-engineering|graph-based-reasoning|machine-learning|nlp|python,8,"This repository is an LLM reasoning/orchestration framework that lets users build and execute graph-structured workflows (Graph of Operations) driven by an LLM, with examples and experimentation code tied to the accompanying research paper. It is directly applicable to ML/NLP workflows for designing, evaluating, and comparing structured reasoning strategies (e.g., GoT vs. CoT/ToT) and can be integrated into prototyping and research pipelines that use LLM APIs. While it is not a general-purpose training framework or data-processing library, it has strong educational and practical value for LLM-based problem-solving and evaluation, which merits a high but not maximal score.",success
https://github.com/CamDavidsonPilon/lifelines,lifelines,"A pure-Python library for survival analysis, providing estimators and models (e.g., Kaplan–Meier and Cox regression) to analyze time-to-event data with censoring. It includes documentation, tutorials, and examples for applying survival/reliability methods in research and industry.",2500,python|data-science|statistics|survival-analysis|cox-regression|reliability-analysis,8,"This repository implements core survival analysis tooling in Python (time-to-event modeling with censoring), including widely used estimators and regression approaches such as Cox models. It is directly applicable to data science workflows in healthcare, customer churn, reliability engineering, and A/B test time-to-action analyses, and integrates naturally with the Python data stack. While it is not a general-purpose ML framework, it is a highly relevant specialized statistical/ML library with strong community adoption (notably high GitHub usage and many downstream dependents).",success
https://github.com/GeorgeSeif/Semantic-Segmentation-Suite,Semantic-Segmentation-Suite,"A TensorFlow-based semantic segmentation training framework that makes it easy to implement, train, test, and compare multiple segmentation architectures with built-in augmentation, metrics (e.g., mean IoU), and plotting utilities. The repository is archived (read-only) and described by the author as deprecated/no longer handling issues.",2500,computer vision|semantic segmentation|deep learning|tensorflow|model training|image segmentation|research code,8,"This repository is primarily an ML/computer-vision codebase: it provides a full pipeline to train and evaluate semantic segmentation models in TensorFlow, with multiple implemented architectures and common evaluation metrics (including mean IoU). It is directly useful for ML engineers for prototyping and benchmarking segmentation models and for educational purposes (reading/learning classic segmentation implementations). However, community adoption is moderate (a few thousand stars) and the project is archived/deprecated (archived July 5, 2021), which reduces practical value for production or up-to-date workflows compared to actively maintained alternatives.",success
https://github.com/benedekrozemberczki/awesome-decision-tree-papers,awesome-decision-tree-papers,"A curated “awesome list” of research papers on decision trees and tree ensembles (classification/regression trees), typically grouped by year/venue, with links to papers and (when available) implementations/code.",2500,machine learning|decision trees|tree ensembles|research papers|bibliography|explainable ai|classification|regression,8,"This repository is primarily a curated collection of decision tree and tree-ensemble research papers, often including links to implementations, making it directly useful for ML practitioners doing literature review or looking for reference code. It does not provide a single unified training library or dataset itself, but it strongly supports ML workflows by helping users discover relevant methods (e.g., interpretability, robustness, optimization of trees) and associated code. Its clear focus on ML and practical “paper + implementation” pointers justifies a high score, though not a 10 since it’s not a widely adopted core ML framework/tool.",success
https://github.com/curiousily/Getting-Things-Done-with-Pytorch,Getting-Things-Done-with-Pytorch,"A collection of Jupyter Notebook tutorials (and companion book materials) showing how to solve real-world machine learning/deep learning problems with PyTorch, spanning NLP, computer vision, and time series. Includes end-to-end examples such as BERT sentiment analysis (and FastAPI deployment), face/object detection (Detectron2/YOLOv5), and LSTM forecasting/anomaly detection.",2500,pytorch|deep-learning|machine-learning|jupyter-notebook|nlp|computer-vision|time-series|transformers,8,"This repository is primarily an applied ML education resource: a curated set of PyTorch notebooks (plus manuscript/book links) demonstrating common real-world tasks like classification, object/face detection, time-series forecasting/anomaly detection, and transformer-based sentiment analysis. It directly supports ML workflows by providing runnable examples and patterns for training and (in at least one case) deploying models (FastAPI). Community adoption appears solid for an educational repo (about 2.5k stars), but it is not a widely adopted production library/framework, which keeps it below a 9–10.",success
https://github.com/deepnote/deepnote,deepnote,"Deepnote Open Source is a drop-in successor/replacement for Jupyter notebooks centered around a human-readable .deepnote (YAML) project format, block-based notebooks (code/SQL/charts/inputs), and a reactive execution model. The repo provides tooling to convert between .ipynb and .deepnote and to edit/run Deepnote notebooks locally via integrations such as VS Code/Cursor/Windsurf and a JupyterLab extension, with a path to scaling into Deepnote Cloud collaboration and deployable apps.",2500,data-science-notebooks|jupyter|developer-tools|typescript|cli-tools|notebook-conversion|vs-code-extension|data-workflows,8,"This repository focuses on a modern notebook/workflow system positioned as a successor to Jupyter, including a new notebook/project file format (.deepnote), a block-based notebook model, reactive execution, and tooling to convert to/from .ipynb. It’s directly applicable to data science and ML workflows because notebooks are a primary medium for exploration, experimentation, reporting, and collaboration, and the repo targets local IDE usage plus integrations (e.g., VS Code and JupyterLab) that data practitioners already use. While it is not an ML framework itself (no modeling algorithms/training runtime like PyTorch), it strongly supports ML/data productivity via notebook authoring, version-control-friendly artifacts, and workflow tooling, hence a high (but not perfect) score.",success
https://github.com/kha-white/manga-ocr,manga-ocr,"Optical character recognition (OCR) for Japanese text focused on manga, using a custom end-to-end Transformer-based VisionEncoderDecoder model. It is designed to handle manga-specific scenarios like vertical/horizontal text, furigana, text over images, and multi-line speech bubbles in a single pass.",2500,optical character recognition|computer vision|deep learning|transformers|Japanese language|manga|Python,8,"This repository provides a practical, ML-powered OCR system for Japanese (with a strong manga focus) built around a Transformer vision-encoder/text-decoder architecture, making it directly applicable to real-world ML/CV workflows. It has clear value for ML engineers and data scientists working on OCR, document understanding, or Japanese text recognition, and it includes tooling intended for inference usage plus development/training-related code references. Community adoption appears solid for a specialized OCR model (e.g., ~2.5k stars and notable downstream usage), but it is narrower in scope than general-purpose ML frameworks, so it fits best as a high-quality applied OCR project rather than a foundational ML toolkit.",success
https://github.com/lmnr-ai/lmnr,lmnr,"Laminar is an open-source observability platform built for AI agents, providing OpenTelemetry-native tracing plus evals, monitoring, datasets/annotation, SQL querying, and dashboards. It includes SDKs (e.g., TS and Python) to instrument LLM/agent frameworks and a self-hostable stack (e.g., via Docker Compose).",2500,LLMOps|observability|tracing|OpenTelemetry|AI agents|evaluation|monitoring|TypeScript|Python|Rust,8,"This repository provides a full observability and evaluation platform for AI-agent/LLM applications, including OpenTelemetry-native tracing, eval tooling (SDK + CLI), monitoring, datasets/annotation, and dashboards. It directly supports common ML/LLM workflows by instrumenting model calls and agent steps, enabling experiment/eval tracking and operational monitoring in local dev and CI/CD. While it is not a model-training framework, it is highly applicable to modern LLM engineering (LLMOps) and production ML systems, which justifies a high score but not a 10.",success
https://github.com/paulpierre/RasaGPT,RasaGPT,"RasaGPT is a headless LLM chatbot platform/boilerplate built on top of Rasa and LangChain, providing a reference implementation for integrating retrieval-augmented generation (document upload, indexing, embeddings + pgvector) with a production-style backend (FastAPI) and channels like Telegram.",2500,llm|chatbots|rasa|langchain|fastapi|rag|vector-database|pgvector,8,"This repository provides an end-to-end reference implementation for building an LLM-powered chatbot using Rasa for conversation orchestration plus LangChain/LlamaIndex-style retrieval and context injection, exposed via FastAPI with document upload and a “training” workflow. It directly supports common ML/LLM engineering workflows like embeddings creation, similarity search in Postgres via pgvector, and RAG-style knowledge base augmentation, which makes it practically useful for ML engineers building applications. While it is not a core ML training framework and the author notes it is not production-hardened (security/prompt-injection caveats), it is still highly relevant as applied LLM tooling and integration code rather than general software infrastructure.",success
https://github.com/xusenlinzy/api-for-open-llm,api-for-open-llm,"An OpenAI-compatible (ChatGPT-style) HTTP API server for running and serving many open-source LLMs with consistent request/response formats, including streaming. It also provides embedding support, LangChain integration helpers, LoRA loading, and optional vLLM-based inference acceleration for concurrency.",2500,large-language-models|openai-api|inference-server|llm-serving|nlp|vllm|langchain,8,"This repository primarily provides an OpenAI-style API layer to serve multiple open-source LLMs (and embeddings) behind a unified interface, including streaming responses and optional vLLM acceleration for higher throughput. It is highly applicable to ML/LLM engineering workflows because it enables standardized deployment, testing, and integration of local/self-hosted models into applications that expect the OpenAI API schema (and it includes LangChain-related support). Community adoption appears strong (multi-thousand stars), suggesting practical usefulness and maturity. It is not a training framework, but as LLM serving/inference infrastructure it is highly relevant, hence an 8/10.",success
https://github.com/AminHP/gym-anytrading,gym-anytrading,"A collection of OpenAI Gym-compatible trading environments for developing and evaluating reinforcement learning trading agents. It provides a general TradingEnv base class plus ready-to-use ForexEnv and StocksEnv, with observation windows built from pandas DataFrames and a simple discrete Buy/Sell action space.",2400,reinforcement learning|OpenAI Gym|algorithmic trading|quant finance|Python|trading environments|pandas,8,"This repository’s primary purpose is to provide standardized Gym environments (TradingEnv, ForexEnv, StocksEnv) specifically for reinforcement learning-based trading research and experimentation. It directly supports common ML workflows by supplying a training/evaluation interface (observations, actions, rewards, episode stepping) that plugs into RL libraries and uses tabular market data (pandas DataFrames) as inputs. While it is not a full training framework (e.g., no built-in algorithms like PPO/DQN), it is highly applicable and widely useful as an environment layer for RL-in-finance projects, which justifies a high (but not maximum) score.",success
https://github.com/deeplearningturkiye/turkce-yapay-zeka-kaynaklari,turkce-yapay-zeka-kaynaklari,"Deep Learning Türkiye topluluğu tarafından derlenen, Türkiye’de/ Türkçe yapay zeka, derin öğrenme ve makine öğrenmesi alanındaki kaynakların (blog yazıları, video dersler, bilimsel makaleler, kodlar ve veri setleri) listelendiği bir rehber deposu.",2400,machine learning|deep learning|AI resources|Turkish language|education|datasets|research papers,8,"Bu depo, ML/DL ile ilgili Türkçe içerikleri kategoriler halinde derleyen bir “kaynak listesi/rehber” (awesome-list benzeri) olarak kullanılır; doğrudan bir kütüphane veya model eğitim aracı değildir. Buna rağmen veri setleri, makaleler, eğitimler, framework bağlantıları ve topluluk odaklı içerikler sunduğu için veri bilimi/ML öğrenimi ve keşif aşamasında oldukça yüksek pratik ve eğitim değeri sağlar. Geniş topluluk ilgisi (yaklaşık 2.4k yıldız) ve kapsamlı konu başlıkları nedeniyle 8/10 verdim; ancak doğrudan üretim iş akışına entegre edilen bir yazılım olmadığı için 9-10 seviyesinde değildir.",success
https://github.com/dipanjanS/practical-machine-learning-with-python,practical-machine-learning-with-python,"Companion repository for the book ""Practical Machine Learning with Python"", containing Jupyter notebooks, code examples, figures, and bonus materials that walk through end-to-end machine learning pipelines and real-world case studies using the Python ML ecosystem (e.g., pandas, scikit-learn, TensorFlow/Keras, NLP libraries).",2400,machine learning|deep learning|python|jupyter notebooks|scikit-learn|tensorflow|data science education|nlp,8,"This repository is primarily an educational codebase that accompanies a machine learning book, providing notebooks and worked examples across the ML lifecycle (data wrangling, feature engineering, modeling, tuning, and deployment concepts) plus multiple applied case studies. It is highly relevant for ML/data workflows as practical reference material and starter implementations using common Python ML tools (e.g., pandas/scikit-learn and deep learning frameworks). However, it is not a standalone production ML library/framework with broad industry integration or ongoing community-driven feature development, so it scores below 9–10 despite strong learning value.",success
https://github.com/explosion/spacy-course,spacy-course,"Repository for the free online course “Advanced NLP with spaCy” (course.spacy.io), including the interactive course content (chapters/exercises in multiple languages) and the open-source web framework used to deliver it. It teaches building NLP systems with spaCy using both rule-based techniques and machine learning approaches, with interactive code execution via Binder.",2400,natural language processing|NLP education|spaCy|machine learning|Python|course platform|Gatsby,8,"This repository primarily provides an interactive learning course focused on applied NLP using spaCy, covering both rule-based pipelines and machine-learning-based approaches. While it’s not a general-purpose ML framework or a production training library, it is directly useful to data scientists/ML practitioners as structured educational material with hands-on exercises and runnable environments (e.g., via Binder). Its strong community adoption (high GitHub stars) and practical, workflow-relevant NLP content make it highly valuable for ML/data learning and onboarding, warranting an 8/10.",success
https://github.com/fhamborg/news-please,news-please,"An open-source Python news crawler and article information extractor that can crawl news sites (via root URLs, internal links, and RSS) and output structured article data. It also supports extracting articles from Common Crawl’s news archive and can be used via a CLI or as a Python library.",2400,web scraping|news crawling|information extraction|data collection|python|scrapy|common crawl|NLP,8,"This repository primarily focuses on collecting and extracting structured content from news articles at scale (including Common Crawl), which is a core upstream step for many ML/NLP workflows such as dataset creation, topic modeling, classification, and event/sentiment analysis. While it is not a model-training framework itself, it provides direct, practical value for data scientists by automating acquisition and normalization of text + metadata (title, authors, publish date, language, main text, etc.) and supporting storage backends (e.g., JSON, PostgreSQL, Elasticsearch). Its relatively strong community adoption (2.4k GitHub stars) and ready-to-use CLI/library interface justify a high score focused on ML/data enablement rather than ML algorithms.",success
https://github.com/numaproj/numaflow,numaflow,"Numaflow is a Kubernetes-native, serverless platform for running scalable, reliable, massively-parallel data and stream-processing pipelines (event-driven applications). It provides language-agnostic pipeline steps, autoscaling with back-pressure, built-in observability, and strong delivery guarantees including exactly-once semantics for supported streaming sources.",2400,kubernetes|stream-processing|data-engineering|event-driven|data-pipelines|serverless|distributed-systems,8,"Numaflow is primarily a Kubernetes-native platform for building and operating streaming/data-processing pipelines with autoscaling and delivery guarantees, which makes it directly useful for production data engineering. It is highly relevant to ML/data workflows because it supports real-time analytics and streaming inference use cases, and can be used to run feature pipelines or online inference pipelines (though it is not itself an ML training framework). The score reflects strong applicability and integration potential for ML ops/data platforms, while being less central than core ML libraries/frameworks.",success
https://github.com/pipeshub-ai/pipeshub-ai,pipeshub-ai,"PipesHub is an extensible workplace AI platform for enterprise search and workflow automation across common business apps (e.g., Google Workspace, Microsoft 365, Slack, Jira, Confluence). It emphasizes explainable results with citations and a knowledge-graph-backed architecture, and supports building custom apps/AI agents (including via a no-code interface).",2400,enterprise search|LLM applications|RAG|knowledge graph|vector database|workflow automation|FastAPI|LangChain,8,"This repository provides an end-to-end workplace AI/search platform that integrates LLM workflows (LangChain/LangGraph), vector search (Qdrant), and a graph/document database (ArangoDB) to deliver retrieval-augmented, citation-backed enterprise search and automation. It is directly applicable to ML/DS workflows for building and deploying RAG systems, document ingestion/indexing pipelines, and agentic workflow automation in production-like settings. The score is high because it is ML-centric infrastructure with clear integration points to common ML components, but it is not a foundational ML library/framework nor (based on the repo page) a widely adopted industry-standard on the scale of major ML ecosystems.",success
https://github.com/reiinakano/scikit-plot,scikit-plot,"Scikit-plot is a Python library that adds convenient, single-function plotting utilities for common machine learning evaluation and analysis tasks, designed to work naturally with scikit-learn-style inputs. It provides quick visualizations (e.g., ROC curves, precision-recall curves, confusion matrices) with minimal boilerplate on top of Matplotlib.",2400,machine learning|data visualization|scikit-learn|python|matplotlib|model evaluation|classification metrics,8,"This repository provides an easy-to-use plotting layer for typical ML workflows, especially for evaluating classification models (e.g., ROC and precision-recall curves) with scikit-learn-compatible inputs. It is directly applicable to day-to-day data science work because it reduces boilerplate for standard evaluation visualizations and integrates cleanly with scikit-learn and Matplotlib. While it is not a training framework or pipeline system, its strong focus on ML evaluation/visualization makes it highly relevant and practical for ML practitioners, justifying a score of 8.",success
https://github.com/D-X-Y/Awesome-AutoDL,Awesome-AutoDL,"A curated “awesome list” of resources for Automated Deep Learning (AutoDL), including blogs, AutoML/NAS libraries, benchmarks (e.g., NAS-Bench series), and paper collections organized by venue and year. It serves primarily as a reference hub for neural architecture search (NAS) and related hyperparameter optimization (HPO) literature and tooling.",2300,automl|automated deep learning|neural architecture search|hyperparameter optimization|benchmarking|research papers|awesome-list,8,"This repository is an “awesome list” focused on Automated Deep Learning, compiling key references across NAS/HPO papers, benchmarks (e.g., NAS-Bench and related suites), and notable AutoML libraries. It is highly relevant to ML workflows because it helps practitioners and researchers discover established datasets/benchmarks and tooling ecosystems used for architecture and hyperparameter search, though it is not itself a training framework. Community adoption appears strong for a reference repository (on the order of ~2.3k stars), indicating meaningful utility and educational value. I assigned an 8 because it is highly useful for learning and navigating AutoDL/NAS resources, but it provides limited direct executable functionality compared to core ML frameworks or pipelines.",success
https://github.com/OpenLineage/OpenLineage,OpenLineage,"OpenLineage is an open standard and set of libraries/integrations for collecting data lineage and operational metadata from running jobs (runs, jobs, datasets) via a common event model. It defines an extensible lineage specification (facets) and provides integrations for data platforms like Airflow, Spark, dbt, and Flink, enabling consistent emission of lineage events to compatible backends.",2300,data lineage|data engineering|data observability|metadata|OpenAPI|Apache Airflow|Apache Spark|MLOps,8,"This repository provides an open standard (schema/spec) plus tooling and integrations to emit lineage events for data jobs, datasets, and runs, enabling end-to-end traceability and operational metadata collection across data pipelines. While it is not an ML algorithm library, it is directly applicable to ML/data workflows because ML pipelines are typically orchestrated and executed on the same data platforms (e.g., Airflow/Spark) and benefit from lineage for reproducibility, debugging, governance, and impact analysis. It also has meaningful ecosystem adoption as a Linux Foundation LF AI & Data project with multiple producer/consumer integrations, making it highly useful for MLOps and data platform engineering. The score is 8 (highly relevant) because it materially improves ML/data operational capabilities, even though it is not itself a model training/serving framework.",success
https://github.com/Separius/awesome-sentence-embedding,awesome-sentence-embedding,"An ""awesome list""-style curated catalog of pretrained sentence and word embedding models, organized with tables and links to papers, code, and pretrained weights across classic and contextual embedding approaches. The repository also includes JSON data files and a generator script used to build/update the list.",2300,natural language processing|sentence embeddings|word embeddings|representation learning|pretrained models|awesome-list|research papers,8,"This repository is a curated reference list of pretrained sentence and word embedding models, with structured tables linking to key papers, implementations, and downloadable pretrained weights. It is highly relevant to ML/NLP workflows because practitioners can use it to discover and select embedding models for downstream tasks (similarity, retrieval, classification, clustering) and to compare approaches and evaluation resources. While it is not an executable training/inference library itself (so it’s less directly “plug-and-play” than a framework), its educational and practical value for model selection is strong and it has meaningful community adoption (2.3k stars).",success
https://github.com/approximatelabs/sketch,sketch,"Sketch is an AI code-writing assistant for pandas users that summarizes tabular data (“data sketches”) and feeds that context to language models to produce more relevant answers and code suggestions. It adds a .sketch extension to pandas DataFrames with helpers like ask, howto, and apply for Q&A, code generation, and feature/data generation workflows.",2300,python|data-science|pandas|tabular-data|llm|code-generation|data-summarization|data-sketches,8,"This repository provides a pandas-centric assistant that uses compact statistical summaries of DataFrame columns to give LLMs better context for answering questions and generating analysis/cleaning/feature-engineering code. It is directly applicable to common data science workflows (EDA, data cleaning, transformations, basic modeling scaffolding) via df.sketch.ask/howto/apply, and it integrates with LLM backends (including OpenAI and some Hugging Face options per the README). While it is not a model-training framework itself, it meaningfully improves day-to-day data work and has notable community adoption (2.3k GitHub stars), which supports an 8/10 score rather than a perfect 10.",success
https://github.com/instill-ai/instill-core,instill-core,"Instill Core is an end-to-end, full-stack AI infrastructure platform for orchestrating unstructured data pipelines, components, and model serving. It helps teams build AI-first applications by transforming documents/images/audio/video into AI-ready formats and supporting RAG and workflow automation via APIs and a no-code console.",2300,unstructured-data|data-pipelines|rag|llmops|mlops|model-serving|kubernetes|docker-compose,8,"This repository provides a full-stack platform (Instill Core CE) for building and running unstructured-data ETL pipelines, transforming data into AI-ready artifacts, and deploying/monitoring models as API services, with local (Docker Compose) and scalable (Kubernetes/Helm) deployment options. It is highly applicable to ML/data workflows—especially RAG systems and LLM-centric applications—because it focuses on data ingestion/processing, orchestration, and model operations rather than just application UI. While it is not a model-training framework like PyTorch, it is a strong MLOps/LLMOps and data-orchestration system with meaningful adoption (2.3k GitHub stars), justifying a high (but not maximal) score.",success
https://github.com/justmarkham/pandas-videos,pandas-videos,"Jupyter notebooks and example datasets that accompany Data School’s Python pandas video series (and related bonus lessons), covering core pandas workflows and common data-wrangling tasks.",2300,pandas|python|data analysis|data wrangling|jupyter notebooks|education|tutorial,8,"This repository is primarily an educational collection of pandas notebooks and datasets tied to a structured video course/playlist, intended to teach practical tabular data manipulation and analysis. Pandas is foundational in most data science/ML workflows for data loading, cleaning, feature engineering, and exploratory analysis, so the materials are directly useful to practitioners and learners. It is not an ML training framework or modeling library itself, but it strongly supports upstream ML tasks and includes content relevant to working with scikit-learn-style pipelines (e.g., preparing data for submissions). Based on its direct applicability and educational value for data workflows (but not being a core model-training tool), an 8/10 is appropriate.",success
https://github.com/salesforce/decaNLP,decaNLP,"Reference implementation for the Natural Language Decathlon (decaNLP), a multitask NLP benchmark that casts 10 diverse NLP tasks as question answering and trains/evaluates models such as the Multitask Question Answering Network (MQAN). Includes code for data handling, training, prediction, and evaluation across tasks (with Docker-based workflows).",2300,natural language processing|multitask learning|question answering|PyTorch|benchmark|research code|deep learning,8,"This repository provides the codebase for the Natural Language Decathlon, packaging ten NLP tasks into a unified question-answering format and supplying training/evaluation tooling and a multitask model (MQAN). It is directly useful for ML researchers/engineers working on multitask learning, transfer learning, and benchmarking in NLP, and it is educational as a concrete, end-to-end research implementation. However, it is archived (read-only) and targets older PyTorch-era setups, which reduces integration ease for modern production workflows, keeping it below a 9–10 despite strong relevance.",success
https://github.com/achillesrasquinha/bulbea,bulbea,"Bulbea is a deep learning–based Python library for stock market prediction and modeling. It provides utilities for loading market data, preprocessing/splitting datasets, training neural-network models (e.g., RNNs), and includes a sentiment-analysis component (e.g., via Twitter/TextBlob) to support quantitative finance workflows.",2200,machine learning|deep learning|time series|stock market prediction|quantitative finance|sentiment analysis|python|RNN,8,"This repository is explicitly built for ML-driven stock market forecasting and modeling, providing end-to-end examples that cover data loading, preprocessing, model training (notably RNN-based), and evaluation. It directly supports common data-science workflows (time-series modeling and feature augmentation via sentiment analysis), and it integrates with standard ML/data tooling (e.g., TensorFlow/Keras-style deep learning plus common Python data/science libraries). While it is clearly ML-focused and reasonably adopted for its niche (thousands of GitHub stars), it is not a foundational, broadly used ML framework, and parts of its approach/dependencies may be dated for modern production finance pipelines—hence an 8 rather than a 9–10.",success
https://github.com/chiphuyen/lazynlp,lazynlp,"A Python library for crawling/scraping web pages, cleaning the extracted text, and deduplicating URLs/pages to build large-scale monolingual text datasets (e.g., for training language models). It includes utilities for downloading pages from URL lists and cleaning HTML into normalized plain text.",2200,natural language processing|dataset creation|web scraping|web crawling|data cleaning|deduplication|python,8,"This repository is primarily designed to help users build massive text datasets by crawling URLs, extracting/cleaning webpage text, and deduplicating at the URL/file level, which is a common upstream step for training NLP and language models. It is directly applicable to ML/data workflows for corpus construction and preprocessing, though it is not a modeling/training framework itself. Community adoption appears solid (about 2.2k GitHub stars), indicating meaningful usage and educational value for practitioners assembling large text corpora.",success
https://github.com/pretzelai/pretzelai,pretzelai,"Pretzel is a modern, open-source fork of JupyterLab positioned as a replacement for Jupyter Notebooks, adding AI-assisted coding features like inline tab completion, in-notebook “Ask AI” code generation/editing, sidebar chat, and error fixing while keeping compatibility with existing Jupyter settings and extensions.",2200,jupyterlab|notebooks|data-science|developer-tools|ai-assistant|code-completion|typescript|python,8,"This repository primarily provides an enhanced JupyterLab-based notebook environment, adding AI-driven coding assistance (inline completions, chat, code generation/editing, and error fixing) on top of the standard Jupyter workflow. It is highly relevant to ML/data practitioners because Jupyter notebooks are a core tool in data science, and these features directly improve day-to-day exploratory analysis, prototyping, and iteration speed. While it is not an ML framework or training library itself, it integrates into ML/data workflows as a productivity layer over the most common interactive computing environment, warranting a high (but not “core framework”) score.",success
https://github.com/sfu-db/dataprep,dataprep,"DataPrep is an open-source low-code Python library for data preparation, providing modules to collect data from common sources, perform exploratory data analysis (EDA) with interactive profiling reports, and clean/standardize dataframes (including optional notebook GUI workflows).",2200,data preparation|exploratory data analysis|data cleaning|python|pandas|dask|jupyter,8,"This repository provides a practical, end-to-end data preparation toolkit (connectors, automated/interactive EDA reports, and dataframe cleaning/standardization utilities) aimed at accelerating analysis workflows in Python. It is directly applicable to ML/data science work because data collection, EDA, and cleaning are core steps in most model-building pipelines, and the project explicitly supports Pandas/Dask and notebook-based usage. While it is not an ML modeling framework itself, it meaningfully improves the upstream data quality and understanding that ML practitioners rely on, and its feature set (profiling reports, auto-insights, scalable computation via Dask) makes it highly valuable for real-world datasets.",success
https://github.com/Thinklab-SJTU/awesome-ml4co,awesome-ml4co,"A curated “awesome list” of machine learning for combinatorial optimization (ML4CO) resources, primarily papers and surveys, organized by problem type (e.g., TSP, VRP, JSSP, SAT, MIP). It also highlights related benchmarks/toolkits from SJTU Thinklab and the broader community.",2100,machine learning|combinatorial optimization|research papers|survey|reinforcement learning|graph neural networks|neural combinatorial optimization,8,"This repository is an actively maintained, structured bibliography of ML4CO literature (surveys and problem-specific papers), plus pointers to benchmarks/toolkits in the same ecosystem. It’s highly relevant to ML/data workflows for researchers and practitioners working on decision-making, reinforcement learning, and learning-based solvers because it accelerates literature review, problem framing, and method selection. However, it’s primarily a resource index rather than a direct ML framework or production-grade library, which limits immediate integration into pipelines compared to core ML tooling—hence an 8/10 rather than 9–10.",success
https://github.com/cerlymarco/MEDIUM_NoteBook,MEDIUM_NoteBook,"A collection of Jupyter notebooks accompanying the author's Medium posts, covering a wide range of applied data science and machine learning topics (e.g., anomaly detection, time series forecasting, model explainability, uncertainty estimation). The repository serves primarily as educational/reference code and experiments rather than a single packaged library.",2100,machine learning|data science|jupyter notebooks|time series|anomaly detection|model explainability|forecasting,8,"This repository aggregates many ML/data-science notebooks tied to Medium articles, spanning practical techniques such as anomaly detection (including LSTM/VAR variants), forecasting/uncertainty, and explainability. It is directly useful for ML practitioners as a learning resource and as runnable reference implementations, though it is not a cohesive, production-ready framework or toolkit. Community adoption appears solid for an educational notebook repo (about 2.1k GitHub stars), supporting a high relevance score but not a 9–10 reserved for widely adopted core ML libraries.",success
https://github.com/deepklarity/jupyter-text2code,jupyter-text2code,A proof-of-concept Jupyter Notebook extension that converts English queries into relevant Python code inside notebooks. It supports intent/snippet insertion (including pandas-oriented commands) using an embedding-based approach and includes guidance for training and extending intents/entities.,2100,jupyter|jupyter-nbextension|python|nlp|text-to-code|machine-learning|sentence-transformers|pandas,8,"This repository provides a Jupyter Notebook extension that translates natural-language requests into Python code/snippets, aimed at streamlining exploratory data analysis and notebook workflows. It is directly relevant to ML/data science because it integrates into Jupyter and leverages NLP/embeddings (e.g., SentenceTransformers) for intent detection and code generation/snippet retrieval. While it’s labeled as a proof-of-concept and not a widely adopted core framework, its practical notebook integration and ML-based approach make it highly useful for data/ML productivity and experimentation.",success
https://github.com/heshengtao/comfyui_LLM_party,comfyui_LLM_party,"An LLM agent framework implemented as a ComfyUI extension, providing nodes and integrations for building agentic workflows (e.g., MCP server/tools, OCR, TTS/voice, prompt utilities) and connecting to many LLM providers via OpenAI-like interfaces, including support for local models.",2100,ComfyUI|LLM agents|generative AI|workflow orchestration|MCP|NLP|local LLMs|OCR/TTS,8,"This repository primarily targets ML practitioners building agentic LLM workflows inside ComfyUI, adding nodes and integrations (e.g., MCP tooling, prompt nodes, OCR, TTS/voice, and connectors to multiple hosted and local LLM/VLM backends). It is directly applicable to ML/NLP prototyping and automation because it provides a workflow UI and glue code to orchestrate models and external tools in repeatable pipelines. Community adoption appears strong for a niche ComfyUI ecosystem project (about 2.1k GitHub stars and 164 forks), which supports a high relevance score, though it is not a general-purpose ML training framework on the scale of core libraries like PyTorch.",success
https://github.com/jamwithai/arxiv-paper-curator,arxiv-paper-curator,"A learner-focused, production-oriented project/course for building an end-to-end arXiv research assistant using Retrieval-Augmented Generation (RAG). It includes infrastructure (Docker, FastAPI, PostgreSQL, OpenSearch, Airflow), automated paper ingestion, BM25 + hybrid retrieval, a full RAG pipeline with a UI (Gradio), monitoring (Langfuse), caching (Redis), and an agentic workflow with LangGraph plus a Telegram bot integration.",2100,retrieval-augmented generation (RAG)|LLM applications|search (BM25 / OpenSearch)|data pipelines (Airflow)|FastAPI|MLOps / observability (Langfuse)|hybrid search|Gradio,8,"This repository is designed to teach and implement a production-grade RAG system that ingests arXiv papers, indexes them for keyword/hybrid retrieval, and answers questions via an LLM-backed pipeline with a chat UI. It directly supports common ML/data workflows (document ingestion, chunking, indexing, retrieval, evaluation/monitoring, and serving) and integrates standard tooling used in applied NLP/LLM engineering (FastAPI, OpenSearch, Airflow, Langfuse, LangGraph, Gradio, Docker). While it is not a general-purpose ML framework or model-training library, it is highly applicable for data/ML engineers building LLM-powered knowledge systems, hence a high (but not perfect) score.",success
https://github.com/ivan-bilan/The-NLP-Pandect,The-NLP-Pandect,"A curated “pandect” (encyclopedia) of online resources for Natural Language Processing, organized into a large table of contents covering research resources, datasets, benchmarks, frameworks, learning materials, and related NLP topics. It functions primarily as a comprehensive reference/awesome-list rather than a runnable software library.",2000,NLP|natural-language-processing|awesome-list|machine-learning|deep-learning|datasets|benchmarks|learning-resources,8,"This repository is a large, structured directory of NLP resources (papers, datasets, benchmarks, tools/frameworks, and educational materials), intended to help users find high-quality NLP references across many subtopics. It is highly relevant to ML/data workflows because it directly supports literature review, dataset discovery, and tool selection, which are common tasks for data scientists and ML engineers. While it is not itself a modeling/training framework or data pipeline, its breadth and organization make it very valuable as a practical guide and roadmap for NLP work. The relatively strong community adoption (about 2k stars) supports an 8/10 rather than a perfect score reserved for core ML tooling with major industry adoption.",success
https://github.com/AutoViML/AutoViz,AutoViz,AutoViz is a Python library that automatically generates exploratory data analysis (EDA) visualizations for a dataset (any size) with minimal code. It focuses on quickly producing insightful plots and includes data-quality assessment and a FixDQ() utility to help address common data-quality issues.,1900,python|data-visualization|exploratory-data-analysis|automated-eda|data-science|data-quality|pandas,8,"AutoViz is primarily an automated EDA/data visualization tool intended to help users rapidly understand datasets by generating a suite of plots with very little code. This is directly applicable to ML/data-science workflows because EDA and data-quality checks are core steps before feature engineering and model training, and the repo explicitly supports dataset quality assessment and remediation. It also shows meaningful community adoption (about 1.9k GitHub stars), but it is not a model-training/framework tool, so it scores below core ML frameworks while still being highly valuable for data practitioners.",success
https://github.com/ContextLab/hypertools,hypertools,"HyperTools is a Python toolbox for dimensionality-reduction-based visual exploration of high-dimensional data. It provides a simple pipeline to reduce one or more datasets (e.g., via common DR methods) and plot them using familiar scientific Python tooling.",1900,dimensionality reduction|data visualization|python|scikit-learn|umap|matplotlib|exploratory data analysis,8,"This repository provides a dedicated toolkit for exploring high-dimensional datasets using dimensionality reduction and visualization in Python, built on top of common ML/data libraries (e.g., scikit-learn, matplotlib, seaborn, umap-learn). It directly supports data science workflows for exploratory data analysis, representation inspection, and communicating structure in embeddings/projections. While it is not a model-training framework itself, it is highly applicable to ML/data projects and has meaningful community adoption (on the order of ~1.9k GitHub stars).",success
https://github.com/Marktechpost/AI-Tutorial-Codes-Included,AI-Tutorial-Codes-Included,"A collection of code and Jupyter notebooks for hands-on AI/ML tutorials and projects, covering topics like agentic workflows, LLM evaluation, RAG, computer vision, reinforcement learning, and related tooling.",1900,machine learning|jupyter notebooks|llms|rag|ai agents|computer vision|llm evaluation|reinforcement learning,8,"This repository primarily serves as a curated set of runnable tutorial notebooks and project code for modern AI topics (notably LLM/agentic systems, RAG, evaluation, and other applied ML areas). It is directly usable by data scientists and ML engineers as reference implementations and starting points for experiments, prototyping, and learning workflows. While it is not a single cohesive production library/framework with a stable API, its broad educational and practical applicability across ML tasks makes it highly valuable for ML/data work, hence a score of 8 rather than 9–10.",success
https://github.com/VivekPa/AIAlpha,AIAlpha,"AIAlpha is an educational financial machine learning project that builds a pipeline to predict stock returns/direction using tick-derived bars, feature engineering, dimensionality reduction via a stacked autoencoder, and downstream models (including an LSTM regressor and a Random Forest classifier). It includes scripts to preprocess data, train models, and run end-to-end experiments (with a small sample dataset due to repository size limits).",1900,financial machine learning|algorithmic trading|time series forecasting|deep learning|autoencoders|LSTM|random forest|feature engineering,8,"This repository implements a practical end-to-end ML workflow for financial time-series prediction: creating tick/volume/dollar bars, engineering features, compressing them with a stacked autoencoder, and training predictive models (LSTM regression and Random Forest classification). It is directly applicable to ML/data workflows as a template for data preprocessing + representation learning + supervised modeling, and it has meaningful educational value by explaining each pipeline stage in the README. It is not a widely adopted industry-standard library/framework and the full original dataset is not included (only a limited sample), which reduces plug-and-play utility and community integration; these factors keep it below a 9–10.",success
https://github.com/minimaxir/automl-gs,automl-gs,"A Python AutoML command-line tool that takes a tabular CSV plus a target column and performs hyperparameter search to produce a high-performing model along with fully generated, editable native Python code for the training/prediction pipeline. It supports regression and classification, emphasizing transparent preprocessing and reproducible artifacts (model script, pipeline script, results CSV, and serialized encoders).",1900,AutoML|tabular machine learning|Python|feature engineering|hyperparameter search|TensorFlow/Keras|XGBoost|CLI tool,8,"This repository is a purpose-built AutoML utility for supervised learning on tabular CSV data, automatically handling preprocessing (e.g., categorical/datetime encoding) and running multiple trials to find strong baseline models. It directly fits common ML workflows because it outputs native Python code (model + pipeline) and training metrics, making it easy to integrate, retrain, and productionize without vendor/platform lock-in. While it is clearly ML-focused and practically useful, its framework coverage is relatively limited (primarily TensorFlow/Keras and XGBoost) and community adoption is moderate rather than ecosystem-defining, so it scores below the top-tier industry-standard tools.",success
https://github.com/robertmartin8/MachineLearningStocks,MachineLearningStocks,"A Python starter project/guide for building a fundamentals-based machine learning stock predictor: it prepares historical price + fundamental datasets with pandas, trains a scikit-learn classifier to predict stock outperformance, and includes simple backtesting plus generating predictions on current data.",1900,machine learning|quantitative finance|stock prediction|python|scikit-learn|pandas|backtesting,8,"This repository is explicitly focused on an end-to-end ML workflow for equity prediction: data acquisition/cleaning, feature engineering from fundamentals, model training with scikit-learn, and backtesting/prediction scripts. It is directly applicable for data scientists learning or prototyping tabular ML for financial markets, and it includes example datasets/CSVs to keep the pipeline runnable even when upstream data sources are unreliable. However, it is noted as no longer actively maintained (per the README), and it is not a broadly adopted production-grade library/framework, which keeps it below the very top scores.",success
https://github.com/szilard/benchm-ml,benchm-ml,"A minimal benchmarking suite comparing scalability (runtime/memory), speed, and accuracy (AUC) of popular open-source machine learning implementations for large-scale binary classification (e.g., linear models, random forests, boosting/GBMs, and deep neural networks) across tools such as R packages, scikit-learn, H2O, xgboost/lightgbm, Vowpal Wabbit, and Spark MLlib.",1900,machine learning|benchmarking|binary classification|scikit-learn|xgboost|lightgbm|spark-mllib|R,8,"This repository provides a practical, experiment-oriented benchmark focused on training time, memory usage, and predictive performance (AUC) for common ML algorithms and implementations on increasingly large tabular datasets. It is directly relevant to ML/data workflows because it helps practitioners evaluate tool/algorithm tradeoffs (scalability and speed vs. accuracy) across widely used ecosystems (R, Python/scikit-learn, H2O, xgboost/lightgbm, Spark). It is not a general-purpose ML framework, but it has high educational and applied value for model/tool selection and performance testing, and shows meaningful community interest (about 1.9k GitHub stars).",success
https://github.com/uber/petastorm,petastorm,"Petastorm is a Python data access library for reading datasets stored in Apache Parquet for single-machine or distributed deep learning training and evaluation. It integrates with common ML/data ecosystems including TensorFlow, PyTorch, and PySpark, and can also be used from plain Python code.",1900,machine learning|data engineering|apache parquet|pyspark|tensorflow|pytorch|distributed training,8,"Petastorm’s primary purpose is to enable efficient access to Parquet-backed datasets for model training/evaluation in both single-node and distributed settings. It is directly applicable to ML workflows because it provides dataset reading APIs and integrations for TensorFlow, PyTorch, and Spark-based pipelines, bridging data storage (Parquet) with training input pipelines. Community adoption appears solid for a specialized library (around 1.9k GitHub stars), but it is not a general-purpose core ML framework, so it scores below 9–10. Overall it is highly relevant for ML engineers working with large-scale Parquet data and Spark-based ETL who need consistent input pipelines into training code.",success
https://github.com/youngfish42/Awesome-FL,Awesome-FL,"A curated, regularly updated collection of federated learning resources, including academic papers (organized by venue/category), frameworks, datasets, surveys, tutorials/courses, and relevant conferences/workshops/journals. It also references an auxiliary tracker project for automatically monitoring updates to FL papers.",1900,federated learning|machine learning|deep learning|research papers|datasets|ML frameworks|privacy-preserving ML|awesome-list,8,"This repository is primarily a curated knowledge base for federated learning, organizing papers by top-tier venues and categories and aggregating practical resources like frameworks, datasets, surveys, and tutorials. It is highly relevant to ML/data workflows because it directly supports literature review, method selection, and tooling discovery for federated learning research and engineering. While it is not itself a training/inference framework, its breadth, structure, and community adoption (high star count) make it very valuable for ML practitioners, hence an 8/10 rather than a 9–10 reserved for core ML tooling.",success
https://github.com/Yvictor/TradingGym,TradingGym,"TradingGym is an OpenAI Gym–inspired trading and backtesting environment for training reinforcement learning agents (or testing simple rule-based strategies) on market data such as tick data and OHLC. It provides configurable environments (e.g., training and backtest modes) and examples for stepping through market episodes and collecting transaction details.",1800,reinforcement learning|algorithmic trading|backtesting|openai-gym|python|financial time series|trading environment,8,"This repository’s primary purpose is to provide a Gym-like environment specifically for training and evaluating (backtesting) reinforcement learning trading agents, including state/step/reward mechanics and transaction tracking. That makes it directly applicable to ML workflows involving RL on financial time-series data (data loading, environment simulation, experimentation). While it does not appear to be a full training framework with completed example agents (several training sections are marked WIP), it is still highly relevant as an environment component and shows meaningful community adoption (≈1.8k GitHub stars).",success
https://github.com/skfolio/skfolio,skfolio,"skfolio is a Python library for portfolio optimization and risk management built on top of scikit-learn. It provides scikit-learn-compatible tools to build, tune, cross-validate, and stress-test portfolio optimization models (e.g., mean-risk, risk budgeting, hierarchical risk parity, and related estimators).",1800,python|portfolio-optimization|quant-finance|risk-management|scikit-learn|cvxpy|time-series|backtesting,8,"This repository implements a scikit-learn-style framework specifically for quantitative portfolio optimization and risk management, including model selection, cross-validation, and stress testing workflows. It is directly applicable to data science/ML workflows because it treats portfolio construction as an estimator/pipeline problem and integrates with standard sklearn tooling (pipelines, CV, hyperparameter search). While it is not a general-purpose ML framework, it is a highly relevant applied ML/statistics library for financial data problems with meaningful community adoption (about 1.8k GitHub stars), warranting a high score but not a 10.",success
https://github.com/tidyverse/tidyverse,tidyverse,"The tidyverse R package makes it easy to install and load a set of core tidyverse packages in one step, providing a cohesive collection of tools that share common data structures and API design for data science workflows (e.g., ggplot2, dplyr, tidyr, readr, purrr, tibble).",1800,r|data-science|data-wrangling|data-visualization|statistics|tidyverse|package-management,8,"This repository contains the source for the 'tidyverse' R meta-package, which streamlines installing and attaching the core tidyverse packages and provides utilities like conflict reporting and update checks. It is directly applicable to data science workflows because it underpins common tasks like data import, cleaning, transformation, and visualization, which are foundational steps in most ML pipelines. While it is not an ML model training framework itself, it is widely adopted in the data/ML community (especially in R) and provides high educational and practical value for preparing and exploring data. Based on its strong relevance to data workflows and broad adoption, but indirect focus on model training, it merits an 8/10.",success
https://github.com/ClimbsRocks/auto_ml,auto_ml,"An (unmaintained) Python AutoML library for quickly training optimized classifiers/regressors from a pandas DataFrame, with a production-oriented API for fast single-row predictions plus model saving/loading. It integrates with common ML stacks (scikit-learn) and optional third-party learners like XGBoost, LightGBM, CatBoost, and TensorFlow/Keras.",1700,automl|machine-learning|python|scikit-learn|feature-engineering|model-training|tabular-data|model-deployment,8,"This repository provides an end-to-end automated machine learning workflow (training, scoring, and model serialization/loading) via a simple Predictor API, aimed at both analytics and production use. It is directly applicable to typical tabular ML tasks and can integrate with widely used ML libraries (e.g., scikit-learn; optional XGBoost/LightGBM/CatBoost/TensorFlow-Keras integrations), making it useful in real ML workflows. However, it is explicitly marked UNMAINTAINED and appears to have relatively old activity, which reduces practical value today despite meaningful adoption (~1.7k GitHub stars).",success
https://github.com/ScottfreeLLC/AlphaPy,AlphaPy,"AlphaPy is a Python-based machine learning/AutoML framework aimed at building predictive models and pipelines, especially for trading systems and sports betting. It supports feature engineering, visualization, and model training with common ML libraries (e.g., scikit-learn) and also references integrations with deep learning and gradient-boosting frameworks.",1700,machine learning|AutoML|data science|algorithmic trading|time series|sports betting|scikit-learn|pandas,8,"AlphaPy’s primary purpose is to provide an end-to-end machine learning framework (pipelines, feature engineering, modeling, and ensembles) targeting market prediction/trading workflows and sports outcome prediction, which are common applied-ML use cases. It is directly applicable for data scientists because it is built around mainstream Python ML tooling (notably scikit-learn and pandas) and describes support for multiple modeling libraries and ensemble techniques. While it has meaningful educational and practical value for applied ML and time-series/sports modeling, its community adoption appears modest compared to top-tier ML platforms and active development has shifted toward a newer commercial/professional successor (AlphaPy Pro), keeping it from scoring in the 9–10 range.",success
https://github.com/enzoampil/fastquant,fastquant,"fastquant is a Python library for quickly backtesting and optimizing quantitative trading strategies (including ML-driven strategies) with minimal code. It also provides helpers to fetch historical market data (e.g., Yahoo Finance equities and Binance crypto) to support research workflows.",1700,quantitative-finance|algorithmic-trading|backtesting|python|time-series|market-data|strategy-optimization|machine-learning,8,"This repository primarily provides a Python backtesting and strategy-optimization toolkit aimed at data-driven investing, including support for ML-based trading strategies and automated parameter search. It is directly applicable to common data science workflows (time-series data access, feature/strategy evaluation, and experiment-style backtests), making it useful for applied ML in finance. While it is not a general-purpose ML framework, its strong alignment with practical financial ML research and its visible adoption (1.7k GitHub stars) justify a high score.",success
https://github.com/jadianes/spark-py-notebooks,spark-py-notebooks,"A collection of Jupyter/IPython notebooks that teach Apache Spark concepts using Python (PySpark), covering RDD fundamentals through Spark SQL/DataFrames and MLlib examples (e.g., statistics, logistic regression, decision trees), plus a few application-style tutorials like a movie recommender service.",1700,apache spark|pyspark|jupyter notebooks|big data|data engineering|machine learning|spark mllib|spark sql,8,"This repository is primarily an educational set of PySpark notebooks that walk through core Spark data-processing workflows (RDDs, aggregations, key/value patterns) and then apply Spark MLlib for exploratory analysis and supervised learning examples. It is directly useful for data scientists and ML/data engineers who want hands-on Spark + Python training, including practical notebooks on feature exploration and model building (logistic regression, decision trees) and a recommendation-system application. While it is not a modern, actively-evolving ML framework itself, it has strong instructional value and solid applicability to real-world distributed data preparation and ML prototyping in Spark, which supports a high (but not maximum) score.",success
https://github.com/mlr-org/mlr,mlr,"mlr is an R machine-learning framework that provides a unified interface over many learning algorithms plus infrastructure for resampling, benchmarking, hyperparameter tuning, feature selection, visualization, and parallelization. The project is now retired/deprecated by the mlr-org team in favor of the newer mlr3 ecosystem, with only severe bug fixes expected.",1700,r|machine-learning|data-science|model-evaluation|hyperparameter-tuning|feature-selection|benchmarking,8,"This repository implements the {mlr} R package, a full-featured machine-learning workflow framework (tasks/learners, resampling & benchmarking, tuning, feature selection, and parallel execution) intended directly for ML experiments in R. It is broadly applicable to typical data science workflows (classification, regression, survival, clustering) and integrates with common experiment infrastructure (e.g., OpenML connectivity as described in the project docs). However, because {mlr} is explicitly deprecated/retired in favor of mlr3 and is no longer adding features, its forward-looking integration potential and long-term adoption trajectory are weaker than an actively developed core framework, so it scores below 9-10.",success
https://github.com/uber-research/deep-neuroevolution,deep-neuroevolution,"Distributed implementations of deep neuroevolution algorithms (Evolution Strategies, Genetic Algorithms/DeepGA, and novelty-seeking variants) for training deep neural networks in reinforcement learning. Includes tooling to run experiments locally/AWS (Redis-based) plus a visualization component (VINE) and a more GPU-efficient implementation.",1700,machine learning|reinforcement learning|neuroevolution|evolution strategies|genetic algorithms|distributed training|python,8,"This repository provides research-grade implementations of neuroevolution methods for training deep RL policies, including distributed runs (Redis) and experiment configurations for environments like Atari and MuJoCo. It is directly applicable to ML workflows for experimenting with alternative policy-optimization methods (ES/GA) and includes supporting infrastructure and visualization tooling, making it valuable for ML engineers and researchers. Community adoption appears moderate (about 1.7k GitHub stars) and it is educational for understanding deep neuroevolution, but it is not a broadly general-purpose ML framework on the level of PyTorch/TensorFlow, so it scores below 9–10.",success
https://github.com/apache/opennlp,apache/opennlp,"Apache OpenNLP is a Java-based, machine-learning-driven toolkit for processing natural language text, providing components for common NLP tasks such as tokenization, sentence detection, POS tagging, named entity recognition, chunking, parsing, coreference resolution, and language detection. It can be used via a Java API or CLI and can integrate into data pipelines (e.g., Flink, NiFi, Spark) for text processing workflows.",1600,natural language processing|machine learning|Java|text processing|named entity recognition|part-of-speech tagging|CLI tools|Apache,8,"This repository contains Apache OpenNLP, a production-oriented ML-based NLP library implementing classic statistical classifiers (e.g., MaxEnt, Perceptron, Naive Bayes) and end-to-end components for core NLP tasks, along with CLI tooling and model-loading utilities. It is directly applicable to ML/data workflows focused on text preprocessing, feature extraction, and traditional NLP model training/inference, particularly in Java ecosystems and batch/streaming pipelines. It scores an 8 (highly relevant) because it is explicitly an ML/NLP toolkit with broad utility and integration potential, but it is not a general-purpose modern deep-learning training framework on the scale of PyTorch/TensorFlow.",success
https://github.com/asavinov/intelligent-trading-bot,intelligent-trading-bot,"An automated trading/signal-generation system (focused on crypto) that trains machine-learning models offline and then runs an online service to compute features, make predictions, backtest strategies, and send signals (e.g., to Telegram) or potentially execute trades. It emphasizes consistent feature engineering between batch training and streaming inference and supports multiple time frequencies (e.g., 1m/1h/1d).",1600,algorithmic trading|cryptocurrency|machine learning|feature engineering|time series|backtesting|python,8,"This repository’s primary goal is to build an ML-driven trading/signal pipeline, explicitly separating offline training (data download/merge, feature creation, labeling, model training) from online prediction and signal delivery. It is directly relevant to ML/data workflows because it operationalizes time-series feature engineering, supervised learning for market prediction, and evaluation via backtesting, and provides an extensible framework for derived features and different sampling frequencies. While it is not a widely adopted general-purpose ML framework, it has clear educational and practical value for applied ML on financial time series and for building end-to-end ML pipelines, justifying a high (but not top-tier) score.",success
https://github.com/caesarHQ/textSQL,textSQL,"textSQL is a natural-language-to-SQL project that uses LLMs (e.g., GPT-3.5) to turn user questions into SQL queries against datasets (such as US Census and San Francisco city data) and present results with visualizations. It also supports a BYOD (Bring Your Own Data) mode to connect and self-host against your own database/datasets.",1600,text-to-sql|llm|data-analysis|natural-language-interface|business-intelligence|data-visualization|javascript|python,8,"The repository’s primary use case is enabling natural-language data analysis by converting questions into SQL with an LLM and querying a database, which is directly applicable to analytics/BI and data exploration workflows. It is not an ML training framework, but it is highly relevant to practical ML/data tooling because it operationalizes LLMs for querying and interpreting structured data and includes an extensible BYOD/self-hosting path. Community adoption appears solid for a specialized tool (about 1.6k GitHub stars), which supports a high (but not maximal) score.",success
https://github.com/justmarkham/DAT8,DAT8,"Course materials for General Assembly's 2015 Data Science course in Washington, DC, including lesson notebooks, slides, homework, code samples, and datasets covering core data science topics (e.g., cleaning, EDA, visualization, and scikit-learn-based machine learning).",1600,data science education|machine learning|python|jupyter notebooks|scikit-learn|data cleaning|exploratory data analysis,8,"This repository is a structured set of instructional materials (notebooks, slides, assignments, and datasets) for a full data science course, with multiple sessions dedicated to machine learning methods and evaluation. It is directly useful to data scientists and ML learners as hands-on learning content and as reference implementations for common workflows (data wrangling, EDA, feature engineering, model training, and validation) largely in Python/Jupyter with scikit-learn. While it is not a production-grade ML library or widely adopted framework, its breadth of applied ML topics and practical exercises make it highly valuable educationally, warranting a high (but not top-tier) score.",success
https://github.com/keras-team/keras-contrib,keras-contrib,"Archived community extension repository for Keras providing additional components (e.g., layers, activations, loss functions, optimizers) that were not part of Keras core. The project is deprecated and directs users to TensorFlow Addons for ongoing development.",1600,machine learning|deep learning|keras|tensorflow|neural networks|python,8,"This repository extends the Keras deep learning framework with extra model-building primitives like custom layers, activations, losses, and optimizers, which are directly useful in ML model development workflows. It has meaningful community adoption (about 1.6k GitHub stars) and practical educational value for understanding how to implement Keras-compatible components. However, it is archived (read-only as of June 23, 2025) and deprecated in favor of TensorFlow Addons, reducing its current integration value for modern production stacks.",success
https://github.com/AxeldeRomblay/MLBox,MLBox,"MLBox is an Automated Machine Learning (AutoML) Python library that provides data preprocessing/cleaning, feature selection (including leak detection), hyperparameter optimization, and model training for classification and regression (e.g., LightGBM, stacking, deep learning), with support for model interpretation.",1500,automl|machine learning|data preprocessing|feature selection|hyperparameter optimization|classification|regression|lightgbm,8,"This repository is purpose-built as an AutoML library, covering key ML workflow steps such as preprocessing, feature selection/leak detection, hyperparameter optimization, and training predictive models for classification/regression. It is directly applicable to data science work because it helps automate end-to-end model development and includes tooling for interpretation. Community adoption appears solid (about 1.5k GitHub stars), but it does not have the massive, industry-standard adoption level of top-tier frameworks (e.g., scikit-learn, PyTorch), so it scores high but not a 9–10.",success
https://github.com/CamDavidsonPilon/lifetimes,lifetimes,"A Python library for customer analytics focused on modeling repeat transactions, churn (""alive"" vs. ""dead"" customers), and estimating customer lifetime value (CLV) using probabilistic/statistical models. The repository is archived (read-only) and points to PyMC-Marketing as a successor.",1500,python|data-science|statistics|customer-lifetime-value|customer-analytics|churn-modeling|survival-analysis|marketing-analytics,8,"This repository provides ready-to-use Python implementations for customer lifetime value and repeat-purchase/churn modeling, which are common applied statistical/ML tasks in marketing analytics and retention. It is directly useful in data science workflows (feature engineering from transaction logs, probabilistic CLV estimation, and forecasting customer behavior), and it has notable community adoption (about 1.5k GitHub stars). The score is not higher mainly because the repo is archived (no ongoing development/support) and it is more specialized to CLV/BTYD-style modeling rather than being a general-purpose ML framework.",success
https://github.com/DLTK/DLTK,DLTK,"DLTK (Deep Learning Toolkit) is a Python library built on top of TensorFlow for fast prototyping and reproducible deep learning workflows in medical image analysis. It provides tooling, examples, and reference implementations to accelerate research and development for biomedical imaging tasks.",1500,machine learning|deep learning|medical imaging|computer vision|tensorflow|python|biomedical image analysis,8,"This repository provides a deep learning toolkit specifically targeting medical image analysis, including examples/tutorials and infrastructure intended to make model development reproducible and easier to prototype. It is directly applicable to ML workflows in biomedical imaging (data handling, model development, and experimentation) and integrates with TensorFlow as its underlying framework. While it is clearly ML-focused and useful for practitioners and researchers, it is not a dominant, broadly adopted core industry standard on the level of major general-purpose frameworks, so it scores below 9-10.",success
https://github.com/RamiAwar/dataline,dataline,"DataLine is an AI-driven tool to chat with your data using natural language, generating SQL queries and creating visualizations (charts/tables/reports). It connects to multiple data sources (e.g., CSV/Excel/SQLite and databases like Postgres, MySQL, Snowflake) and emphasizes local, privacy-focused usage.",1500,data-analysis|data-visualization|natural-language-to-sql|business-intelligence|LLM|SQL|data-engineering|analytics,8,"This repository provides an AI-driven data analysis and visualization application that lets users query and explore datasets and databases using natural language, including generating and executing SQL and producing charts. It is directly applicable to data/analytics workflows (rapid exploratory analysis, SQL drafting, and reporting) and supports many common data sources used in practice. While it is not an ML model training framework, it is strongly ML-adjacent via LLM-powered querying and has meaningful community adoption (about 1.5k stars), making it highly valuable for data teams.",success
https://github.com/capitalone/DataProfiler,DataProfiler,"A Python library for automated data profiling that loads common file formats into DataFrames and extracts schema, statistics, and metadata. It also includes sensitive-data/entity detection (e.g., PII/NPI) with a pre-trained deep learning model and can generate downstream reports.",1500,data profiling|data quality|exploratory data analysis|PII detection|entity recognition|python|data engineering,8,"DataProfiler is built specifically for dataset understanding and monitoring: it auto-loads multiple data formats and produces structured profiles with schema and rich per-column statistics, plus optional reporting and comparisons. Its sensitive-data/entity recognition uses a pre-trained deep learning model and supports extending entities or swapping pipelines, which is directly applicable to ML and analytics workflows (data preparation, feature vetting, governance, and privacy). Community adoption appears solid for a specialized data-quality tool (≈1.5k GitHub stars), but it is not a general-purpose model training framework, so it falls short of a 9–10 score.",success
https://github.com/firmai/awesome-google-colab,awesome-google-colab,"A curated “awesome list” of GitHub repositories and click-and-run Google Colab notebooks, organized by courses/tutorials, technologies (e.g., NLP, CV, RL), and application areas. It serves as a directory for finding Colab-ready ML/data science notebooks and projects.",1500,google-colab|jupyter-notebooks|machine-learning|data-science|deep-learning|nlp|computer-vision,8,"This repository is primarily a curated index of Google Colab-ready notebooks and ML/data science repositories, rather than a standalone library or framework. It is highly applicable for ML/data workflows because it helps practitioners quickly find runnable examples, tutorials, and reference implementations across NLP, computer vision, reinforcement learning, and more using Colab GPU/TPU runtimes. Its value is strongest for discovery and education (and rapid prototyping), but it’s less direct as a production tool since it mainly links out to other projects and is noted by the author as not actively maintained.",success
https://github.com/hi-primus/optimus,optimus,"Optimus is an opinionated Python library for agile data preparation that lets you load, clean/transform, profile, and plot data with a unified API across multiple execution engines (Pandas, Dask, cuDF/dask-cuDF, Vaex, and Spark). It also includes helpers for data quality tasks and building ML models on top of these backends.",1500,data preparation|data cleaning|data engineering|pandas|dask|pyspark|gpu-accelerated (cudf)|data profiling,8,"This repository provides a Python data-prep layer that standardizes common wrangling, profiling, and plotting operations across popular dataframe/distributed engines (Pandas, Dask, cuDF, Vaex, Spark), making it directly useful in real-world data science workflows. It is strongly aligned with ML/data work because cleaning, feature preparation, and data quality checks are core steps before modeling, and the project explicitly supports scaling from local notebooks to distributed/GPU execution. While it is not a mainstream ML framework and its adoption is moderate (about 1.5k GitHub stars), it offers practical, reusable tooling for dataset preparation and exploration. These factors make it highly valuable for data/ML practitioners, but not at the “industry-standard core framework” level, justifying an 8/10 score.",success
https://github.com/kyleskom/NBA-Machine-Learning-Sports-Betting,NBA-Machine-Learning-Sports-Betting,"A Python-based NBA sports betting project that builds datasets from historical team/game data (2007–08 season to current) and sportsbook odds, then trains ML models (including neural networks and XGBoost) to predict winners and totals (over/under). It outputs predicted edges/expected value and includes Kelly Criterion bankroll sizing plus an optional Flask web app for viewing results.",1500,machine learning|data science|NBA analytics|sports betting|Python|TensorFlow|XGBoost|Flask,8,"This repository is primarily an applied ML project for sports analytics and betting: it acquires/creates datasets (historical NBA team/game data plus sportsbook odds), trains models (neural networks and XGBoost), and produces actionable predictions with expected value and Kelly staking guidance. It is directly useful to ML/data practitioners as an end-to-end example covering data collection, feature/dataset creation, model training, and inference for a real-world prediction task. Community adoption appears solid (about 1.5k stars and 500+ forks), and the README includes runnable commands and a Flask viewer, increasing educational and practical value. It is not a general-purpose ML framework, so it scores below a 9–10, but it is highly relevant as an applied ML/data workflow project.",success
https://github.com/pysal/pysal,pysal,"PySAL (Python Spatial Analysis Library) is a meta-package for geospatial data science in Python, providing tools for spatial statistics, spatial econometrics/regression, spatial graph/weights construction, and exploratory spatio-temporal analysis. Since v2.0.0 it primarily serves as an umbrella/federation package, with most feature development happening in the affiliated subpackage repositories rather than in this repo.",1500,geospatial|spatial-analysis|spatial-statistics|spatial-econometrics|python|data-science|geopandas-ecosystem,8,"This repository is the PySAL meta-package that ties together a federation of Python packages for geospatial data science, including exploratory spatial data analysis (e.g., cluster/outlier detection), spatial weights/graphs, and spatial regression/econometrics workflows. It is highly relevant to data science because it directly supports common analytical tasks on geographically referenced (vector) data and integrates with the scientific Python stack (e.g., GeoPandas/Numpy/Scipy). It is not a general-purpose ML training framework, but it is a widely used, domain-specific analytics toolkit that frequently complements ML pipelines via feature engineering, spatial diagnostics, and spatial modeling—hence an 8/10 rather than 9–10.",success
https://github.com/sepandhaghighi/pycm,pycm,"PyCM (Python Confusion Matrix) is a multi-class confusion matrix library for Python that supports building confusion matrices from label vectors or from an existing matrix, and provides a broad set of per-class and overall classification evaluation metrics. It also supports reporting/printing and optional plotting integrations (e.g., via Matplotlib/Seaborn).",1500,machine learning|model evaluation|classification|confusion matrix|metrics|python library|data science,8,"This repository provides a dedicated library for constructing multi-class confusion matrices and computing a wide range of classification metrics, which is directly useful for evaluating predictive models. It fits naturally into ML/data science workflows (e.g., alongside scikit-learn) for post-training evaluation and reporting, and includes optional visualization support. While it is not a training framework or end-to-end pipeline tool, its focus and feature breadth for classification evaluation make it highly relevant; its visible community adoption (about 1.5k GitHub stars) supports an above-average score.",success
https://github.com/starpig1129/DATAGEN,DATAGEN,"DATAGEN is an AI-driven multi-agent research and data analysis assistant that automates hypothesis generation, data cleaning/transformation, analysis, visualization, and report writing using an agent workflow (e.g., via LangGraph/LangChain and LLM APIs). It also indicates an expansion focus toward crypto market intelligence via its associated website.",1500,multi-agent systems|data analysis automation|research assistant|LLM orchestration|LangChain|LangGraph|Python,8,"This repository’s primary purpose is to automate end-to-end research and data analysis tasks (hypothesis generation, analysis code writing, visualization, web/literature search, and report generation) using a coordinated multi-agent architecture. It is directly applicable to data science workflows because it aims to take a dataset (e.g., CSV) and produce analyses and graphical reports, integrating common LLM orchestration tooling and external model APIs. It scores below 9–10 because it is not a foundational ML framework with broad industry-standard adoption, but it is still highly relevant as an applied automation tool for DS/ML analysis and reporting.",success
https://github.com/MaxHalford/prince,prince,"Prince is a Python library for multivariate exploratory data analysis on tabular data, providing scikit-learn-style implementations of methods such as PCA, CA, MCA, MFA, FAMD, and GPA, with plotting support via Altair.",1400,python|data-science|exploratory-data-analysis|dimensionality-reduction|multivariate-analysis|scikit-learn|statistics|data-visualization,8,"This repository provides practical, scikit-learn-API implementations of classic multivariate exploratory/factor-analysis methods (e.g., PCA/CA/MCA/MFA/FAMD/GPA) used to summarize and analyze tabular datasets. These techniques are directly useful in data science workflows for dimensionality reduction, feature exploration, and mixed-type data analysis, and the library includes plotting support (Altair) for interpretation. It has solid community adoption for a specialized stats/EDA package (around 1.4k GitHub stars) and clear educational value due to well-known statistical methods and examples. It’s scored 8 (not 9–10) because it’s focused on exploratory/statistical decomposition rather than being a general-purpose ML training framework or widely adopted industry-standard core library like scikit-learn itself.",success
https://github.com/ikatsov/tensor-house,tensor-house,"TensorHouse is a collection of reference Jupyter notebooks and demo AI/ML applications aimed at common enterprise use cases (e.g., marketing analytics, pricing, supply chain, smart manufacturing). It provides prototyping templates, readiness/requirements questionnaires, and datasets/simulators to accelerate exploratory analysis and model evaluation.",1400,machine learning|data science|jupyter notebooks|enterprise ai|reinforcement learning|causal inference|tensorflow|pytorch,8,"This repository is primarily a curated toolkit of AI/ML reference notebooks and prototype applications for real-world enterprise use cases (marketing, pricing, supply chain, manufacturing), including readiness assessment materials and data/simulation assets. It directly supports ML workflows by providing end-to-end examples and templates spanning deep learning, reinforcement learning, causal inference, and LLM-based solutions, which can be adapted to real projects. While it is not a core framework/library with massive ecosystem-level adoption, it has strong educational and practical value for ML practitioners and meaningful community interest (notably a substantial star count).",success
https://github.com/obsei/obsei,obsei,"Obsei is an open-source, low-code, AI-powered automation framework for building workflows that collect unstructured data (e.g., social/media/reviews), run analysis tasks (e.g., classification, sentiment, translation, PII), and send results to downstream systems (e.g., ticketing, storage, dataframes). It is organized around Observer (collect), Analyzer (analyze), and Informer (send) components and supports stateful operation via databases for scheduled/serverless use cases.",1400,NLP|data pipelines|social listening|automation|ETL|Python|sentiment analysis|MLOps,8,"This repository provides a workflow-oriented framework to collect unstructured text data from many sources and run common NLP/AI analyses (sentiment, classification, translation, PII), then route outputs to downstream systems for action or further analysis. It directly supports ML/data workflows by enabling dataset creation, automated labeling/triage, and building repeatable data pipelines around AI models, including optional installation of analyzer dependencies (notably PyTorch). While it is not a general-purpose ML training framework, its end-to-end “data ingestion → NLP inference → delivery” focus makes it highly useful for applied ML and data engineering use cases, warranting a high (but not maximal) score.",success
https://github.com/quiltdata/quilt,quilt,"Quilt is a data lakehouse/data mesh platform for managing, versioning, and sharing datasets (“Quilt packages”) stored in AWS S3, with a web catalog for browsing, search, previews, and governance plus a Python SDK for programmatic packaging and access.",1400,data-engineering|data-versioning|data-catalog|aws-s3|python|data-governance|lakehouse,8,"This repository implements Quilt’s core platform (including the web catalog) and Python SDK for packaging datasets with metadata, versioning them in S3, and making them discoverable/searchable via a catalog experience. It is highly applicable to ML/data workflows because teams can use it to curate, govern, and reproducibly share large datasets that don’t fit in git, and to integrate dataset access into notebooks and pipelines. While it is not an ML training framework itself, it directly supports foundational MLOps/data management needs (dataset versioning, discovery, and governance) and is well-aligned with common data-science collaboration patterns, warranting a high but not maximal score.",success
https://github.com/robert-mcdermott/ai-knowledge-graph,ai-knowledge-graph,"A Python tool that converts unstructured text into an interactive knowledge graph by using an LLM to extract Subject–Predicate–Object (SPO) triples, optionally standardize entity names across chunks, and infer additional relationships. It outputs interactive HTML visualizations (and underlying structured graph data) and supports any OpenAI-compatible API endpoint (e.g., Ollama, LM Studio, OpenAI, vLLM, LiteLLM).",1400,knowledge graphs|LLM|NLP|information extraction|graph visualization|python,8,"This repository’s primary purpose is ML/NLP-driven knowledge extraction: it chunks documents and uses an LLM to extract SPO triples, then optionally performs entity canonicalization and relationship inference before generating an interactive graph visualization. It is directly applicable to common data/ML workflows like document mining, ontology/graph construction, and exploratory analysis of unstructured text, and it integrates with multiple LLM backends through OpenAI-compatible APIs. While it’s not a general-purpose ML framework and appears more like an application/tool than a reusable library ecosystem, it is highly relevant for practical ML-enabled data extraction and knowledge graph building, warranting an 8/10 score.",success
https://github.com/ThousandBirdsInc/chidori,chidori,"Chidori is an open-source orchestrator/runtime (with an IDE/debugger) for building durable AI agents, providing a reactive execution model with caching/resume, observability, and branching/time-travel debugging. The core runtime is written in Rust and supports executing Python and JavaScript as part of long-running agent workflows.",1300,ai-agents|agent-runtime|llm-orchestration|observability|debugging|rust|python|javascript,8,"This repository provides an agent runtime/orchestrator plus a visual debugger aimed at building and operating long-running LLM-driven agents, with features like caching/resume, detailed execution tracing, and time-travel/branching over execution state. It is directly useful in ML/LLM workflows as agent infrastructure (integration/orchestration/monitoring) rather than a model-training library. The score is high because it targets AI-agent development specifically and offers practical tooling for reliability and debugging, but it is not a widely adopted, foundational data-science library on the level of core ML frameworks.",success
https://github.com/ahmetozlu/tensorflow_object_counting_api,tensorflow_object_counting_api,"An open-source object counting framework built on top of TensorFlow/Keras (and the TensorFlow Object Detection API) for counting/tracking objects in videos, webcam streams, and images, with example scripts for pedestrian/vehicle counting and targeted-object counting.",1300,computer-vision|object-detection|object-tracking|object-counting|tensorflow|keras|opencv|tensorflow-object-detection-api,8,"This repository provides a practical, end-to-end framework and example applications for object detection, tracking, and counting using TensorFlow/Keras and OpenCV, including real-time and cumulative counting modes and case studies like vehicle/pedestrian counting. It is directly applicable to ML/computer-vision workflows (especially prototyping and deploying counting systems) and includes guidance for using pretrained detection models and training custom counters. While it is clearly ML-focused and fairly adopted (1.3k stars), parts of the stack are tied to older TensorFlow 1.x-era dependencies, which can reduce modern plug-and-play usability compared to current TF2-native projects; this keeps it below a 9–10.",success
https://github.com/devAmoghS/Machine-Learning-with-Python,Machine-Learning-with-Python,"A collection of small-scale Python machine learning projects and notes designed to teach core ML concepts through hands-on implementations and example use cases (e.g., classification, regression, clustering, neural networks, NLP, and recommender systems). Includes scripts, datasets/examples, and learning resources such as interview prep notes.",1300,machine learning|python|scikit-learn|keras|neural networks|NLP|recommender systems|data science education,8,"This repository is primarily an educational collection of practical machine-learning mini-projects (e.g., LDA topic modeling, K-means clustering, logistic regression, decision trees, random forests, MNIST neural networks, churn prediction, and recommender systems). It directly relates to common ML/data workflows by demonstrating end-to-end modeling tasks and core techniques using standard Python ML tooling (notably scikit-learn and Keras). While it is not a widely adopted production framework, it has strong educational and applied value for learners and practitioners looking for reference implementations and project ideas. The relatively high community interest (stars/forks) supports its usefulness, but its focus on learning projects keeps it below “core industry tool” status.",success
https://github.com/ebhy/budgetml,budgetml,"BudgetML is a Python library for quickly deploying an ML model as a secured HTTPS inference API endpoint with minimal code. It auto-generates a FastAPI server and targets low-cost Google Cloud Platform preemptible VMs, including SSL and OAuth2-protected endpoints.",1300,machine-learning|model-deployment|ml-inference|MLOps|FastAPI|Google-Cloud-Platform|REST-API|Python,8,"This repository’s primary purpose is ML model deployment: it helps users stand up an inference service by automatically generating a FastAPI endpoint, adding HTTPS (LetsEncrypt), and deploying on low-cost GCP preemptible instances. It is directly applicable to ML workflows (serving trained models behind an API) and includes practical production-adjacent features like auth and interactive Swagger docs. Community adoption appears moderate (about 1.3k GitHub stars), but the README notes the project is not actively maintained, which reduces reliability for ongoing ML engineering use. Given its clear ML-serving focus and practical utility despite maintenance risk, it merits an 8/10.",success
https://github.com/nok/sklearn-porter,sklearn-porter,"Transpiles trained scikit-learn estimators into standalone source code for other programming languages (e.g., C, Java, JavaScript, Go, PHP, Ruby) so models can be deployed without a Python/scikit-learn runtime, including options to embed or export model parameters and to validate integrity/predictions.",1300,machine learning|scikit-learn|model deployment|model export|code generation|transpiler|embedded systems|MLOps,8,"This repository’s primary purpose is to convert (transpile) trained scikit-learn models into equivalent prediction code in other languages, enabling deployment in environments where Python/scikit-learn isn’t available (e.g., embedded or performance-critical systems). It fits directly into ML engineering workflows as a post-training deployment tool and includes utilities for exporting model data and checking prediction integrity between the original and transpiled versions. Community adoption appears solid (around 1.3k GitHub stars), but its scope is narrower than core ML frameworks and it supports a limited subset of estimators/scikit-learn versions, which keeps it below a 9–10.",success
https://github.com/reiinakano/xcessiv,xcessiv,"Xcessiv is a web-based Python application for scalable, automated hyperparameter tuning and building stacked ensemble models. It helps manage large numbers of model–hyperparameter experiments, supports scikit-learn-compatible estimators, and provides automated ensemble construction workflows.",1300,machine learning|data science|scikit-learn|hyperparameter optimization|ensemble learning|stacking|AutoML|bayesian optimization,8,"This repository provides an end-to-end tool focused on model selection workflows: tracking many model/hyperparameter configurations, running (parallelizable) searches, and constructing stacked ensembles via a web UI. These capabilities map directly to common ML engineering tasks (hyperparameter optimization, experiment management, and ensembling) and integrate with the scikit-learn API and AutoML-style components (e.g., TPOT). It scores an 8 (highly relevant) because it is purpose-built for ML model building and optimization, but it does not have the broad, industry-standard adoption and ongoing activity typical of a 10/10 core ML platform (its latest GitHub release is v0.5.1 from Aug 21, 2017).",success
https://github.com/Renumics/spotlight,spotlight,"Renumics Spotlight is a Python tool to interactively explore unstructured datasets directly from a dataframe, opening a browser-based UI for visual exploration. It supports modalities like images, audio, text, video, time-series, and geometric data, and can leverage enrichments such as embeddings, predictions, and uncertainty for data/model debugging and EDA.",1200,machine-learning|exploratory-data-analysis|data-visualization|unstructured-data|computer-vision|embeddings|python|data-centric-ai,8,"This repository provides an interactive, dataframe-driven application for exploring and debugging unstructured datasets (images/audio/text/video/time-series/meshes) with rich visualizations and workflows aimed at ML teams. It directly supports common ML/data tasks such as dataset inspection, cluster discovery using embeddings, and model debugging using predictions/uncertainties, making it practically useful in real ML pipelines. While it is not a training framework itself (so not a 9–10), its focus on data-centric AI and unstructured data EDA makes it highly valuable for data science and ML work.",success
https://github.com/annoviko/pyclustering,pyclustering,"PyClustering is an open-source Python + C++ (optional accelerated core) data-mining library focused on clustering algorithms and related models such as oscillatory and neural-network-based approaches, with utilities for analysis and visualization. The repository README notes the project is no longer maintained as of 2021.",1200,clustering|data mining|machine learning|python|c++|unsupervised learning|scientific computing,8,"This repository provides a substantial collection of clustering and related data-mining algorithms implemented in Python with an optional C++ core for performance, making it directly applicable to common ML/data science workflows (especially unsupervised learning and exploratory analysis). It also has clear educational value for learning clustering methods and their implementations, and shows meaningful community interest (about 1.2k GitHub stars). The score is not higher primarily because the repository is explicitly marked as no longer supported/maintained since 2021, which reduces reliability and long-term integration potential for production use.",success
https://github.com/mGalarnyk/Python_Tutorials,Python_Tutorials,"A collection of Python, machine learning, and AI tutorials provided primarily as Jupyter notebooks and companion blog/YouTube resources. Content spans Python basics, data analysis (e.g., Pandas/visualization), and ML topics (e.g., scikit-learn, TensorFlow, PyTorch, time series).",1200,python|jupyter-notebook|data-science|machine-learning|pandas|scikit-learn|tensorflow|pytorch,8,"This repository is primarily an educational/tutorial collection covering Python fundamentals plus many data-science and machine-learning topics, organized into folders like Pandas, Sklearn, TensorFlow, PySpark_Basics, Statistics, Visualization, and Time_Series. It is directly applicable to ML/data workflows as reference material and runnable notebooks for common tasks (data manipulation, modeling, and training examples). While it is not a single cohesive production ML library or pipeline tool, its breadth and practical notebook format make it highly valuable for learning and prototyping, justifying a score of 8 rather than 9–10.",success
https://github.com/marsupialtail/quokka,quokka,"Quokka is a Python-native, push-based distributed query engine designed for stateful and windowed analytics over large-scale historical time series data. It supports SQL-style relational operations and excels at time-series patterns and joins (e.g., windowing, asof/range joins, complex event/pattern recognition), built on components like Ray, Polars, DuckDB, Arrow, and Redis.",1200,data engineering|distributed query engine|time series analytics|feature engineering|SQL|Python|Ray|Apache Arrow,8,"This repository provides a distributed computation/query engine specifically optimized for large-scale time series workloads, including windowed/stateful processing and join patterns commonly needed in analytics and feature engineering. While it is not an ML model training framework, it directly supports ML/data workflows by enabling scalable historical backtesting, embedding analytics, and high-throughput feature computation over data lakes, and it integrates with core data tools (Ray, Polars, DuckDB, Arrow, Redis). It also has meaningful community adoption (about 1.2k stars), suggesting practical interest among data practitioners. Based on strong direct applicability to data preparation/analytics for ML (but not being a core training framework), it merits an 8/10.",success
https://github.com/nfstream/nfstream,nfstream,"NFStream is a multiplatform Python framework for fast network flow data analysis from live interfaces or offline PCAPs. It provides high-level flow data structures, statistical feature extraction, encrypted (L7) application identification/metadata via nDPI, extensibility via plugins, and export to Pandas/CSV for downstream analytics and ML workflows.",1200,network-traffic-analysis|network-flow|pcap|feature-extraction|python|cybersecurity|deep-packet-inspection|machine-learning,8,"This repository focuses on converting raw network traffic (live capture or PCAP files) into structured, analysis-ready flow records with rich statistical and protocol/application metadata, including support for encrypted-traffic identification using nDPI. It directly supports ML/data workflows by standardizing and reproducing feature computation (a critical step for training and deploying traffic classification/anomaly models) and by offering convenient exports (e.g., Pandas/CSV) and plugin-based extensibility for custom features. While it is not itself an ML training framework, it is a highly practical upstream data/feature engineering tool for network-security ML pipelines with meaningful community adoption (on the order of ~1.2k GitHub stars).",success
https://github.com/shsarv/Machine-Learning-Projects,Machine-Learning-Projects,"A curated collection of end-to-end machine learning projects (including deep learning, NLP, and computer vision) with example applications such as Flask-deployed predictors and Tkinter GUI demos. It serves as a practical learning portfolio showcasing multiple ML use cases, datasets, and implementations across domains.",1200,machine learning|data science|deep learning|computer vision|NLP|Flask|PyTorch|scikit-learn,8,"This repository is primarily a portfolio-style collection of many ML projects (e.g., brain tumor detection, arrhythmia classification, diabetes prediction, driver drowsiness detection) spanning classic ML and deep learning. It is directly useful for ML learners and practitioners as reference implementations and end-to-end examples (including some deployed Flask apps and structured project layouts), but it is not a single reusable framework/library intended for broad integration. Community adoption is solid for an educational repo (about 1.2k stars), yet it lacks the ecosystem-level impact and extensibility of core ML tooling, which keeps it below 9–10.",success
https://github.com/EmbeddedLLM/JamAIBase,JamAIBase,"JamAI Base is an open-source backend platform for building AI/RAG applications with a spreadsheet-like interface and a REST API. It combines an embedded relational store with vector search and orchestration for LLM prompts, embeddings, reranking, and multi-step workflows (via concepts like Generative/Action/Knowledge/Chat tables).",1100,llm|rag|vector-database|lancedb|sqlite|ai-agent-workflows|llmops|backend-as-a-service,8,"JamAIBase’s primary purpose is to provide an AI/RAG-focused backend (with a spreadsheet-like UI and REST API) that orchestrates LLM workflows, including retrieval, embeddings, reranking, and agent/chat-style interactions. This directly supports common ML/data workflows—especially building and operating RAG systems—by offering storage (including vector storage), workflow primitives (tables), and integration surfaces (API/clients). While it’s less about model training and more about ML application infrastructure, its features are highly applicable to ML engineers building production LLM apps, which justifies a high (but not ‘core framework’) score.",success
https://github.com/campusx-official/ML-Roadmap-for-2022,ML-Roadmap-for-2022,"An educational roadmap repository that curates a structured machine-learning learning path (with estimated timelines) and links to external resources such as YouTube playlists, practice problems, projects, and datasets. It is intended to guide learners from Python/data analysis fundamentals through core ML concepts and practical projects over ~6 months.",1100,machine learning|data science|learning roadmap|python|EDA|statistics|projects,8,"This repository primarily serves as a curated learning roadmap for machine learning, organizing topics (Python, NumPy, Pandas, visualization, statistics, EDA, ML basics, etc.) with links to high-utility external learning resources and projects. While it is not a runnable ML library or production tool, it is directly applicable to ML/data workflows as a structured self-study plan and reference hub. Community adoption is moderate (notable star count), and its educational value is high, but integration/tooling value is limited because the repo mostly aggregates links rather than providing code or datasets itself.",success
https://github.com/comet-ml/kangas,kangas,"Kangas is an open-source tool to explore, analyze, and visualize large-scale multimedia datasets via a Python API and a fast interactive viewer. It centers around a scalable “DataGrid” that can store millions of rows and supports filtering/grouping/sorting, including built-in computer-vision-friendly views for images, bounding boxes, labels, and metadata.",1100,machine learning|data visualization|exploratory data analysis|computer vision|python|dataset management|multimedia data,8,"Kangas is primarily a data-centric tool for ML workflows: it helps practitioners log and organize large tabular + multimedia datasets and interactively explore them through a viewer optimized for fast querying at scale. It directly supports common ML data formats and integrations (e.g., Pandas DataFrames, Hugging Face Datasets, and Parquet), and includes first-class features for computer-vision dataset inspection (bounding boxes, labels, metadata). While it’s not a model-training framework, it is highly applicable to EDA, dataset QA, and prediction/label analysis, which are critical parts of practical ML pipelines; community adoption appears solid but not at “industry standard” scale, hence an 8 rather than 9–10.",success
https://github.com/databricks/lilac,lilac,"Lilac is an open-source tool for exploring, curating, and performing quality control on datasets used to train, fine-tune, and monitor LLMs. It provides a local web UI plus a Python API to compute dataset “signals” (e.g., PII detection, near-duplicates, language detection), embeddings, clustering, and LLM-powered search/annotation workflows.",1100,llm|dataset-curation|data-quality|data-labeling|nlp|embeddings|data-engineering|python,8,"This repository is purpose-built for LLM dataset exploration, curation, and quality control, offering both an interactive UI and a Python API for common data-prep and auditing tasks (clustering, embeddings, semantic/conceptual search, and signals like PII and near-duplicate detection). These capabilities map directly onto practical ML/LLM workflows such as cleaning training corpora, diagnosing dataset issues, and monitoring data drift/changes over time. While it is not a model training framework itself and the GitHub repo is archived (read-only as of July 25, 2025), it remains highly applicable as an upstream data tooling component for ML teams and data scientists.",success
https://github.com/fraunhoferportugal/tsfel,tsfel,"TSFEL (Time Series Feature Extraction Library) is an open-source Python library for extracting a large set of time-series features across statistical, temporal, spectral, and fractal domains. It provides configurable, reproducible feature-extraction pipelines and utilities for applying feature extraction to sensor/time-series signals.",1100,time series|feature extraction|signal processing|python|machine learning|data preprocessing|statistics|spectral analysis,8,"This repository provides a ready-to-use Python toolkit focused on time-series feature engineering (extracting 65+ features from statistical, temporal, spectral, and fractal domains), which is a common prerequisite step for classical ML and many applied data-science workflows involving sensor/telemetry/biomedical signals. It is directly applicable for building ML datasets (transforming raw sequences into tabular features), supports reproducible configuration of extraction pipelines, and includes documentation and tests, making it practical for both production and education. It is not a full modeling/training framework, but it strongly supports ML pipelines via domain-relevant feature computation and has meaningful community adoption (1.1k GitHub stars).",success
https://github.com/makcedward/nlp,nlp,"An educational NLP tutorial/learning repository documenting the author’s NLP journey, collecting notes and curated links, and providing example code/datasets for practical NLP tasks (e.g., text preprocessing, text representation, and common NLP problems).",1100,natural language processing|machine learning|deep learning|NLP tutorials|text preprocessing|embeddings|Python,8,"This repository is primarily an NLP learning and reference hub, organizing many NLP topics (e.g., tokenization, lemmatization, embeddings, and NLP problem areas) with supporting materials and some example source code/datasets. It is directly relevant to ML/data workflows because it helps practitioners learn and implement common NLP preprocessing and representation techniques that are foundational to model training and evaluation. However, it appears more like an educational/curation repository than a widely adopted production library or framework, which limits community-adoption and integration depth compared with core tools like PyTorch/Hugging Face. Given its strong educational value and practical relevance to NLP work, but limited evidence of being a standard dependency in ML stacks, a score of 8 is appropriate.",success
https://github.com/J535D165/recordlinkage,recordlinkage,"A Python toolkit for record linkage and deduplication, providing indexing (e.g., blocking), record comparison/similarity features, and supervised/unsupervised classifiers to identify matching records across one or more datasets.",1000,record linkage|entity resolution|deduplication|data cleaning|pandas|scikit-learn|python,8,"This repository provides an end-to-end framework for record linkage/entity resolution: generating candidate pairs via indexing, computing comparison features (string/date/numeric similarities), and classifying matches using both supervised models (e.g., logistic regression) and unsupervised approaches (ECM/EM-style). It is directly applicable to data science workflows involving data integration, deduplication, and dataset joining where ground truth may or may not exist, and it integrates with common Python data tools (notably pandas and scikit-learn). Community adoption appears solid for a specialized library (around ~1k GitHub stars) and it has strong educational value due to clear examples and modular components. It is not a general-purpose ML framework, but it is highly relevant for a common applied ML/data engineering problem area, justifying a score of 8.",success
https://github.com/Kismuz/btgym,btgym,"BTGym is a scalable, event-driven backtesting framework for algorithmic trading research that wraps the Backtrader engine with an OpenAI Gym-style environment API to run reinforcement learning experiments in market-like trading simulations.",1000,reinforcement learning|algorithmic trading|backtesting|openai gym|python|backtrader|financial markets,8,"This repository provides an OpenAI Gym-compatible environment on top of the Backtrader trading/backtesting engine, explicitly aimed at running reinforcement learning experiments in simulated trading environments. It is directly applicable to ML workflows for RL in finance (environment design, episodic sampling, observation/reward pipelines, and experiment scaffolding), and includes examples/tests that can be used as starting points for training agents. While it is research/development grade and focused on a specific domain (trading), it is clearly an ML-enabling tool rather than a general backtesting library, justifying a high (but not maximal) score.",success
https://github.com/aws-samples/aws-machine-learning-university-accelerated-tab,aws-machine-learning-university-accelerated-tab,"Course materials for AWS Machine Learning University’s “Accelerated Tabular Data” class, including lecture slides, Jupyter notebooks, and datasets. It teaches core ML techniques for tabular (spreadsheet-like) data and includes a final project using a real-world-style dataset.",1000,machine learning|tabular data|education|jupyter notebooks|python|scikit-learn|mxnet|feature engineering,8,"This repository is primarily an educational ML resource: it provides structured lectures (slides), hands-on Jupyter notebooks, and datasets for learning and practicing tabular machine learning. It directly supports common ML/data workflows (EDA, model training, evaluation, feature engineering, tree-based methods, boosting, neural networks, and an end-to-end final project). While it’s not a broadly adopted production library/tool, it has strong practical learning value and reusable notebook examples for data scientists and ML engineers, justifying a high (but not maximal) score.",success
https://github.com/google/lightweight_mmm,lightweight_mmm,"LightweightMMM is a Python library for Bayesian Marketing Mix Modeling (MMM) that helps train MMMs and produce media channel attribution and budget optimization insights. It is built on JAX/NumPyro and provides utilities for data scaling, model evaluation, optimization, and common MMM visualizations.",1000,marketing-mix-modeling|bayesian-inference|jax|numpyro|marketing-analytics|causal-inference|budget-optimization|python,8,"This repository provides an end-to-end Bayesian MMM implementation (including adstock/saturation variants, hierarchical modeling options, and budget optimization tooling) aimed directly at marketing analytics and measurement problems. It is highly applicable to data science workflows for attribution and spend optimization using aggregated time-series data, and it integrates with modern probabilistic/ML tooling via JAX and NumPyro. While useful and reasonably adopted, it is explicitly noted in the repository README as no longer supported and Google recommends switching to the newer Meridian MMM (released Jan 29, 2025), which reduces its forward-looking value versus actively maintained MMM stacks. Because it remains a focused Bayesian modeling toolkit with strong educational and practical relevance, it merits a high (but not top-tier) score.",success
https://github.com/ropensci/targets,targets,"An R package for function-oriented, Make-like declarative pipelines that track dependencies and skip up-to-date work to make data analysis workflows faster and more reproducible. It orchestrates target execution (including parallel computing) and stores intermediate results as R objects.",1000,r|data-science|workflow-management|pipelines|reproducible-research|parallel-computing|data-engineering,8,"This repository provides the R package `targets`, a workflow/pipeline tool designed specifically for statistics and data science projects, enabling dependency-aware execution and caching to avoid rerunning completed steps. It is directly applicable to ML/data workflows because it can structure end-to-end analyses (data prep, model fitting, simulations, reporting) with reproducibility and performance benefits, and it supports parallel/distributed execution (e.g., via integrations like `crew`). While it is not an ML algorithm library itself, it is a strong MLOps-adjacent orchestration tool for R-centric data science, which justifies a high (but not maximal) score.",success
https://github.com/TJU-DRL-LAB/AI-Optimizer,AI-Optimizer,"AI-Optimizer is a next-generation deep reinforcement learning suite that provides a broad library of RL algorithms (model-free to model-based, single-agent to multi-agent). It also includes a flexible distributed training framework intended to speed up and scale policy training.",,reinforcement learning|deep reinforcement learning|multi-agent reinforcement learning|offline reinforcement learning|model-based reinforcement learning|distributed training|PyTorch,8,"This repository is primarily an applied machine learning toolkit focused on deep reinforcement learning, offering multiple RL sub-libraries (e.g., multi-agent RL, offline RL, model-based RL, self-supervised RL) and a distributed training setup for efficient experimentation. It is directly useful for ML researchers/engineers working on RL who want implementations and training infrastructure rather than a general-purpose utility. While it appears to have meaningful community interest (thousands of stars shown), the exact star count is displayed in an abbreviated form (e.g., ""3.5k""), so an exact integer could not be confirmed here. Based on its strong alignment with ML workflows and practical/educational value in RL (but not being a universally adopted core framework like PyTorch itself), a score of 8 is appropriate.",success
https://github.com/Tanu-N-Prabhu/Python,Python,"An educational repository of Python and machine learning materials, primarily as Jupyter notebooks, covering topics like data analysis, web scraping, pandas/numpy usage, exploratory data analysis, and introductory-to-advanced ML concepts.",,python|machine learning|data science|jupyter notebooks|pandas|numpy|exploratory data analysis|web scraping,8,"This repository is primarily a learning resource with many notebooks organized around data science and machine learning topics (e.g., EDA, feature engineering, and building ML models). It’s directly applicable for learners and practitioners who want practical, notebook-based examples using common ML/data tooling (notably Python, pandas, and numpy). While it is not a widely adopted production library or framework, its breadth of DS/ML educational content makes it highly valuable for learning and experimenting, supporting a score of 8.",success
https://github.com/daveebbelaar/ai-cookbook,ai-cookbook,"A collection of practical examples and tutorials (with copy/paste code snippets) for building AI systems, including agent patterns, model usage, tooling, and framework-specific implementations.",,python|generative ai|llm|ai agents|openai|anthropic|prompting|mcp,8,"This repository is primarily an AI engineering cookbook: it provides examples, tutorials, and reusable snippets for building LLM-based systems (including agent patterns and integrations with popular model providers). It is directly applicable to ML/GenAI workflows for practitioners building applications on top of LLMs (prompting, orchestration, tool use, and related implementation patterns), though it is not focused on traditional model training or data pipelines. Given its strong educational and practical value for production-oriented GenAI development, it merits a high score, but not a 10 because it is not a core ML framework or widely adopted foundational library.",success
https://github.com/duoergun0729/nlp,nlp,"A Chinese-language, open-source introductory NLP book/learning repository that collects tutorials and notes on core NLP concepts and common modeling approaches (e.g., TF-IDF, Word2Vec/Doc2Vec, LDA, TextRank) plus example applications like sentiment analysis. It also includes some accompanying Python code and references/papers.",,natural language processing|machine learning|NLP education|text classification|word embeddings|topic modeling|Python,8,"This repository is primarily an educational NLP resource (an open-source intro book) with articles/tutorials covering foundational NLP/ML methods and practical tasks like document classification, keyword extraction, and sentiment analysis. It is directly relevant to ML/data workflows because it teaches core techniques that data scientists routinely apply and includes Python code and example write-ups. While it is not a widely adopted production library/framework, it has strong learning value and curated coverage of important NLP building blocks, justifying a high (but not maximum) score.",success
https://github.com/f/awesome-chatgpt-prompts,awesome-chatgpt-prompts,"A community-maintained collection of prompts for ChatGPT and other AI chat models, with prompts hosted in PROMPTS.md and synced from prompts.chat. It also includes code and guides to self-host a private prompts.chat instance for teams (branding, themes, authentication).",142000,prompt engineering|LLM|ChatGPT|NLP|prompt library|community dataset|self-hosted web app,7,"This repository primarily serves as a large, community-curated prompt library (PROMPTS.md / prompts.csv) and an associated self-hostable prompt management app (prompts.chat). It’s not an ML framework or training toolkit, but it is directly useful in ML/LLM workflows for prompt design, evaluation, prototyping, and building prompt datasets for experimentation. Strong community adoption (very high GitHub stars) and practical educational value for prompt engineering push the score up, while limited direct support for model training/MLOps keeps it below 8+.",success
https://github.com/d3/d3,d3,"D3 (Data-Driven Documents) is an open-source JavaScript library for visualizing data on the web. It provides low-level, highly flexible building blocks to create dynamic, data-driven graphics using web standards like SVG, Canvas, and HTML.",112000,data visualization|javascript|d3.js|svg|canvas|web development|charting,7,"This repository is the core D3.js library, primarily used to build interactive, data-driven visualizations in web applications. While it is not an ML framework or modeling tool, it is highly relevant to data science workflows for communicating results, exploring datasets interactively, and building dashboards or explanatory visualizations. Its wide adoption and ecosystem value for analysis communication justify a moderately high score, but it does not provide core ML/data processing functionality such as training, inference, or feature engineering.",success
https://github.com/modelcontextprotocol/servers,servers,"A collection of official/reference server implementations for the Model Context Protocol (MCP), demonstrating how to provide LLMs secure, controlled access to tools and data sources via MCP SDKs. It also includes references to additional community resources and an MCP Registry link for published servers.",75800,LLM tooling|agent frameworks|Model Context Protocol (MCP)|TypeScript|API integrations|developer tools|tool calling,7,"This repository provides reference MCP servers (e.g., filesystem, fetch, git, memory, time) that expose tools and resources to LLM-powered applications in a secure and controlled way. While it is not a model-training or data-processing library, it is directly useful for ML/LLM engineers building agentic systems, RAG apps, and tool-augmented workflows, especially for integrating external data sources and operational tools. Its strong relevance to modern LLM application development and broad adoption signals (high star count) justify a moderately high score, but it is not a core data science library like pandas/Spark, so it does not reach 8–10.",success
https://github.com/tesseract-ocr/tesseract,tesseract,"Tesseract is an open-source optical character recognition (OCR) engine providing the libtesseract library and a tesseract command-line tool. It supports an LSTM-based OCR engine (introduced in Tesseract 4), legacy OCR mode, 100+ languages, multiple image inputs (e.g., PNG/JPEG/TIFF), and several output formats (text, hOCR, PDF, TSV, ALTO, PAGE).",71800,optical character recognition|computer vision|document processing|text extraction|C++|LSTM,7,"This repository is the core Tesseract OCR engine, used to convert images (and image-derived documents) into machine-readable text via a CLI and the libtesseract API. It is highly applicable to ML/data workflows for document AI, dataset creation (label extraction), preprocessing for NLP pipelines, and large-scale text digitization, though it is not a general model-training framework. It has very broad adoption and strong integration potential (via APIs and wrappers), but its scope is focused on OCR inference and tooling rather than end-to-end ML development, so a 7/10 reflects strong but specialized relevance.",success
https://github.com/apache/superset,superset,"Apache Superset is an open-source, modern data exploration and data visualization (BI) platform for building interactive dashboards and analyzing data across many SQL-compatible data sources. It includes a SQL editor, a semantic layer, and extensible visualization capabilities for self-service analytics.",69800,business intelligence|data visualization|analytics|dashboarding|sql|python|react|data engineering,7,"This repository powers Apache Superset, a widely adopted BI and analytics platform focused on exploring data and building visualizations/dashboards over many database backends. While it is not an ML training framework, it is highly valuable in data science workflows for EDA, metric tracking, stakeholder reporting, and operational analytics (including monitoring model outputs and features via SQL-accessible stores). Its strong community adoption and integrations with common data infrastructure make it moderately-to-highly relevant for ML/data practitioners, warranting a 7 rather than a higher score reserved for core ML/MLops frameworks.",success
https://github.com/chartjs/Chart.js,Chart.js,"Chart.js is a simple yet flexible JavaScript charting library for building HTML5 charts using the canvas element. It provides configurable, responsive charts (e.g., line, bar, pie, etc.) and an extensible plugin system with comprehensive documentation and samples.",67000,javascript|typescript|data-visualization|charting|html5-canvas|frontend|web-development,7,"This repository is primarily a widely-used JavaScript charting/data-visualization library for rendering charts in web applications using the HTML5 canvas. While it is not an ML framework, it is directly useful in data science and ML workflows for exploratory analysis dashboards, experiment tracking UIs, model monitoring visualizations, and communicating results (especially when outputs must be embedded in web apps). Its strong adoption (tens of thousands of stars and very large downstream usage) makes it a practical, high-leverage tool for ML/data teams, but it does not provide ML algorithms or data processing itself, so it scores below core ML tooling. ",success
https://github.com/OpenHands/OpenHands,OpenHands,"OpenHands is an AI-driven development platform for building and running software agents. It provides a composable Python Agent SDK, a CLI for agent-assisted coding, and a local GUI (React + REST API), with options to deploy hosted/cloud and enterprise self-hosted versions.",66400,ai-agents|llm|developer-tools|cli|python|typescript|agent-sdk|code-assistant,7,"This repository is primarily an agentic software-development toolkit (SDK/CLI/GUI) that orchestrates LLM-powered agents to perform coding and related development tasks. While it is not a data-science library for model training or analytics, it is directly relevant to ML workflows as a practical framework for building/hosting/evaluating LLM-driven agents and integrating them into developer productivity pipelines. Strong community adoption (66.4k stars) and its focus on agent infrastructure and evaluation make it valuable to ML engineers working on applied LLM systems, but it is less central for typical data science tasks like ETL, modeling, or visualization.",success
https://github.com/prakhar1989/awesome-courses,awesome-courses,"A curated list of university-level computer science courses with freely available online materials (lectures, notes, assignments, readings, and exams). It organizes links by subject areas such as systems, algorithms, AI, machine learning, and statistics.",65600,computer science education|awesome-list|online courses|machine learning|artificial intelligence|algorithms|systems|statistics,7,"This repository is primarily an educational resource: a curated index of high-quality university CS courses and their materials, including a dedicated Machine Learning section and a Statistics/Regression section. It is not an ML library or tool you would integrate into a production workflow, but it is directly useful for learning and upskilling in ML/data science concepts via structured course content. The repository also shows strong community adoption (tens of thousands of stars), increasing its practical value as a widely referenced learning roadmap.",success
https://github.com/apache/echarts,echarts,"Apache ECharts is an open-source JavaScript charting and data visualization library for the browser, providing interactive and highly customizable charts with Canvas/SVG rendering support. It is designed to help developers build rich, responsive visual analytics and dashboards for web applications.",65400,data visualization|javascript|charting library|web development|dashboarding|canvas|svg,7,"This repository provides a widely used, production-grade charting and visualization library (Apache ECharts) for building interactive plots and dashboards in the browser. While it is not an ML framework, it is directly useful in ML/data workflows for exploratory data analysis, model monitoring dashboards, and communicating results through interactive visualizations. Its broad adoption and rich feature set (many chart types, large-data rendering, dataset/transforms support) make it moderately to highly valuable to data practitioners, but it does not cover core ML tasks like training or inference, so it does not score in the 8–10 range.",success
https://github.com/OpenBB-finance/OpenBB,OpenBB,"Open Data Platform by OpenBB (ODP) is an open-source financial data toolset that integrates proprietary, licensed, and public data sources and exposes them to multiple consumption surfaces. It supports Python workflows (via the `openbb` package), a CLI, REST APIs (FastAPI/Uvicorn), and integrations used by analysts, quants, and AI agents.",57600,financial data|data integration|python|API|FastAPI|quantitative finance|data engineering|AI agents,7,"This repository provides a financial data integration and delivery platform (OpenBB Open Data Platform) that consolidates multiple data sources and makes them consumable through Python, a CLI, and a FastAPI-based REST server. It is highly useful in data science workflows for acquiring, normalizing, and serving market/financial datasets that can feed feature engineering, backtesting, and downstream ML models, but it is not itself a model-training framework or MLOps system. Its strong adoption (tens of thousands of GitHub stars) and breadth of integrations make it a solid data/ML-enabling tool, warranting a 7/10 rather than a higher score reserved for core ML frameworks.",success
https://github.com/ClickHouse/ClickHouse,ClickHouse,"ClickHouse is an open-source, column-oriented OLAP database management system designed for real-time analytical queries at high throughput and low latency. It supports SQL and is built for scalable analytics workloads on large datasets.",45100,database|olap|analytics|data engineering|columnar storage|distributed systems|sql|cpp,7,"This repository contains ClickHouse, a widely used real-time analytics (OLAP) columnar database system rather than an ML library. It is highly relevant to ML/data workflows as a backend for feature stores, analytics over training/serving logs, experiment metrics, observability, and large-scale dataset exploration/aggregation via SQL. Its strong community adoption and performance/scalability make it valuable infrastructure for data science teams, but it is not a direct model-training or MLOps framework, so it scores below core ML tools.",success
https://github.com/sansan0/TrendRadar,TrendRadar,"TrendRadar is an AI-assisted public-opinion/trend monitoring and hot-topics filtering tool that aggregates multi-platform trending content and RSS feeds with keyword-based filtering. It supports MCP integration for AI chat-based analysis (e.g., sentiment insights and trend forecasting), Docker one-click deployment, and multi-channel notifications (WeChat, Feishu, DingTalk, Telegram, email, ntfy, Bark, Slack, etc.).",42600,trend monitoring|rss aggregation|keyword filtering|LLM integration|MCP|sentiment analysis|Docker|notifications,7,"This repository primarily provides an AI-driven workflow for aggregating and filtering trending/public-opinion data from multiple sources and RSS, then pushing curated results through various notification channels. It is moderately relevant to ML/data workflows because it can serve as a data collection + analysis surface for LLM-based natural-language analytics (including sentiment and trend-oriented insights) and can support building downstream datasets/monitoring pipelines. The strong community adoption (tens of thousands of stars) and focus on trend/sentiment/LLM-assisted analysis justify a higher-than-average score, but it is not a core ML framework or model-training library, so it does not reach the 8–10 range.",success
https://github.com/DataExpert-io/data-engineer-handbook,data-engineer-handbook,"A curated “Data Engineering Handbook” containing links and structured resources to learn data engineering, including roadmaps, books, communities, newsletters, projects, and beginner/intermediate bootcamp materials.",39300,data engineering|learning resources|data pipelines|ETL|data warehousing|MLOps|bootcamp,7,"This repository is primarily an educational, curated index of data engineering resources (books, communities, newsletters, projects) and includes materials for beginner and intermediate bootcamps. It’s not an ML library or framework, but it is directly useful for ML/data workflows because data engineering skills and tooling (pipelines, orchestration, quality, warehouses/lakes) are foundational prerequisites for building reliable ML systems. Community adoption appears strong (tens of thousands of GitHub stars), suggesting high educational value and broad relevance across data roles. I scored it a 7 because it’s highly useful for data/ML practitioners as a learning and reference hub, but it doesn’t provide core ML functionality like training/inference code or ML-specific APIs.",success
https://github.com/naptha/tesseract.js,tesseract.js,"Tesseract.js is a JavaScript OCR library that wraps a WebAssembly port of the Tesseract OCR engine to extract text from images in the browser and in Node.js, supporting 100+ languages. It provides a worker-based API and outputs recognized text plus layout details like bounding boxes for paragraphs/words/characters.",37700,OCR|computer vision|JavaScript|WebAssembly|browser|Node.js|document processing,7,"This repository provides a production-grade OCR capability in JavaScript by wrapping the Tesseract engine via WebAssembly, enabling text extraction from images and returning structured recognition outputs (e.g., text and bounding boxes). It is highly useful in data workflows for document ingestion, labeling, and feature extraction from scanned images, which often precede downstream NLP/ML tasks, but it is not itself a model training framework or dataset tool. Community adoption appears strong (tens of thousands of GitHub stars), which increases practical value and ecosystem reliability. The score is 7 (moderately relevant) because it is a key enabling component for ML/data pipelines involving document understanding, yet it focuses on inference/utility OCR rather than broader ML experimentation or training infrastructure.",success
https://github.com/vnpy/vnpy,vnpy,"VeighNa (vn.py) is an open-source Python quantitative trading platform/framework for building trading applications, integrating market/trading gateways, strategy engines, and backtesting. It also includes an AI/ML-oriented module (vnpy.alpha) for factor feature engineering, model training, and research-to-live trading workflows.",35200,quantitative trading|algorithmic trading|backtesting|python|financial markets|machine learning|factor modeling,7,"The repository’s primary use case is quantitative trading system development (connect to brokers/exchanges via gateways, build strategy apps, and run/backtest strategies), so it is not a general-purpose ML library. However, it explicitly includes vnpy.alpha for AI-quant workflows such as factor/feature engineering (including an Alpha 158 feature set inspired by Microsoft Qlib), standardized ML model training templates, and research workflow tooling. This makes it moderately relevant to ML/data science (especially for financial ML and factor modeling), but its community adoption and design focus are centered on trading infrastructure rather than broad ML tooling.",success
https://github.com/DataTalksClub/data-engineering-zoomcamp,data-engineering-zoomcamp,"Course repository for DataTalksClub's Data Engineering Zoomcamp, a free 9-week program focused on building production-ready end-to-end data pipelines. It includes a structured syllabus with hands-on modules covering containerization/IaC, orchestration, data warehousing, analytics engineering, batch processing, streaming, and a final project.",34600,data engineering|data pipelines|ETL|Docker|Terraform|Apache Spark|Kafka|dbt,7,"This repository is primarily an educational, hands-on curriculum for building modern data engineering pipelines (e.g., ingestion, orchestration, warehousing, batch/stream processing) rather than a dedicated ML library. It is highly applicable to ML/data workflows because strong data pipelines are foundational for feature generation, training data preparation, and production data reliability, and the course includes commonly used tools in data/ML stacks (e.g., Spark, Kafka, BigQuery, dbt). I scored it a 7 because it delivers substantial practical value for data practitioners and ML engineers upstream of modeling, but it is not centered on model training, evaluation, or MLOps frameworks themselves.",success
https://github.com/666ghj/BettaFish,BettaFish,“微舆”是一个从0实现、无需依赖框架的多智能体（multi-agent）舆情分析系统：用户以对话方式提出需求后，系统会自动对国内外30+主流社媒与海量评论进行抓取/检索、分析整合，并生成结构化研究报告（含HTML等形式），用于辅助研判与决策。,34100,multi-agent|LLM|opinion-mining|social-media-analytics|sentiment-analysis|web-scraping|multimodal|python,7,该仓库核心用途是围绕“舆情/社媒内容”构建多Agent分析流水线：包含检索/爬取、内容理解与总结、论坛式协作机制，以及最终报告生成等模块，属于典型的数据收集+分析+产出链路。它与ML/数据工作流的关系较强（文本/多模态信息抽取、情感分析、统计/模型协同、自动化研究报告），对数据科学实践有直接参考价值。虽然并非通用ML框架且未体现大规模ML社区生态标准化程度，但作为可运行的端到端舆情分析系统与工程化实现，仍具较高的应用与学习价值。,success
https://github.com/apache/kafka,kafka,"Mirror of Apache Kafka, an open-source distributed event streaming platform for building high-throughput, fault-tolerant data pipelines, streaming analytics, data integration, and mission-critical applications.",31700,event streaming|distributed systems|data engineering|stream processing|message broker|apache kafka|java|scala,7,"This repository contains the core implementation of Apache Kafka, a distributed event streaming platform used to publish, store, and process streams of records at scale (including Kafka Streams and Kafka Connect). While it is not an ML library, it is widely used in data/ML workflows for reliable ingestion of training/feature data, real-time feature pipelines, streaming ETL, and feeding online inference systems. Its strong ecosystem adoption and integration potential with common ML/data tooling make it highly valuable infrastructure for ML engineering, but it is not directly focused on model training or ML algorithms—hence a 7/10.",success
https://github.com/AMAI-GmbH/AI-Expert-Roadmap,AI-Expert-Roadmap,"A curated set of roadmap charts and guidance for becoming an AI expert, covering fundamentals plus paths for data science, machine learning, deep learning, and data/big-data engineering. It also powers an interactive version of the roadmap website via a VuePress-based docs site.",30600,machine learning|data science|deep learning|learning roadmap|educational|study plan|vuepress,7,"This repository provides structured learning roadmaps (charts + an interactive site) that map out skills, topics, and technologies for becoming a data scientist / ML / AI expert. It is strongly relevant to ML/data workflows as an educational reference for what to learn and in what order, but it is not a tool/library for building models or running pipelines. Community adoption appears high (tens of thousands of stars), increasing its practical value as a widely referenced guide, which supports a solid but not “core tooling” score.",success
https://github.com/getredash/redash,redash,"Redash is an open-source platform for querying and visualizing data from many SQL/NoSQL sources. It provides a browser-based query editor, dashboards, sharing/collaboration, scheduled refreshes, alerts, and a REST API for programmatic access.",28100,business intelligence|data visualization|dashboards|sql|analytics|data engineering|web application|python,7,"This repository powers Redash, a BI/analytics web application centered on running queries against many databases/warehouses and turning results into visualizations and dashboards. While it is not an ML training or modeling framework, it is highly useful in ML/data workflows for exploratory analysis, feature/data quality monitoring, KPI tracking, and sharing insights across teams. Its alerting, scheduled refresh, and broad connector support make it practical for ongoing monitoring of datasets and model-related metrics, which justifies a moderately high score.",success
https://github.com/ItzCrazyKns/Perplexica,Perplexica,"Perplexica is a privacy-focused, self-hostable AI answering engine (an open-source alternative to Perplexity AI) that combines web search with LLMs to produce answers with cited sources. It supports local models via Ollama as well as multiple cloud LLM providers, and can be run easily via Docker with a bundled SearxNG-powered metasearch setup.",28000,LLM|AI search|RAG|web search|SearxNG|self-hosted|Next.js,7,"Perplexica’s primary use case is an AI-powered answering/search engine that integrates web retrieval (via SearxNG and other providers) with LLMs to generate cited responses, which aligns with retrieval-augmented generation (RAG) patterns commonly used in ML applications. While it is not a model training library, it is directly applicable to ML/LLM engineering workflows (building assistants, search/research tools, and private RAG systems) and offers practical educational value for understanding end-to-end LLM app architecture. Its strong community adoption (tens of thousands of GitHub stars) further supports a moderately high score, but it stops short of being a core ML framework or data-processing library.",success
https://github.com/kestra-io/kestra,kestra,"Kestra is an open-source, event-driven orchestration and scheduling platform for building and running both scheduled and real-time workflows defined declaratively in YAML or created via a UI. It focuses on scalable, version-control-friendly automation with a rich plugin ecosystem for integrating databases, cloud services, APIs, and scripts.",26200,workflow orchestration|data pipelines|scheduler|event-driven|ETL/ELT|DevOps automation|MLOps,7,"This repository provides a general-purpose workflow orchestration and scheduling platform (Kestra) aimed at automating processes and coordinating tasks across systems, with workflows expressed as YAML and runnable/visualizable in a UI. While it is not an ML library itself, it is directly useful in ML/data workflows for orchestrating ETL/ELT, feature generation, training/evaluation jobs, and deployment/monitoring pipelines via its plugin ecosystem and script execution support. Its relevance is therefore moderately high for data engineering/MLOps use cases, but it is not a core ML framework, so it doesn’t merit an 8–10 score.",success
https://github.com/datasciencemasters/go,go,"The Open Source Data Science Masters (OSDSM) is a collaboratively maintained, self-guided curriculum for learning data science using free/open resources. It organizes learning into core foundations, specialty tracks, and a capstone project, with supporting resource lists (e.g., datasets and projects).",25900,data science|machine learning|curriculum|open education|self-study|learning resources|capstone projects,7,"This repository is primarily an open-source curriculum/roadmap that curates learning materials, datasets, and project ideas to help people train for an entry-level data scientist role. It is directly relevant to ML/data workflows as an educational scaffold (what to learn and in what order), but it does not provide an ML library, tooling, or runnable pipeline code. Community adoption appears strong (tens of thousands of GitHub stars), boosting its practical value for learners, while the lack of executable ML functionality keeps it below the highest scores.",success
https://github.com/apache/flink,apache/flink,"Apache Flink is an open-source distributed stream processing framework that supports both streaming and batch processing. It provides high-throughput, low-latency execution with features like event-time processing, windowing, and exactly-once fault tolerance.",25700,data engineering|stream processing|batch processing|distributed systems|apache|java|big data,7,"This repository is the core Apache Flink engine, primarily used to build scalable data processing pipelines for real-time (streaming) and offline (batch) workloads. While it is not an ML framework itself, Flink is highly relevant in ML/data workflows as backbone infrastructure for feature engineering, real-time ingestion, data enrichment, and ETL feeding training/serving systems. It also includes/mentions libraries for machine learning and complex event processing, and is widely adopted in data engineering, which makes it moderately-to-strongly valuable for ML practitioners building production data pipelines.",success
https://github.com/plotly/dash,dash,"Dash is an open-source Python framework for building interactive analytical web applications and dashboards (data apps) without requiring JavaScript. It combines Python callbacks with UI components and Plotly-based visualizations, built on technologies like Flask (backend) and React (frontend).",24400,data visualization|dashboards|python|web development|plotly|react|flask,7,"This repository provides Dash, a framework for creating interactive data apps and dashboards driven by Python code and reactive callbacks. It is directly useful in ML/data workflows for model monitoring, exploratory analysis, experiment/result reporting, and building internal tools that wrap data pipelines or model outputs into shareable UIs. While it is not an ML training/inference framework itself, its strong adoption in the data science community and tight integration with common Python analytics tooling make it moderately-to-highly valuable for ML/data work.",success
https://github.com/Fosowl/agenticSeek,agenticSeek,"AgenticSeek is a fully local, privacy-focused autonomous AI assistant (positioned as a local alternative to Manus AI) that can browse the web, plan and execute tasks, and write/run code while keeping data on the user’s machine. It is designed to work with local LLM providers (e.g., Ollama/LM Studio) and can optionally use API-based providers, with supporting services (e.g., SearxNG) commonly run via Docker.",24300,autonomous-agents|local-llm|llm-orchestration|web-browsing-automation|developer-tools|python|docker,7,"This repository implements an autonomous agentic assistant that orchestrates LLM reasoning plus tool use (notably automated web browsing and coding/execution), primarily targeting local/private setups via local model providers. While it is not a data-science library (no direct focus on training models, datasets, or core ML algorithms), it can be meaningfully useful in ML/data workflows as an automation layer for research, information extraction, code generation, and multi-step task execution. Community adoption appears strong (tens of thousands of GitHub stars), which increases its practical relevance, but its value is more in agentic tooling than in data/ML fundamentals—hence a moderately high (but not core) ML/data score.",success
https://github.com/wilsonfreitas/awesome-quant,awesome-quant,"A curated “awesome list” of libraries, packages, and learning resources for quantitative finance. It organizes tools across many languages (e.g., Python, R, Julia) and domains like data structures, pricing, indicators, and backtesting.",23600,quantitative finance|financial engineering|data science|machine learning|python|time series|trading|awesome-list,7,"This repository is primarily a curated index of quantitative finance software and educational resources rather than a single ML library or dataset. It is still very relevant to ML/data workflows because it aggregates widely used data/ML-adjacent tools (e.g., numerical computing, dataframes, time-series storage, portfolio optimization, and some ML-oriented quant tooling) that data scientists can discover and adopt. Its strong community adoption (large star count) increases its practical and educational value as a starting point for selecting quant/data tooling. The score is not higher because it does not provide direct ML implementations, training pipelines, or datasets itself; it mainly points to external projects.",success
https://github.com/ashishpatel26/500-AI-Agents-Projects,500-AI-Agents-Projects,"A curated directory of 500+ AI agent project ideas and real-world use cases across industries, with categorized tables and links to open-source implementations. It also organizes examples by popular agent frameworks (e.g., CrewAI, AutoGen, LangGraph) to help users find relevant patterns and references.",22300,ai agents|llm applications|multi-agent systems|agent frameworks|generative ai|llm tools|project collection,7,"This repository primarily serves as a curated catalog of AI agent use cases and links to external open-source implementations, rather than being a standalone ML library or dataset. It is still quite useful for ML/LLM practitioners because it accelerates discovery of agent patterns, industry applications, and framework-specific examples that can be adapted into real workflows. Community adoption appears strong (high star count), and the educational value is high, but direct integration value is moderate since most implementations live in linked projects rather than in this repo itself.",success
https://github.com/matplotlib/matplotlib,matplotlib,"Matplotlib is a comprehensive Python library for creating static, animated, and interactive data visualizations, producing publication-quality figures across many output formats and interactive environments. It supports use in scripts, notebooks, shells, web servers, and GUI toolkits.",22200,python|data-visualization|plotting|data-science|scientific-computing|jupyter|gui,7,"This repository contains Matplotlib, a general-purpose plotting and visualization library for Python used to generate publication-quality charts and figures. It is not an ML framework, but it is a core tool in data science and ML workflows for exploratory data analysis, experiment reporting, and visualizing model behavior and results. Its broad adoption in the scientific Python ecosystem and strong integration with notebooks and common DS tooling make it moderately-to-highly valuable for ML/data work, hence a 7/10.",success
https://github.com/airbnb/visx,visx,"visx is a modular collection of reusable, low-level React visualization components that use D3 for calculations and data-to-pixels math while letting React handle DOM updates. It’s intentionally unopinionated (state, styling, animation) and designed for building custom charts or your own charting system with small, pick-and-choose packages.",20500,data visualization|react|d3|typescript|frontend|charting|svg,7,"This repository provides low-level visualization primitives for React, leveraging D3 under the hood, and is primarily used to build interactive charts and analytical UI components. It’s moderately relevant to ML/data workflows because data scientists and ML engineers frequently need to visualize datasets, features, metrics, experiments, and model performance in dashboards or internal tools, and visx is well-suited for custom, production-grade visualizations. It is not an ML framework or data processing toolkit, so it doesn’t directly support model training/inference, but its strong adoption and flexibility make it a valuable visualization layer for data products and analytics applications.",success
https://github.com/airbytehq/airbyte,airbyte,"Airbyte is an open-source data integration platform for building and running ETL/ELT pipelines, moving data from APIs, databases, and files into warehouses, lakes, and lakehouses. It includes a large connector catalog plus tools like a Connector Builder and CDK for creating custom connectors, and supports orchestration/integration with common workflow tools.",20400,data engineering|ETL|ELT|data integration|data pipelines|connectors|data warehouses|orchestration,7,"This repository is primarily a data integration/ELT platform (not an ML framework), focused on extracting data from many sources and loading it into analytics destinations with a large connector ecosystem. It is highly applicable to ML and data science workflows as upstream infrastructure for dataset creation, feature/analytics data centralization, and reliable ingestion into warehouses/lakes that ML pipelines commonly read from. Community adoption appears strong (20.4k GitHub stars) and it integrates well with orchestration tools and broader data stack components, making it valuable for ML/data engineering—though it does not directly provide model training/inference capabilities.",success
https://github.com/bokeh/bokeh,bokeh,"Bokeh is an interactive data visualization library for modern web browsers that lets you build interactive plots, dashboards, and data applications from Python, with a JavaScript (BokehJS) frontend for high-performance interactivity (including for large or streaming datasets).",20300,data visualization|interactive plotting|python|javascript|dashboards|jupyter|web visualization,7,"This repository provides Bokeh, a widely used Python + JavaScript library for building interactive visualizations and browser-based data apps. While it is not an ML framework, it is highly applicable to ML/data science workflows for exploratory data analysis, communicating results, building interactive dashboards, and integrating into Jupyter notebooks and data applications. Its strong ecosystem adoption and focus on performant interactivity over large/streaming datasets make it a solid enabling tool for data science, but it does not directly address model training, inference, or MLOps—hence a 7/10 rather than a higher score.",success
https://github.com/Skyvern-AI/skyvern,skyvern,"Skyvern is an AI agent platform for automating browser-based workflows using LLMs and computer vision, exposed via APIs and SDKs. It aims to replace brittle script/XPath-driven RPA by using vision-enabled reasoning to interact with websites that can change layout over time.",20100,llm-agents|browser-automation|computer-vision|playwright|rpa|python|typescript-sdk|automation-platform,7,"This repository primarily provides an AI-driven browser automation/agent system (with local + cloud execution) that uses vision-capable LLMs to plan and execute web tasks, plus SDKs for integration into applications. It is relevant to ML workflows because it operationalizes LLM+vision capabilities in an agentic automation setting and includes evaluation/performance materials, but it is not a general-purpose ML training framework or data processing library. Community adoption appears strong for an automation tool (tens of thousands of GitHub stars), which increases practical value for ML engineers building agentic systems. I scored it a 7 because it is a substantial applied-ML/agent infrastructure project, moderately-to-highly useful for ML practitioners working on agents/automation, but not a core data science toolkit like pandas/Spark/PyTorch.",success
https://github.com/mementum/backtrader,backtrader,"Backtrader is a Python framework for backtesting and live trading of algorithmic strategies. It supports multiple data feeds and timeframes, built-in technical indicators/analyzers, broker simulation, plotting, and integrations with some live brokers/data sources (e.g., Interactive Brokers, Oanda) plus optional TA-Lib support.",20000,algorithmic trading|backtesting|quantitative finance|python|time series|technical analysis|trading strategies,7,"This repository is primarily a trading strategy backtesting and live-trading engine in Python, including data feed handling, indicators, analyzers (e.g., returns/Sharpe-style metrics), and plotting. It is not an ML framework itself, but it is directly useful in data science workflows for financial time-series research, feature/indicator engineering, strategy evaluation, and experimentation over historical market data. Its broad adoption in the quant/trading community and built-in analytics/strategy infrastructure make it moderately-to-highly valuable for ML-adjacent research (especially for systematic trading), but it lacks native model training, ML pipelines, or deep integrations with modern ML tooling—hence a 7/10.",success
https://github.com/quantopian/zipline,zipline,"Zipline is a Pythonic, event-driven algorithmic trading library for backtesting trading strategies. It integrates with the PyData stack (e.g., Pandas DataFrames) and provides built-in tools for performance/statistics analysis and strategy development workflows.",19300,algorithmic-trading|backtesting|quant-finance|python|pandas|event-driven|time-series,7,"This repository provides an event-driven backtesting engine and related tooling for developing and evaluating quantitative trading strategies, with tight integration into common data-science workflows via Pandas DataFrames. While it is not an ML framework, it is frequently used in data/ML pipelines for feature engineering, time-series research, and systematic strategy evaluation, and it explicitly supports use alongside ML/statistics libraries (e.g., scikit-learn and statsmodels). Its value for ML/data work is solid due to practical applicability in quant research and education, but it scores below core ML libraries because its primary focus is trading/backtesting rather than model training.",success
https://github.com/SWE-agent/SWE-agent,SWE-agent,"SWE-agent is a Python-based autonomous software engineering agent that takes a GitHub issue and attempts to generate and validate a fix using a language model plus tool use (e.g., running commands/tests) and supports configurable workflows via a single YAML file. It is also used for related domains like coding challenges and (optionally) offensive cybersecurity tasks (EnIGMA mode).",18200,LLM agents|automated software engineering|GitHub issue automation|developer tools|benchmarking (SWE-bench)|cybersecurity|Python,7,"This repository provides an LLM-driven agent framework focused on automatically solving real GitHub issues by executing tools (shell/test runs) and producing code changes, making it primarily a software-engineering automation system rather than a general ML library. It is relevant to ML workflows because it is widely used in the coding-agent research ecosystem (e.g., SWE-bench evaluations) and can be used to generate agent trajectories/logs and run systematic benchmarks, which are valuable for agent research and training/evaluation data. However, it is not directly a core data science toolkit (like data processing/model training frameworks), so its value to typical ML/data practitioners is moderate-to-high rather than central, justifying a 7/10.",success
https://github.com/openai/openai-agents-python,openai-agents-python,"The OpenAI Agents SDK is a lightweight, provider-agnostic Python framework for building multi-agent workflows. It supports OpenAI Responses and Chat Completions APIs as well as 100+ other LLMs, and includes concepts like agents, handoffs, guardrails, sessions, and built-in tracing for debugging and optimization.",18200,LLM agents|multi-agent systems|Python|OpenAI API|agent orchestration|tool calling|MLOps observability,7,"This repository provides a Python SDK for orchestrating LLM-based agents, including tool calling, agent handoffs, guardrails for validation/safety checks, session management, and tracing for inspecting runs. It is directly useful to ML/LLM engineers building agentic applications and evaluating/debugging agent behavior, but it is not primarily a model-training or data-processing library like core ML frameworks. The strong adoption signal (high GitHub stars) and built-in tracing/guardrails make it valuable for practical LLM application development and lightweight MLOps-style workflows, justifying a moderately high score rather than a 9–10.",success
https://github.com/plotly/plotly.py,plotly.py,"Plotly's interactive, open-source graphing library for Python, built on top of plotly.js. It provides high-level, declarative APIs for creating interactive charts (including 3D, statistical, scientific, and map visualizations) for use in notebooks, standalone HTML, or Dash apps.",18200,data visualization|python|interactive charts|plotly|jupyter|dash|webgl,7,"This repository implements Plotly's core Python visualization library, enabling interactive, browser-rendered charts from Python with strong support for notebooks and web app integration. While it is not an ML framework, it is highly useful in ML/data science workflows for exploratory data analysis, communicating model results, and building interactive dashboards around datasets and predictions. Its broad adoption and rich charting capabilities make it a strong general-purpose data science tool, but it does not directly provide model training/inference functionality, so it rates below core ML libraries.",success
https://github.com/plotly/plotly.js,plotly.js,"Plotly.js is an open-source JavaScript data visualization library for building interactive charts (including statistical, scientific, 3D, mapping, and financial visualizations). It also serves as the underlying charting engine for Plotly’s higher-level libraries and frameworks such as Plotly.py/Plotly.R and Dash.",18000,javascript|data-visualization|charting-library|interactive-visualization|dash|plotly|web-development|data-science,7,"This repository provides a widely used interactive charting and visualization engine that is central to exploratory data analysis, dashboarding, and communicating ML results. While it is not an ML framework itself, it is directly applicable in ML/data workflows for visualizing datasets, feature distributions, model diagnostics, and predictions (and it underpins Dash apps used frequently in data science). Its broad adoption in the data community and strong integration into Python/R ecosystems justify a moderately high score, but it does not cover core ML tasks like training, inference, or pipeline orchestration.",success
https://github.com/k4yt3x/video2x,video2x,"Video2X is a machine learning-based framework for video upscaling (super-resolution) and frame interpolation. It provides a fast, cross-platform pipeline (C/C++ rewrite) and supports multiple popular upscaling/interpolation backends such as Anime4K, Real-ESRGAN, Real-CUGAN, and RIFE.",16700,video super-resolution|frame interpolation|computer vision|image upscaling|Vulkan|ncnn|C/C++,7,"This repository is primarily a practical application framework that uses ML-based models (e.g., Real-ESRGAN/Real-CUGAN for super-resolution and RIFE for interpolation) to enhance videos, focusing on an optimized processing pipeline and end-user tooling (CLI/GUI, installers). It is directly useful in ML-adjacent workflows for generating higher-quality visual data, preprocessing media for downstream tasks, or benchmarking/producing enhanced datasets, but it is not itself a training framework or dataset library. Community adoption appears strong (high star count), and it has educational value for integrating pretrained CV models into a performant production-style pipeline, justifying a moderately high score rather than a core-ML score.",success
https://github.com/mediar-ai/screenpipe,screenpipe,"Screenpipe is an open-source, local-first “AI app store” built on a 24/7 desktop history system that records screen and microphone activity, performs indexing (including OCR/vision), and exposes the data via an API for building context-aware desktop AI apps/plugins (“pipes”). It targets developer-friendly creation, publishing, and monetization of desktop-native AI agents and automations powered by full on-device user context.",16400,machine-learning|ai|computer-vision|multimodal|llm|desktop-agents|rust|tauri,7,"The repository’s primary purpose is to continuously capture and index desktop context (screen + mic) locally and provide an API/plugin ecosystem (“pipes”) so developers can build desktop AI apps/agents with rich user context. This is meaningfully relevant to ML/data workflows because it enables creation of multimodal context pipelines (OCR/vision + audio) and supports agentic applications that depend on logged real-world interaction data, but it is not itself a model-training framework or core ML library. Community adoption appears strong (16.4k stars) and it has practical integration potential for building ML-powered assistants and automations, justifying a moderately-high score rather than a core-framework score.",success
https://github.com/AccumulateMore/CV,CV,"A large collection of deep learning study notes and Jupyter notebooks covering PyTorch tutorials and popular deep learning courses (e.g., D2L, Andrew Ng), intended as a comprehensive learning/reference repository.",15800,deep learning|PyTorch|Jupyter notebooks|computer vision|machine learning education|tutorials|neural networks,7,"This repository primarily contains extensive deep learning learning materials in the form of numerous Jupyter notebooks (including many PyTorch-focused tutorials and course-style notes), making it directly useful for practitioners learning or revising ML/DL concepts. It is relevant to ML/data workflows mainly as educational/reference content rather than a reusable library, dataset, or production tool, so integration potential into pipelines is limited. Community adoption appears strong for a learning repo (15.8k GitHub stars and ~1.8k forks), supporting a moderately high score. Overall, it is valuable for ML education and experimentation but not a core ML framework or widely-integrated tooling, hence a 7/10.",success
https://github.com/bbfamily/abu,abu,"Abu is a Python-based open-source quantitative trading system/framework for backtesting and strategy research across markets such as stocks, options, futures, and Bitcoin, with included learning materials and UI components. The repository contains the core library (abupy), tutorials/lectures, and example code referenced by the project's documentation site.",15800,quantitative trading|algorithmic trading|backtesting|python|finance|time series|machine learning|cryptocurrency,7,"This repository primarily provides a Python quantitative trading framework (abupy) plus tutorials and example notebooks/code for building and testing trading strategies across multiple asset classes. It is relevant to ML/data workflows because quant research typically involves time-series data ingestion, feature/indicator engineering, strategy evaluation, and (optionally) ML-driven signals; the repo explicitly positions itself as supporting machine learning in trading research. However, it is not a general-purpose ML framework and its applicability is concentrated in the finance/quant domain rather than broad ML tasks, which is why it scores as moderately-high rather than top-tier.",success
https://github.com/apache/hadoop,hadoop,"Apache Hadoop is an open-source framework for distributed storage and processing of large datasets across clusters, providing core components such as HDFS (distributed filesystem), YARN (cluster resource management), and MapReduce (batch processing). This repository contains the full source code, build tooling, and subprojects that make up Hadoop.",15400,big data|distributed systems|data engineering|hadoop|hdfs|yarn|mapreduce|java,7,"This repository implements Apache Hadoop, a foundational big-data platform for distributed storage (HDFS) and cluster compute/resource management (YARN) with batch processing via MapReduce. While Hadoop itself is not an ML framework, it is heavily used in data engineering workflows that feed ML (data ingestion, ETL, large-scale batch feature generation, and storage), and it integrates with common analytics/ML ecosystem components (e.g., Hive, Spark, distributed training pipelines via YARN). Its broad industry adoption and infrastructure role make it valuable for ML/data practitioners, but the lack of native model training/serving features keeps it below core ML libraries/frameworks.",success
https://github.com/langbot-app/LangBot,LangBot,"LangBot is a production-grade, open-source platform for building and managing LLM-powered instant-messaging bots across many chat apps. It provides an admin web UI plus features like agents, knowledge-base/RAG orchestration, and a plugin system, with integrations for popular LLM/model providers and AI app stacks.",14800,LLM|chatbots|agent|RAG|instant messaging|plugin system|Python|MLOps / LLMOps,7,"This repository is primarily an IM-bot development and operations platform (multi-channel connectors + web admin + plugin runtime) for deploying LLM-powered assistants across chat platforms. It is meaningfully relevant to ML/AI workflows because it supports agent-style tool use and knowledge-base/RAG capabilities and integrates with multiple model providers, making it useful as an LLMOps deployment layer. However, it is not a core data-science library for data processing/model training, and its value to data scientists is mostly on the application/deployment side rather than research/training, so a mid-high score is appropriate.",success
https://github.com/pydantic/pydantic-ai,pydantic-ai,"Pydantic AI is a Python GenAI/LLM agent framework built by the Pydantic team to create production-grade agentic applications and workflows with strong type-safety and Pydantic-validated structured outputs. It is model-agnostic (supports many LLM providers), includes tooling/dependency injection patterns, streaming structured outputs, evals, and integrations for observability (e.g., via Pydantic Logfire).",14200,generative-ai|llm-agents|python|pydantic|agent-framework|tool-calling|observability,7,"This repository provides an agent framework for building applications and workflows on top of LLMs, emphasizing Pydantic-based validation, typed dependency injection, tool calling, streaming structured outputs, and evaluation/monitoring support. It is not a model-training or data-processing library, but it is directly useful for ML/AI engineers building LLM-powered systems (agents, RAG-like apps, tool-augmented workflows) and for evaluating and operating them in production. The strong ecosystem fit with multiple model providers and evaluation/observability features make it moderately-to-highly relevant for practical applied ML, hence a 7 rather than a core-ML-framework score.",success
https://github.com/apache/dolphinscheduler,apache/dolphinscheduler,"Apache DolphinScheduler is an open-source, distributed workflow orchestration and scheduling platform for building and running DAG-based data pipelines. It provides low-code workflow design plus execution, monitoring, and management for ETL/data integration jobs and other task types.",14100,workflow orchestration|data pipelines|ETL|scheduler|big data|DAG|Apache,7,"This repository provides a production-grade workflow orchestration/scheduling system aimed at running complex DAG workflows, commonly used for data engineering and ETL. While it is not an ML framework itself, it is directly useful for ML/data workflows as the orchestrator for data preparation, feature pipelines, batch scoring, and integration with engines like Spark/Flink/Hive via task plugins. Its strong community adoption as an Apache project and its broad task/plugin ecosystem increase its practical value for data teams, but it remains infrastructure/orchestration rather than model-development tooling, which keeps it below the highest scores.",success
https://github.com/janishar/mit-deep-learning-book-pdf,mit-deep-learning-book-pdf,"A repository providing a “beautiful and flawless” PDF compilation of the MIT Press Deep Learning book (originally published as free HTML at deeplearningbook.org), including a complete PDF and chapter-wise PDFs. It also includes a small Java utility (Pdf2EpubConverter.java) related to converting the PDFs.",13800,deep learning|machine learning|book pdf|educational resource|neural networks|MIT Press|PDF,7,"This repository primarily distributes PDF versions (full and chapter-wise) of the well-known Deep Learning textbook by Goodfellow, Bengio, and Courville, with minimal code beyond a small Java converter utility. It is highly relevant educational material for ML practitioners and students, but it is not an ML library, dataset, training codebase, or tooling that directly plugs into ML workflows. The strong community adoption (high star count) and clear learning value justify a moderately high score, but the lack of practical ML code, data, or integrations keeps it below an 8-10.",success
https://github.com/mwaskom/seaborn,seaborn,"Seaborn is a Python library for statistical data visualization built on top of Matplotlib. It provides a high-level API for creating attractive, informative statistical graphics and integrates well with pandas data structures.",13700,python|data-visualization|statistics|data-science|matplotlib|pandas,7,"This repository contains Seaborn, a widely used Python library focused on statistical data visualization, offering high-level plotting functions that make exploratory data analysis (EDA) and presentation graphics easier. While it is not an ML training/inference framework, it is directly useful in ML/data workflows for understanding datasets, diagnosing feature/target relationships, and communicating results through visualizations. Its strong community adoption and tight integration with common DS tools (notably pandas and matplotlib) make it a solid supporting library for ML practitioners, warranting a 7/10 rather than a higher score reserved for core modeling or pipeline frameworks.",success
https://github.com/visgl/deck.gl,deck.gl,"deck.gl is a GPU-powered (WebGL2/WebGPU) visualization framework for rendering large-scale datasets in the browser using a composable layer architecture. It supports interactive picking/highlighting, geospatial projections, and integration with popular basemap providers, with usage options including JavaScript/React and Python (via pydeck).",13700,data visualization|geospatial|WebGL|WebGPU|JavaScript|TypeScript|React,7,"This repository provides a high-performance GPU-accelerated framework for interactive visualization of large datasets, especially geospatial data, via a layered rendering model. While it is not an ML training or modeling library, it is directly valuable in ML/data workflows for exploratory data analysis, visual analytics, and communicating model outputs (e.g., spatial predictions, clustering results, trajectories) at scale. Its broad adoption in the data visualization ecosystem and integrations (including a Python pathway via pydeck) make it moderately-to-highly relevant to data science use cases, but it is not core infrastructure for model development, hence a 7/10.",success
https://github.com/antvis/G2,G2,"G2 is a JavaScript/TypeScript “visualization grammar” for building web-based charts for dashboards, data exploration, and storytelling using a declarative, extensible grammar of marks, transforms, scales, coordinates, and compositions.",12500,data visualization|javascript|typescript|charting|grammar of graphics|web development|dashboarding,7,"This repository provides a visualization grammar and rendering pipeline for creating interactive charts in the browser (Canvas/SVG/WebGL) with a declarative API and strong extensibility. While it is not an ML framework, it is directly useful in data science workflows for exploratory data analysis (EDA), reporting, and communicating model results via dashboards and visual storytelling. Its broad adoption and mature feature set make it a solid tool for data practitioners, but it does not cover model training, evaluation, or MLOps, which keeps the score below the core ML tooling range.",success
https://github.com/trinodb/trino,trino,"Trino is a fast, distributed SQL query engine for big data analytics (formerly known as PrestoSQL). It enables federated queries across multiple data sources via a connector/plugin architecture and includes a CLI and server for running distributed SQL workloads.",12400,distributed-sql|query-engine|big-data|data-engineering|federated-query|java|analytics,7,"This repository is the official codebase for Trino, a distributed SQL query engine used to run interactive analytics and federated queries across many data sources. While it is not an ML framework, it is highly relevant to data science and ML workflows because it is commonly used to access, join, and transform large datasets (often from data lakes/warehouses) that feed feature engineering, training, and evaluation pipelines. Its mature ecosystem of connectors and broad adoption in the data engineering world makes it valuable infrastructure for ML/data teams, but its primary purpose is SQL analytics rather than model development—hence a moderately high score instead of a core-ML score.",success
https://github.com/dbt-labs/dbt-core,dbt-core,"dbt Core is the open-source command-line tool that lets data analysts and engineers define analytics transformations as SQL “models” and build them into tables/views in a data warehouse with software-engineering best practices like dependency graphs, testing, and documentation.",12100,data engineering|analytics engineering|ELT|SQL|data modeling|data warehouse|Python|dbt,7,"dbt-core is primarily a data transformation and modeling tool for analytics/warehouse workflows (building SQL models into tables/views, managing dependencies, and running tests/docs). It is not an ML framework, but it is highly useful in ML/data workflows for creating reliable, version-controlled feature tables and curated datasets that downstream training and inference pipelines depend on. It has strong community adoption in the modern data stack and integrates well with orchestration and warehouse ecosystems, making it moderately-to-highly valuable for ML and data science teams (especially for data preparation and governance), but not for model training itself.",success
https://github.com/spencermountain/compromise,compromise,"Compromise is a lightweight JavaScript natural language processing library that parses text into a queryable document model, enabling pattern matching (tags), extraction, and text transformations (e.g., conjugation, pluralization, contractions). It aims for modest, fast, and “sensible” NLP rather than heavy statistical/ML-based parsing.",12000,nlp|natural language processing|javascript|nodejs|text parsing|information extraction|text normalization|tokenization,7,"This repository provides a practical NLP toolkit for turning raw text into structured, queryable data and performing common linguistic transformations, which is directly useful in many data preparation and feature-engineering workflows. While it is not an ML model-training framework and does not primarily focus on statistical/learned NLP, it can still be valuable for preprocessing, rule-based extraction, and building lightweight text pipelines in JavaScript/Node environments. Its strong adoption (12k GitHub stars) indicates broad utility and community use, supporting a moderately high score.",success
https://github.com/jacomyal/sigma.js,sigma.js,Sigma.js is an open-source JavaScript library for rendering and interacting with large network/graph visualizations (thousands of nodes and edges) in the browser using WebGL. It is built to work with the Graphology graph data model and ecosystem.,11800,javascript|typescript|webgl|graph-visualization|network-graphs|data-visualization|graphology|frontend-library,7,"This repository provides a high-performance WebGL-based graph (network) visualization and interaction library for the browser, typically used to display node-link diagrams at scale. While it is not an ML framework or data-processing library, network visualization is a common and valuable step in exploratory data analysis, graph analytics workflows, and communicating results (including ML outputs on graph-structured data). Its relevance is strongest for data scientists and ML engineers working with graph data (e.g., social networks, knowledge graphs) who need interactive visualization in web apps, which justifies a moderately high score rather than a core-ML score.",success
https://github.com/vega/vega,vega,"Vega is a declarative visualization grammar that lets you describe interactive data visualizations in JSON and render them to the web using HTML5 Canvas or SVG. It supports creating, saving, and sharing visualization designs, with documentation, examples, and an online editor available via the Vega website.",11800,data visualization|visualization grammar|javascript|typescript|json specification|svg|canvas,7,"This repository implements Vega, a widely used declarative grammar for building interactive data visualizations from JSON specifications, rendered via Canvas or SVG. While it is not an ML framework, it is directly useful in ML/data workflows for exploratory data analysis (EDA), model result reporting, and building interactive dashboards/visual analytics around datasets and predictions. Its strong adoption and integration into the broader visualization ecosystem make it highly valuable to data scientists, but its focus is visualization rather than data processing or model training, which keeps it below the 8–10 range.",success
https://github.com/TA-Lib/ta-lib-python,ta-lib-python,"Python wrapper (Cython-based) for the TA-Lib technical analysis library, providing access to 150+ trading indicators and candlestick pattern recognition with NumPy support. It also supports integration with common dataframe libraries like Pandas and Polars for financial time-series workflows.",11600,python|technical-analysis|quant-finance|trading-indicators|time-series|numpy|pandas|cython,7,"This repository provides Python bindings to TA-Lib, a widely used library for computing technical analysis indicators and candlestick patterns on financial market time-series. It is directly useful in data science workflows for feature engineering in quantitative finance (e.g., generating RSI/MACD/Bollinger Bands features for downstream modeling) and integrates well with NumPy as well as Pandas/Polars. It is not an ML framework itself (no model training/inference), but it is a commonly adopted, practical preprocessing/feature library for ML on price/volume data, which justifies a moderately high score rather than a core-tool score.",success
https://github.com/keplergl/kepler.gl,kepler.gl,"Kepler.gl is an open-source, high-performance web app and React component for interactive visual exploration and geospatial analysis of large-scale location datasets. It is built on MapLibre GL and deck.gl to render millions of points, visualize trips, and perform spatial aggregations in the browser.",11500,geospatial|data visualization|mapping|web application|react|deck.gl|maplibre-gl|spatial analytics,7,"This repository provides a widely used geospatial data visualization and exploration tool (plus embeddable React components) aimed at analyzing large-scale location datasets in the browser. While it is not an ML framework, it is directly useful in data science workflows for exploratory data analysis (EDA), feature understanding, and communicating spatial patterns and results via interactive maps. Its broad adoption and integrations (including a Jupyter widget binding) make it a strong enabling tool for data/ML practitioners working with geospatial data, but it does not cover model training or MLOps, keeping it below the highest scores.",success
https://github.com/myhhub/stock,stock,"InStock is a stock analysis and trading system that captures daily stock/ETF data, computes technical indicators and chip/position cost distributions, recognizes candlestick (K-line) patterns, and supports stock screening strategies with validation/backtesting and optional automated trading. It includes a web UI suitable for PC/mobile and provides Docker images for easier deployment.",11100,quantitative trading|stock market|data collection|time series|technical analysis|backtesting|python|docker,7,"This repository focuses on quantitative investing workflows: acquiring daily stock/ETF data, engineering features via many technical indicators, and running screening strategies with validation/backtesting, with optional automation for trading. It is strongly relevant to data science because it provides a ready-made pipeline for financial time-series data ingestion and feature computation that can feed ML models, even though the repo’s primary approach appears to be rule/indicator-driven rather than model-training-centric. Given its practical DS utility (feature engineering + backtesting) and evident community adoption (high star count), it merits a moderately-high score, but not an 8–10 since it is not a general-purpose ML framework or a dedicated MLOps/modeling toolkit.",success
https://github.com/PointCloudLibrary/pcl,pcl,"The Point Cloud Library (PCL) is a large-scale, standalone C++ library for 2D/3D image and point cloud processing. It provides algorithms and tools for tasks like filtering, feature estimation, segmentation, registration, surface reconstruction, and visualization.",10800,point-cloud-processing|3d-computer-vision|lidar|robotics|c-plus-plus|3d-geometry|registration-and-segmentation|visualization,7,"This repository is the core implementation of PCL, a widely used C++ toolkit for processing point clouds (often from LiDAR, RGB-D cameras, or 3D scanners) with modules for filtering, segmentation, registration, and feature computation. While it is not primarily an ML training framework, it is highly relevant to ML/data workflows as a preprocessing and geometry/feature-extraction pipeline for 3D perception datasets and as a foundation for building 3D perception systems. Its broad adoption in robotics and 3D computer vision, plus its practical utilities for preparing and transforming 3D data before learning-based stages, justify a moderately-high score rather than a core-ML score.",success
https://github.com/altair-viz/altair,altair,"Vega-Altair is a declarative statistical data visualization library for Python built on the Vega-Lite JSON specification. It provides a concise, type-checked API for creating interactive charts (commonly from pandas DataFrames) and rendering/exporting them in notebook and web contexts.",10200,data visualization|python|vega-lite|interactive charts|pandas|jupyter,7,"This repository provides Altair, a Python library for declarative statistical visualization (including interactive visualizations) based on the Vega-Lite grammar. It is directly useful in ML/data workflows for exploratory data analysis, model/result reporting, and building shareable interactive visualizations from common data structures like pandas DataFrames. While it is not an ML training/inference framework, it has strong adoption in the data science community and integrates well with notebook-based workflows, warranting a moderately high relevance score.",success
https://github.com/google/magika,magika,"Magika is Google’s AI-powered file content-type detection tool, using a compact deep learning model to identify 200+ file types accurately and quickly (millisecond-level inference) from only small byte ranges of files. It provides a high-performance Rust CLI plus language bindings/APIs (notably Python and JavaScript/TypeScript) for integration into security and content-processing pipelines.",10000,file-type-detection|deep-learning|security-tooling|rust|python|typescript-javascript|onnx-runtime|content-classification,7,"This repository delivers an ML-backed classifier for file content-type identification, shipping a compact model and production-ready tooling (Rust CLI and language bindings) aimed at fast inference on CPUs. It is directly useful in data/ML and security workflows for dataset curation, ingestion validation, file triage, and pipeline routing (e.g., detecting Parquet/HDF5/ipynb and many other formats), but it is not a general-purpose ML framework for training or experimentation. Community adoption appears meaningful (e.g., broad usage and official Google release/maintenance), and it has solid educational value for applied ML inference/packaging, which supports a moderately-high score rather than a core-ML-tool score.",success
https://github.com/rerun-io/rerun,rerun,"Rerun is an open-source SDK and viewer for logging, storing, querying, and visualizing time-aware multimodal data (e.g., images, tensors, point clouds, text, time series). It targets robotics-style, multi-stream data and supports live streaming to a viewer, saving to .rrd recordings, and querying via a dataframe-style API.",9900,data-visualization|robotics|computer-vision|multimodal-data|time-series|python|rust|c++,7,"This repository provides a time-aware multimodal data logging and visualization stack (SDK + Viewer) designed to help inspect and debug complex systems that generate rich sensor/ML outputs (2D/3D, tensors, text, signals) over time. It is directly useful in ML/data workflows for computer vision and robotics because it can capture model inputs/outputs and system state, visualize them live, and export/query recordings (including via a dataframe API) to build datasets for training/evaluation. However, it is not itself a model-training framework or core ML library; its value is strongest as an observability/visual analytics and dataset-extraction tool, hence a moderately high (but not top-tier) ML/data score.",success
https://github.com/NoFxAiOS/nofx,nofx,"NOFX is an open-source, self-hosted “agentic trading OS” that connects market data to AI model reasoning and automated trade execution across multiple markets and exchanges. It provides a web UI for strategy configuration, real-time monitoring, backtesting/competition features, and supports multiple LLM providers as a pluggable “AI brain.”",9700,algorithmic-trading|fintech|llm|ai-agents|backtesting|crypto-trading|web-dashboard|golang,7,"This repository is primarily an AI-assisted automated trading platform/OS that orchestrates data ingestion (market data), LLM-based reasoning, and trade execution via exchanges, with a web interface and modules like backtesting and competition. It is moderately to highly relevant to ML workflows because it operationalizes AI models (LLMs) in a real-time decision system and includes experimentation/monitoring surfaces, but it is not a general-purpose ML framework or a dataset/toolkit for model training. The strong community adoption signal (9.7k stars) and built-in features for strategy testing increase its practical value for ML engineers working on agentic finance systems, while its domain specificity keeps it below “core ML tool” scores.",success
https://github.com/yutiansut/QUANTAXIS,QUANTAXIS,"QUANTAXIS is a local-first quantitative trading platform for stocks/futures/options, providing data acquisition/management, backtesting, simulation, trading execution, visualization, and multi-account support, with support for distributed deployment and task scheduling. Recent versions integrate a Rust core (QARS2) to significantly accelerate account operations and backtesting while maintaining Python API compatibility.",9700,quantitative finance|algorithmic trading|backtesting|financial data|python|rust|data engineering|distributed systems,7,"This repository is primarily a quantitative trading and research stack that covers financial data ingestion/storage plus backtesting/simulation and trading workflows, rather than a dedicated machine-learning framework. It is valuable to data scientists working in finance because it provides an end-to-end environment for building datasets, running strategy experiments, and integrating execution—core steps that often surround ML modeling in real trading pipelines. Its sizable community adoption (thousands of stars) and broad feature set (data, backtesting, visualization, deployment) make it practically useful, but ML model training itself is not the central focus, so it scores below pure ML/MLOps frameworks.",success
https://github.com/apache/seatunnel,seatunnel,"Apache SeaTunnel is a high-performance, distributed data integration tool for building batch and streaming data pipelines. It provides a large ecosystem of connectors and supports multiple execution engines (including SeaTunnel Zeta Engine, Flink, and Spark) to move and synchronize data across diverse sources and sinks.",9000,data-engineering|etl|data-integration|data-pipelines|stream-processing|batch-processing|apache-flink|apache-spark,7,"This repository provides an ETL/data integration platform designed to move and synchronize large volumes of data across many systems using a connector-based architecture and multiple runtime engines. While it is not an ML framework, it is directly useful in ML/data workflows for building ingestion and feature/data pipelines that feed warehouses, lakes, or training/serving systems. Its broad connector support and distributed execution make it a solid enabling tool for data science and ML engineering, but the core focus remains data transport/integration rather than modeling or MLOps, hence a 7.",success
https://github.com/uber/react-vis,react-vis,"A React-based data visualization library (built around D3 concepts) providing composable components for common charts like line/area/bar charts, scatterplots, heatmaps, contour/hexbin heatmaps, pie/donut charts, sunbursts, radar charts, parallel coordinates, and treemaps.",8800,data visualization|react|javascript|d3|charts|frontend|ui-components,7,"react-vis is primarily a frontend charting/component library for building interactive data visualizations in React, offering many common chart types and composable primitives. While it is not an ML framework, it is directly useful in ML/data workflows for exploratory data analysis dashboards, model monitoring UIs, and reporting/communication of results. Its relevance is moderate-to-high for data science because visualization is central to analysis and monitoring, but it does not provide modeling, training, or data processing capabilities, which keeps it below core ML tooling.",success
https://github.com/iamseancheney/python_for_data_analysis_2nd_chinese_version,python_for_data_analysis_2nd_chinese_version,《利用Python进行数据分析·第2版》的中文内容仓库，按章节提供数据分析相关的学习资料/笔记（Markdown），涵盖NumPy、pandas、数据清洗、可视化、时间序列及建模库简介等主题。,8700,data analysis|python|pandas|numpy|jupyter|data cleaning|data visualization|time series,7,该仓库主要提供《利用Python进行数据分析·第2版》的中文章节内容与学习资料，主题集中在Python数据分析栈（NumPy/pandas）以及常见数据处理流程（加载、清洗、规整、聚合、可视化、时间序列）。它对数据科学工作流的“数据准备与分析”环节非常直接可用，且教育价值较高，适合系统学习或查阅示例思路。由于它不是可复用的ML训练/推理框架或MLOps工具，且更偏内容/教材型资源而非工程化库，因此评分为7（中等偏高的ML/数据相关性）。,success
https://github.com/Ewenwan/MVision,MVision,"A large, Chinese-language robotics/computer-vision knowledge-and-code collection covering mobile robotics, visual SLAM (including ORB-SLAM2/VS-SLAM), and deep-learning-based vision (e.g., YOLOv3), alongside OpenCV/PCL examples and assorted ML study materials.",8500,computer vision|robotics|SLAM|object detection|deep learning|OpenCV|PCL|autonomous driving,7,"MVision is primarily a broad robotics and machine-vision repository that aggregates code, notes, and materials across SLAM, perception, and general ML/deep-learning topics (including YOLO-style detection). It is relevant to ML/data workflows mainly as an educational and reference resource (examples, papers/notes, and practical CV components) rather than a focused, production-grade ML library or dataset. Community adoption (stars) is strong for a curated resource, but integration as a single reusable ML framework is limited by the repo’s breadth and “collection” nature, so it scores as moderately relevant rather than core infrastructure.",success
https://github.com/IntelRealSense/librealsense,librealsense,"RealSense SDK 2.0 is a cross-platform library for Intel/RealSense depth cameras, enabling depth and color streaming and providing camera calibration (intrinsics/extrinsics). It includes tools, examples, and language/framework wrappers (e.g., Python, ROS, C#, Unity) for integrating RealSense sensors into applications.",8400,computer vision|depth cameras|sensor SDK|robotics|3D perception|Python bindings|ROS,7,"This repository provides the core RealSense SDK used to interface with RealSense depth cameras, stream depth/RGB/IMU data, and access calibration information and tooling (e.g., viewer and quality tools). It is not an ML framework itself, but it is highly applicable to ML/data workflows that rely on collecting and preprocessing depth/RGB data for tasks like robotics perception, 3D reconstruction, pose/people tracking, and dataset capture. Community adoption appears strong (thousands of stars/forks) and the provided wrappers (notably Python and ROS) make it straightforward to integrate with common ML stacks, which justifies a moderately high relevance score rather than a core-ML score.",success
https://github.com/apache/iceberg,apache/iceberg,"Apache Iceberg is a high-performance open table format for huge analytic datasets, providing reliable SQL-table semantics (e.g., schema evolution and safe concurrent reads/writes) for data lakes. It includes the core Java reference implementation and integrations so multiple engines (e.g., Spark, Trino, Flink, Hive/Presto/Impala) can work with the same tables.",8400,data lake|table format|data engineering|big data|spark|flink|trino,7,"This repository implements Apache Iceberg, an open table format and associated libraries/integrations that enable reliable, high-performance analytics over large datasets in data lakes. While it is not an ML framework, it is directly useful in ML/data workflows because it improves dataset management (schema/partition evolution, snapshotting/time travel, concurrent access) for feature generation and training/serving pipelines. It has broad adoption across the modern data stack via integrations with common compute engines, making it a strong enabling infrastructure component for ML platforms. I scored it a 7 because it’s moderately-to-highly relevant infrastructure for ML/data teams, but not a core modeling/training library.",success
https://github.com/open-metadata/OpenMetadata,OpenMetadata,"OpenMetadata is an open-source unified metadata platform for data discovery, data observability, and data governance. It provides a central metadata repository with column-level lineage, a pluggable ingestion framework with many connectors, and collaboration features for managing data assets across an organization.",8400,data catalog|metadata management|data governance|data lineage|data observability|data quality|data engineering|data discovery,7,"This repository implements a full-featured metadata platform (catalog + governance + observability) with a central metadata store, APIs, and an ingestion framework to connect to many data systems. It is directly useful in ML/data workflows because it helps teams discover datasets/features, track lineage, monitor freshness/quality, and enforce ownership/policies—capabilities that improve reliability and compliance of ML pipelines. It is not an ML training/inference framework, but it is strong data infrastructure and widely applicable to data science and MLOps operations, justifying a moderately high score.",success
https://github.com/bytedeco/javacv,javacv,"JavaCV is a Java (JVM/Android) library that provides Java-friendly APIs and utilities on top of JavaCPP Presets to access native computer-vision and multimedia libraries such as OpenCV, FFmpeg, and Tesseract. It includes helpers for tasks like video I/O/display, parallel execution, calibration, feature detection/matching, and related vision utilities.",8300,computer vision|multimedia|opencv|ffmpeg|java|jni|android|ocr,7,"This repository provides Java bindings/utilities around widely used CV and multimedia backends (notably OpenCV and FFmpeg) via JavaCPP Presets, enabling image/video ingestion, processing, display, and related vision workflows from the JVM. It is not an ML training framework, but it is directly useful in ML/data pipelines for data acquisition (camera/video), preprocessing/augmentation, feature extraction, and deploying CV-heavy applications in Java/Android environments. Community adoption appears strong (thousands of GitHub stars) and it integrates well with vision tooling commonly used alongside ML, so it earns a moderately high relevance score rather than a core-ML score.",success
https://github.com/iflytek/astron-agent,astron-agent,"Astron Agent is an enterprise-grade, commercial-friendly agentic workflow development platform for building and orchestrating production-ready “SuperAgents”. It integrates AI workflow orchestration, model management, MCP/tool integration, RPA automation, team collaboration, and supports high-availability deployment.",8300,AI agents|agentic workflow|LLM orchestration|MCP (Model Context Protocol)|RPA automation|MLOps/model management|enterprise platform|Java,7,"This repository provides an enterprise platform to design and run agentic workflows, integrating LLM/tool (including MCP) orchestration, model management, and RPA-style execution to automate business processes. It is not a core ML training library, but it is directly useful in applied ML/LLM productization (agent building, tool integration, deployment/operations, and workflow automation). The project shows meaningful adoption (thousands of stars) and offers practical deployment options (e.g., Docker Compose; Helm charts noted as under development), making it moderately strong for ML engineers building agentic applications rather than for data science experimentation.",success
https://github.com/Arindam200/awesome-ai-apps,awesome-ai-apps,"A curated collection of 70+ practical example projects, tutorials, and recipes for building LLM-powered applications, including RAG apps, AI agents, workflows, and MCP (Model Context Protocol) tool-integration examples across multiple frameworks.",8200,large language models|AI agents|RAG|model context protocol (MCP)|LLM application development|tutorials|LangChain|LlamaIndex,7,"This repository is primarily an application-focused, hands-on catalog of LLM/agent/RAG example apps rather than a new ML algorithm or training library. It is still quite useful to ML engineers and data practitioners for learning and quickly bootstrapping real-world LLM workflows (agents, retrieval-augmented generation, tool use via MCP) and integrating popular frameworks in end-to-end demos. Its relatively strong community adoption (8.2k GitHub stars) and breadth of runnable examples make it valuable for applied ML/LLM engineering, though it is less directly about datasets, model training, or core data-science methods—hence a 7/10.",success
https://github.com/igorbarinov/awesome-data-engineering,awesome-data-engineering,"A curated “awesome list” of data engineering tools, platforms, and learning resources, organized by categories such as ingestion, storage, processing (batch/stream), orchestration, monitoring, datasets, and community materials.",8200,data engineering|awesome-list|data pipelines|big data|ETL|stream processing|workflow orchestration|data infrastructure,7,"This repository is a curated directory of data engineering technologies and resources rather than a runnable library or framework. It’s strongly relevant to ML/data workflows because data scientists and ML engineers rely on ingestion, storage, processing, orchestration, and monitoring tooling to build reliable training/feature pipelines and production data systems. However, it provides guidance and links more than direct code artifacts or integrations, so its immediate, hands-on applicability is lower than an actual ML/data tool. The relatively high star count suggests meaningful community adoption and good educational/reference value for selecting and learning about data stack components.",success
https://github.com/TeamWiseFlow/wiseflow,wiseflow,"Wiseflow is an LLM-driven system for monitoring and tracking online sources (websites, RSS feeds, and social media) and extracting the information you care about. It emphasizes “crawl + extract” in one workflow using real browser automation (rather than traditional rule-based scraping).",7900,llm|web-scraping|information-extraction|rss|web-monitoring|crawler|python|browser-automation,7,"This repository provides an LLM-driven crawler/scraper that monitors multiple online sources and performs targeted extraction, which is directly useful for building data-collection pipelines and dataset generation for downstream analytics or ML/NLP tasks. While it is not a model-training framework itself, it integrates LLM calls into the core retrieval/extraction workflow, making it practical for data engineers and applied ML teams who need reliable, relevance-filtered web data ingestion. Its substantial GitHub adoption (thousands of stars) suggests meaningful community interest and potential integration value in real-world ML/data workflows.",success
https://github.com/lastmile-ai/mcp-agent,mcp-agent,"mcp-agent is a Python framework for building robust AI agents on top of the Model Context Protocol (MCP), handling MCP server connection lifecycles and exposing composable agent workflow patterns. It also supports scaling to durable, production-grade execution using Temporal (pause/resume/retries) without changing agent APIs.",7900,ai-agents|model-context-protocol|python|llm-tools|agent-framework|workflow-orchestration|temporal,7,"This repository provides an MCP-native agent framework: it connects LLMs to MCP servers (tools/resources/prompts) and implements reusable workflow patterns (e.g., router, map-reduce, evaluator-optimizer) to build agent applications. While it is not a model-training or data-processing library, it is directly useful in many ML/LLM engineering workflows for tool-using agents, orchestration, and productionization. Its Temporal-backed durability and MCP interoperability make it especially relevant for deploying LLM-powered systems, but its focus is agent runtime/orchestration rather than core data science, which is why it scores a 7 instead of 8+.",success
https://github.com/microsoft/UFO,UFO,"UFO³ is Microsoft’s digital-agent framework that evolves from a Windows desktop automation agent (UFO²) into a multi-device “Galaxy” orchestration system. It decomposes requests into executable DAG workflows, coordinates tasks across heterogeneous devices via an interaction protocol, and supports LLM-powered automation with optional RAG/knowledge components.",7900,LLM agents|agentic automation|multi-agent orchestration|workflow DAG|RAG|desktop automation|Python,7,"This repository primarily provides an LLM-agent automation and orchestration framework (UFO³ Galaxy) plus a Windows-focused device agent (UFO²) for GUI/API task execution across applications and devices. It is not a model-training library, but it is directly useful for ML/AI engineers building agentic systems, tool-using assistants, and automation pipelines that integrate LLM APIs and retrieval/knowledge substrates. The strong agent orchestration focus (DAG decomposition, async coordination, protocol-based device communication) gives it solid integration value for real-world AI workflows, though its applicability is more ""agent platform"" than ""core data science"".",success
https://github.com/alibaba/spring-ai-alibaba,spring-ai-alibaba,"Spring AI Alibaba is a production-ready agentic AI framework for Java/Spring developers, providing an agent framework plus a graph-based workflow runtime for building multi-agent, long-running, stateful AI applications. It also includes an admin/studio experience and Spring Boot starters for integrating with LLM providers, tool calling, and MCP (Model Context Protocol).",7800,java|spring-boot|agentic-ai|llm|multi-agent|workflow-orchestration|mcp|ai-application-framework,7,"This repository is primarily an application framework for building agentic and workflow-driven LLM applications in Java (e.g., multi-agent orchestration, context engineering patterns, and a graph runtime for persistence/orchestration/streaming). It is directly relevant to ML engineering and data/AI product workflows for deploying and orchestrating LLM agents (including tool calling and MCP integration), but it is not a model-training library or a data processing framework. The score reflects strong practical value for building LLM-powered systems (especially in Spring ecosystems) while being less central for core data science tasks like feature engineering, training, and evaluation pipelines.",success
https://github.com/microsoft/ailab,microsoft/ailab,"Microsoft AI Lab is a collection of sample projects and experiments that help developers learn and build with Microsoft AI, spanning areas like bots, computer vision, OCR, translation, and Azure-based AI workflows. The repository aggregates multiple demo projects (e.g., Sketch2Code, Snip-Insights, Pix2Story) with code and supporting materials.",7800,machine learning|computer vision|bots|Azure Functions|OCR|NLP|developer education|sample projects,7,"This repository primarily serves as an educational and experiential hub that aggregates multiple Microsoft AI demo projects (bots, vision, OCR, translation, and related tooling) intended to help developers get started with applied AI. It is relevant to ML/data workflows because it provides end-to-end example implementations and integrations (including Azure-centric components) that data/ML practitioners can adapt for prototypes and learning. However, it is not a single cohesive ML library/framework or widely adopted core tool, and much of its value is in reference implementations rather than reusable, production-grade ML infrastructure—hence a moderately high score rather than an 8–10.",success
https://github.com/python-visualization/folium,folium,"Folium is a Python library for creating interactive web maps by combining Python data manipulation with Leaflet.js map rendering. It lets you visualize geospatial data (e.g., markers, tiles, GeoJSON layers, choropleths) and export maps as HTML for use in notebooks and web pages.",7300,python|geospatial|data-visualization|interactive-maps|leaflet|jupyter,7,"This repository provides a widely used Python tool for building interactive Leaflet.js-based maps, turning Python-side data structures into shareable HTML map visualizations. While it is not an ML framework, it is strongly relevant to data science workflows for exploratory data analysis and communicating spatial patterns (e.g., plotting model outputs, clustering results, or geographically indexed features). Its large adoption in the Python data ecosystem and easy integration with notebooks make it a practical visualization component in many ML/data pipelines, which justifies a moderately high score.",success
https://github.com/awslabs/agent-squad,agent-squad,"Agent Squad is an open-source, lightweight framework for orchestrating multiple AI agents to handle complex, multi-turn conversations. It provides intent classification and routing, context management, and extensible components (in both Python and TypeScript) to build multi-agent conversational systems and demos.",7200,multi-agent|agent-orchestration|llm|conversational-ai|intent-classification|python|typescript|aws-bedrock,7,"This repository focuses on orchestrating and coordinating multiple AI agents for conversational applications, including intent classification/routing and shared context handling, with implementations in Python and TypeScript. It is directly useful for ML/LLM engineers building multi-agent systems (an emerging area adjacent to MLOps/application-layer AI), but it is not a core data science library for model training, evaluation, or datasets. Community adoption appears strong (thousands of stars), and the examples/demos provide practical educational value for building agentic AI workflows, justifying a moderately high score.",success
https://github.com/microsoft/SandDance,SandDance,"SandDance is an open-source, web-based data exploration and visualization toolkit from Microsoft Research that uses unit visualizations (one mark per row) with smooth animated transitions to help users find and communicate insights. It is modular and embeddable, with core JS packages plus React and Explorer/Embed components for integrating into applications (including Power BI, Azure Data Studio, and VS Code).",7100,data visualization|visual analytics|interactive data exploration|javascript|react|vega|webgl|powerbi,7,"SandDance’s primary purpose is interactive data exploration and communication of insights through 2D/3D unit visualizations, delivered as modular JavaScript/React components that can be embedded into other tools and apps. While it is not an ML training or modeling framework, it is directly useful in data science workflows for exploratory data analysis (EDA), hypothesis generation, and presenting results, and it integrates with common data/BI environments. Its relevance is therefore moderately high for data/ML practitioners (especially on the visualization/EDA side), but it is not core MLOps/modeling infrastructure, so it scores below dedicated ML frameworks.",success
https://github.com/Rockyzsu/stock,stock,"A Python-based, continuously updated collection of scripts and notebooks for quantitative trading, including data collection (stocks/funds/FX), market analysis, K-line/technical pattern recognition, monitoring/alerts, and some machine-learning-based prediction examples.",7000,quantitative-trading|stock-analysis|python|data-collection|web-scraping|technical-analysis|backtesting|machine-learning,7,"This repository is primarily a quantitative trading toolkit/learning project with substantial data acquisition, analysis, and monitoring code (e.g., fund/ETF tracking, news/market data ingestion, K-line pattern recognition, and strategy utilities). It includes a dedicated ""machine_learning"" area and multiple data-centric components that are directly useful for data science workflows (feature building, time-series exploration, and strategy evaluation), even if it is not a general-purpose ML framework. Community adoption appears strong for a personal project (about 7k stars and 1.5k forks), increasing its practical/educational value for applied finance data work. It scores 7/10 because ML is present but not the sole focus; much of the repo centers on data engineering for trading and domain-specific analytics rather than reusable, state-of-the-art modeling infrastructure.",success
https://github.com/jvns/pandas-cookbook,pandas-cookbook,"A hands-on cookbook of Jupyter notebooks that teaches practical data analysis with Python’s pandas using real-world datasets (e.g., NYC 311 calls, Montréal bike counts, and Montréal hourly weather). Includes runnable examples and guidance for running locally (pip/venv), via Docker, or in-browser via JupyterLite.",7000,python|pandas|data-analysis|jupyter-notebook|data-cleaning|exploratory-data-analysis|tutorial,7,"This repository is an educational collection of Jupyter notebooks demonstrating core pandas workflows (loading CSV/SQL data, slicing/filtering, groupby/aggregation, string operations, and data cleaning) on real datasets. It is strongly relevant to data science day-to-day work (EDA and data wrangling), but it is not an ML framework and does not focus on model training/evaluation or MLOps. Its usefulness is high for preparing and exploring data prior to modeling, and its popularity and practical examples make it a solid learning resource, warranting a moderately high score.",success
https://github.com/jwilber/roughViz,roughViz,"Reusable JavaScript library for creating sketchy/hand-drawn styled charts in the browser. It provides multiple chart types (e.g., bar, line, pie, scatter, stacked bar) and exposes RoughJS-style rendering options on top of a D3-based charting API.",7000,data visualization|javascript|d3.js|roughjs|charting|web development|frontend,7,"roughViz is primarily a frontend data-visualization library that renders charts with a hand-drawn aesthetic in the browser, rather than an ML training or data-processing toolkit. It is still quite useful in ML/data workflows for communicating analysis results, model performance summaries, and exploratory findings via lightweight, embeddable charts. Its relevance is moderate-to-high because visualization is a core part of data science deliverables, but it does not provide ML algorithms, feature engineering, or pipeline/MLOps functionality.",success
https://github.com/snowplow/snowplow,snowplow,"Snowplow is a customer data infrastructure (CDI) platform for collecting, validating, enriching, and delivering event-level behavioral data in real time to warehouses, lakes, or streams. This repository aggregates major Snowplow pipeline components as individual git submodules (trackers, collectors, enrich, storage, and data modeling).",7000,data-engineering|event-tracking|customer-data-infrastructure|analytics-pipeline|data-collection|stream-processing|product-analytics|marketing-analytics,7,"This repository is primarily an event data collection and processing platform (trackers/collectors, schema validation, enrichments, and delivery into storage/stream destinations), aimed at producing governed, high-fidelity behavioral datasets. While it is not an ML framework, it is directly useful for ML/data science workflows because it helps generate clean, well-structured event data that can feed feature engineering, analytics, personalization, and fraud detection pipelines. The score reflects strong relevance as data infrastructure commonly used upstream of ML, but with limited direct model-training or MLOps functionality in this repo itself.",success
https://github.com/tidyverse/ggplot2,ggplot2,"ggplot2 is an R data-visualization package implementing the Grammar of Graphics, enabling users to build plots declaratively by mapping data to aesthetics and adding layers (geoms), scales, facets, and coordinate systems. It is a core tidyverse tool for creating publication-quality statistical graphics with a large ecosystem of extensions.",6800,data visualization|R|grammar of graphics|tidyverse|statistical graphics|plotting library|data science,7,"This repository is the source for ggplot2, a widely used R library for constructing statistical graphics via the Grammar of Graphics, focused on visualization rather than model training. It is highly applicable in ML/data workflows for exploratory data analysis (EDA), model diagnostics, and communicating results, and it integrates well with common R data tools (e.g., tidyverse pipelines) and many ML/statistics packages. Because it is not an ML framework or pipeline tool but is still foundational for data science practice and education, it merits a strong but not top-tier ML/data score.",success
https://github.com/ranaroussi/quantstats,quantstats,"QuantStats is a Python library for portfolio analytics and performance reporting, providing risk/performance metrics, visualizations, and automated tear-sheet/HTML reports for return series.",6600,python|quantitative-finance|portfolio-analytics|performance-metrics|risk-management|data-visualization|pandas|backtesting,7,"This repository focuses on quantitative portfolio profiling: computing performance/risk statistics (e.g., Sharpe, drawdowns, volatility), plotting diagnostics, and generating tear sheets/reports from return series. While it is not an ML training framework, it is directly useful in data-science workflows for financial datasets, feature/metric engineering, model/strategy evaluation, and benchmarking. Its broad adoption in quant workflows and easy integration with pandas-based pipelines make it moderately-to-highly relevant to ML/data practitioners, hence a 7/10.",success
https://github.com/liuruoze/EasyPR,EasyPR,EasyPR is an open-source Chinese license plate recognition (LPR) system/library built on OpenCV for unconstrained images. It provides plate detection plus character recognition (OCR) and includes example code and supporting resources/models for end-to-end recognition.,6400,computer vision|license plate recognition|OCR|OpenCV|C++|image processing|intelligent transportation,7,"This repository implements an end-to-end computer-vision pipeline for Chinese license plate detection and character recognition, primarily as a C++/OpenCV library with training/resources included. It is directly relevant to applied ML/CV workflows (dataset-driven recognition and model-based OCR), and is useful for learning or bootstrapping LPR systems, though it is not a general-purpose ML framework. Community adoption appears solid (thousands of GitHub stars and forks), but its scope is focused on the specific LPR task and ecosystem rather than broad ML integration, supporting a moderately high score.",success
https://github.com/polakowo/vectorbt,vectorbt,"VectorBT is a Python library for fast, vectorized backtesting, algorithmic trading research, and portfolio analysis at scale. It provides tools to generate trading signals, run large strategy parameter sweeps, and analyze/visualize results (often via pandas + Plotly).",6400,algorithmic trading|backtesting|quantitative finance|time series|python|pandas|plotly|portfolio analytics,7,"This repository is primarily a quantitative finance/backtesting engine that enables large-scale, vectorized experimentation on time-series price data, including parameter sweeps and performance analytics. While it is not an ML training framework, it is highly useful in data science workflows for feature/signal research, evaluation, and simulation—especially for financial time series. Community adoption appears solid (thousands of GitHub stars), and it integrates well with common DS tooling like pandas/NumPy and visualization (Plotly), supporting iterative research pipelines. I assigned a 7 because it is strongly data-driven and research-oriented, but ML model training/inference is not its core focus.",success
https://github.com/qinwf/awesome-R,awesome-R,"A curated “awesome list” of R packages, frameworks, and software, organized by topic (e.g., data manipulation, visualization, reproducible research, databases, machine learning, NLP, spatial, etc.). It serves as a directory for discovering commonly used tools in the R ecosystem rather than providing a single library or application.",6400,R|awesome-list|data-science|statistics|machine-learning|NLP|data-visualization|packages,7,"This repository is a curated index of R tooling (packages/frameworks/software) across many categories, including explicit sections for Machine Learning and Natural Language Processing, plus core data workflows like manipulation, visualization, and reproducible research. It’s directly useful to data scientists as a discovery/reference resource, but it does not itself implement ML algorithms, pipelines, or MLOps capabilities—its value is primarily navigational and educational. The repo shows substantial community adoption (thousands of GitHub stars), which increases its practical value as a widely recognized catalog. Based on being broadly helpful for data workflows (but not a core ML framework/tool), a 7/10 is appropriate.",success
https://github.com/rushter/data-science-blogs,data-science-blogs,"A curated, community-maintained list of data science and machine learning blogs with links to each site and (where available) RSS feeds. The repo also includes an OPML feed list and small scripts to generate/maintain it.",6400,data science|machine learning|curated list|blogs|rss|opml|python,7,"This repository’s primary purpose is to catalog data science/ML blogs and provide RSS/OPML artifacts so readers can subscribe and track content in feed readers. It supports ML/data workflows indirectly by helping practitioners discover learning resources, stay current with techniques, and follow research/industry writing, but it is not itself a modeling, training, or data-processing library. Given its strong practical/educational utility and noticeable community adoption (thousands of stars), but limited direct integration with ML tooling, a 7/10 is appropriate.",success
https://github.com/Hironsan/BossSensor,BossSensor,BossSensor is a Python computer-vision app that uses a webcam and a CNN-based classifier (via Keras/TensorFlow) to detect when a specific person (your “boss”) is approaching and hide/cover your screen. It includes scripts to collect/training images and then run real-time webcam inference to trigger the screen-hiding behavior.,6300,computer vision|deep learning|machine learning|opencv|tensorflow|keras|cnn|python,7,"This repository is primarily a practical computer-vision demo: it trains a CNN to classify webcam face images as “boss” vs “other” and then performs real-time inference to trigger a screen-hiding action. It is directly relevant to ML workflows because it includes data collection organization (boss/other folders), a training script, and an inference pipeline using common ML tooling (OpenCV + Keras/TensorFlow). However, it is a niche, application-specific example (and appears tied to older environment assumptions like Python 3.5/OSX/PyQt4), so while educational and reusable as a template, it is not broadly applicable or a widely adopted ML library.",success
https://github.com/apache/flink-cdc,apache/flink-cdc,"Flink CDC is a distributed streaming data integration tool that lets you define real-time and batch data pipelines (sources, transforms, routing, sinks) via YAML and run them on Apache Flink. It supports capabilities like full database sync, sharded table synchronization, schema evolution, and in-pipeline data transformations.",6300,data engineering|change data capture|apache flink|streaming|data integration|ETL/ELT|data pipelines,7,"This repository provides a CDC-based data integration framework on Apache Flink, enabling users to build production-grade streaming/batch pipelines via YAML and deploy them as Flink jobs. While it is not an ML library, it is directly useful in ML/data workflows for continuously ingesting and transforming operational data into analytical stores or feature/serving systems, and for maintaining up-to-date datasets. Community adoption appears strong (thousands of stars), and the pipeline-first approach plus connectors make it broadly applicable in data platform and MLOps contexts. The score is 7 because it is highly relevant infrastructure for ML/data pipelines, but not a core modeling/training framework.",success
https://github.com/nteract/nteract,nteract,"Monorepo for the nteract interactive computing suite, including the nteract core SDK plus desktop and web applications for working with (especially Jupyter) notebooks and REPL-style workflows. It also contains related documentation and supporting packages/components for building notebook-based UIs.",6300,jupyter|interactive-computing|notebooks|data-science-tools|electron|react|typescript|monorepo,7,"This repository provides an interactive computing environment and SDK centered around Jupyter notebooks/REPLs, including a cross-platform desktop app (Electron) and supporting web/React components. It’s not an ML framework, but it is directly useful in data science and ML workflows for authoring, running, and building custom notebook-based analysis interfaces. Its long-standing adoption within the Jupyter ecosystem and focus on notebook UX/integration makes it moderately-to-highly relevant for ML/data practitioners (especially for tooling, UI, and reproducible analysis), but it doesn’t deliver core modeling/training capabilities, keeping it below the top-tier ML tool scores.",success
https://github.com/openMVG/openMVG,openMVG,"OpenMVG (open Multiple View Geometry) is a C++ library and toolchain for end-to-end 3D reconstruction from images, focused on multiple-view geometry and Structure-from-Motion (SfM). It provides reusable libraries plus command-line binaries and pipelines for feature extraction/matching, camera pose estimation, and sparse 3D reconstruction, with exports to downstream MVS tools.",6300,computer vision|3D reconstruction|structure-from-motion|photogrammetry|multiple-view-geometry|C++|feature-matching,7,"This repository implements classic multiple-view geometry and Structure-from-Motion algorithms to reconstruct camera poses and sparse 3D structure from image collections, primarily as a C++ library plus CLI pipelines. It is highly relevant to ML/data workflows in computer vision (e.g., generating 3D data, camera pose labels, or SfM priors for learned methods, and integrating with modern matchers), but it is not itself a model-training framework or MLOps tool. Given its strong adoption in the 3D vision community and practical utility for building data/geometry pipelines, it merits a moderately high score even though it focuses on classical CV rather than ML training.",success
https://github.com/alibaba/BizCharts,BizCharts,"BizCharts is a React-based charting and data visualization library built on AntV G2, providing reusable components for common charts and interactive visualizations. The repository includes source code, demos, and documentation (now hosted in-repo) and notes recommending migration to the AntV ecosystem due to reduced/ended maintenance.",6200,data-visualization|react|charting-library|antv-g2|javascript|typescript|canvas,7,"BizCharts primarily provides React components for building charts and interactive data visualizations on top of AntV G2, making it directly useful for exploratory data analysis and dashboards. While it is not an ML framework, visualization is a core part of many ML/data workflows (data understanding, feature inspection, model monitoring/metrics dashboards). Its value for ML/data work is solid but bounded because it focuses on front-end rendering rather than data processing, modeling, or MLOps tooling.",success
https://github.com/axa-group/Parsr,Parsr,"Parsr is a document parsing and extraction toolchain that converts PDFs, images, and other document formats into enriched, structured outputs (e.g., JSON, Markdown, CSV/Pandas DF, or TXT). It performs document cleaning and layout reconstruction plus detection of elements like headings, tables, lists, headers/footers, links, and more, exposed via an API and supported by Docker images and a Python client.",6200,document-understanding|pdf-parsing|ocr|data-extraction|etl|api|python-client|docker,7,"This repository focuses on turning unstructured/semi-structured documents (PDFs/images/docx/eml) into clean, structured, label-enriched data outputs, which is a common upstream need in data science workflows. While it is not an ML framework itself, it is highly useful for building datasets, feature extraction, analytics pipelines, and document-automation systems (often paired with OCR/NLP/LLM steps). Its clear positioning toward analysts/data scientists, multiple structured export formats (including CSV/Pandas DF), and strong community adoption (6.2k GitHub stars) justify a moderately high score rather than a core-ML score.",success
https://github.com/quantopian/pyfolio,pyfolio,"Pyfolio is a Python library for performance and risk analysis of financial portfolios, best known for generating “tear sheets” of plots and statistics to evaluate trading strategies. It integrates well with the Zipline backtesting ecosystem and is commonly used in Jupyter-based research workflows.",6200,quantitative-finance|portfolio-analytics|risk-analysis|backtesting|python|data-visualization|jupyter,7,"This repository provides portfolio performance and risk analytics tooling (e.g., tear sheets with key metrics and visualizations) primarily aimed at evaluating trading algorithms and investment strategies. It’s highly applicable to data-science workflows in quantitative finance (returns analysis, factor/strategy evaluation, reporting), commonly used alongside notebooks and backtesting libraries like Zipline. It is not an ML training framework, but it is a strong supporting library for applied financial data science and research, with notable adoption (thousands of GitHub stars).",success
https://github.com/aymericdamien/TopDeepLearning,TopDeepLearning,"A curated, star-ranked list of popular GitHub projects related to deep learning. The repository primarily consists of a README that aggregates links to major deep learning libraries, tutorials, and related tools.",6100,deep learning|machine learning|awesome-list|curated-resources|GitHub-projects|education|TensorFlow|PyTorch,7,"This repository is a curated directory of deep learning-related GitHub projects ranked by stars, serving as a discovery and learning resource rather than a code library. It is directly relevant to ML workflows because it helps practitioners find widely used frameworks, example repositories, and educational materials, but it does not provide reusable ML code or datasets itself. Community adoption is solid (thousands of stars), yet its practical utility is mainly informational and the README indicates it was last updated on 2020-07-09, which reduces its up-to-date value compared to actively maintained ML tooling.",success
https://github.com/PrefectHQ/marvin,marvin,"Marvin is a Python framework for producing structured outputs (e.g., cast/classify/extract/generate) from LLMs and for building agentic AI workflows using tasks, agents, and threaded orchestration. It integrates with LLM providers (OpenAI by default) and supports PydanticAI model backends for typed/validated results.",6000,python|llm|agentic-workflows|structured-output|pydantic|ai-orchestration|nlp,7,"This repository provides a Python framework to reliably turn unstructured text into structured, typed outputs (cast/classify/extract/generate) and to orchestrate agentic workflows via tasks and agents. It is directly useful in ML/data workflows for data extraction, labeling/classification, schema-constrained generation, and building LLM-powered pipelines that feed downstream analytics or ML systems. While it is not a model-training framework and doesn’t focus on core data processing at scale, its structured-output and workflow abstractions are highly practical for LLM-centered data and MLOps-adjacent applications, and it shows meaningful community adoption (≈6k GitHub stars).",success
https://github.com/apache/hive,apache/hive,"Apache Hive is a distributed data warehouse system for reading, writing, and managing large datasets in distributed storage using SQL. It runs on the Hadoop ecosystem and supports scalable analytics/ETL workloads with components like HiveServer2 and the Hive Metastore.",6000,data warehouse|big data|SQL|Hadoop|ETL|data engineering|distributed systems,7,"This repository contains Apache Hive, a widely used distributed SQL data warehouse for querying and managing large-scale data in Hadoop-compatible storage (e.g., HDFS and cloud object stores) with tooling for ETL and analytics. While it is not an ML framework, it is highly relevant to ML/data workflows because it is commonly used to build and query data lakes/warehouses that feed feature engineering, training datasets, and BI/analytics. Its strong ecosystem integration and broad adoption in enterprise data platforms make it valuable infrastructure for data science teams, but it is indirect rather than core model-building software—hence a 7/10.",success
https://github.com/paperswithcode/ai-deadlines,ai-deadlines,"A community-maintained site (aideadlin.es) that tracks major AI/ML/CV/NLP/Robotics conference submission deadlines with countdown timers. Deadlines are curated in a YAML file and published via a GitHub Pages/Jekyll site, with an included calendar (ICS) feed.",6000,machine learning|conference deadlines|Jekyll|GitHub Pages|YAML|calendar/ICS|computer vision|natural language processing,7,"This repository powers a widely used, community-updated listing of top-tier AI conference deadlines (the aideadlin.es countdown site), with the core data stored in a structured YAML file and rendered via a static site. It is not an ML library or dataset for modeling, but it is directly useful in ML research workflows for planning submissions, tracking timelines, and integrating deadlines via its calendar/ICS output. The repo has strong community adoption (thousands of stars and many PRs/issues), and provides practical value to ML practitioners despite not being a training/inference tool.",success
https://github.com/shimat/opencvsharp,opencvsharp,"OpenCvSharp is an OpenCV wrapper for .NET (C#) that provides managed bindings plus required native runtime packages, enabling image processing and computer vision workflows across Windows, UWP, Linux, and WebAssembly via NuGet.",5900,computer vision|OpenCV|.NET|C#|image processing|interop|NuGet,7,"This repository provides OpenCV bindings for .NET along with native runtime packages, letting C# applications use OpenCV’s core computer vision and image processing APIs. It is moderately relevant to ML/data workflows because feature extraction, preprocessing, classical CV (e.g., filtering, edge detection, geometry), and dataset/image handling are common steps in ML pipelines, and this makes those steps accessible in .NET ecosystems. It is not itself an ML training/inference framework (and notes limitations such as no CUDA support out of the box), which prevents a higher score, but its broad utility and adoption as an OpenCV bridge makes it valuable for applied CV work in production .NET stacks.",success
https://github.com/stdlib-js/stdlib,stdlib,"The fundamental numerical (scientific) standard library for JavaScript and TypeScript, focused on high-performance math, statistics, data processing, and related utilities for both Node.js and browser environments. It emphasizes a decomposable architecture so users can mix and match APIs and functionality.",5700,numerical computing|scientific computing|statistics|math library|data processing|javascript|typescript,7,"This repository provides a broad, high-performance numerical/scientific computing standard library for JavaScript/TypeScript, including math and statistics functionality and utilities useful in data processing workflows. While it is not an end-to-end ML framework (e.g., training, model serving, MLOps), it can directly support ML/data work via foundational numerical and statistical primitives, especially in JS/TS environments. Its scope, modularity, and emphasis on robustness and performance make it meaningfully useful for data science tasks, but its primary focus is general numerical/scientific computation rather than machine learning specifically.",success
https://github.com/ujjwalkarn/DataSciencePython,DataSciencePython,"A curated, topic-wise collection of tutorials and learning resources for doing data science, NLP, and machine learning with Python. It mainly serves as a structured index of external links (and a few example scripts/folders) rather than a single runnable library/package.",5700,data science|machine learning|python|NLP|tutorials|resource list|pandas,7,"This repository is primarily a curated list of Python-focused resources for data science, NLP, and machine learning, organized as a large README linking to tutorials, articles, and references. It is useful for ML/data workflows as a learning roadmap and reference hub, but it is not an ML framework, dataset, or production tool that can be directly integrated into pipelines. Community adoption is solid (thousands of stars), and educational value is high, which supports a moderately high score, but limited direct applicability keeps it below 8-10.",success
https://github.com/alexlenail/NN-SVG,NN-SVG,"NN-SVG is a JavaScript-based tool for generating publication-ready neural network architecture diagrams parametrically (rather than drawing them manually) and exporting them as SVG files. It supports common schematic styles including fully-connected networks, LeNet-style CNN diagrams, and AlexNet-style deep network figures with extensive styling parameters.",5600,machine-learning|deep-learning|neural-network-diagrams|data-visualization|svg-generation|d3.js|three.js,7,"This repository provides a specialized visualization tool for machine learning researchers to create neural network architecture schematics (FCNN/CNN/AlexNet-style) and export them to SVG for papers and web pages. While it does not train models or process datasets, it directly supports common ML workflows by improving how models are documented, communicated, and published. Its strong adoption (thousands of GitHub stars) and focused utility for ML documentation and pedagogy justify a moderately high score, but it is not a core ML framework or data pipeline tool.",success
https://github.com/holoviz/panel,panel,"Panel is an open-source Python library for building interactive data exploration tools, dashboards, and full web applications entirely in Python. It integrates with the PyData/visualization ecosystem (e.g., Bokeh, HoloViews/hvPlot, Plotly, Altair) and supports multiple deployment targets including notebook, server-hosted apps, and standalone/static outputs.",5600,python|data-visualization|dashboards|web-app-framework|data-exploration|jupyter|bokeh|holoviz,7,"This repository provides Panel, a Python framework for creating interactive dashboards and data-driven web apps, commonly used to share analyses and build exploratory interfaces. While it is not an ML training framework, it is strongly relevant to ML/data workflows for model/result visualization, interactive EDA, and building lightweight apps to present and monitor data products. Its broad integration with common PyData visualization tools and notebook workflows makes it a practical, moderately high-value component in many data science stacks, justifying a 7/10.",success
https://github.com/rstudio/shiny,shiny,"Shiny is an R package for building interactive web applications using a reactive programming model, without requiring HTML/CSS/JavaScript. It provides UI widgets, server-side reactivity, and tooling for embedding apps (e.g., in R Markdown) and extending apps via modules and integrations.",5600,R|shiny|web development|interactive dashboards|data visualization|reactive programming|data science,7,"This repository provides the core Shiny framework for building interactive web apps and dashboards in R, centered on reactive programming and a rich set of UI components. While it is not an ML library itself (it does not implement model training/inference algorithms), it is widely used by data scientists to build interactive interfaces for data exploration, model diagnostics, and communicating results. Its strong ecosystem and common use in analytical workflows make it moderately-to-highly valuable for ML/data work, primarily as an application and visualization layer rather than a modeling toolkit.",success
https://github.com/Open-LLM-VTuber/Open-LLM-VTuber,Open-LLM-VTuber,"A cross-platform, locally runnable voice-interactive AI companion/VTuber that enables hands-free real-time conversations with LLMs, voice interruption, and a Live2D avatar. It supports offline operation and integrates multiple backends for LLM inference, ASR (speech recognition), and TTS (speech synthesis).",5500,LLM|voice assistant|speech recognition (ASR)|text-to-speech (TTS)|Live2D|multimodal AI|Python,7,"This repository is primarily an end-user application/framework for building a voice-driven AI companion/VTuber with a Live2D avatar, integrating many LLM, ASR, and TTS providers (including local/offline options). It is relevant to ML workflows because it serves as an integration layer and reference implementation for deploying and orchestrating LLM + speech pipelines, plus optional visual perception features, rather than focusing on model training or dataset work. The score reflects strong practical value for applied ML/AI engineers working on real-time conversational agents, but comparatively limited direct utility for core data science tasks like data analysis, model training, or benchmarking.",success
https://github.com/argosopentech/argos-translate,argos-translate,"Open-source offline machine translation library written in Python, usable as a Python package and via a CLI (with a separate GUI repo). It uses OpenNMT-based models packaged as .argosmodel files and can pivot through intermediate languages when a direct model is not installed.",5400,machine translation|NLP|offline translation|Python|OpenNMT|CLI tool|language models,7,"This repository provides an offline neural machine translation system (library + CLI) and a packaging mechanism for distributing pre-trained translation models. It is directly relevant to ML/NLP workflows because it enables local inference, model installation/management, and language-pair translation (including pivoting through intermediate languages). However, it is primarily an application/inference + model distribution tool rather than a general-purpose ML training framework, which keeps it below the highest scores.",success
https://github.com/lux-org/lux,lux,"Lux is an open-source Python library that accelerates exploratory data analysis by automatically recommending and rendering insightful visualizations for pandas DataFrames when they are displayed in Jupyter environments. It provides an interactive widget for browsing recommendations, supports user intent to steer recommendations, and can export/translate visualizations to libraries like Altair/Matplotlib/Vega-Lite.",5400,python|data-visualization|exploratory-data-analysis|pandas|jupyter|visualization-recommendation|altair|vega-lite,7,"This repository primarily provides an EDA-focused visualization recommendation system for pandas DataFrames, automatically surfacing charts and “next-step” recommendations directly inside notebook workflows. It is strongly relevant to data science workflows (data understanding, feature/relationship discovery, reporting), but it is not a model training framework or MLOps system, so its ML-directness is moderate rather than core. The project shows meaningful adoption (thousands of GitHub stars) and practical integration value for analysts working in Jupyter with pandas, hence a score of 7 rather than 8+.",success
https://github.com/mbadry1/DeepLearning.ai-Summary,DeepLearning.ai-Summary,"A collection of the author’s personal notes and summaries for the DeepLearning.ai Deep Learning Specialization (Coursera), organized by the five course modules (NNs, improving DNNs, ML project structuring, CNNs, sequence models).",5300,deep learning|machine learning education|course notes|coursera|neural networks|computer vision|NLP,7,"This repository primarily provides educational notes and summaries for the DeepLearning.ai Deep Learning Specialization rather than executable ML code or a reusable library. It is still quite valuable for ML practitioners and learners as a structured reference covering core deep learning topics (e.g., CNNs, sequence models, optimization/regularization concepts) and can support study, interview prep, and conceptual understanding. Community adoption appears strong for an educational notes repo (thousands of stars), but integration into ML workflows is limited because it’s mostly documentation rather than tooling or datasets.",success
https://github.com/Netflix/vmaf,vmaf,"VMAF (Video Multi-Method Assessment Fusion) is Netflix’s perceptual video quality assessment toolkit, providing the libvmaf C library, a CLI, and Python tooling to compute metrics and to train/test custom VMAF models. It also includes implementations of related quality metrics such as PSNR, SSIM, MS-SSIM, and others for codec evaluation workflows.",5200,video-quality|perceptual-metrics|codec-evaluation|signal-processing|computer-vision|c-library|python,7,"This repository provides an industry-standard perceptual video quality metric (VMAF) plus tooling (C library, CLI, and Python wrappers) for computing quality scores and for training/testing custom VMAF models. It is directly useful in data/ML workflows for dataset labeling and evaluation (e.g., objective quality targets, codec comparisons, perceptual optimization), and it includes model training utilities rather than only inference. However, it is specialized to video quality assessment rather than a general-purpose ML framework, so its relevance is strong but domain-specific.",success
https://github.com/promptslab/Awesome-Prompt-Engineering,Awesome-Prompt-Engineering,"A hand-curated “awesome list” of Prompt Engineering resources focused on LLMs such as GPT/ChatGPT and PaLM. It aggregates links to papers, tools & code, APIs, datasets, models, courses/tutorials, and related communities.",5200,prompt engineering|large language models|generative AI|NLP|LLM tooling|datasets|educational resources,7,"This repository is primarily a curated collection of prompt-engineering resources (papers, tools, APIs, datasets, models, and learning materials) rather than a standalone ML library or executable system. It is directly useful to ML practitioners working with LLMs by centralizing practical references (including datasets and tooling) that can support experimentation and workflow design. While it shows solid community adoption (thousands of stars) and strong educational value, it does not itself provide core ML functionality (e.g., training/inference framework), so it scores below dedicated ML toolkits.",success
https://github.com/tensorspace-team/tensorspace,tensorspace,"TensorSpace.js is a browser-based 3D neural network visualization framework built on TensorFlow.js and Three.js, providing Keras-like APIs to define layers, load/preprocess pre-trained models, and render interactive model visualizations with intermediate inference information.",5200,machine learning visualization|deep learning|tensorflow.js|three.js|javascript|webgl|model interpretability,7,"This repository primarily provides an in-browser 3D visualization framework for neural network architectures and inference flow, including APIs to build layers and visualize pre-trained models exported from TensorFlow/Keras/TensorFlow.js. It is directly useful in ML workflows for communicating, teaching, debugging, and demonstrating models, but it is not a training/inference framework itself (it depends on TensorFlow.js for ML computation). Community adoption appears solid (5.2k GitHub stars and hundreds of forks), indicating meaningful interest, but its scope is specialized around visualization rather than core model development, so a 7/10 reflects strong relevance with narrower applicability.",success
https://github.com/adbar/trafilatura,trafilatura,"Trafilatura is a Python library and command-line tool for crawling/downloading web pages and extracting the main text plus metadata (e.g., title/author/date), turning noisy HTML into structured content. It supports sitemaps/feeds, configurable extraction, and outputs multiple formats including JSON, CSV, TXT/Markdown, HTML/XML (including TEI).",5100,web scraping|web crawling|text extraction|HTML parsing|data extraction|NLP preprocessing|Python,7,"This repository’s primary use case is high-quality web content extraction (main text + metadata) from raw HTML via a Python API and CLI, with crawling/discovery features and multiple structured output formats. It is not an ML framework, but it is highly useful in ML/data workflows as a data acquisition and text-cleaning/preprocessing tool for building corpora, dataset generation, and downstream NLP pipelines. Community adoption appears strong (thousands of dependent projects and ~5.1k GitHub stars), which increases its practical value for data practitioners. I scored it a 7 because it’s a robust, directly applicable data-processing utility for ML/NLP, but it does not itself provide modeling, training, or MLOps capabilities.",success
https://github.com/chatopera/Synonyms,Synonyms,"A Python toolkit for Chinese synonyms and semantic similarity, providing word/sentence vector utilities (e.g., nearby synonyms lookup, similarity comparison, segmentation) for NLP/NLU tasks like search, QA/chatbots, and RAG-style retrieval. It ships code via pip but requires a paid license (via Chatopera) to download the associated ML model packages/word vectors.",5100,natural language processing|Chinese NLP|synonyms|semantic similarity|word embeddings|Python|information retrieval,7,"This repository provides practical Chinese NLP functionality centered on synonym discovery and semantic similarity, exposing APIs like synonyms.nearby, synonyms.compare, segmentation, and vector access utilities backed by pretrained word vectors. These capabilities are directly useful in ML/data workflows for text retrieval, deduplication, recommendation features, feature engineering, and evaluation/analysis tasks, especially in Chinese-language pipelines. However, it is not a general-purpose ML framework and a key dependency for many data science use cases (the downloadable model package/word vectors) is gated behind a paid license, which can limit reproducibility and integration in open workflows. Its community adoption is solid (thousands of GitHub stars), supporting a moderately high but not top-tier ML/data value score.",success
https://github.com/datawhalechina/joyful-pandas,joyful-pandas,"A Chinese-language pandas tutorial project (Joyful-Pandas) providing learning materials, notebooks, datasets, and accompanying documentation, including exercises and references for practical data manipulation with pandas.",5100,pandas|data science education|python|data analysis|tutorial|notebooks,7,"This repository is primarily an educational pandas tutorial (in Chinese) with structured learning content, notebooks, datasets, and many practice exercises. It is directly useful for data science workflows because pandas is a core tool for data cleaning, feature preparation, exploratory analysis, and general tabular data processing used before/alongside ML. It is not an ML framework itself, but it provides strong practical value and learning utility for data practitioners, and it shows substantial community adoption (about 5.1k GitHub stars).",success
https://github.com/geekywrites/datascience,datascience,"A curated roadmap and collection of free learning resources for data science, organized by topics (e.g., fundamentals, databases/SQL, ML concepts, and related tooling). It functions as an educational, link-rich guide rather than a software library or framework.",5100,data science|learning resources|roadmap|machine learning|python|statistics|sql|mlops,7,"This repository primarily provides an organized compilation of free data science learning resources and a structured roadmap (with sections covering core fundamentals and data/ML-adjacent topics), rather than implement reusable ML code. It is directly useful for data scientists as a curriculum/starting point and reference list, offering strong educational value even if it is not a production ML tool. Community adoption appears solid for a curated list (thousands of stars and hundreds of forks), but its integration potential in ML workflows is limited because it is mostly documentation and links rather than a package or pipeline.",success
https://github.com/tidyverse/dplyr,dplyr,"dplyr is an R package that provides a consistent, “grammar”-style set of verbs for data manipulation (e.g., filter, select, mutate, summarise, arrange) and grouped operations. It supports multiple backends beyond data frames/tibbles (e.g., SQL via dbplyr, Arrow, data.table via dtplyr, DuckDB via duckplyr, Spark via sparklyr).",5000,r|data-manipulation|data-wrangling|tidyverse|data-science|etl|relational-databases|sql-translation,7,"This repository contains the source for dplyr, a widely used R library focused on data transformation and manipulation through a small set of composable verbs. While it is not an ML framework itself, it is a core part of many ML/data science workflows because it enables feature engineering, data cleaning, aggregation, and join operations prior to modeling. Its broad adoption in the data community and strong ecosystem/backends support make it highly practical for ML practitioners, but the lack of model training/inference functionality keeps it below the top tier.",success
https://github.com/Helicone/helicone,helicone,"Helicone is an open-source AI Gateway and LLM observability platform that lets you monitor, debug, and analyze LLM/agent requests with minimal code changes. It provides logging, tracing/sessions, cost & latency metrics, a playground, prompt management, and integrates with many model providers and frameworks, with options for self-hosting (e.g., Docker).",4900,llm-observability|mlops|ai-gateway|prompt-management|agent-tracing|typescript|nextjs|clickhouse,7,"This repository primarily provides infrastructure for LLM applications: an AI gateway plus an observability platform to log requests, inspect traces/sessions, and analyze operational metrics like cost and latency. It is strongly relevant to ML/LLM production workflows (MLOps/LLMOps), enabling evaluation/experimentation and operational monitoring, but it is not a model-training library or a general-purpose data-science toolkit. The relatively high adoption (thousands of GitHub stars) and broad integrations (multiple providers and frameworks) make it practically useful for ML engineers deploying LLM systems, which supports a 7/10 rather than a lower, purely tangential score.",success
https://github.com/dlt-hub/dlt,dlt,"dlt (data load tool) is an open-source Python library for building data loading pipelines that extract data from many sources (e.g., REST APIs, SQL databases, cloud storage) and load it into structured datasets in supported destinations. It provides schema inference/normalization and operational features like incremental loading and schema evolution to simplify ongoing pipeline maintenance.",4800,data engineering|ETL/ELT|Python|data pipelines|data ingestion|schema inference|data warehousing,7,"This repository provides a general-purpose data loading/pipeline library (ELT-style) intended to move data from diverse sources into analytics destinations with automated normalization and schema management. While it is not an ML framework, it is directly useful in ML/data science workflows for building and maintaining reliable ingestion pipelines that feed feature stores, training datasets, and analytics layers. Its relevance is strong for data engineering tasks commonly adjacent to ML (dataset creation, incremental refreshes, schema evolution), but it does not itself cover modeling, training, or MLOps core functions, so it scores below the top tier.",success
https://github.com/strands-agents/sdk-python,sdk-python,"Strands Agents is a Python SDK for building and running AI agents using a model-driven, lightweight agent loop. It is model-provider agnostic (e.g., Amazon Bedrock, Anthropic, Gemini, LiteLLM, OpenAI, Ollama) and supports tools, multi-agent/autonomous workflows, streaming, and built-in Model Context Protocol (MCP) integration for accessing external tools.",4800,ai-agents|llm|agent-framework|python|model-context-protocol|tool-calling|streaming|amazon-bedrock,7,"This repository provides a practical SDK for building LLM-powered agents, including tool calling, multi-agent/autonomous patterns, and streaming interactions across multiple model providers. While it is not a data-science library for data processing/model training, it is directly applicable for ML/LLM engineers to orchestrate LLM workflows, integrate external tools via MCP, and prototype or deploy agentic systems. Community adoption appears meaningful (thousands of stars), and the repo has strong educational and integration value for agent-based ML applications, justifying a moderately high (but not core-ML) score.",success
https://github.com/ArroyoSystems/arroyo,arroyo,"Arroyo is a distributed stream processing engine written in Rust for building high-performance, stateful real-time data pipelines. It supports streaming SQL, windows/joins, checkpointing for fault tolerance, and connectors such as Kafka and Iceberg.",4700,stream processing|streaming SQL|data engineering|real-time analytics|Rust|Kafka|Iceberg,7,"This repository provides a distributed stream processing engine focused on building and running stateful, real-time SQL pipelines at high throughput, with features like checkpointing and connectors (e.g., Kafka and Iceberg). It is directly useful to data engineering and analytics workflows and can support ML systems via real-time feature generation and streaming ingestion into lakes/warehouses. While it is not an ML framework for model training/inference, it is a strong enabling component for ML data pipelines and feature stores, so it merits a moderately high relevance score.",success
https://github.com/BrambleXu/pydata-notebook,pydata-notebook,"A Chinese translation-and-notes Jupyter Notebook companion to the book ""Python for Data Analysis, 2nd Edition (2017)"" by Wes McKinney, focused on practical NumPy/pandas-based data analysis workflows. The repo organizes notebooks by book chapters and includes example datasets and supporting materials for learning data wrangling and analysis in Python.",4700,data analysis|jupyter notebook|pandas|numpy|educational|python|data cleaning,7,"This repository primarily provides educational Jupyter notebooks (Chinese translation notes) covering core Python data analysis concepts from ""Python for Data Analysis""—especially pandas and NumPy—plus example datasets and chapter-structured materials. It is directly useful for data science workflows (data wrangling, cleaning, descriptive statistics, time series basics) and for learning foundational tooling used in ML pipelines, though it is not itself an ML framework or production library. The repo mentions limited coverage of tools like scikit-learn/statsmodels, but its main value is as a high-quality learning resource for data preparation and analysis, which warrants a moderately high data/ML relevance score.",success
https://github.com/aipotheosis-labs/aci,aci,"ACI.dev is an open-source tool-calling platform that connects 600+ integrations to agentic IDEs or custom AI agents. It provides intent-aware, multi-tenant authentication, granular permissions, dynamic tool discovery, and exposes tools via direct function calls or a unified MCP (Model Context Protocol) server.",4700,ai-agents|llm|function-calling|mcp|tool-calling|oauth2|developer-tools|integrations,7,"This repository provides infrastructure for AI agents to securely call external tools (600+ integrations) through direct function calling or a unified MCP server, including multi-tenant OAuth, permissions, and tool discovery. While it is not a model-training or data-processing library, it is directly useful in many ML/LLM application workflows (agent orchestration, RAG assistants needing tool access, production integrations, logging, and governance). Its strong relevance to building real-world LLM systems and solid community adoption (thousands of stars) justify a moderately high score, but it is not a core data science library like a training framework or dataset toolkit.",success
https://github.com/amundsen-io/amundsen,amundsen,"Amundsen is an open-source data discovery and metadata platform that indexes data assets (e.g., tables, dashboards, streams) and provides a Google-like search experience to help analysts, data scientists, and engineers find and understand data. It is composed of multiple microservices (frontend, search, metadata) plus ingestion tooling to build the metadata graph and search index.",4700,data discovery|metadata management|data catalog|data engineering|search|elasticsearch|neo4j|data ingestion,7,"This repository provides a data catalog/data discovery system focused on metadata indexing and search across enterprise data assets, rather than model training or ML algorithms. It is directly useful in ML/data workflows because data scientists and ML engineers commonly need reliable dataset discovery, ownership/lineage context, and a searchable inventory of tables and dashboards to support feature creation and analysis. Its microservice architecture and integrations (notably a search layer and metadata backends) make it practical infrastructure for data platforms, but it is not an ML framework or MLOps training/deployment tool, which is why it scores as moderately (not maximally) relevant to ML/data work.",success
https://github.com/openvenues/libpostal,libpostal,"libpostal is a C library for parsing and normalizing international street addresses using statistical NLP and open geographic data. It converts free-form address strings into structured/normalized forms and provides official language bindings for multiple ecosystems (e.g., Python, Ruby, Go, Java, PHP, Node.js).",4700,NLP|address-parsing|geocoding|geospatial|C-library|text-normalization|OpenStreetMap,7,"This repository’s primary purpose is address parsing/normalization at global scale, implemented as a high-performance C library and powered by statistical NLP models trained from open geo data. It’s not a general ML framework, but it is directly useful in data/ML workflows that involve entity resolution, deduplication, geocoding pipelines, location intelligence, and feature engineering from address text. Its broad adoption (large star count) and availability of bindings make it easy to integrate into data engineering and ML systems, warranting a moderately high score rather than a top-tier ML-framework score.",success
https://github.com/volcengine/MineContext,MineContext,"MineContext is an open-source, proactive context-aware AI desktop app that captures and understands your on-screen context (via screenshots and content comprehension) and then generates useful outputs like insights, daily/weekly summaries, to-do items, and activity records. It emphasizes a local-first approach and can work with OpenAI-compatible model endpoints (including local models) for privacy-preserving workflows.",4700,AI assistant|context engineering|multimodal|desktop app|Electron|React|TypeScript|LLM,7,"This repository provides a context-capture and context-engineering framework packaged as a cross-platform desktop application that continuously collects user context (notably screenshots), processes it, and produces structured summaries, insights, and task suggestions. It is meaningfully related to ML workflows because it integrates with LLM/VLM and embedding models (including OpenAI-compatible endpoints and local model setups), and it operationalizes multimodal context ingestion, retrieval, and generation. However, it is primarily an end-user productivity product rather than a reusable ML library or widely adopted ML infrastructure component, which limits its direct applicability and community adoption in mainstream data-science pipelines. The score reflects strong relevance to applied LLM/multimodal systems and RAG-style context management, but not a core ML training/analysis toolkit.",success
https://github.com/Kanaries/Rath,Rath,"RATH is an open-source platform for automated exploratory data analysis (EDA) and data visualization, positioning itself as an alternative to tools like Tableau. It provides augmented analytics features such as one-click insight discovery, visualization recommendations/auto-generation, data wrangling, dashboards, and natural-language querying (including GPT integration).",4600,exploratory data analysis|data visualization|augmented analytics|business intelligence|dashboarding|natural language interface|causal analysis|data wrangling,7,"This repository is primarily an automated EDA and visualization platform (augmented analytics) that helps users quickly explore datasets, generate/recommend visualizations, and build interactive dashboards, with additional features like data wrangling and an alpha-stage causal analysis module. It is directly applicable to data science workflows for dataset understanding, feature/relationship exploration, and communicating results, but it is not a model training framework or MLOps stack. Its relevance is strengthened by features like natural-language querying and support for many data sources, yet its core value is analytics/visualization rather than ML model development, so a moderately high (but not top-tier) ML/data score is appropriate.",success
https://github.com/r0f1/datascience,datascience,"A curated “awesome list” of Python-focused data science resources, linking to libraries, tutorials, code snippets, blog posts, and talks across common DS/ML topics (e.g., pandas, scikit-learn, visualization, Jupyter, big data tooling). It primarily serves as a reference/catalog rather than a runnable package or framework.",4600,data science|machine learning|python|awesome-list|learning-resources|data analysis|jupyter|data visualization,7,"This repository is an “awesome list” that curates and categorizes Python resources useful for data science work, including core libraries (e.g., pandas, scikit-learn) and tooling for visualization, notebooks, and scalable data processing. It’s directly useful to data scientists as a high-signal index for discovering and choosing tools and learning materials, but it does not itself provide executable ML models, pipelines, or a software library to integrate into production. Community adoption appears solid (thousands of stars), and its main value is educational/reference and workflow discovery rather than implementation, which supports a moderately high (but not top-tier) ML/data usefulness score.",success
https://github.com/yanshengjia/ml-road,ml-road,"A curated collection of machine learning and agentic AI learning resources, including course links and a large set of reference materials (e.g., ML/DL/NLP books and PDFs), plus some practice/research organization. It functions primarily as a “learning roadmap” and resource index rather than a software library.",4600,machine learning|agentic ai|deep learning|learning resources|roadmap|nlp|computer vision,7,"This repository is primarily a curated roadmap of ML/AI resources (courses, books, and other study materials) rather than code for training models or running pipelines. It is still quite useful for ML practitioners and learners because it aggregates many relevant references in one place and appears to have strong community adoption (thousands of stars). The score is not higher because it offers limited direct workflow integration (e.g., no core framework, library APIs, or MLOps tooling), but it has solid educational value for ML/data science.",success
https://github.com/has2k1/plotnine,plotnine,"Plotnine is a Python implementation of a grammar of graphics (inspired by R's ggplot2) for building data visualizations by composing layers that map dataframe variables to visual aesthetics. It supports incremental plot construction with geoms/stats/scales/themes and integrates with the scientific Python stack (e.g., pandas/matplotlib/statsmodels).",4500,data-visualization|grammar-of-graphics|python|ggplot2|pandas|matplotlib|statistics,7,"This repository provides Plotnine, a grammar-of-graphics plotting library for Python that enables expressive, layered visualization of tabular data (typically pandas DataFrames). It is directly useful in data science workflows for exploratory data analysis, reporting, and communicating model/data insights, and is widely recognizable in the Python data ecosystem as a ggplot2-like tool. It is not an ML training/inference framework, but it strongly complements ML/data work by improving visualization and statistical plotting capabilities, which justifies a moderately high (but not core) ML/data score.",success
https://github.com/markusschanta/awesome-jupyter,awesome-jupyter,"A curated “awesome list” of Jupyter projects, libraries, extensions, and learning resources. It organizes tools across areas like runtimes/frontends, collaboration, visualization, JupyterLab extensions, testing, and hosted notebook solutions.",4500,jupyter|data-science|machine-learning|notebooks|jupyterlab|data-visualization|awesome-list,7,"This repository is a curated index of Jupyter-related tools and resources rather than a single ML library or framework. It is strongly relevant to ML/data workflows because Jupyter is a primary environment for exploratory data analysis, prototyping, visualization, and model experimentation, and the list includes many ML-adjacent tools (e.g., visualization, collaboration, notebook execution/packaging, and hosted notebook platforms). Its high community adoption (about 4.5k GitHub stars) and broad coverage make it valuable for discovering and assembling an effective data science stack, but it is indirect (a directory of links) rather than a core ML implementation tool.",success
https://github.com/dmMaze/BallonsTranslator,BallonsTranslator,A deep-learning-assisted comic/manga translation tool that automates a one-click pipeline (text detection + OCR + text removal/inpainting + machine translation) and provides a GUI for image and rich-text editing to refine and typeset translated text back into speech balloons.,4400,computer vision|OCR|machine translation|manga/comic translation|image inpainting|PyTorch|desktop GUI,7,"This repository’s primary use case is computer-aided comic/manga translation, combining multiple ML-driven components (text detection/OCR, text removal/inpainting, and machine translation) into an end-to-end workflow with additional GUI-based editing and typesetting features. It is directly relevant to applied ML/CV/NLP workflows because it operationalizes trained models for real-world document/comic image processing rather than focusing on model research or dataset creation. The score is not higher because it appears to be an application/tool (not a general ML framework) and its value for data science depends on whether you are specifically working on OCR/CV-assisted translation or similar pipelines, even though it has strong practical integration and adoption (4.4k stars).",success
https://github.com/janhuenermann/neurojs,neurojs,"NeuroJS is a JavaScript deep learning framework focused primarily on reinforcement learning, designed to run in the browser and provide interactive demos (e.g., a 2D self-driving car). The repository includes implementations of neural-network training components plus RL utilities like replay buffers and support for DQN and actor-critic style methods, though it is noted as no longer maintained in favor of TensorFlow.js.",4400,javascript|machine-learning|deep-learning|reinforcement-learning|neural-networks|browser-ml|tensorflow-js-alternative,7,"This repository provides a browser-based JavaScript framework for deep learning with an emphasis on reinforcement learning (e.g., DQN/actor-critic tooling, replay buffers) and includes runnable examples/demos. It is directly relevant for ML practitioners interested in educational RL implementations or in-browser experimentation/visualization, but it is explicitly marked as no longer maintained, reducing practical workflow adoption and integration potential compared to modern alternatives like TensorFlow.js. Given its clear ML focus and educational value but limited maintenance/modern ecosystem fit, a score of 7/10 is appropriate.",success
https://github.com/plotters-rs/plotters,plotters,"Plotters is a pure-Rust drawing and charting library for creating high-quality data plots (figures, charts, and graphs) for both native applications and WebAssembly. It supports multiple rendering backends (e.g., bitmap and SVG) and can be used for static and real-time plotting.",4400,rust|data-visualization|plotting|charting|wasm|svg|graphics,7,"This repository provides a general-purpose data visualization and charting library in Rust, aimed at producing publication-quality plots across native and WebAssembly targets with multiple backends. While it is not an ML framework or data-processing library, visualization is a core part of ML/data science workflows for exploratory data analysis, model evaluation, and reporting. Its utility is strongest for Rust-based data/ML stacks and for embedding plots into Rust applications (including WASM), which justifies a moderately high score rather than a core-ML score.",success
https://github.com/wzhe06/Ad-papers,Ad-papers,"A curated, continuously updated reading list of papers and learning resources on computational advertising, organized by topic (e.g., CTR prediction, bidding strategy, budget control, embeddings, optimization methods). It serves as a reference index with links to papers/materials rather than an implementation/code library.",4400,computational advertising|click-through rate prediction|recommender systems|machine learning|deep learning|optimization|ad ranking,7,"This repository is primarily a curated collection of computational advertising papers and study materials, organized into practical ML-adjacent topics like CTR prediction (classic and deep learning), bidding, budget control, embeddings, and optimization methods. It is directly relevant to ML/data science work as a high-signal roadmap for learning and literature review in ads/recsys, but it provides limited executable code or datasets for immediate integration into production workflows. Community adoption appears strong for a reading list (thousands of stars), which boosts its educational value, but the lack of tools/implementations keeps it below the highest scores.",success
https://github.com/JerBouma/FinanceToolkit,FinanceToolkit,"FinanceToolkit is an open-source Python toolkit for transparent financial analysis, providing 150+ financial ratios, indicators, performance and risk metrics, and utilities to work with historical market data and financial statements. It supports multiple asset classes (e.g., equities, ETFs, crypto, indices) and can fetch data primarily from Financial Modeling Prep with an automatic fallback to Yahoo Finance.",4300,python|finance|quantitative-finance|financial-analysis|data-science|time-series|portfolio-analytics|risk-management,7,"This repository primarily provides a Python library for financial data retrieval and computation of a large set of standardized financial ratios and performance/risk measurements (e.g., Sharpe ratio, Value at Risk) across multiple asset classes. It is not an ML framework, but it is directly useful in data science and ML workflows as a feature-engineering and financial metrics layer for modeling, backtesting, screening, and analysis. The strong practical applicability to quantitative research and the size of its public adoption (about 4.3k GitHub stars) justify a moderately high score rather than a top-tier ML score.",success
https://github.com/StructuredLabs/preswald,preswald,"Preswald is a Python-first static-site/WASM packaging tool for building interactive data apps (dashboards, reports, notebooks) that run entirely in the browser (offline, no server). It bundles Python code via Pyodide along with data access/compute (e.g., DuckDB, Pandas) and UI/visualizations into a self-contained export (e.g., an .html app).",4300,python|data-apps|data-visualization|webassembly|pyodide|duckdb|pandas|static-site-generator,7,"Preswald’s primary use case is packaging and shipping interactive Python data applications that execute client-side in the browser using a WASM runtime (Pyodide) and in-browser analytics tooling like DuckDB and Pandas. This makes it directly useful for data workflows involving exploratory analysis, interactive reporting, and visualization delivery without a server, which is a common need in analytics and applied data science. It is not an ML training framework or MLOps platform, but it can be a strong companion for presenting/inspecting datasets, metrics, and experiment results and sharing them as portable, offline artifacts. The repo also shows meaningful adoption (thousands of stars), reinforcing its practical value to data practitioners.",success
https://github.com/briefercloud/briefer,briefer,"Briefer is an open-source collaborative data workspace for creating and sharing Notion-like notebooks and code-driven dashboards using SQL, Python, Markdown, scheduling, native visualizations, and AI-assisted query/code generation. It supports interactive “data apps” (inputs, dropdowns, date pickers) and real-time multiplayer editing for teams.",4300,data analytics|sql|python|notebooks|dashboards|data visualization|bi|ai assistant,7,"This repository provides a full data analysis workspace that blends SQL querying, Python execution, notebooks, dashboards, scheduling, and interactive controls in a team-collaboration environment. While it is not an ML framework for training models, it is highly relevant to data science workflows because it supports exploratory analysis, building reports/dashboards, and operationalizing analyses via scheduling and shareable artifacts. Its AI-assisted code/query generation and integrations with common data sources make it practical for data teams, but its primary focus is analytics/workspaces rather than core ML modeling—hence a solid but not top-tier ML score.",success
https://github.com/pyqtgraph/pyqtgraph,pyqtgraph,"PyQtGraph is a pure-Python graphics/GUI library for fast, interactive 2D and 3D scientific visualization using Qt (PyQt5/PyQt6/PySide6) and NumPy. It targets real-time plotting and image/volume visualization, leveraging Qt’s GraphicsView and optional OpenGL acceleration.",4300,data-visualization|scientific-computing|python|qt|pyqt|pyside|real-time-plotting|gui,7,"This repository provides high-performance plotting, image display, and interactive visualization widgets for scientific/engineering Python applications, built around Qt and NumPy with optional OpenGL support. While it is not an ML framework, it is highly useful in ML/data workflows for real-time monitoring (training curves, metrics dashboards), exploratory data analysis, and interactive visualization of signals and images/volumes. It has strong community adoption (about 4.3k GitHub stars) and integrates well with the broader scientific Python stack, making it moderately-to-highly valuable for data science tooling rather than core model development.",success
https://github.com/theOehrly/Fast-F1,Fast-F1,"FastF1 is a Python package for accessing and analyzing Formula 1 data, including schedules, session results, timing data, and telemetry. It exposes the data primarily as Pandas DataFrames, supports Ergast-compatible data via the jolpica-f1 API, integrates with Matplotlib for visualization, and includes request caching for faster workflows.",4300,formula-1|motorsport-analytics|python|data-science|pandas|telemetry|data-visualization|matplotlib,7,"This repository provides a mature, widely used Python toolkit for acquiring and analyzing structured motorsport data (timing, results, telemetry) in Pandas-friendly formats, with built-in helpers and visualization integration. While it is not an ML framework, it is highly practical for ML/data workflows as a reliable data ingestion + feature-engineering layer for predictive modeling (e.g., lap-time prediction, strategy modeling) and exploratory analysis. Community adoption appears strong (4.3k stars and hundreds of forks), and its domain-specific abstractions and caching improve real-world data science productivity. I scored it 7 because it is a strong data/analytics library with clear DS utility, but it does not directly provide model training, ML algorithms, or MLOps capabilities.",success
https://github.com/whoiskatrin/sql-translator,sql-translator,"SQL Translator is a free, open-source web app that uses AI to translate natural-language questions into SQL and also translate SQL into human-readable natural language. It includes UI features like syntax highlighting, query history, and a beta ""schema awareness"" mode.",4300,natural language to SQL|text-to-SQL|AI|OpenAI API|data engineering|SQL|Next.js,7,"This repository provides an AI-powered translator between natural language and SQL, which is directly useful for analytics and data-access workflows (e.g., helping non-SQL users generate queries and helping analysts explain queries). It is ML-adjacent rather than a core ML framework: it applies an LLM API to a practical data task, and includes features like schema awareness, but it does not focus on model training, evaluation, or datasets. Community adoption appears solid (thousands of stars), making it a reasonably valuable reference/utility for data teams exploring text-to-SQL interfaces, hence a 7/10.",success
https://github.com/zerocore-ai/microsandbox,microsandbox,"Microsandbox is an open-source, self-hosted sandboxing system for securely running untrusted user/AI code using hardware-isolated microVMs with fast startup times. It supports running OCI-compatible container images and provides SDKs (Python/JavaScript/Rust) plus a CLI/server workflow for managing sandboxes and integrating with agent workflows (e.g., via MCP).",4300,sandboxing|microVM|AI agents|secure code execution|container runtime|MCP|Rust|developer tooling,7,"This repository provides infrastructure for executing untrusted code safely (microVM-based sandboxes with fast boot and OCI image support), which is a common requirement when building or deploying AI agents that run tool/code workloads. While it is not an ML framework or data processing library, it is directly applicable to ML/LLM agent systems that need secure, isolated execution for generated code, data exploration, or tool use. Its SDKs (including Python) and MCP integration increase practical adoption potential in ML/agent workflows, but it remains primarily an execution/security/runtime project rather than a data science toolkit.",success
https://github.com/matplotlib/mplfinance,mplfinance,"A Python library for visualizing financial market data with Matplotlib, providing high-level plotting utilities for OHLC/OHLCV data (e.g., candlesticks, OHLC bars, line charts) and related studies, designed to work well with Pandas DataFrames.",4236,python|data-visualization|matplotlib|pandas|quant-finance|financial-charts|time-series,7,"This repository provides a Matplotlib-based plotting API specifically aimed at financial time-series visualization (OHLC/OHLCV) and technical-style overlays, with a workflow centered on Pandas DataFrames. It is not an ML framework, but it is directly useful in data science/ML workflows for exploratory data analysis, feature/label inspection, and communicating results on market data. The project has strong adoption for its niche (thousands of GitHub stars) and integrates cleanly into Python data stacks, which justifies a moderately high score rather than a core-ML score.",success
https://github.com/LLMBook-zh/LLMBook-zh.github.io,LLMBook-zh.github.io,"This repository hosts the GitHub Pages site and materials for the Chinese book 《大语言模型》, providing a structured introduction to large language model fundamentals, key techniques (pretraining, finetuning, alignment, prompting, RAG, etc.), and accompanying resources such as a PDF and course slides.",4200,large language models|natural language processing|machine learning education|documentation|github pages|deep learning|transformers,7,"The repo’s primary purpose is educational: it publishes and maintains a Chinese-language book/site about large language models and includes companion materials (e.g., a PDF and slides). It is relevant to ML workflows mainly as a learning and reference resource (concepts, methods, and pointers), rather than as a production-grade toolkit for training/deployment. Community adoption appears strong for an educational repo (thousands of stars), but its direct integration potential is moderate because it is largely documentation/content rather than reusable ML code—hence a solid but not top-tier ML/data score.",success
https://github.com/ResidentMario/missingno,missingno,"missingno is a Python library for quickly visualizing patterns of missing data in tabular datasets (typically pandas DataFrames). It provides plots such as nullity matrices, bar charts, nullity-correlation heatmaps, and dendrograms to help diagnose data completeness issues.",4200,python|data-visualization|data-science|pandas|missing-data|exploratory-data-analysis|matplotlib|data-quality,7,"This repository provides a focused toolkit for exploratory data analysis and data quality assessment by visualizing missingness patterns (e.g., matrix, bar, heatmap, dendrogram) in datasets. While it is not an ML modeling framework, it is directly useful in ML/data workflows because understanding and treating missing values is a common prerequisite to feature engineering and model training. It has strong practical applicability for data scientists working with real-world messy data and appears to have meaningful community adoption (thousands of GitHub stars). The score reflects that it is highly relevant to data preparation/EDA, but not a core model-training or MLOps system.",success
https://github.com/h2oai/wave,wave,"H2O Wave is an open-source framework for building beautiful, low-latency, real-time web applications and dashboards entirely in Python or R (no HTML/JS/CSS required). It’s designed for streaming updates and interactive analytics-style UIs with many built-in components and examples.",4200,dashboarding|data-visualization|python|r|web-app-framework|real-time|analytics,7,"This repository provides a full stack for building real-time browser-based dashboards and apps in Python/R, emphasizing low-latency updates and a rich set of UI components. While it is not an ML training/inference framework itself, it is highly applicable to ML/data workflows for creating internal tools, monitoring dashboards, interactive model demos, and data/experiment reporting UIs. Its utility is strongest in visualization and app delivery around data products rather than core modeling, which places it in the moderately-high relevance range.",success
https://github.com/hal9ai/awesome-dataviz,awesome-dataviz,"A curated “awesome list” of data visualization frameworks, libraries, and tools across multiple languages (JavaScript, Python, R, etc.), plus learning resources like books, catalogs, podcasts, and websites.",4200,data visualization|awesome-list|javascript|python|r|charting|geospatial-visualization,7,"This repository is primarily a curated directory of data visualization libraries and related resources, not an executable ML library or framework. It is directly useful in ML/data workflows because visualization is a core part of exploratory data analysis (EDA), model evaluation, and communicating results, and the list includes many commonly used plotting/vis ecosystems (e.g., Python and JavaScript tooling). Community adoption appears strong for a reference list (4.2k stars), but it does not provide ML pipelines, training, or MLOps functionality, so it rates as moderately (not highly) relevant.",success
https://github.com/DTStack/chunjun,chunjun,"ChunJun is a distributed data integration framework based on Apache Flink for batch/stream unified data synchronization and computation across heterogeneous data sources. It provides plugin-based source/sink/lookup connectors, supports JSON/SQL (Flink SQL-compatible) job definitions, and includes operational features like checkpoint-based fault tolerance and breakpoint resume.",4100,data integration|data engineering|ETL|Apache Flink|stream processing|batch processing|connectors,7,"This repository provides a Flink-based data integration/ETL framework (formerly FlinkX) focused on syncing and transforming data between many heterogeneous sources via source/sink/lookup plugins and Flink SQL/JSON-defined jobs. It is not an ML library, but it is directly useful in ML/data workflows as pipeline infrastructure for moving training/feature data into lakes/warehouses and supporting incremental/real-time ingestion. Its relevance is strengthened by broad connector support and production deployment orientation, but it doesn’t address model training/serving or ML-specific tooling, so it scores as moderately (not core) ML/data value.",success
https://github.com/nteract/hydrogen,hydrogen,"Hydrogen is an interactive coding environment for the Atom editor that lets you run code inline using Jupyter kernels (e.g., Python, R, JavaScript), inspect results, and render rich outputs like plots and images. It supports features like watch expressions, kernel-based autocompletions, and connecting to custom/remote kernels.",4100,jupyter|interactive-computing|atom-editor|python|data-science|repl|notebooks,7,"This repository provides an Atom editor integration that brings Jupyter-kernel-powered, inline execution to source files, enabling a notebook-like workflow while coding. It’s directly useful for data science and ML practitioners because it runs Python/R kernels, displays rich outputs (plots/images), and supports variable inspection and iterative experimentation. While it isn’t an ML library itself, it meaningfully improves ML/data workflows by tightening the experiment–edit–run loop and integrating with the broader Jupyter ecosystem. The score is moderated because Atom has been sunset and Hydrogen is primarily an editor tool rather than a core data/ML framework.",success
https://github.com/p-e-w/heretic,heretic,"Heretic is a Python CLI tool that automatically removes safety-alignment/refusal behavior (“censorship”) from transformer-based language models using directional ablation (“abliteration”) and automated hyperparameter search (Optuna/TPE), aiming to minimize refusals while preserving original model behavior (low KL divergence). It also includes optional research/interpretability utilities such as residual-vector visualization with dimensionality reduction and animations.",4100,large-language-models|llm-alignment|model-editing|transformers|pytorch|optuna|interpretability,7,"This repository is primarily an automation tool for modifying (editing) transformer LLMs to reduce refusal/safety behavior via directional ablation plus Optuna-based parameter optimization, with built-in evaluation and an optional interpretability-focused plotting workflow. It is directly relevant to ML engineering and LLM research workflows (model editing, alignment/safety research, evaluation, and analysis of internal representations), though it is not a general-purpose data-science library or end-to-end training framework. Community adoption appears meaningful (thousands of GitHub stars), and the repo has clear educational value for understanding practical LLM editing/abliteration and related evaluation tradeoffs, supporting a moderately high score rather than a core-ecosystem score.",success
https://github.com/gopherdata/gophernotes,gophernotes,"A Go language kernel for Jupyter notebooks and nteract, enabling interactive execution of Go code in notebook environments. It supports creating and sharing documents containing live Go code alongside text, equations, and visualizations, and uses the gomacro Go interpreter under the hood.",4000,jupyter|go|notebook-kernel|interactive-computing|data-science|nteract|gomacro,7,"This repository provides a Jupyter/nteract kernel for the Go programming language, letting users run Go code interactively in notebooks, which is a common workflow interface for data science. While it is not an ML library itself (no modeling algorithms or training pipelines), it is directly useful for ML/data practitioners who want to do exploratory analysis, visualization, and experimentation in Go within Jupyter. Its strong applicability as an interactive data-science environment (plus substantial community adoption indicated by ~4k stars) supports a moderately high score, but it is not a core ML framework, so it does not warrant an 8–10.",success
https://github.com/xviniette/FlappyLearning,FlappyLearning,"A JavaScript demo that trains an AI to play Flappy Bird using neuroevolution (evolving neural networks via a genetic algorithm). It includes a playable Flappy Bird implementation plus a Neuroevolution.js module to generate, mutate, and score networks across generations.",4000,machine learning|neuroevolution|genetic algorithms|reinforcement learning (game AI)|javascript|browser demo|flappy bird,7,"This repository demonstrates training agents to play Flappy Bird using neuroevolution, providing an end-to-end example of evolutionary optimization of neural-network weights in a game environment. It is directly relevant for ML education (agent evaluation, fitness/score assignment, mutation/elitism, and generation loops) and can be adapted to other simple environments, but it is not a general-purpose ML framework and lacks modern tooling (datasets, experiment tracking, GPU training, integrations). Community interest appears solid (thousands of stars), supporting its educational value, but its applicability is mostly as a learning/demo project rather than a production ML component.",success
https://github.com/briatte/awesome-network-analysis,awesome-network-analysis,"A curated “awesome list” of resources for constructing, analyzing, and visualizing network (graph) data, including books, courses, datasets, papers, and software across multiple languages (e.g., Python, R, Julia). It serves as a reference index rather than a standalone analysis library.",3900,network analysis|graph analytics|data science|social network analysis|resource list|python|r,7,"This repository is primarily a curated directory of network/graph analysis learning materials, datasets, and software links (not an executable ML package). It is strongly relevant to data science workflows because network analysis is a common data modality and the list points to practical tools and datasets used in research and applied analytics. It’s moderately high value for ML practitioners (especially graph ML / network science) due to its breadth and discoverability, but it doesn’t directly provide ML models, pipelines, or code beyond references, so it’s not a core ML framework.",success
https://github.com/quadratichq/quadratic,quadratichq/quadratic,"Quadratic is an AI-enabled spreadsheet application that combines traditional spreadsheet workflows with code execution (e.g., Python/SQL/JavaScript) and data connections, enabling interactive data analysis and collaboration in a spreadsheet-like UI.",3900,spreadsheet|data-science|data-analysis|python|sql|ai|wasm|data-engineering,7,"This repository powers Quadratic, an AI-enabled spreadsheet that supports data analysis with built-in code cells (notably Python and SQL) plus data connections, making it directly useful for exploratory data analysis and analytics workflows. While it is not an ML framework for training/deploying models, it is a strong productivity and analysis environment that can integrate with ML/data tasks via Python and database querying. Its relevance comes from enabling data wrangling, analysis, and visualization in a spreadsheet UI with AI assistance, which is valuable to data scientists and analysts. The score is moderated because the repo’s primary goal is an end-user spreadsheet product rather than a dedicated ML library or MLOps platform, despite meaningful applicability to data workflows.",success
https://github.com/zvtvz/zvt,zvt,"ZVT is a modular quantitative trading/research framework that supports market data acquisition, persistence, incremental updates, factor/signal research, backtesting, and visualization. It also provides a REST API/server mode and includes ML components for training and prediction workflows within the framework.",3900,quantitative finance|algorithmic trading|backtesting|market data|python|machine learning|dash-plotly|REST API,7,"This repository is primarily a quantitative finance framework that ingests and manages market data (e.g., equities) and supports research/backtesting and UI visualization, which are common data-science workflows. It includes an explicit ML module (e.g., training/prediction examples in the README) and is structured to support end-to-end pipelines from data capture through modeling and result display. However, its focus is domain-specific (trading/markets) rather than a general-purpose ML library, and broad ML-community adoption appears more limited than core ML frameworks, so a strong-but-not-top-tier score is appropriate.",success
https://github.com/atlanhq/camelot,camelot,"Camelot is a Python library for extracting tables from text-based PDF files into structured outputs (including pandas DataFrames). It supports configurable table extraction and exporting results to formats like CSV/JSON/Excel/HTML/SQLite, and also provides a command-line interface.",3700,python|pdf|table-extraction|data-extraction|etl|pandas|data-processing,7,"This repository provides a practical PDF table extraction library that turns tables into pandas DataFrames and supports multiple export formats, making it directly useful for data ingestion and preprocessing. While it is not an ML framework, it is highly relevant to data science workflows because extracting structured tabular data from PDFs is a common upstream step before analysis or modeling. Its popularity (thousands of GitHub stars) suggests meaningful community adoption, though it is archived/read-only as of January 6, 2025, which reduces long-term integration confidence. Overall, it is a strong data engineering utility with clear DS applicability but not a core ML tool.",success
https://github.com/jtablesaw/tablesaw,tablesaw,"Tablesaw is a Java dataframe and visualization library for loading, cleaning, transforming, filtering, and summarizing tabular data. It also includes descriptive statistics and Plotly-based charting, and can be used to prepare data for Java ML libraries (e.g., Smile, Tribuo, H2O.ai, DL4J).",3700,java|dataframe|data-processing|data-wrangling|data-visualization|descriptive-statistics|etl,7,"This repository provides a pandas-like dataframe API for Java, with strong support for ingesting common data formats (CSV/Excel/JSON/HTML/RDBMS), cleaning and transforming tables, summarizing data, and producing visualizations. It is directly useful in ML/data workflows for feature engineering, exploratory data analysis, and preparing datasets before modeling, but it is not itself a model-training framework. The score reflects that it is moderately-to-highly relevant for data science work in the Java ecosystem, especially as a preprocessing/EDA layer that integrates well with downstream Java ML libraries.",success
https://github.com/llm-workflow-engine/llm-workflow-engine,llm-workflow-engine,"LLM Workflow Engine (LWE) is a Python-based power CLI and workflow manager for interacting with LLMs from the terminal and via a Python API. It supports the official OpenAI ChatGPT API, a plugin-based architecture for multiple LLM providers, and building larger automation workflows (e.g., via Ansible playbooks), with optional Docker support.",3700,large language models|LLM tooling|OpenAI API|CLI|Python|workflow automation|plugin architecture|MLOps,7,"This repository provides a CLI and workflow framework to integrate LLM calls (including OpenAI’s ChatGPT API) into scripts and automation, plus a Python library for programmatic use. It is relevant to ML/data workflows as an orchestration and tooling layer for LLM-powered tasks (prompting, tool use, provider plugins, automation via playbooks), but it is not a model-training or data-processing library itself. Community adoption appears solid (thousands of GitHub stars), and it can be directly useful for ML engineers and data scientists building LLM-enabled pipelines, which supports a moderately high score rather than a top-tier core ML framework score.",success
https://github.com/miso-belica/sumy,sumy,"Sumy is a Python library and command-line tool for automatic text summarization of plain text and HTML pages. It includes multiple extractive summarization algorithms (e.g., LexRank, LSA, Luhn, Edmundson) and basic evaluation utilities for summaries.",3700,natural language processing|text summarization|extractive summarization|python|nlp|command-line tool|information retrieval,7,"This repository provides practical NLP functionality for extractive text summarization, available both as a Python API and a CLI, which makes it directly usable in data science workflows involving document preprocessing and content condensation. While it is not a model-training framework and primarily implements classic (non-deep-learning) summarization methods, it is still a solid, reusable component for ML/data pipelines (feature engineering, dataset exploration, summarizing scraped content) and includes evaluation tooling. Its relatively strong GitHub adoption and multi-language support further increase its utility for applied NLP work, but it does not reach the level of a core ML framework.",success
https://github.com/moondevonyt/moon-dev-ai-agents,moon-dev-ai-agents,"A Python repository of autonomous AI agents focused on crypto/algo trading workflows, including research/backtesting agents, live trading orchestration, and market-monitoring agents (e.g., sentiment, whales, funding, liquidations). It also includes assorted automation/content agents and a multi-model “swarm” approach for consensus decision-making across multiple LLM providers.",3700,python|ai-agents|algorithmic-trading|crypto-trading|llm-orchestration|backtesting|market-analysis,7,"This repository is primarily an agent-based automation toolkit for trading: it includes research/backtesting agents that turn external resources (videos/PDFs/text/web pages) into strategy research and backtests, plus live-trading and market-monitoring agents. It relates to ML/data workflows through practical integration of LLMs (multi-model consensus “swarm”) and data-driven market analysis/backtesting, which can be directly useful for quantitative research and experimentation. However, it is not a general-purpose ML library/framework and its value depends on the user’s trading/data sources and careful validation, so it scores below core ML/data tooling but remains moderately-highly relevant for applied ML/agent workflows in trading.",success
https://github.com/olivia-ai/olivia,olivia,"Olivia is an open-source chatbot built in Go that uses machine-learning techniques to power conversational responses, positioned as a free alternative to services like Dialogflow. It supports text chat and can optionally use speech-to-text (STT) and text-to-speech (TTS), with Docker and docker-compose deployment options.",3700,chatbot|machine-learning|natural-language-processing|golang|speech-to-text|text-to-speech|docker,7,"This repository implements an ML-powered chatbot (in Go) and includes training-related assets (e.g., a saved neural-network dataset/model file referenced in the README) and a workflow for retraining by removing the saved model artifact. It is meaningfully relevant to ML workflows because it touches model training/inference, NLP-style conversational systems, and dataset/model management, and can be used as a practical reference or baseline for an ML chatbot implementation. However, it appears to be more of an end-to-end application than a general-purpose ML library, and the repository is archived (read-only as of Feb 6, 2025), which limits ongoing community adoption and long-term integration value.",success
https://github.com/1nchaos/adata,adata,"AData is a free, open-source A-share (China stock market) quantitative trading data toolkit/database with a Python SDK. It provides unified APIs to fetch stock codes, K-line (daily/weekly/monthly) and real-time quotes, concept/industry/indices data, and other market datasets via multi-source aggregation and optional proxy support for higher availability.",3600,python|quantitative-finance|stock-market-data|financial-data-api|data-engineering|trading|china-a-shares,7,"This repository primarily provides a Python SDK and dataset/API layer for retrieving and organizing A-share market data (prices, concepts, indices, calendars, etc.), aimed at personal quantitative trading workflows. It is directly useful for ML/data science because it supplies key supervised-learning inputs (time series OHLCV, real-time snapshots, categorical features like concepts/industries) needed for feature engineering, backtesting research, and model training. Community adoption appears solid (about 3.6k GitHub stars), but it is not itself an ML framework or modeling toolkit, so it scores as moderately-to-strongly relevant rather than core ML infrastructure.",success
https://github.com/camelot-dev/camelot,camelot,"Camelot is a Python library for extracting tabular data from text-based PDF files. It outputs extracted tables as pandas DataFrames and supports exporting results to formats like CSV/JSON/Excel/HTML/Markdown/SQLite, with both a Python API and a CLI.",3600,pdf-table-extraction|data-extraction|document-processing|pandas|python|etl|data-analysis,7,"This repository provides a practical data-extraction tool focused on pulling tables from PDFs into structured data (notably pandas DataFrames) and exporting them into analytics-friendly formats. While it is not an ML framework, it is highly useful in ML/data workflows as an upstream data ingestion/cleanup component when datasets originate in PDFs (common in finance, policy, and scientific reporting). Its value is primarily in data engineering and preprocessing rather than model training, which justifies a moderately high score rather than an 8–10.",success
https://github.com/opengeos/leafmap,leafmap,"Leafmap is a Python package for interactive mapping and geospatial analysis in Jupyter environments (e.g., JupyterLab/Notebook/Colab) with minimal coding. It builds on mapping backends like ipyleaflet/folium and integrates tools (e.g., WhiteboxTools) to load, visualize, and analyze raster/vector geospatial data interactively.",3600,geospatial|interactive-mapping|jupyter|python|data-visualization|gis|remote-sensing,7,"The repository primarily provides interactive geospatial mapping and analysis tools for Python users working in Jupyter, including convenient workflows for loading and exploring raster/vector datasets and running geospatial analysis tooling (e.g., via WhiteboxTools). While it is not an ML training framework, it is highly useful in ML/data workflows for geospatial EDA, visualization of predictions/labels, and preparing/inspecting spatial datasets (often a key part of GeoML pipelines). Community adoption appears strong (thousands of GitHub stars) and it integrates well with common geospatial Python tooling used by data scientists, justifying a moderately-high relevance score rather than a core-ML score.",success
https://github.com/seandavi/awesome-single-cell,awesome-single-cell,"A community-curated “awesome list” of software packages, tutorials/workflows, web portals, and data resources for single-cell analysis (e.g., scRNA-seq, scATAC-seq, multi-omics, spatial transcriptomics), organized by task/category.",3600,single-cell|bioinformatics|computational biology|scRNA-seq|scATAC-seq|omics|data resources|awesome-list,7,"This repository is primarily a curated directory of tools, methods, and resources for single-cell omics analysis rather than a standalone ML library. It is directly useful to data scientists and ML practitioners working in genomics because it aggregates relevant packages (including ML-heavy methods like embedding, clustering, annotation, and foundation models) and helps with tool discovery and workflow building. However, because it does not itself provide an implementation, dataset, or executable pipeline, its value is more informational/curational than operational, which is why it scores below core ML tooling.",success
https://github.com/spotify/chartify,chartify,"Chartify is a Python data-visualization library designed to help data scientists create clean, consistent charts with a simple API and sensible defaults. It is built on top of Bokeh and supports a tidy-data input format with optional PNG export (via Chrome/Chromedriver).",3600,data-visualization|python|data-science|bokeh|plotting|analytics,7,"This repository provides a Python plotting library aimed at data scientists, emphasizing consistent tidy-data inputs, smart styling defaults, and an approachable API, while still allowing fallback to Bokeh for advanced control. It is not an ML modeling framework, but it directly supports core ML/data workflows by making exploratory data analysis (EDA), experiment reporting, and dashboard-style visualization easier and more standardized. Community adoption appears solid (on the order of ~3.6k GitHub stars), indicating practical usage beyond a niche internal tool. Based on its strong relevance to data science work (visualization/EDA) but lack of direct training/inference/MLOps functionality, a 7/10 is appropriate.",success
https://github.com/holoviz/datashader,datashader,"Datashader is a Python data rasterization pipeline that turns very large datasets into meaningful images by projecting data to a grid, aggregating it, and transforming the results for visualization. It can be used standalone or as a preprocessing stage for plotting libraries to enable scalable rendering of big data.",3500,data visualization|big data|python|geospatial|data rasterization|dask|xarray,7,"This repository provides Datashader, a high-performance pipeline for rasterizing and visualizing extremely large datasets by binning/projecting records onto a pixel grid and computing aggregations before rendering an image. It is not an ML model-training framework, but it is directly valuable in data science workflows for exploratory data analysis and visual inspection of large/tabular and geospatial datasets, including in distributed contexts (e.g., via Dask integrations). Community adoption appears strong for a specialized visualization tool (about 3.5k GitHub stars), and it integrates well with the broader Python data stack, which justifies a moderately high (but not core-ML) score.",success
https://github.com/mckinsey/vizro,vizro,"Vizro is an open-source, Python-based low-code toolkit for building production-ready data visualization apps (dashboards) with strong default design patterns. Apps are defined via simple configuration (e.g., Pydantic models, YAML/JSON, or Python dicts) and can be extended with custom code; the repo also includes Vizro-MCP to help LLM clients generate Vizro charts/dashboards step-by-step.",3500,data visualization|dashboards|python|plotly|dash|pydantic|low-code,7,"Vizro primarily helps users build data visualization apps quickly using Python and a configuration-driven (low-code) approach, leveraging Plotly/Dash and Pydantic. It is directly useful in data science workflows for communicating analyses, monitoring data/metrics, and shipping interactive dashboards, and it includes an LLM-assistance component (Vizro-MCP) for generating charts/dashboards with MCP-enabled clients. However, it is not a core ML training/inference framework or data pipeline engine, so its value is strongest on the analytics/visualization and reporting side rather than model development itself.",success
https://github.com/vispy/vispy,vispy,"VisPy is a high-performance interactive 2D/3D scientific data visualization library for Python that leverages GPUs via OpenGL to render very large datasets. It provides tools for fast plotting, real-time visualization, and building visualization widgets/GUI components (e.g., via Qt and Jupyter/WebGL backends).",3500,data visualization|scientific computing|python|GPU acceleration|OpenGL|2D/3D rendering|interactive visualization,7,"This repository provides an interactive, GPU-accelerated visualization stack (2D/3D plotting, scene graph/visuals, and an OpenGL-oriented API) primarily aimed at scientific visualization rather than model training. It is strongly relevant to ML/data workflows for exploratory data analysis, large point-cloud/embedding visualization, real-time monitoring dashboards, and custom visual analytics tools, but it is not an ML framework and does not provide modeling algorithms. Its utility is high for data scientists who need high-performance interactive rendering beyond standard plotting libraries, which supports a moderately-to-highly relevant score.",success
https://github.com/apache/linkis,apache/linkis,"Apache Linkis is a computation middleware layer that provides standardized interfaces (e.g., REST/WS/JDBC) to connect, govern, and orchestrate tasks across multiple underlying data engines. It decouples upper-layer applications from engines like Spark, Hive, Flink, Presto/Trino, JDBC sources, and more, while offering governance features such as routing, load balancing, and multi-tenant resource control.",3400,data engineering|big data|workflow orchestration|compute governance|distributed systems|Spark|Flink|Hive,7,"This repository implements Apache Linkis, a middleware/orchestration and governance layer that standardizes how applications submit and manage computation across diverse data engines (Spark/Hive/Flink/Trino/JDBC, etc.). It is strongly relevant to data engineering and analytics platform building, and can be used to unify and operationalize data/ML workloads by providing consistent access, routing, and resource governance over the compute layer. However, it is not an ML library or MLOps training framework itself; its value for ML comes from infrastructure integration and orchestration rather than model development, which is why it scores as moderately-high (7/10) rather than core (9–10).",success
https://github.com/bruin-data/ingestr,ingestr,"ingestr is an open-source CLI that copies/ingests data from many sources (databases and SaaS/platform APIs) into supported destinations using a single command, without writing code. It supports common ingestion patterns like incremental loading (append/merge/delete+insert) and includes a catalog of supported connectors.",3400,data ingestion|data engineering|ELT|ETL|CLI|connectors|data pipelines|Python,7,"This repository provides a command-line ingestion engine for moving tabular data from many operational sources (databases and SaaS APIs like GitHub, Shopify, etc.) into analytics destinations (e.g., BigQuery, Snowflake, Postgres, Databricks). While it is not an ML library, it is directly useful in ML/data workflows as a practical tool for collecting and syncing training/feature data into warehouses or lakehouse systems, and it supports incremental ingestion strategies that are common in production data pipelines. The repo appears to have meaningful adoption (thousands of GitHub stars) and strong integration potential as a component within broader analytics/ML stacks (e.g., feeding data into warehouse-based feature engineering). It is scored 7/10 because it is a solid data-engineering utility that enables ML work, but it does not focus on modeling, feature stores, or MLOps/model lifecycle management itself.",success
https://github.com/dathere/qsv,qsv,"qsv is a blazing-fast, composable command-line toolkit (written in Rust) for wrangling tabular data—especially CSVs—supporting tasks like querying, filtering, joining, validating, converting formats, and running analytics at scale. It is designed to be CPU-accelerated/parallel and can also work with spreadsheets and other tabular formats, integrating with modern engines like Polars for high performance.",3400,data-wrangling|csv|command-line-tool|rust|data-engineering|etl|polars|open-data,7,"This repository provides a high-performance CLI for slicing/dicing and transforming tabular datasets (primarily CSV, but also spreadsheets and other formats), which is a common and often time-consuming step in ML and analytics workflows. While it is not an ML framework for model training, it is directly useful for dataset preparation, profiling, validation, feature engineering-like transformations, and building reproducible data pipelines (including very large files) from the terminal. Its adoption appears strong for a specialized data tool (thousands of GitHub stars) and it integrates with data-oriented technologies (e.g., Polars), which increases practical value for data scientists and ML engineers. The score is not higher because the core purpose is data wrangling/processing rather than modeling, MLOps, or ML-native APIs.",success
https://github.com/grananqvist/Awesome-Quant-Machine-Learning-Trading,Awesome-Quant-Machine-Learning-Trading,"A curated “awesome list” of resources for quantitative/algorithmic trading with an emphasis on machine learning, including books, courses, videos, blogs, interviews, and papers related to financial machine learning.",3400,quantitative finance|algorithmic trading|financial machine learning|trading research|resource list|deep learning|reinforcement learning|python,7,"This repository is primarily a curated collection of learning and reference resources for applying machine learning to quantitative trading, rather than a code library or dataset. It is strongly relevant to ML/data workflows in finance because it points practitioners to foundational material (books, papers, courses) and practical educational content for building and evaluating trading models. However, since it is not an implementation toolkit (no core framework, training codebase, or data pipeline) and is mainly links and references, its direct plug-and-play applicability and integration potential are moderate rather than high. Its popularity (around 3.4k stars) suggests meaningful community adoption, supporting a solid but not top-tier score.",success
https://github.com/shashankvemuri/Finance,Finance,"A collection of 150+ Python programs for quantitative finance that help gather, manipulate, and analyze stock market data. It includes stock screening, technical indicators, portfolio strategy simulations, data collection via APIs/web scraping, and some introductory ML-based stock classification/prediction scripts.",3400,python|quantitative-finance|stock-market-data|algorithmic-trading|technical-analysis|pandas|machine-learning|portfolio-strategies,7,"This repository is primarily a large educational/practical code collection for working with equities data: downloading/collecting data, analyzing individual stocks, computing technical indicators, and simulating trading/portfolio strategies. It directly supports data workflows (data acquisition, feature/indicator creation, analysis/visualization) and includes a dedicated machine_learning section for basic stock prediction/classification. While it is not a widely adopted core ML framework, it is quite useful for applied financial data science learning and for jump-starting quant research prototypes, which justifies a moderately high score.",success
https://github.com/filipecalegario/awesome-generative-ai,awesome-generative-ai,"A curated “awesome list” of Generative AI resources, including tools, projects, models, papers, courses, and reference links across areas like LLMs, prompt engineering, RAG, agents, multimodal, and creative media (image/audio/video). It’s organized into topical sections and is intended to be regularly updated with new resources added in reverse-chronological order within sections.",3300,generative AI|large language models|prompt engineering|retrieval-augmented generation|AI agents|datasets|awesome-list,7,"This repository is primarily a curated directory of generative AI resources (tools, models, papers, courses, and references) rather than an executable ML library or data pipeline. It’s directly useful for ML/data practitioners for discovery, learning, and evaluating the ecosystem (e.g., LLM frameworks, RAG, embeddings, evaluation, datasets), but it does not itself provide code for training/inference or production integration. Community adoption appears solid for a reference list (thousands of stars), supporting a moderately high score, but it’s not a core ML framework with direct workflow integration, so it doesn’t reach 8–10.",success
https://github.com/jupyter-widgets/ipywidgets,ipywidgets,"ipywidgets (aka jupyter-widgets) provides interactive HTML widgets for Jupyter notebooks using the IPython kernel, enabling UI controls (sliders, text inputs, buttons, outputs, etc.) that let users interactively explore and visualize data and model behavior.",3300,jupyter|ipywidgets|interactive-widgets|data-visualization|python|jupyterlab|notebook-ui|widgets-framework,7,"This repository implements the core interactive widgets framework used in Jupyter notebooks/JupyterLab, providing controls and outputs that make notebooks interactive and extensible (including support for custom widget libraries). It is not an ML framework itself, but it is widely used in data science/ML workflows for interactive exploration, visualization, and building lightweight experiment dashboards inside notebooks. Its strong adoption in the Jupyter ecosystem and direct utility for model/demo interactivity justify a moderately high score, though it does not provide data processing or training capabilities on its own.",success
https://github.com/WeBankFinTech/DataSphereStudio,DataSphereStudio,"DataSphereStudio (DSS) is WeBank’s one-stop data application development and management portal, providing a unified UI for end-to-end data workflows such as data exchange, desensitization/cleansing, analysis/mining, data quality, visualization, and scheduling. It uses a pluggable integration framework and integrates with Linkis (computing middleware) to connect multiple data application systems via standardized connectors (AppConn).",3200,data engineering|data platform|workflow orchestration|ETL|data quality|data visualization|multi-tenant|MLOps,7,"This repository primarily delivers an integrated data application development portal (with workflow-style, drag-and-drop development) that supports key data lifecycle activities such as ingestion/exchange, cleaning/desensitization, analysis/mining, quality checks, visualization, and scheduling. It is directly useful to data teams as a data engineering and orchestration platform and can serve as a foundation for analytics workflows, but it is not itself an ML model training framework. Its ML relevance is moderate-to-high because it explicitly integrates a “one-stop machine learning platform” component (Prophecis) and is designed to integrate multiple specialized tools via AppConn/Linkis, enabling ML/data pipelines in an enterprise setting. The score reflects strong applicability to data workflows and platform integration value, with ML being a supported scenario rather than the core focus.",success
https://github.com/apache/paimon,paimon,"Apache Paimon is a lake format for building a real-time lakehouse with Apache Flink and Apache Spark, supporting both streaming and batch workloads. It combines a table/lake format with an LSM-based storage design to enable real-time updates in a data lake architecture.",3200,big data|data lakehouse|table format|Apache Flink|Apache Spark|real-time analytics|streaming ingestion|data engineering,7,"This repository implements Apache Paimon, a storage/table format for lakehouse systems aimed at enabling real-time updates and analytics using engines like Flink and Spark. While it is not an ML library (no model training/inference focus), it is directly relevant to ML/data workflows as upstream data infrastructure for producing, managing, and querying large-scale datasets used for feature generation, offline/online data prep, and analytics. Its integration with common data processing engines and its role in building reliable streaming/batch pipelines make it moderately-to-highly valuable for data science and ML engineering teams, hence a 7/10.",success
https://github.com/chrisconlan/algorithmic-trading-with-python,algorithmic-trading-with-python,"Source code accompanying the book ""Algorithmic Trading with Python"" (2020) by Chris Conlan. Includes Python modules and example code for backtesting/portfolio simulation, technical indicators & signals, performance metrics, optimization (grid search), and repeated K-fold cross-validation, plus bundled simulated EOD and alternative datasets.",3200,algorithmic trading|quantitative finance|python|pandas|backtesting|time series|technical analysis|cross-validation,7,"This repository is primarily an educational quant-trading codebase: it provides reusable Python components for indicators/signals, portfolio simulation/backtesting, and strategy evaluation/optimization, along with example datasets. It relates to ML/data workflows through time-series feature engineering (technical indicators), model evaluation utilities (multi-core repeated K-fold cross-validation), and optimization wrappers that are directly applicable to applied data science in finance. However, it is not a general-purpose ML framework or widely adopted ML infrastructure tool; its ML relevance is moderate-to-strong within the trading/financial time-series niche, hence a 7/10.",success
https://github.com/lakesoul-io/LakeSoul,LakeSoul,"LakeSoul is an open-source, cloud-native real-time lakehouse framework that provides ACID transactions, concurrent upserts, and incremental read/compute on cloud/Hadoop storage (e.g., S3/HDFS). It integrates with engines like Spark, Flink, and Presto (and offers Python access) to support real-time ingestion, CDC-style pipelines, and analytics for BI and AI workloads.",3200,data engineering|lakehouse|data lake|ACID transactions|upsert|Apache Flink|Apache Spark|CDC (change data capture),7,"LakeSoul’s primary purpose is data-lakehouse infrastructure: transactional storage with concurrent upsert, incremental reads, and real-time ingestion/analytics using engines such as Spark and Flink. This is directly useful for ML/data workflows because it helps build reliable, up-to-date tabular datasets and incremental pipelines that can feed feature engineering, model training, and near-real-time scoring, with Python access enabling DS/ML tool integration. It is not an ML framework itself (no core modeling/training algorithms), so it scores below 8–10, but it is a strong enabling layer for production data/ML systems and real-time datasets.",success
https://github.com/mne-tools/mne-python,mne-python,"MNE-Python is an open-source Python library for reading, preprocessing, visualizing, and analyzing human neurophysiological data (e.g., MEG, EEG, sEEG, ECoG). It provides tools for time-frequency analysis, source estimation, connectivity analysis, statistics, and ML/decoding workflows built around M/EEG data structures.",3200,python|neuroscience|neuroimaging|eeg|meg|signal-processing|time-series-analysis|machine-learning,7,"This repository is primarily a neurophysiology (MEG/EEG) signal-processing and analysis toolkit rather than a general-purpose ML framework, but it directly supports data-science workflows on brain time-series data (cleaning/preprocessing, feature extraction, time-frequency transforms, source estimation, connectivity, and statistical analyses). It is widely adopted in the M/EEG research community and integrates well with common scientific Python tooling, making it valuable for building ML/decoding pipelines on electrophysiology datasets. The score is not higher because its core focus is domain-specific analysis (M/EEG) and not end-to-end model training/MLOps, but for neuro data science it is a highly practical foundation.",success
https://github.com/Intelligent-Internet/ii-agent,ii-agent,"II-Agent is an open-source framework and full-stack assistant for building and deploying intelligent agents that can execute complex tasks end-to-end (e.g., development workflows, slide generation, and deep research) via multi-model/tool integrations.",3100,ai-agents|llm|agent-framework|agentic-ai|python|typescript|full-stack-webapp|automation,7,"This repository provides an agent framework and accompanying web application for orchestrating LLM-driven assistants across models and tools to perform multi-step tasks like software development and deep research. It is moderately valuable for ML/data workflows because it supports agentic automation and research/report generation, but it is not primarily a model-training, data-processing, or MLOps library. The relatively strong community adoption signal (thousands of GitHub stars) increases practical/educational value for ML engineers building LLM-agent systems, though its usefulness is more on orchestration/application-layer tooling than core data science.",success
https://github.com/Josh-XT/AGiXT,AGiXT,"AGiXT is an AI agent automation/orchestration platform that manages instructions and executes complex tasks across multiple AI providers. It includes adaptive memory, smart planning/chat features, and an extensible plugin/command system for integrating external services and automating workflows.",3100,AI agents|agent orchestration|LLM|automation|plugins|FastAPI|MLOps,7,"AGiXT’s primary purpose is to orchestrate AI agents (including multi-provider LLM support) and automate tasks via extensions/plugins, chains/workflows, and memory management, rather than to train models or provide core ML algorithms. It can still be directly useful in ML/data workflows as an agent layer for tool-using assistants (e.g., data retrieval, analysis automation, report generation, and integrating with APIs/services), and it supports running with local inference components. Community adoption appears meaningful (about 3.1k GitHub stars), but it is not a foundational ML/data library like PyTorch/Pandas; it’s better categorized as an AI automation/agent platform with moderate relevance to data science engineering use cases.",success
https://github.com/bfortuner/ml-glossary,ml-glossary,"A community-maintained machine learning glossary that defines ML/data science terms with an emphasis on clear explanations, citations, and (when possible) visuals, code snippets, and equations. The content is built/published as documentation (Sphinx/RST) and linked to an online glossary site.",3100,machine learning|data science|deep learning|ml education|glossary|documentation|sphinx,7,"This repository’s primary purpose is educational: it collects and publishes definitions of machine-learning concepts as a browsable glossary, with contribution guidelines requiring concise explanations and citations. It’s relevant to ML/data workflows mainly as a reference/learning resource rather than as a tool for building models or processing data. Community adoption appears solid (about 3.1k GitHub stars and many contributors), but it doesn’t provide a reusable ML library or pipeline, so it scores below dedicated ML frameworks and production tools.",success
https://github.com/blockchain-etl/ethereum-etl,ethereum-etl,"Python-based ETL tooling to extract Ethereum blockchain data (blocks, transactions, receipts, logs, contracts, traces/internal transactions, token transfers) and export it to convenient formats such as CSV and relational databases, with options for streaming data continuously. It also references public Ethereum datasets available in Google BigQuery and provides command-line utilities and documentation for common export/query workflows.",3100,blockchain|ethereum|ETL|data engineering|Python|BigQuery|data pipelines|CLI,7,"This repository is primarily a data engineering/ETL toolkit for extracting and transforming raw Ethereum blockchain data into analytics-friendly outputs (e.g., CSV and database tables) and supports both batch exports and continuous streaming. While it is not an ML library, it is directly useful for data science workflows that need large-scale blockchain feature generation, labeling, and dataset creation (e.g., fraud detection, address/entity analysis, market microstructure research). The project has strong practical adoption signals (notably a large star count) and integrates cleanly into downstream ML pipelines by producing structured data, but it does not provide modeling, training, or MLOps functionality—hence a moderately high (not core) ML/data score.",success
https://github.com/pydata/pandas-datareader,pandas-datareader,"A Python library that provides up-to-date remote data access for pandas by extracting data from a wide range of internet sources into pandas DataFrames (e.g., economic and financial data sources).",3100,python|pandas|data-ingestion|financial-data|economic-data|time-series|data-analysis|api-clients,7,"This repository provides connectors to download and normalize external datasets (notably financial and economic time series like FRED and other market/econ sources) directly into pandas DataFrames, making it a practical data acquisition tool. While it is not an ML framework and does not focus on model training, it is commonly useful in ML/data science workflows as an upstream data ingestion step for feature creation and analysis. Its strong fit with pandas and broad adoption in the Python data ecosystem increase its utility for practitioners, but its scope is primarily data retrieval rather than ML-specific methods, so it scores as moderately-high rather than core ML.",success
https://github.com/quantopian/qgrid,qgrid,"Qgrid is a Jupyter widget that uses SlickGrid to render pandas DataFrames as an interactive spreadsheet-like grid inside Jupyter Notebook/Lab, enabling fast scrolling plus in-notebook sorting, filtering, and cell editing.",3100,jupyter|ipywidgets|pandas|dataframe|data-visualization|interactive-widget|slickgrid,7,"The repository provides an interactive DataFrame grid widget for Jupyter (sorting, filtering, editing), which directly supports common data science workflows such as exploratory data analysis and data cleaning. It is not an ML modeling framework itself, but it integrates tightly with pandas and notebook-based analysis, making it broadly useful to data scientists. Community adoption appears solid (thousands of GitHub stars), but the original Quantopian project is no longer actively maintained and has largely been continued via forks like QgridNext, which slightly reduces its practical value today compared to an actively maintained alternative.",success
https://github.com/tirthajyoti/Data-science-best-resources,Data-science-best-resources,"A curated collection of links and reference materials for data science and related topics (AI/ML, cloud platforms like AWS, blogs, books/courses, etc.) gathered into a single repository, along with a few included PDF cheat sheets/notes.",3100,data science|machine learning|artificial intelligence|learning resources|curated list|cheat sheets|AWS,7,"This repository is primarily a curated directory of data science and AI/ML learning resources (articles, books/courses, tools/platform links) rather than an executable library or framework. It’s directly useful for education and discovery (finding high-quality references and starting points), but it doesn’t provide code, datasets, or tooling that plugs into ML pipelines. Community adoption appears solid for a resource list (thousands of stars), which supports a moderately high score, but the lack of integration/implementation keeps it below core ML tooling.",success
https://github.com/tradytics/eiten,eiten,"Eiten is an open-source Python toolkit for building and testing statistical/algorithmic investing portfolios (e.g., eigen-portfolios, minimum-variance, maximum-Sharpe, and genetic-algorithm portfolios). It includes modules for loading market data (via yfinance), constructing portfolios, running backtests/forward tests, and simulating performance with Monte Carlo methods.",3100,quantitative-finance|algorithmic-trading|portfolio-optimization|backtesting|python|time-series|monte-carlo-simulation|scikit-learn,7,"This repository focuses on quantitative finance workflows—portfolio construction/optimization, backtesting/forward testing, and simulation—built in Python with common data-science dependencies (NumPy, pandas, SciPy, scikit-learn, yfinance). While it is not a general-purpose ML framework, it is directly applicable to data/ML practitioners working on financial time series, feature research, and portfolio optimization experiments. Its educational value is moderate-to-high due to multiple implemented strategies and an end-to-end testing pipeline, but community adoption is limited compared to mainstream ML/data libraries. Based on its strong relevance to applied data science (especially quant finance) but narrower scope than core ML tooling, a score of 7 is appropriate.",success
https://github.com/CatchTheTornado/text-extract-api,text-extract-api,"A FastAPI-based document extraction service that converts images, PDFs, and Office documents (Word/PPTX, etc.) into high-accuracy Markdown text or structured JSON using OCR (e.g., EasyOCR) plus Ollama-supported vision/LLM models. It supports async processing with Celery, Redis caching, and optional PII anonymization/removal workflows.",3000,OCR|document-ai|information-extraction|fastapi|celery|ollama|pii-redaction|pdf-processing,7,"This repository provides an end-to-end pipeline/API for extracting and structuring text from documents via OCR and local LLM/vision models (through Ollama), including features like table/formula-friendly extraction and optional PII removal. It is directly useful in ML/data workflows as a practical data ingestion and document-understanding component for building datasets, RAG pipelines, or downstream NLP/analytics over PDFs and scanned documents. While it is not an ML training framework itself, it meaningfully integrates modern models and infrastructure (FastAPI/Celery/Redis) to operationalize document extraction, which earns it a moderately high relevance score.",success
https://github.com/Kanaries/graphic-walker,graphic-walker,"Graphic Walker is an open-source, embeddable visual analytics tool positioned as a Tableau alternative. It provides a React component for drag-and-drop exploratory data analysis and visualization, with features like natural-language querying/chat, a data explainer, spatial visualization, and a Vega-Lite/grammar-of-graphics style interface.",3000,data-visualization|visual-analytics|exploratory-data-analysis|react|typescript|vega-lite|business-intelligence|natural-language-interface,7,"This repository provides an embeddable (React) visual analytics/EDA experience, marketed as an open-source alternative to Tableau, including drag-and-drop visualization building and a natural-language/chat interface plus a 'data explainer' feature. It is directly useful in data science workflows for exploratory analysis, communicating findings, and embedding interactive analytics into internal tools or products, but it is not primarily a model training/inference framework. Its relevance is strong for data exploration and visualization (moderate-to-high DS utility) rather than core ML algorithms, which supports a score of 7.",success
https://github.com/automeris-io/WebPlotDigitizer,WebPlotDigitizer,"WebPlotDigitizer is a browser-based, computer-vision-assisted tool for extracting numerical data from images/PDFs of charts (e.g., XY plots, bar charts, polar plots) by calibrating axes and then digitizing points manually or via auto-extraction. It supports exporting digitized data (e.g., CSV) for downstream analysis.",3000,data-extraction|computer-vision|data-digitization|data-visualization|javascript|web-application|scientific-computing|data-mining,7,"This repository provides a computer-vision-assisted web application used to recover structured numerical datasets from plot images/PDFs by calibrating axes and extracting points/curves, then exporting the results for analysis. While it is not an ML framework or model-training toolkit, it is directly useful in data science workflows for dataset creation/augmentation when source data is only available as figures in papers or reports. Its broad adoption in academia/industry and its CV-based auto-extraction features make it more than tangentially relevant, but it remains primarily a digitization/visual data recovery tool rather than core ML infrastructure.",success
https://github.com/weld-project/weld,weld,"Weld is a high-performance runtime and intermediate representation (IR) for optimizing data-intensive analytics workloads across multiple libraries and functions. It lazily builds whole-workflow computations, performs cross-library optimizations, and JIT-compiles efficient code (implemented primarily in Rust with LLVM).",3000,data analytics|runtime|compiler|intermediate representation|JIT|LLVM|Rust|performance optimization,7,"This repository implements Weld, a compiler/runtime system designed to speed up data analytics applications by representing computations in a common IR and applying cross-library optimizations before JIT code generation. It is directly relevant to ML/data workflows because it targets the performance bottlenecks common in analytical pipelines that chain operations across libraries (e.g., array/dataframe-style workloads). However, it is not itself an ML framework or modeling library; it is infrastructure that can accelerate ML-adjacent data processing and could be integrated into ML stacks, which fits a moderately relevant (7/10) score rather than a core ML toolkit.",success
https://github.com/cheshire-cat-ai/core,core,"Cheshire Cat AI Core is an API-first, Dockerized AI-agent microservice for building custom conversational agents. It provides a REST/WebSocket interface, an admin panel, built-in RAG (with Qdrant), and an extensible plugin system with hooks/tools/forms, supporting multiple LLM backends via LangChain.",2900,ai-agents|llm|rag|langchain|vector-database|qdrant|docker|plugin-framework,7,"This repository provides the core service/framework for running and extending an LLM-based agent (API-first microservice with WebSocket/REST, admin UI, plugins, and built-in RAG using a vector database like Qdrant). It’s relevant to ML/data workflows because it operationalizes common applied-ML components (LLM orchestration via LangChain, embeddings + retrieval, document ingestion/memory, tool/function calling) in a deployable service. It’s not a model-training library or data-science toolkit, but it is directly useful for building ML-powered applications and RAG systems, which merits a moderately high score rather than a top-tier one.",success
https://github.com/holoviz/holoviews,holoviews,"HoloViews is an open-source Python library for data analysis and visualization that emphasizes declaring/annotating data rather than manually crafting plots, letting the library generate appropriate visualizations with minimal code. It integrates well with interactive workflows such as Jupyter Notebook/JupyterLab and the broader HoloViz ecosystem.",2900,python|data-visualization|interactive-visualization|jupyter|scientific-computing|data-analysis|holoviz,7,"This repository provides HoloViews, a high-level Python visualization library designed to streamline exploratory data analysis by letting users express visual intent with concise, data-centric code rather than low-level plotting calls. It is directly useful in data science workflows for EDA, communicating results, and building interactive visual analytics (especially in notebooks), but it is not itself an ML training/inference framework. Given its strong adoption in the Python data ecosystem and clear utility for analyzing and presenting ML/data outputs, it merits a moderately high (but not core-ML) score.",success
https://github.com/jbesomi/texthero,texthero,"Texthero is a Python library built on top of pandas to quickly preprocess/clean text, transform text into vector representations (e.g., TF-IDF), run classic analysis steps like clustering and dimensionality reduction, and visualize text/vector-space results for rapid exploratory NLP.",2900,python|nlp|text-preprocessing|pandas|tf-idf|clustering|dimensionality-reduction|data-visualization,7,"This repository provides a pandas-centric toolkit for common NLP data preparation and exploratory analysis tasks, including cleaning pipelines, text vectorization (e.g., TF-IDF), clustering (e.g., K-means/DBSCAN/Meanshift), dimensionality reduction (e.g., PCA/t-SNE/NMF), and visualization. It is directly applicable in many data science workflows as a convenient layer over standard NLP/ML libraries (e.g., spaCy/scikit-learn), especially for quick EDA on text datasets. It’s not a model-training framework, but it meaningfully accelerates typical ML preprocessing and analysis steps for text, which justifies a moderately high score rather than a top-tier one.",success
https://github.com/mpquant/Ashare,Ashare,"A lightweight, single-file Python API for fetching China A-share (沪深) stock market data (daily/weekly/monthly and intraday minute bars) from public sources (Sina Finance and Tencent), with automatic failover and outputs cleaned into pandas DataFrames for quantitative research and trading workflows.",2900,quantitative-finance|financial-data|stock-market-data|china-a-shares|python|pandas|time-series,7,"This repository primarily provides a practical data-access layer for A-share market price time series (historical and intraday) and returns data in pandas DataFrame format, which is directly useful for data science tasks like feature engineering, backtesting, and building predictive models on price/volume data. It is not an ML framework itself (no model training, evaluation, or MLOps components), but it meaningfully reduces the effort to acquire and standardize financial time-series data, making it moderately valuable for ML/data workflows. Community adoption appears solid (thousands of GitHub stars), suggesting it’s a commonly used utility in its niche, which supports a higher score than generic utilities but below core ML tooling.",success
https://github.com/zhaipro/easy12306,easy12306,A Python project that uses machine learning/deep learning models to automatically recognize China Railway 12306 image captchas (text prompts + target images). It provides scripts and pretrained-model download links to run captcha recognition locally from an input image.,2900,captcha|computer-vision|deep-learning|image-classification|python|12306|security-automation,7,"This repository focuses on applying machine learning (including deep learning) to solve a practical computer-vision task: recognizing 12306 captchas using pretrained .h5 models and accompanying Python scripts. It is relevant to ML workflows because it demonstrates an end-to-end applied CV classification system (data/model usage, inference scripts, and supporting utilities), though it is specialized to a single captcha domain rather than being a general-purpose ML library. It has meaningful community adoption for its niche (thousands of stars) but limited integration with broader ML tooling beyond providing models and scripts, so a moderately-high score is appropriate rather than an 8–10.",success
https://github.com/GerevAI/gerev,gerev,"Gerev is an AI-powered enterprise/workplace search engine for organizations that indexes internal knowledge sources (e.g., Slack, Confluence, Jira, Google Drive) and enables natural-language/semantic search across them. It supports self-hosting via Docker and community-contributed connectors for additional data sources.",2800,enterprise-search|semantic-search|vector-search|rag|llama-index|integrations|docker|helpdesk,7,"This repository provides an AI-powered enterprise search engine that connects to common workplace systems (Slack/Confluence/Jira/Drive, etc.) and enables natural-language and semantic (vector) search across indexed content. It is relevant to ML/data workflows primarily as an applied retrieval/semantic-search (RAG-adjacent) system rather than a general-purpose ML library, making it useful for ML engineers building internal knowledge assistants and search experiences. Its GitHub topics and feature set indicate direct use of ML/AI concepts (semantic similarity/vector search, LLM tooling such as LlamaIndex) and it has meaningful community traction (about 2.8k stars), but it is not a foundational ML framework—hence a 7/10 rather than 9–10.",success
https://github.com/Tencent/AI-Infra-Guard,AI-Infra-Guard,"A.I.G (AI-Infra-Guard) is an AI red teaming platform from Tencent Zhuque Lab for security self-assessment of AI systems. It integrates AI infrastructure vulnerability scanning, MCP server risk scanning, and jailbreak evaluation via a web interface and Docker-based deployment.",2800,AI security|red teaming|LLM security|jailbreak evaluation|MCP security|vulnerability scanning|DevSecOps|Docker,7,"This repository primarily provides an AI security/red-teaming platform, including capabilities like AI infra vulnerability scanning, MCP server risk scanning, and jailbreak evaluation, packaged for practical deployment (e.g., via Docker) and use through a web UI. It is directly applicable to ML/LLM workflows for evaluating and hardening model- and agent-based systems, but it is not a general-purpose ML training/inference framework or data-processing library. Community adoption appears solid (about 2.8k GitHub stars), suggesting real-world interest and utility, but its scope is specialized to AI security testing rather than broad ML development.",success
https://github.com/TobikoData/sqlmesh,sqlmesh,"SQLMesh is a next-generation data transformation framework for building, testing, and deploying SQL/Python-based transformations with strong visibility into change impact (lineage/plan) and safe rollout via virtual data environments. It is designed to be efficient (incremental computation, avoiding unnecessary rebuilds) and is backwards compatible with dbt projects.",2800,data engineering|data transformation|ELT|DataOps|dbt|SQL|Python,7,"SQLMesh is primarily a data engineering / transformation and deployment framework (an ELT/DataOps tool) rather than an ML training library, but it directly supports the upstream work required for ML and analytics: building reliable, tested datasets and managing changes safely. Its features like plan/apply workflows, lineage/impact analysis, unit tests/audits, and virtual data environments make it highly applicable for producing and maintaining feature tables and training datasets. Community adoption appears meaningful (2.8k stars, active releases), but its core focus is transformation orchestration rather than modeling, which keeps it below dedicated ML/MLOps frameworks.",success
https://github.com/go-ego/gse,gse,"GSE is a Go (Golang) library for efficient multilingual NLP-focused text segmentation/tokenization (notably Chinese/Japanese/English), offering multiple segmentation modes, dictionary support, POS tagging utilities, and integrations for search engines like Elasticsearch and Bleve.",2800,nlp|text-segmentation|tokenization|golang|chinese-word-segmentation|search|information-retrieval,7,"This repository primarily provides fast, production-oriented multilingual tokenization/word-segmentation in Go (including dictionary-based and HMM-based segmentation approaches), plus features like user dictionaries and POS-related utilities. Tokenization/segmentation is a foundational preprocessing step in many ML and data science NLP workflows (e.g., feature extraction, indexing, retrieval, and preparing text for modeling), so it is directly useful even though it is not a full ML training framework. It appears geared toward practical NLP and search integration (e.g., Elasticsearch/Bleve), which increases its applied value for data pipelines and IR/NLP systems, but it does not provide broad model training/evaluation tooling—hence a moderately high score rather than a top-tier ML framework score.",success
https://github.com/pmorissette/bt,bt,bt is a flexible Python backtesting framework for quantitative trading strategies. It supports modular strategy construction via an algorithm/strategy tree approach and includes reporting/statistics utilities for comparing backtest results.,2800,python|quantitative-finance|algorithmic-trading|backtesting|portfolio-analysis|time-series|data-science,7,"This repository provides a Python framework for backtesting quantitative trading strategies, including composable strategy logic (algo stacks / tree structure) and performance statistics/reporting. While it is not an ML framework, it is directly useful in data science workflows for financial research, feature/signal experimentation, and evaluating ML-driven or rule-based trading signals in historical simulations. It also benefits from the broader Python data ecosystem (e.g., pandas-centric workflows) and has substantial community adoption for systematic trading use cases, warranting a moderately high score.",success
https://github.com/saharmor/dalle-playground,dalle-playground,"A web-based text-to-image playground that lets users generate images from prompts using Stable Diffusion v2 (previously DALL-E Mini). It includes a backend image-generation server and a frontend UI, with options to run via Colab, locally, or with Docker Compose.",2800,text-to-image|stable-diffusion|generative-ai|machine-learning|diffusion-models|web-app|docker,7,"This repository provides an end-to-end application (backend + frontend) for running and interacting with a text-to-image model (Stable Diffusion v2), including deployment options like Colab and Docker. It is directly useful for ML practitioners who want a ready-made UI/server wrapper around a diffusion model for experimentation, demos, and lightweight prototyping, rather than for training models or building data pipelines. Community adoption appears solid (around 2.8k stars), and it has practical educational value for understanding how to operationalize and serve generative models, but it is not a core ML framework or widely used MLOps/training toolkit, so it scores below the highest tier.",success
https://github.com/MakieOrg/Makie.jl,Makie.jl,"Makie.jl is an interactive data visualization and plotting ecosystem for the Julia programming language. It supports multiple rendering backends (e.g., OpenGL, WebGL, Cairo, raytracing) for interactive exploration, GUI-like visual apps, and high-quality static/vector output.",2700,julia|data-visualization|plotting|scientific-visualization|interactive-graphics|opengl|webgl|raytracing,7,"This repository provides a high-performance plotting and visualization ecosystem for Julia, including interactive and static rendering via multiple backends (GLMakie, WGLMakie, CairoMakie, RPRMakie). It is directly useful in ML/data workflows for exploratory data analysis, visual diagnostics (e.g., feature distributions, embeddings, training curves), and publication-quality figures, but it is not an ML framework itself. Community adoption appears strong for Julia visualization (notably a sizable star count and active development), making it a solid, commonly applicable tool for data scientists working in Julia. The score is 7 (moderately relevant) because visualization is a key part of ML/data work, even though the repo’s primary purpose is graphics/plotting rather than modeling/training.",success
https://github.com/douban/dpark,dpark,"DPark is a Python implementation inspired by Apache Spark: a MapReduce-like distributed computing framework that provides an RDD-style API for iterative data processing and can run locally or on a Mesos cluster. It includes job execution, shuffling, and a web UI for DAG/stage visualization and debugging.",2700,data engineering|distributed computing|mapreduce|spark-like rdd|big data|apache mesos|python,7,"This repository implements a Spark-inspired distributed data-processing engine in Python (RDD-style transformations/actions, shuffle, and execution), aimed at large-scale batch/iterative computation rather than model training itself. It is directly useful in ML/data workflows as an ETL/feature-processing and distributed preprocessing layer, and it can integrate into pipelines that feed training systems. However, it is archived (read-only) and is not a mainstream modern ML platform compared with Spark + Python tooling today, which lowers adoption and practical value despite strong educational and systems-learning value.",success
https://github.com/f5/unovis,unovis,"Unovis is a modular, tree-shakable data visualization framework providing charts, maps, and network graphs with bindings for React, Angular, Svelte, Vue, Solid, and vanilla TypeScript/JavaScript. It emphasizes customizable visuals (including CSS variables) and component-level imports to keep bundle sizes small.",2700,data visualization|charts|TypeScript|React|Angular|Vue|Svelte|SolidJS,7,"This repository provides a front-end data visualization framework (charts, maps, graphs) with multiple UI framework integrations, making it directly useful for exploring, communicating, and monitoring data. While it is not an ML framework and does not target model training/inference, it is highly applicable to ML/data workflows for building dashboards, experiment tracking UIs, and analytical visualizations. Community adoption appears solid (thousands of GitHub stars) and the project includes extensive documentation and examples, supporting practical and educational use in data-centric applications.",success
https://github.com/mljs/ml,ml,"A JavaScript machine-learning toolkit (ml.js) that bundles many ML, statistics, optimization, and linear-algebra utilities from the mljs organization into a single library, primarily aimed at browser usage. It exposes algorithms like PCA, k-means, hierarchical clustering, Naive Bayes, KNN, decision trees/random forests, regression models, cross-validation, and matrix decompositions via a unified API.",2700,javascript|machine-learning|data-science|browser|statistics|linear-algebra|clustering|classification,7,"This repository provides a broad collection of classical machine-learning and statistical tools in JavaScript (including clustering, classification, regression, dimensionality reduction, cross-validation, and matrix operations), packaged for convenient use—especially in the browser. It can be directly useful for ML/data workflows when you need lightweight, classical ML in JS (e.g., client-side analytics, education, prototyping, or Node/browser experimentation), but it is not a full deep-learning framework and is less central in mainstream production ML stacks than Python/R ecosystems. Community adoption appears solid for the JS ML niche (thousands of GitHub stars), supporting a moderately high score rather than a top-tier, industry-standard score.",success
https://github.com/plotly/plotly.R,plotly.R,"The source repository for the Plotly R package, which creates interactive web-based data visualizations in R using the open-source JavaScript library plotly.js. It supports converting ggplot2 graphics to interactive plots (via ggplotly) and building interactive charts directly (via plot_ly), with integrations for Shiny/R Markdown and advanced interactive features.",2700,r|data-visualization|interactive-visualization|plotly|ggplot2|shiny|r-markdown|javascript-integration,7,"This repository provides the Plotly R package for building interactive charts and dashboards, including converting ggplot2 plots to interactive visuals and directly constructing plotly.js-based visualizations. It is widely useful in data science workflows for exploratory data analysis, communicating results, and building interactive analytic apps (e.g., with Shiny), but it is not a modeling/training framework itself. Because visualization is a core part of ML/data work and the package is broadly adopted in the R ecosystem, it merits a moderately high score, though below core ML tooling like training libraries or MLOps platforms.",success
https://github.com/sightmachine/SimpleCV,SimpleCV,"SimpleCV is an open-source Python framework for machine vision/computer vision built on top of OpenCV, providing a more concise and beginner-friendly API for working with cameras, images/video, image manipulation, and feature extraction. The repository notes the project is no longer actively maintained and is provided as-is for legacy use.",2700,computer vision|image processing|machine vision|python|opencv|camera|feature extraction,7,"This repository provides a Python computer-vision framework (wrapping/leveraging OpenCV) aimed at making common vision tasks—camera I/O, image manipulation, and feature extraction—simpler and more approachable. It is relevant to ML/data workflows primarily as a preprocessing and classical-vision toolkit rather than a modern model-training framework. Its usefulness is reduced by the project’s stated lack of active maintenance, but it still has notable historical adoption and can be valuable for education or legacy CV pipelines.",success
https://github.com/thisandagain/sentiment,sentiment,"A Node.js sentiment analysis library that scores input text using the AFINN-165 word list and an emoji sentiment ranking. It supports extending/overriding lexicon entries and registering additional languages with custom scoring strategies (e.g., negation/emphasis handling).",2700,NLP|sentiment analysis|Node.js|JavaScript|lexicon-based|text analytics|emoji,7,"This repository provides a practical, production-oriented sentiment analysis tool for Node.js based on lexicon scoring (AFINN) plus emoji sentiment values, returning overall and comparative sentiment scores for text. It is directly usable in ML/data workflows for quick baseline sentiment features, lightweight text analytics, labeling heuristics, or preprocessing without training a model. However, it is not a model-training framework or modern ML method (e.g., transformer-based sentiment), and its accuracy/coverage is limited by the lexicon approach, which keeps it below the highest scores despite strong utility and adoption.",success
https://github.com/apachecn/fe4ml-zh,fe4ml-zh,"A Chinese translation and web-published version of the book “Feature Engineering for Machine Learning (Early Release)”, organized as browsable documentation with chapters on numeric, text, categorical, and image feature engineering. It also provides multiple ways to serve/read the docs locally (e.g., Docker, PyPI, NPM).",2600,machine learning|feature engineering|book translation|documentation site|python|data preprocessing|educational,7,"This repository primarily hosts and publishes a Chinese translation of a feature engineering book, structured as documentation rather than a reusable ML library. It is strongly relevant to ML/data workflows because it teaches practical feature engineering techniques (numeric/text/categorical/image), which are directly applicable to model development. However, its direct integration potential is limited since it is mostly content and a doc-serving setup (Docker/PyPI/NPM) rather than a toolkit used programmatically in pipelines. Community adoption appears solid for an educational repo (about 2.6k GitHub stars), supporting a moderately-high score.",success
https://github.com/harleyszhang/cv_note,cv_note,"A Chinese-language knowledge base and study roadmap for computer vision (CV) algorithm engineers, covering fundamentals, ML/DL, CV tasks, model compression, and deployment, with accompanying interview notes and reference materials.",2600,computer vision|deep learning|machine learning|model compression|model deployment|interview preparation|technical notes,7,"This repository is primarily an educational collection of notes and a learning roadmap for CV/ML topics (e.g., machine learning, deep learning, detection/segmentation), plus interview prep materials, rather than a library/tool meant to be imported into ML pipelines. It is still moderately valuable to ML practitioners because it helps with conceptual learning and practical engineering areas like model compression and deployment, which are common in real ML workflows. Community adoption appears solid for a notes-style repo (about 2.6k GitHub stars), but it offers limited direct integration potential compared to code-heavy ML frameworks or tooling.",success
https://github.com/sahibzada-allahyar/YC-Killer,YC-Killer,"A collection of “enterprise-grade” AI agent projects (e.g., deep research, quant hedge fund, executive assistant, call center, hospital, tutor, accounting firm) intended as open-source alternatives to various startup-style AI products. The repo organizes multiple agent implementations under separate directories with their own setup instructions and focuses on deploying practical LLM-powered systems (often with Docker/cloud tooling).",2600,llm|ai-agents|agentic-workflows|deep-research|quant-trading|data-processing|typescript|docker,7,"This repository is primarily an AI-agents library containing multiple applied agent systems (not a single ML library), including a deep-research agent and an agentic quant hedge fund that explicitly mentions feature engineering, backtesting, and data processing components. It is relevant to ML/data workflows insofar as it provides end-to-end agentic applications that may integrate LLMs, data pipelines, and analytics/backtesting infrastructure, which can be adapted by ML engineers. However, it does not appear to be a foundational ML framework or widely adopted data-science library, and its value is more in applied examples/blueprints than in reusable core ML algorithms—hence a moderately high (but not top-tier) score.",success
https://github.com/danielbeach/data-engineering-practice,data-engineering-practice,"A collection of hands-on data engineering practice problems, organized as exercises that cover Python data processing, file formats (CSV/JSON/Parquet), SQL/Postgres schema design and ingestion, and tools like PySpark, DuckDB, Polars, and Great Expectations—typically run via Docker/docker-compose.",2500,data engineering|python|sql|postgresql|pyspark|docker|duckdb|data quality,7,"This repository is primarily an educational set of data engineering exercises focused on practical skills like ingestion, transformation, data modeling, and data quality checks, with environments packaged using Docker. It is highly relevant to data/ML workflows because these are core upstream steps for ML (preparing, validating, and moving data), and it includes commonly used tooling in the data ecosystem (e.g., PySpark, DuckDB, Polars, Great Expectations). However, it is not centered on building/training models or providing reusable ML libraries, and community adoption is moderate compared to major ML frameworks—so it’s best scored as a strong data-engineering learning resource rather than a core ML tool.",success
https://github.com/nteract/semiotic,semiotic,"Semiotic is a JavaScript data visualization framework that combines React and D3 to build interactive charts and visualizations (e.g., via components like XYFrame) for the web.",2500,data-visualization|react|d3|javascript|typescript|charting|frontend,7,"This repository provides a React + D3-based visualization framework intended for building interactive data graphics in web applications. While it is not an ML modeling/training library, it is directly useful in data science and ML workflows for exploratory data analysis dashboards, communicating model results, and building interactive visualization interfaces around datasets. Its focus on visualization (rather than computation) keeps it below core ML tooling, but its strong applicability to presenting and interrogating data justifies a moderately high score.",success
https://github.com/pmorissette/ffn,ffn,"ffn is a Python library of financial functions for quantitative finance workflows, providing utilities for performance measurement/analysis, portfolio and return calculations, data transformations, and graphing on top of Pandas/Numpy/Scipy.",2500,python|quantitative-finance|financial-analysis|portfolio-analytics|performance-metrics|pandas|time-series,7,"This repository provides a financial analytics utility library focused on return series, performance measurement/evaluation, portfolio calculations (e.g., weights/optimization-style helpers), and related transformations/visualizations. While it is not an ML model training framework, it is directly useful in data science workflows for finance (feature engineering, exploratory analysis, backtesting support, and reporting) and integrates naturally with core Python data tools like Pandas/Numpy. Its adoption (notably thousands of stars and hundreds of dependent repos) indicates meaningful community usage in quant-fin/data contexts. The score reflects strong relevance for financial data analysis, but not being a core ML library for modeling, training, or MLOps.",success
https://github.com/benedekrozemberczki/awesome-community-detection,awesome-community-detection,"A curated “awesome list” of community detection (graph clustering) research papers, organized by method category, with links to available implementations. It serves as a structured bibliography and entry point for practitioners and researchers working on network/community detection.",2422,community detection|graph clustering|network science|machine learning|unsupervised learning|graph mining|research papers|awesome-list,7,"This repository is primarily a curated index of community-detection research papers and code links rather than an ML library you run directly. It is still highly useful for ML/data workflows in graph analytics because it helps practitioners discover state-of-the-art methods (e.g., spectral approaches, factorization, deep learning, random-walk methods) and find corresponding implementations to adapt. Community adoption appears strong for an academic resource (thousands of stars), and its educational value is high for learning the landscape of graph clustering, but integration potential is indirect since it is not itself a toolkit or framework.",success
https://github.com/eddwebster/football_analytics,football_analytics,"A curated collection of football (soccer) analytics projects, datasets, tutorials, libraries, papers, and other learning resources maintained by Edd Webster. It also includes code/notebooks (Python and R) and supporting materials for analytics and visualization work.",2400,sports analytics|football (soccer)|data science|Python|R|Jupyter notebooks|data visualization,7,"This repository is primarily a football analytics resource hub, aggregating data sources, tutorials, libraries, and example projects, with additional Python/R code and notebooks. It is strongly relevant to data science workflows (data sourcing, analysis, visualization, and links to modeling concepts like xG and possession value frameworks), but it is not a single focused ML framework or production-grade ML tool. Community adoption appears solid (thousands of GitHub stars), and the educational value for sports-analytics-oriented ML/data practitioners is high, supporting a moderately high score rather than a top-tier ML tooling score.",success
https://github.com/jayinai/data-science-question-answer,data-science-question-answer,"A curated, community-oriented repository of data science interview questions and concise answers spanning SQL, tools/frameworks, statistics, and multiple ML subfields (supervised, unsupervised, RL, NLP, and systems). The README notes the repo is deprecated in favor of a newer resource (“Nailing Machine Learning Concepts”).",2400,data-science-interview|machine-learning|statistics|sql|nlp|spark|study-notes,7,"This repository primarily serves as an educational Q&A/cheat-sheet for data science practitioners, especially for interview prep and breadth-first review across SQL, statistics, and ML topics. It’s directly useful for learning and revising ML/data concepts, but it is not a software library, dataset, or workflow tool that integrates into production ML pipelines. Community adoption appears moderate-to-strong based on its GitHub star count, but the repo is explicitly marked as deprecated, which reduces its practical value as a living, maintained resource.",success
https://github.com/mpld3/mpld3,mpld3,"mpld3 is an interactive data visualization library that converts Matplotlib figures into web-ready interactive visualizations rendered in the browser using D3.js. It exports plots to a JSON representation and includes a JavaScript runtime plus a Python API and plugin system to add interactivity (e.g., tooltips, linked brushing).",2400,data-visualization|matplotlib|d3.js|python|javascript|interactive-plots|jupyter-notebook,7,"This repository primarily provides tooling to turn Matplotlib charts into interactive, browser-based visualizations via a Python exporter and a D3.js-based JavaScript renderer. It is directly useful in data science workflows for communicating results, building exploratory visualizations, and embedding interactive plots in notebooks or web pages, but it is not an ML framework or modeling library itself. The score reflects strong relevance to data analysis and reporting (visualization is a core DS need) and reasonable adoption, while being indirect with respect to model training, feature engineering, or MLOps.",success
https://github.com/apache/gobblin,gobblin,"Apache Gobblin is a distributed data integration and data management framework for building scalable batch and streaming pipelines. It focuses on data ingestion/replication into and across data lakes, plus data organization and lifecycle/compliance management.",2300,data-engineering|data-integration|etl-elt|data-ingestion|data-lake|streaming|batch-processing|java,7,"This repository provides a production-grade framework for large-scale data ingestion, replication, and data-lake management (including organization, retention, and compliance workflows) across batch and streaming ecosystems. While it is not an ML training library, it is directly useful for ML/data workflows because it helps build and operate the upstream data pipelines that feed feature stores, warehouses, and model training datasets. Its value is strongest for data engineers/ML platform teams (integration potential and operational features), but lower for pure modeling tasks, which is why it scores as moderately relevant rather than core ML.",success
https://github.com/apache/kyuubi,apache/kyuubi,"Apache Kyuubi is a distributed, multi-tenant gateway server that provides serverless SQL access to data warehouses/lakehouses via a Thrift JDBC/ODBC interface. It primarily acts like a HiveServer2-style SQL gateway with resource isolation, security, and high-concurrency support, commonly backed by Spark SQL engines.",2300,data engineering|spark|sql|jdbc|odbc|lakehouse|multi-tenancy|distributed-systems,7,"This repository implements Apache Kyuubi, a server-side SQL gateway (HiveServer2-like) that exposes JDBC/ODBC endpoints and manages multi-tenant, serverless-style execution over big-data engines (notably Spark SQL). It is not an ML framework, but it is highly relevant to ML/data workflows because it simplifies and operationalizes access to large-scale datasets used for feature engineering, analytics, and exploratory data work through standard SQL and BI/DS tooling. The score reflects strong applicability and integration potential in data platforms (especially Spark/lakehouse environments), but limited direct coverage of model training/inference or MLOps-specific capabilities. ",success
https://github.com/malloydata/malloy,malloy,"Malloy is an open-source analytical language for describing data relationships, transformations, and a reusable semantic model that compiles queries to SQL for execution on supported databases. The repo includes the core language/tooling plus a VS Code extension for authoring models, running queries, and basic visualization/dashboarding.",2300,analytics language|semantic modeling|SQL|data modeling|data transformation|business intelligence|TypeScript|VS Code extension,7,"This repository provides Malloy, a semantic modeling + query language that compiles to SQL and targets common analytics backends (e.g., BigQuery, Snowflake, Postgres, MySQL/Trino/Presto, and DuckDB), along with a VS Code extension to develop and run Malloy. It is not an ML training framework, but it is directly useful in ML/data workflows for data exploration, feature/metric definition, reusable transformations, and producing analysis-ready datasets on SQL engines. Its applicability is strongest for analytics engineering and data science SQL-based exploration/modeling, which warrants a moderately high (but not core-ML) score.",success
https://github.com/meltano/meltano,meltano,"Meltano is a declarative, code-first data integration engine for building and running ELT/ETL pipelines using a plugin ecosystem (including Singer taps and targets). It helps teams discover, configure, and orchestrate connectors and data workflows without maintaining bespoke API integrations.",2300,data engineering|ELT|ETL|data pipelines|data integration|Singer|DataOps|Python,7,"This repository provides a data integration and orchestration engine (Meltano) focused on extracting/loading data across many sources via plugins (not an ML modeling library). It is highly useful in ML/data workflows as a foundation for dataset ingestion, pipeline automation, and operationalizing data movement into warehouses/lakes that ML systems depend on. Its value is strongest for data engineering and platform work that supports ML rather than training/inference itself, so it scores solidly but below core ML frameworks.",success
https://github.com/pingcap/ossinsight,ossinsight,"OSS Insight is an open-source analytics platform for exploring and visualizing GitHub open-source trends, rankings, and repository/developer metrics. It also provides a GPT-powered “Data Explorer” that turns natural-language questions into SQL queries over a multi-billion-row GitHub events dataset and returns visualized results.",2300,open-source-analytics|data-visualization|github-data|data-engineering|natural-language-to-sql|LLM-powered-analytics|web-application,7,"This repository powers OSS Insight, a data analytics product built around large-scale GitHub events data (ETL + querying + visualization) and includes a natural-language-to-SQL workflow (GPT-powered Data Explorer) for interactive analysis. It is not an ML framework for model training, but it is directly useful for data science/engineering workflows involving analytics over big datasets, metric computation, and building LLM-assisted BI/query experiences. Because its core value is data analytics infrastructure and an LLM-enabled query interface (rather than general-purpose ML), it rates as moderately relevant for ML/data use cases.",success
https://github.com/sodadata/soda-core,soda-core,"Soda Core is an open-source CLI tool and Python library for data quality testing on SQL-, Spark-, and Pandas-accessible datasets using Soda Checks Language (SodaCL). It runs scans that translate checks into queries to detect invalid, missing, duplicate, or otherwise unexpected data and report failures back to your workflow.",2300,data quality|data validation|data engineering|data testing|data observability|python|spark|sql,7,"This repository provides a practical data quality testing framework (CLI + Python library) that data teams can integrate into pipelines to validate datasets and catch issues like missing/invalid/duplicate values before downstream use. While it is not an ML framework, it is directly relevant to ML and analytics workflows because reliable training/feature data quality is a prerequisite for trustworthy models and metrics, and Soda Core can be used as automated gates in ETL/ELT and feature pipelines. It appears to have meaningful adoption (thousands of GitHub stars and frequent releases), increasing its utility and integration potential for data/ML teams. The score is not higher because it focuses on data quality and checks rather than model training, experimentation, or MLOps for models.",success
https://github.com/zasper-io/zasper,zasper,"Zasper is a high-performance IDE for working with Jupyter notebooks, built to support massive concurrency with low CPU/RAM usage. It implements Jupyter’s wire protocol and runs as both a web app and a desktop app, supporting many Jupyter kernels (Python/Conda, R, Julia, Ruby, JavaScript/Deno, Go, and others).",2300,jupyter|data-science-ide|interactive-computing|notebooks|golang|developer-tools|concurrency|jupyter-kernels,7,"This repository provides an IDE specifically aimed at data science workflows centered on Jupyter notebooks, emphasizing performance, low resource usage, and handling many concurrent connections. It is directly applicable to ML/data work because it improves the core environment many practitioners use for exploratory analysis, prototyping, and running notebooks across multiple kernels/environments. However, it is not an ML library/framework or data-processing engine itself, and community adoption appears meaningful but not on the level of core ML/data ecosystem projects, so a strong-but-not-core score is appropriate.",success
https://github.com/24mlight/A_Share_investment_Agent,A_Share_investment_Agent,"A proof-of-concept AI investing system for China's A-share market that uses a multi-agent workflow (bull/bear researchers, analysts, and a debate-room mechanism) enhanced by LLMs to collect information, analyze news/market signals, and produce structured investment-oriented outputs (educational/research only). It includes CLI-based stock analysis plus an experimental backtesting workflow and upgraded multi-source finance news retrieval with caching/deduplication.",2200,llm|multi-agent|algorithmic-trading|finance|sentiment-analysis|backtesting|python,7,"This repository implements an LLM-driven, multi-agent research/debate pipeline for stock analysis in the A-share market, including CLI tools and a (testing/experimental) backtester, plus a news ingestion component that aggregates from multiple finance sources with caching and deduplication. It is relevant to ML/data workflows because it operationalizes LLM reasoning, sentiment/news analysis inputs, and evaluation via backtesting, which are common in applied DS for finance. However, it is not a general-purpose ML library nor a broadly adopted framework, and the core value is as a reference implementation/proof-of-concept rather than a reusable dataset/model-training toolkit, which limits its score.",success
https://github.com/AGI-Edgerunners/LLM-Agents-Papers,LLM-Agents-Papers,"A curated repository that collects and categorizes research papers related to LLM-based agents (e.g., planning, memory, reflection, RAG, tool use, multi-agent systems, benchmarks, safety). It also includes JSON files and scripts to maintain/parse the paper list and optionally download PDFs.",2200,llm-agents|literature-review|paper-list|natural-language-processing|multi-agent-systems|rag|ai-safety|benchmarks-evaluation,7,"This repository is primarily a curated paper list for LLM-based agent research, organized into many subtopics (planning, memory, tool use, evaluation, safety, etc.) and updated over time, with supporting JSON artifacts and maintenance scripts. It is directly useful for ML practitioners and researchers for literature discovery, tracking, and structured metadata (e.g., papers_v5.json), but it is not itself a model-training or data-processing framework. Its value is therefore strong educational and research-workflow support rather than production ML tooling, which supports a moderately high score.",success
https://github.com/IndrajeetPatil/ggstatsplot,ggstatsplot,"An R package that extends ggplot2 to produce information-rich visualizations with embedded statistical test results (e.g., p-values, effect sizes, Bayes factors) for common analyses such as group comparisons, correlations, regressions, contingency tables, and meta-analysis.",2200,r|ggplot2|data-visualization|statistics|exploratory-data-analysis|bayesian|effect-sizes,7,"ggstatsplot is primarily a statistical visualization toolkit for R that combines exploratory plots with results from statistical tests (parametric, nonparametric, robust, and Bayesian) directly in the graphics. It is highly usable in data science workflows for EDA, reporting, and communicating analysis outcomes, even though it is not an ML model training or MLOps framework. Its strong adoption in the R/data community (notably ~2.2k GitHub stars) and broad coverage of common statistical analyses make it a solid, moderately-to-highly relevant data-science library rather than a core ML framework.",success
https://github.com/davidgasquez/awesome-duckdb,awesome-duckdb,"A curated “awesome list” collecting DuckDB-related resources, including client APIs, tools powered by DuckDB, extensions, integrations, tutorials, and media to help users discover and adopt the DuckDB ecosystem.",2200,duckdb|data-engineering|analytics|sql|database|awesome-list|data-tools,7,"This repository is an ecosystem directory: it aggregates links to DuckDB libraries, tools, extensions, integrations, and learning resources rather than providing a single executable ML package. It is strongly relevant to data/ML workflows because DuckDB is widely used for local analytics, feature extraction, dataset inspection, and working with Parquet/CSV in notebooks and pipelines; the list helps practitioners find clients and tooling to integrate DuckDB into their stack. The score is 7 (moderately relevant) because it’s highly useful for data science enablement and education, but it does not itself implement ML algorithms, model training, or MLOps components.",success
https://github.com/peerchemist/finta,finta,"FinTA (finta) is a Python/Pandas library that implements 80+ common financial technical analysis indicators (e.g., moving averages, RSI, MACD, Bollinger Bands) designed to operate on OHLC/OHLCV market data in a Pandas DataFrame.",2200,python|pandas|technical-analysis|quantitative-finance|trading-indicators|feature-engineering|time-series,7,"This repository provides a collection of technical indicator functions implemented in Pandas, primarily for quantitative finance and trading analysis, taking OHLC/OHLCV time-series data as input. It’s not an ML framework itself, but it is directly useful for ML/data science workflows as a feature-engineering toolkit for financial time-series modeling and backtesting pipelines. Community adoption is solid (about 2.2k GitHub stars) and the indicator coverage is broad, but the repository is archived/read-only (archived Sep 2, 2022), which limits ongoing maintenance and modern integration compared to actively maintained alternatives.",success
https://github.com/pinterest/querybook,querybook,"Querybook is Pinterest’s open-source big data IDE that provides a notebook-style interface (DataDocs) for composing SQL queries, documenting analyses, collaborating in real time, and building visualizations/dashboards. It integrates with multiple query engines and data platforms and is commonly deployed via Docker (and optionally Kubernetes).",2200,data analytics|sql|data engineering|notebooks|business intelligence|data visualization|big data|data collaboration,7,"This repository provides a collaborative, notebook-like big data querying and analysis UI (DataDocs) focused on writing SQL, exploring datasets/metadata, and sharing analyses and dashboards. While it is not an ML framework, it is directly useful in data science workflows for data discovery, exploratory analysis, and producing query-driven visualizations before/alongside model building. Its broad integrations with common query engines and cloud/result-storage options make it practical infrastructure for analytics teams, justifying a moderately high (but not core-ML) score.",success
https://github.com/vaaaaanquish/Awesome-Rust-MachineLearning,Awesome-Rust-MachineLearning,"A curated “awesome list” of machine learning and data-science resources in Rust, aggregating libraries and tools (e.g., dataframes, plotting, NLP, GPU, deep learning) plus references like blogs, books, papers, and discussions. It targets practitioners interested in using Rust for ML, including those migrating from Python.",2200,rust|machine learning|awesome-list|data science|deep learning|nlp|dataframe,7,"This repository primarily serves as a curated index of Rust ML/data-science libraries and learning resources rather than providing a single ML framework or production tool. It is directly useful to ML engineers and data scientists exploring Rust because it organizes the ecosystem across practical workflow areas (e.g., notebooks, plotting, dataframes, NLP, GPU, deep learning) and includes educational references. However, its community adoption is mostly reflected as a reference/curation hub (not an executable library), so it scores below core ML tooling while still offering strong discovery and educational value.",success
https://github.com/wooey/Wooey,Wooey,"Wooey is a Django app that automatically generates web user interfaces for running command-line Python scripts, making it easy to share and operationalize scripts for routine data analysis, file processing, and similar workflows. It focuses on letting non-command-line users run scripts via a browser while helping document and standardize analyst workflows.",2200,python|django|data-science|web-ui|workflow-automation|cli-tools|data-analysis,7,"Wooey’s primary purpose is to wrap Python command-line scripts with an auto-generated web UI, enabling repeatable execution and sharing of analysis and processing workflows in a browser. This is moderately to highly relevant for data/ML teams because it can help operationalize data cleaning, feature generation, batch scoring, and internal analyst tools without building custom frontends. While it is not an ML library or training framework, it can be directly useful as lightweight workflow/UI infrastructure around existing ML/data scripts, and it has visible community adoption (~2.2k stars).",success
https://github.com/Esri/arcgis-python-api,arcgis-python-api,"Documentation and sample notebooks for the ArcGIS API for Python, a Python library for working with maps and geospatial data via Web GIS. It covers GIS administration plus spatial analysis workflows including vector/raster analytics, geocoding, routing, and deep learning integrations commonly used in Jupyter-based data science.",2100,gis|geospatial|arcgis|python|data-science|jupyter-notebooks|spatial-analysis|deep-learning,7,"This repository primarily provides documentation and Jupyter notebook samples for the ArcGIS API for Python, focusing on geospatial data access, mapping, and GIS management workflows rather than being a standalone ML framework. It is strongly relevant to data science because it supports spatial data analysis and integrates with common Python DS/ML tooling (e.g., Pandas and popular ML libraries) and includes deep learning-related geospatial workflows. The score reflects high practical value for geospatial data science/ML engineers, but a narrower scope and adoption compared to general-purpose ML libraries (it is most valuable within the ArcGIS ecosystem).",success
https://github.com/MarquezProject/marquez,marquez,"Marquez is an open-source metadata service that collects, aggregates, and visualizes dataset/job/run metadata and data lineage (provenance) across a data ecosystem. It provides an OpenLineage-compatible API backend plus a web UI for exploring lineage graphs, runtimes, and operational metadata.",2100,data lineage|metadata management|OpenLineage|data engineering|data observability|data governance|MLOps,7,"This repository implements Marquez, a metadata and lineage platform (API server + UI) used to capture how datasets are produced/consumed and to visualize pipeline dependencies, typically via OpenLineage events. While it is not an ML modeling library, it is directly useful to ML/data teams for tracking lineage of training/feature datasets and operational runs across orchestration and processing tools (e.g., Airflow/Spark/dbt integrations via OpenLineage). It has meaningful adoption signals (e.g., ~2.1k GitHub stars) and solid educational value for understanding lineage/metadata systems, but it is infrastructure/observability rather than core ML, so it scores below dedicated ML frameworks.",success
https://github.com/mara/mara-pipelines,mara-pipelines,"Mara Pipelines is an opinionated, lightweight Python framework for building and running ELT/ETL-style data transformation pipelines as code, with PostgreSQL as the processing engine and a strong focus on transparency. It includes CLI execution as well as an extensive web UI for inspecting, debugging, and running pipelines, using make-like dependency semantics and single-machine multiprocessing execution.",2100,data-engineering|etl|elt|data-pipelines|python|postgresql|workflow-orchestration|flask,7,"This repository provides a data pipeline/orchestration framework aimed at building transparent ETL/ELT-style transformation workflows in Python, commonly used in analytics engineering and data warehousing. While it is not an ML framework, it is directly useful in ML/data workflows for building repeatable ingestion/transformation steps and operationalizing feature/data preparation jobs, especially in Postgres-centric stacks. Community adoption appears moderate (about 2.1k GitHub stars), suggesting real-world usage but not ubiquitous ML-standard status; overall it’s solidly relevant infrastructure for data work rather than core ML modeling.",success
https://github.com/neuropsychology/NeuroKit,NeuroKit,"NeuroKit2 is a Python toolbox for neurophysiological (biosignal) processing, providing user-friendly routines to preprocess signals (e.g., filtering, peak detection) and compute analysis features from physiological data such as ECG, respiration (RSP), and electrodermal activity (EDA). It aims to make advanced biosignal analysis accessible to researchers and clinicians with minimal code.",2100,python|biosignal-processing|neurophysiology|ecg|eda|time-series|signal-processing|feature-extraction,7,"This repository provides a mature Python library focused on preprocessing and analyzing physiological time-series signals (e.g., ECG/RSP/EDA), including peak detection, cleaning pipelines, and feature extraction that are directly useful for data analysis workflows. While it is not primarily a model-training framework, it is highly relevant for ML/data pipelines because it produces cleaned signals and engineered features that commonly feed downstream statistical modeling and machine learning tasks. Its strong documentation, packaged distribution (PyPI/conda), and visible community adoption (stars/forks) support a moderately high score, but it stops short of being a core ML framework, so a 7 is appropriate.",success
https://github.com/tylermorganwall/rayshader,rayshader,"An R package for producing 2D and 3D maps and data visualizations, especially terrain/elevation-based scenes using hillshading and raytracing. It supports interactive viewing, scripted camera animations, high-quality path-traced rendering (via rayrender), and exporting 3D models (e.g., STL/OBJ).",2100,R|data-visualization|3D-graphics|geospatial|cartography|terrain-rendering|ggplot2,7,"rayshader is primarily a data visualization and mapping library for R, focused on rendering elevation/terrain matrices and converting ggplot2 plots into 3D scenes. It is not an ML framework, but it is directly useful in data science workflows for exploratory analysis and communicating results (especially for spatial/remote-sensing, earth science, and any dataset that benefits from 3D rendering). Its sizeable GitHub adoption and rich rendering/animation/export features make it a strong supporting tool for ML/data projects, hence a moderately high (but not core-ML) score.",success
https://github.com/ujjwalkarn/DataScienceR,DataScienceR,"A curated collection of R tutorials, packages, and reference links for data science tasks, including NLP and machine learning. It serves primarily as a learning/resource hub rather than a single installable software library.",2100,R|data science|machine learning|NLP|tutorials|curated resources|statistics,7,"This repository is a curated directory of learning materials and references for doing data science, NLP, and machine learning in R, with links organized by topic and some example scripts/files. It is directly relevant to ML/data workflows as an educational and reference resource, but it is not a cohesive toolkit/library for building pipelines or training models. Community adoption appears solid for a resource list (about 2.1k stars), which supports its usefulness, but its integration potential is limited because it mainly aggregates external links rather than providing reusable code.",success
https://github.com/chris1610/pbpython,pbpython,"A collection of code, datasets, and Jupyter notebooks that accompany articles and tutorials from Practical Business Python (pbpython.com), focused on real-world business analytics with Python. It includes examples for working with Excel/data analysis, visualization, and some applied machine learning.",2000,python|pandas|jupyter-notebook|data-analysis|data-visualization|scikit-learn|excel-automation|tutorials,7,"This repository primarily serves as an educational/example companion to Practical Business Python, consisting largely of Jupyter notebooks and supporting data that demonstrate practical data analysis workflows (notably with pandas) and reporting/Excel-adjacent tasks. It is clearly relevant to data science work because it teaches common data wrangling, analysis, and visualization patterns used in day-to-day analytics, and it also includes scikit-learn among its stated topics. However, it is not a dedicated ML framework or production ML tool; its value is strongest for learning and reusable examples rather than end-to-end model development/MLOps, so it rates as moderately-to-highly relevant rather than core-ML.",success
https://github.com/cuemacro/findatapy,findatapy,"findatapy is a Python library that provides a unified API for downloading and managing financial/market data from multiple providers (eg, Bloomberg, Eikon, ALFRED/FRED, Yahoo, Quandl, Dukascopy). It supports configurable/custom tickers and includes utilities like FX cross construction and optional Redis-based caching for repeated data requests.",2000,financial-data|market-data|quant-finance|data-ingestion|time-series|python|pandas|bloomberg,7,"This repository’s primary purpose is financial market data acquisition/normalization: it offers a consistent interface to pull time-series (and some tick/intraday) data from multiple vendors and manage configuration for tickers and sources. That makes it directly useful in ML/data workflows as an ingestion layer for building datasets, feature engineering pipelines, backtesting inputs, and research notebooks, especially in quantitative finance. It is not an ML modeling framework itself, but it provides practical integration points (pandas/numpy outputs, caching, multiple vendor connectors) that are commonly needed before model training, justifying a moderately high relevance score.",success
https://github.com/thomasp85/gganimate,gganimate,"An R package that extends ggplot2’s Grammar of Graphics to support animations, letting you define how plots transition over time (e.g., transitions, views, shadows, and enter/exit effects) and then render them into animated outputs such as GIFs.",2000,r|data-visualization|ggplot2|animation|statistics|data-science|graphics,7,"gganimate is primarily a data visualization library for R that enables animated graphics by extending ggplot2 with animation-specific components like transition_*(), view_*(), shadow_*(), and enter_*/exit_*() layers. While it is not an ML framework or modeling toolkit, it is directly useful in ML/data workflows for exploratory data analysis, communicating model behavior over time (e.g., training dynamics, temporal predictions), and presenting results. It has strong adoption in the R data science ecosystem (notably via ggplot2 integration and CRAN availability), which increases its practical value to data practitioners. The score reflects high relevance for data science communication and EDA, but limited direct applicability to model training, inference, or MLOps.",success
https://github.com/vizzuhq/vizzu-lib,vizzu-lib,"Vizzu is an open-source JavaScript/C++ library (C++ compiled to WebAssembly) for creating animated data visualizations that smoothly transition between chart types, enabling data storytelling and interactive chart explorers. It provides defaults based on dataviz guidelines, supports aggregation/filtering, and renders to an HTML5 canvas with no runtime dependencies.",2000,data-visualization|animated-charts|data-storytelling|javascript|webassembly|charting-library|dashboarding,7,"This repository provides a charting/data-visualization engine focused on animated transitions between chart states, primarily for communicating and exploring data in web contexts. While it is not an ML framework or data-processing library, it is directly useful in data science workflows for exploratory analysis and for presenting model/data results via compelling animated narratives. Its relevance is strengthened by its ability to integrate with typical DS outputs (e.g., aggregated/tabular data) and by its visible community adoption (about 2k GitHub stars).",success
https://github.com/AlexIoannides/pyspark-example-project,pyspark-example-project,"An example PySpark ETL project that demonstrates best practices for structuring Spark jobs, managing configuration and dependencies, and writing meaningful automated tests. It includes a recommended folder layout (configs/jobs/dependencies/tests) and guidance for running with spark-submit and local development/debugging.",1923,pyspark|apache-spark|etl|data-engineering|data-pipelines|python|testing,7,"This repository is primarily a reference implementation for building and testing PySpark-based ETL jobs (project layout, dependency packaging, configuration handling, and unit testing patterns). It is strongly relevant to data engineering workflows and is commonly adjacent to ML workflows because Spark ETL is often used to prepare features and training data, but it does not focus on model training or ML algorithms. The relatively high star count suggests meaningful community adoption as an educational/template resource, which supports a score in the moderately relevant range rather than a core ML-tool score.",success
https://github.com/GiovineItalia/Gadfly.jl,Gadfly.jl,"Gadfly is a plotting and data visualization system written in Julia, inspired by the Grammar of Graphics (similar in spirit to ggplot2). It produces publication-quality graphics (SVG/PNG/PS/PDF), integrates with DataFrames.jl, and supports notebook workflows (IJulia/Pluto) with interactive features.",1900,julia|data-visualization|plotting|grammar-of-graphics|statistics|dataframes|scientific-computing,7,"This repository provides Gadfly, a Julia-based statistical graphics and plotting library designed for building high-quality visualizations with a Grammar-of-Graphics-style API. It is directly useful in data science workflows for exploratory data analysis, communicating results, and producing publication-quality figures, with tight integration into common Julia data tooling like DataFrames and notebook environments. It is not an ML model training framework, but visualization is a core component of ML/data work, making it moderately-to-strongly relevant. The score reflects high practical value for data analysis/visualization while being indirect (supporting) rather than core model-building infrastructure.",success
https://github.com/awesome-spark/awesome-spark,awesome-spark,"A curated “awesome list” of Apache Spark packages, libraries, connectors, and learning resources. It organizes the Spark ecosystem by categories (e.g., language bindings, notebooks/IDEs, SQL data sources, storage, graph processing, and ML extensions) to help users discover tools and references.",1900,apache spark|big data|data engineering|distributed computing|spark ecosystem|awesome-list,7,"This repository is a curated directory of Apache Spark-related projects and resources rather than an executable ML library itself. It is strongly relevant to data workflows because Spark is a common foundation for large-scale data processing, and the list includes categories directly tied to ML on Spark (e.g., ML extensions and model tooling). It earns a 7 because it’s practically useful and educational for data/ML engineers working in the Spark ecosystem, but it doesn’t provide training/inference code or a framework on its own.",success
https://github.com/bytewax/bytewax,bytewax,"Bytewax is a Python-first, stateful stream processing framework with a Rust-based distributed execution engine. It lets you build scalable, fault-tolerant dataflows (e.g., with operators like map/filter/join/windowing) and connect to common streaming sources/sinks such as Kafka, filesystems, and WebSockets.",1900,stream processing|data engineering|python|rust|stateful processing|distributed systems|event streaming|kubernetes,7,"This repository provides a production-oriented framework for stateful event/stream processing, aimed at building real-time dataflows with fault tolerance, state recovery, and scalable distributed execution. It is directly applicable to ML/data workflows for online feature computation, streaming ETL, windowed aggregations, and real-time model inference pipelines, but it is not itself a model-training or ML framework. The score reflects strong relevance to modern data engineering and streaming ML use cases, with solid ecosystem integration (Python-first, connectors, Kubernetes scaling), but more indirect ML focus than core ML libraries.",success
https://github.com/microsoft/msticpy,msticpy,"MSTICPy is Microsoft Threat Intelligence Python security tooling for investigation and threat hunting in Jupyter notebooks. It provides log data acquisition from multiple sources, enrichment (threat intel, geo, Azure resource data), analysis (including anomaly detection/time-series techniques), and interactive visualization components built around pandas DataFrames.",1900,cybersecurity|threat-hunting|threat-intelligence|jupyter|pandas|data-analysis|siem|microsoft-sentinel,7,"This repository is primarily a cybersecurity investigation and threat-hunting toolkit for Jupyter/Python, focused on acquiring, enriching, analyzing, and visualizing security telemetry. While it is not an ML framework, it directly supports data-science-style workflows (pandas-first processing, time series decomposition, and anomaly detection) that can be used by analysts and data scientists working on security analytics. Its practical integrations with common security data sources (e.g., Microsoft Sentinel/Log Analytics and others) make it useful for building data pipelines and exploratory analysis in notebooks. The score reflects strong relevance to applied data analysis (especially security analytics) without being a general-purpose ML training/serving platform.",success
https://github.com/Netflix/genie,genie,"Genie is a federated big data orchestration and execution engine from Netflix that abstracts away cluster/binary/configuration details so users (e.g., data scientists) can submit jobs/queries (like Spark/SparkSQL) through a consistent interface. It dynamically assembles dependencies and configuration, executes and monitors jobs, and records job metadata for auditing and debugging.",1800,big data|job orchestration|distributed systems|data infrastructure|spark|spring boot|java,7,"This repository provides an orchestration and execution service for big data jobs, aimed at simplifying how consumers (including data scientists) run queries and batch workloads by hiding cluster selection and dependency/configuration management. While it is not an ML library or model-training framework, it is directly useful in data/ML platforms as infrastructure for scheduling/routing/executing large-scale Spark and similar workloads. Its relevance is strongest for ML engineers and data platform teams building production pipelines rather than for standalone experimentation, which supports a moderately high (but not core-ML) score.",success
https://github.com/apachecn/python_data_analysis_and_mining_action,python_data_analysis_and_mining_action,"A Python (Python 3) code-and-notes companion repository for the book 《Python 数据分析与挖掘实战》, organized by chapter with annotated source code and accompanying datasets used in the examples.",1800,data-science|data-analysis|python|python3|machine-learning|educational|reading-notes,7,"This repository primarily provides chapter-structured, annotated Python implementations and notes corresponding to a practical data analysis and data mining textbook, including example datasets. It is directly useful for learning and reproducing common data analysis/data mining workflows (data preprocessing, analysis, and model-like techniques) in a hands-on way, though it is not a reusable ML framework or production library. Community adoption appears moderate (around 1.8k stars), suggesting it is valued as a learning resource more than an industry-standard tool. Therefore, it scores well for educational value and direct applicability to learning ML/data concepts, but lower for integration potential and being a core ML tool.",success
https://github.com/benedekrozemberczki/awesome-fraud-detection-papers,awesome-fraud-detection-papers,"A curated “awesome list” of research papers on fraud detection, organized by year and venue (e.g., AAAI, KDD, CIKM, WWW), with links to the papers. It serves as a literature index for data mining/graph/AI approaches to fraud detection.",1800,fraud detection|machine learning|data mining|graph neural networks|research papers|awesome-list|literature review,7,"This repository is primarily a curated bibliography of fraud-detection research papers (not a software library), making it most useful for discovery, literature review, and staying current on methods and benchmarks. It is strongly related to ML/data workflows because it points practitioners to relevant algorithms and papers (including graph-based and deep learning approaches), but it does not directly provide datasets, training code, or reusable ML components. Community adoption is solid (about 1.8k GitHub stars), which supports its educational and reference value. Therefore it scores high for learning and research acceleration, but lower than executable ML tooling or datasets.",success
https://github.com/dreamRs/esquisse,esquisse,"An RStudio add-in (and Shiny-based UI) for interactively building ggplot2 visualizations by dragging/dropping variables and choosing plot types, then exporting the plot or generating reproducible ggplot2 code.",1800,R|ggplot2|data-visualization|RStudio addin|Shiny|exploratory-data-analysis|plotting,7,"The repository provides an interactive RStudio add-in to explore datasets and construct ggplot2 charts (e.g., scatter plots, histograms, boxplots, and sf maps) with options to export plots or retrieve the underlying code. This is directly useful in data science workflows for exploratory data analysis and rapid visualization/prototyping, but it is not an ML modeling or training framework. Community adoption appears solid for an R visualization tool (about 1.8k GitHub stars), supporting a moderately high score focused on DS utility rather than core ML.",success
https://github.com/san089/Udacity-Data-Engineering-Projects,Udacity-Data-Engineering-Projects,"A collection of Udacity-style data engineering projects covering data modeling (Postgres/Cassandra), building AWS-based data warehouses and data lakes (Redshift, S3, Spark/EMR), and orchestrating ETL pipelines with Apache Airflow, plus an API-to-Postgres ETL example.",1800,data engineering|ETL|Apache Airflow|AWS|Amazon Redshift|data warehouse|data lake|PostgreSQL,7,"This repository is primarily a set of educational/practical data engineering projects (ETL pipelines, data modeling, orchestration, and cloud data platforms on AWS). It is strongly relevant to data/ML workflows because these components are foundational for collecting, transforming, storing, and scheduling data used for analytics and model training, but it does not focus on model development or ML frameworks themselves. Community adoption appears moderate (about 1.8k stars), and the learning value is high for building end-to-end data pipelines; therefore it scores well for ML/data enablement but not as a core ML tool.",success
https://github.com/JetBrains/lets-plot,lets-plot,"Lets-Plot is a multiplatform plotting library based on the Grammar of Graphics, providing ggplot2-style data visualization for Python and Kotlin (including notebooks, JVM, Kotlin/JS, and Compose Multiplatform embedding). It also integrates with JetBrains tooling (e.g., SciView) to support interactive plotting workflows.",1700,data visualization|grammar of graphics|ggplot2|python|kotlin|jupyter|geospatial|compose-multiplatform,7,"This repository provides a Grammar-of-Graphics plotting library (ggplot2-like) for Python and Kotlin, aimed at creating statistical graphics and interactive visualizations across notebook and application environments. Data visualization is a core part of ML/data science workflows for EDA, feature understanding, and communicating results, so it is directly useful to practitioners even though it is not an ML training/inference framework. Its integrations with notebooks and IDE tooling increase practical applicability, but it remains primarily a visualization library rather than a broader ML/data processing platform, so it scores as moderately relevant rather than core ML.",success
https://github.com/VisActor/VChart,VChart,"VChart is a cross-platform charting component library in the VisActor visualization system, built on top of VGrammar (visual grammar) and VRender (rendering engine). It focuses on rich charting plus “data storytelling” features such as annotations, animations, flow control, and narrative templates.",1700,data visualization|charting|typescript|javascript|react|cross-platform|storytelling,7,"This repository provides a charting and visualization library (plus wrappers such as React components) intended to render charts across platforms (web/H5 and various mini-app environments) and to support narrative “storytelling” features like annotations and animations. It is not an ML framework, but it is directly useful in data science and ML workflows for exploring, presenting, and communicating data and model results via interactive charts and dashboards. The score reflects strong relevance to data work (visual analytics and reporting) but limited direct support for model training, evaluation pipelines, or MLOps.",success
https://github.com/bytedance/bitsail,bitsail,"BitSail is ByteDance’s open-source, distributed high-performance data integration (data sync/ETL) engine for moving data between heterogeneous sources and sinks. It supports batch, streaming, and incremental synchronization scenarios with a connector-based architecture and operational features like monitoring and dirty-data handling.",1700,data engineering|data integration|ETL|streaming|batch processing|data pipeline|connectors|distributed systems,7,"BitSail’s primary use case is large-scale data integration/synchronization across many data sources and sinks (batch, streaming, and incremental), which is a core enabling layer for data platforms. While it is not an ML framework, it is directly useful in ML/data workflows for building and operating reliable ingestion pipelines into lakes/warehouses and streaming systems that feed feature engineering and training/serving datasets. The score reflects strong relevance for data engineering and pipeline reliability, but less direct applicability to modeling, training, or MLOps compared with dedicated ML tools.",success
https://github.com/feldera/feldera,feldera,"Feldera is an incremental computation/query engine that continuously maintains SQL views as underlying tables receive inserts, updates, and deletes. It supports running SQL “pipelines” with strong consistency guarantees, connectors to common batch/streaming systems, and a WebConsole/manager for operating pipelines.",1700,data engineering|stream processing|incremental computation|sql|analytics|feature engineering|rust,7,"This repository implements Feldera, a SQL-first incremental computation engine designed to maintain query results (views/materializations) efficiently as data changes, aimed at high-throughput streaming and hybrid batch/stream use cases. It is directly relevant to ML/data workflows because it can be used to build ETL and real-time/batch feature engineering pipelines and to serve consistently updated analytical views. However, it is not an ML framework for model training/inference itself; its value is primarily as data infrastructure that feeds ML systems, which places it in the “moderately relevant” range rather than core ML tooling.",success
https://github.com/fmilthaler/FinQuant,FinQuant,"FinQuant is a Python library for financial portfolio management, analysis, and optimisation. It helps build portfolios from historical price data, compute key metrics (e.g., expected return/volatility/Sharpe ratio), visualize indicators (moving averages, Bollinger bands), and perform portfolio optimisation (efficient frontier / Monte Carlo).",1700,quantitative-finance|portfolio-optimization|time-series|python|pandas|data-visualization|trading-analytics,7,"This repository primarily provides portfolio analytics and optimisation tooling (e.g., return calculations, risk metrics, efficient frontier and Monte Carlo optimisation) for financial time-series data. It is directly useful for data science workflows in quantitative finance (feature/indicator exploration, exploratory analysis, and optimization experiments), but it is not primarily an ML model training framework or MLOps tool. Its relevance is boosted by common data-science dependencies (NumPy/Pandas/Matplotlib, and optional scikit-learn listed as a dependency on PyPI), yet overall adoption appears moderate rather than industry-standard at the level of core ML libraries, supporting a solid but not top-tier score.",success
https://github.com/fonnesbeck/statistical-analysis-python-tutorial,statistical-analysis-python-tutorial,"An introductory tutorial (originally for SciPy 2013) that teaches statistical data analysis in Python using Jupyter/IPython notebooks, covering Pandas data handling, visualization with Matplotlib, and basic statistical modeling with NumPy/SciPy (plus optional Statsmodels). The repository includes notebooks and sample datasets for hands-on exercises and is archived (read-only).",1700,data science|statistics|python|pandas|jupyter-notebooks|data-visualization|scipy,7,"This repository is primarily an educational set of notebooks and datasets for learning statistical data analysis in Python (Pandas wrangling, plotting, and statistical modeling). It is directly useful to data science practitioners as a learning resource and as example code for common analysis workflows, though it is not an ML framework, training library, or production tooling. Community adoption appears solid for a tutorial (about 1.7k stars), but it is archived/read-only and targets older package versions, limiting integration into modern ML pipelines. Based on strong educational value and relevance to data workflows (but not core ML infrastructure), a 7/10 is appropriate.",success
https://github.com/galaxyproject/galaxy,galaxy,"Galaxy is an open-source, web-based scientific workflow and data analysis platform designed to make data-intensive research accessible, reproducible, and transparent. It provides a UI and APIs for building/running analysis workflows, managing datasets, and integrating diverse scientific tools (notably in bioinformatics).",1700,scientific workflows|bioinformatics|data analysis platform|reproducible research|python|web application|workflow orchestration,7,"This repository implements the Galaxy platform, a widely used web-based environment for running and sharing data-intensive scientific analyses and workflows, especially in computational biology. While it is not an ML framework, it is highly relevant to ML/data workflows because it supports data ingestion, preprocessing, tool execution, pipeline/workflow composition, provenance, and reproducibility—capabilities often needed alongside model training and evaluation. Its strong community adoption in scientific data analysis and extensive integration surface (tools, workflows, APIs) make it valuable infrastructure for data science teams working with large datasets, though ML-specific functionality is not its primary focus.",success
https://github.com/olgabot/prettyplotlib,prettyplotlib,"A Python library that enhances Matplotlib defaults to produce cleaner, more aesthetically pleasing plots (e.g., improved styling for lines, scatter, bars, histograms, and pcolormesh) with minimal effort. The project is no longer actively maintained by the original author, who recommends using Seaborn instead.",1700,python|data-visualization|matplotlib|plotting|scientific-computing|seaborn|statistics,7,"prettyplotlib is primarily a Matplotlib styling/enhancement library aimed at producing better-looking default scientific plots with less manual tweaking. Data scientists and ML practitioners can use it directly in exploratory data analysis (EDA), reporting, and visualization of model results, but it is not an ML framework or a data-processing toolkit. Its usefulness is moderated by the repository’s maintenance status (the author states it is no longer maintained and suggests Seaborn), which reduces integration confidence for modern workflows. Despite that, visualization is a core part of ML/data work, so it remains moderately valuable.",success
https://github.com/yobix-ai/extractous,extractous,"Extractous is a high-performance unstructured document text and metadata extraction library written in Rust, with language bindings (currently Python) and broad file-format coverage. It extracts from formats like PDF/Word/HTML (and many others via Apache Tika), and can perform OCR for scanned documents using Tesseract, all designed to run locally without external services.",1700,unstructured-data|document-parsing|text-extraction|ocr|rust|python|apache-tika|data-engineering,7,"This repository provides fast local extraction of text and metadata from many document types (e.g., PDF/Word/HTML) with optional OCR, making it a practical building block for ingesting unstructured data. It is not an ML model or training framework, but it is directly useful in ML/data workflows (e.g., dataset creation, RAG/LLM pipelines, document preprocessing) where robust document-to-text conversion is critical. Community adoption appears solid (about 1.7k GitHub stars), which increases confidence in real-world utility, but its scope remains primarily extraction rather than end-to-end ML, so it scores below core ML libraries.",success
https://github.com/TomAugspurger/effective-pandas,effective-pandas,"A collection of Jupyter notebooks that accompany Tom Augspurger’s “Effective Pandas”/“Modern Pandas” articles, teaching idiomatic pandas workflows (method chaining, indexes, performance, tidy data, visualization, time series, and some out-of-core topics).",1600,pandas|data analysis|python|jupyter notebooks|data wrangling|data visualization|time series,7,"This repository is primarily an educational set of pandas notebooks backing a series of articles, focusing on practical data manipulation patterns (e.g., method chaining, indexing, performance, tidy data, and time series). It is directly useful for data science workflows because pandas is a core tool for data preparation and exploratory analysis that typically precede modeling. However, it is not an ML framework and does not center on model training/evaluation, so its value is strong for data handling fundamentals rather than end-to-end machine learning.",success
https://github.com/d3plus/d3plus,d3plus,"D3plus is an open-source JavaScript visualization library built on top of D3.js that streamlines creating SVG-based charts by handling common concerns (tooltips, color assignment, label placement) via a configuration-driven API. It is organized as multiple installable packages (including a React wrapper) to support modular usage across web apps.",1600,data visualization|javascript|d3.js|svg|charts|react|frontend,7,"This repository provides a JavaScript data visualization toolkit (plus React components) for quickly building interactive SVG charts from data using a configuration-based approach. While it is not an ML framework, it is directly useful in data science and ML workflows for exploratory data analysis, dashboarding, and presenting model outputs (e.g., distributions, segmentations, hierarchical results). Its adoption appears solid (about 1.6k GitHub stars) and it offers practical educational value for learning visualization patterns, justifying a moderately relevant score rather than a core-ML score.",success
https://github.com/devinpleuler/analytics-handbook,analytics-handbook,"A soccer analytics “handbook” centered on a Jupyter notebook that teaches practical techniques and best practices for working with public soccer data in Python (including tutorials and curated learning resources). It includes code examples using open datasets (e.g., StatsBomb and Metrica) and relies on commonly used, pip-installable soccer analytics/data-science libraries.",1600,soccer analytics|sports analytics|data science|python|jupyter notebook|tutorial|statsbomb,7,"This repository is primarily an educational, hands-on soccer analytics guide delivered via a Jupyter notebook, with code samples for working with public soccer datasets in Python. It is directly applicable to data-science workflows (data ingestion/cleaning, analysis, visualization, and some modeling techniques common in soccer analytics), but it is not a general-purpose ML framework or MLOps tool. Its strong practical and educational value for sports analytics practitioners justifies a moderately high score, though community adoption appears concentrated around this specific domain rather than broad ML infrastructure.",success
https://github.com/stefan-jansen/zipline-reloaded,zipline-reloaded,"A maintained fork of Quantopian's Zipline: an event-driven, Pythonic backtesting engine for algorithmic trading strategies, with strong integration into the PyData ecosystem (notably Pandas) and support for common analytics/stat/ML libraries used in strategy research.",1600,algorithmic-trading|backtesting|quant-finance|python|pandas|data-science|time-series|trading-strategies,7,"This repository provides an event-driven backtesting framework for quantitative trading research, producing and consuming market/strategy data primarily via Pandas DataFrames and related PyData tooling. It is not an ML training framework itself, but it is directly useful for ML/data workflows in finance (feature engineering on historical prices, walk-forward testing, and evaluating ML-driven signals/strategies in a realistic simulation loop). Community adoption appears meaningful for a niche domain (notably a maintained Zipline fork with substantial GitHub interest), and it has solid educational value for learning systematic trading research and evaluation. I scored it a 7 because it is highly relevant to data science in quantitative finance, but not a general-purpose or widely adopted core ML library.",success
https://github.com/tomasonjo/blogs,blogs,"A collection of Jupyter notebooks accompanying Tomaz Bratanic's Graph Data Science blog posts, primarily demonstrating Neo4j-based graph analytics and related experiments across various datasets and use cases.",1600,graph data science|neo4j|jupyter notebooks|graph algorithms|data science|graph analytics|python,7,"This repository is an educational/experimental notebook collection supporting graph data science blog posts, with many examples centered on Neo4j and graph algorithms. It is directly useful for data science workflows involving graph modeling, exploratory analysis, and graph feature engineering, and can serve as practical reference material for learning and prototyping. However, it is not a general-purpose ML framework or widely adopted production tool; its value is strongest for learning and for graph-analytics-driven data projects, which supports a moderately high score.",success
https://github.com/Intel-bigdata/HiBench,HiBench,"HiBench is a big data benchmarking suite for evaluating the performance of big-data frameworks (notably Hadoop, Spark, and several streaming engines) in terms of throughput, latency, and resource utilization. It provides a collection of workloads across categories such as micro benchmarks, SQL, graph, web search, streaming, and a set of ML-oriented benchmarks implemented primarily on Spark.",1500,big data|benchmarking|apache spark|hadoop|streaming|performance testing|data engineering|machine learning benchmarks,7,"This repository’s primary purpose is benchmarking: it runs standardized workloads to measure and compare performance of data-processing frameworks (e.g., Hadoop/Spark and streaming systems), rather than providing an ML modeling library. It is still meaningfully relevant to ML/data workflows because it includes an explicit ML workload category (e.g., classification/clustering/regression-style benchmarks) and helps ML/data engineers evaluate cluster performance and tuning for large-scale data processing. Community adoption appears solid (notable star count), but its direct applicability is mainly for performance characterization and infrastructure evaluation rather than day-to-day model development, which is why it scores moderately high but not in the 8–10 range.",success
https://github.com/antvis/AVA,AVA,"AVA is a framework for automated visual analytics that helps with data processing, automatic insight extraction, and intelligent chart recommendation/generation. It includes a core library (@antv/ava) and a React component library (@antv/ava-react) for plug-and-play automated charting and insight presentation.",1500,data visualization|visual analytics|automated insight|chart recommendation|javascript|typescript|react,7,"This repository provides an automated visual analytics framework with modules for statistical data processing, automatic insight discovery over multidimensional datasets, and chart knowledge-based recommendations/optimization. It is directly useful in data science workflows for exploratory data analysis (EDA) and communicating insights via automated chart selection and narrative/insight components, though it is not a general-purpose model training framework. Community adoption appears solid for a visualization-focused library (around 1.5k GitHub stars), supporting a moderately high relevance score for ML/data practitioners who need automated EDA and insight reporting.",success
https://github.com/aws-samples/aws-glue-samples,aws-glue-samples,"A collection of AWS Glue code samples and utilities demonstrating how to use AWS Glue for serverless data integration, ETL, streaming, and related data engineering workflows (including Glue for Spark and other Glue features).",1500,aws|aws-glue|data-engineering|etl|data-integration|apache-spark|data-lake,7,"This repository provides practical AWS Glue examples (jobs, utilities, and tutorials) for building data integration and ETL pipelines, including Spark-based and streaming use cases. It is directly useful for data engineering workflows that commonly support ML (data ingestion, transformation, and lakehouse/table-format patterns), but it is not primarily an ML modeling library. Because it helps implement real-world data pipelines and can be used to prepare features/training data at scale, it merits a moderately high score even though it does not focus on training or deploying ML models.",success
https://github.com/owid/owid-grapher,owid-grapher,"Our World in Data’s monorepo for creating and publishing embeddable, interactive data visualizations (“Grapher”), including a charting/visualization library plus supporting tooling like an admin UI, an explorer UI layer, and site/static-build components backed by a MySQL data store.",1500,data-visualization|typescript|react|mobx|data-platform|interactive-charts|mysql,7,"This repository primarily powers OWID’s end-to-end workflow for managing datasets and publishing interactive charts (including the Grapher visualization library, an admin interface, and related site/build tooling). It is strongly relevant to data workflows because it focuses on storing, configuring, and rendering data-driven visualizations at scale, which is a common need in data science communication and analytics platforms. However, it is not an ML training/framework repo; its value for ML is indirect (visualization, data publishing, and tooling) and it is noted by OWID as not currently optimized for reuse outside their production environment.",success
https://github.com/pyjanitor-devs/pyjanitor,pyjanitor,"pyjanitor is a Python library that extends pandas with a user-friendly, method-chaining API for common data cleaning and preprocessing tasks, inspired by the R package ""janitor"". It provides many convenience functions for cleaning column names, handling missing/empty data, reshaping, and other data-wrangling utilities.",1500,python|pandas|data-cleaning|data-wrangling|data-preprocessing|data-science|method-chaining|etl,7,"This repository provides a pandas-extension library focused on streamlining data cleaning and preprocessing via readable method chaining, which is a common and important step in most ML/data science workflows. While it is not an ML framework (it does not train models), it is directly applicable to preparing tabular datasets and improving pipeline readability/maintainability, and it is referenced in the broader pandas ecosystem. I rated it a 7 because it is a strong, practical data-processing tool frequently useful for ML projects, but it is not a core modeling/training or MLOps system.",success
https://github.com/quixio/quix-streams,quix-streams,"Quix Streams is an open-source Python framework for building reliable real-time data engineering pipelines on Apache Kafka using a Streaming DataFrame API. It supports sources/sinks connectors, common stream-processing operators (e.g., windowing, joins), and fault-tolerant stateful processing with Kafka features like transactions for exactly-once semantics.",1500,stream processing|data engineering|apache kafka|python|streaming dataframes|event-driven architecture|etl,7,"This repository provides a Python stream-processing framework centered on a Streaming DataFrame abstraction for transforming Kafka topic data, plus connectors (sources/sinks) and streaming primitives like windowing, joins, branching, and group-by. While it is not an ML framework, it is directly useful in ML/data workflows for real-time feature engineering, online inference pipelines, operational analytics, and streaming anomaly detection use cases. The score reflects strong applicability to data engineering for ML systems and good educational value for streaming concepts, but less direct relevance than model-training or core ML libraries.",success
https://github.com/san089/goodreads_etl_pipeline,goodreads_etl_pipeline,"An end-to-end Goodreads data pipeline that ingests data from the Goodreads API, lands it in AWS S3, transforms it with Spark, and loads it into an Amazon Redshift data warehouse orchestrated by Apache Airflow, with data quality checks and analytics queries.",1500,data engineering|ETL|Apache Airflow|Apache Spark|AWS|Amazon S3|Amazon Redshift|data warehouse,7,"This repository implements an end-to-end data engineering pipeline for ingesting Goodreads API data into an S3-backed data lake and loading curated datasets into a Redshift warehouse using Spark transformations orchestrated by Airflow. It is directly relevant to ML/data workflows because it covers core production data-pipeline patterns (landing/working/processed zones, orchestration, warehousing, and data quality checks) that are foundational for building ML-ready datasets. However, it is not primarily an ML library (no model training/serving focus), and community adoption appears moderate (about 1.5k stars) rather than ecosystem-defining, which is why it scores below 8.",success
https://github.com/vega/voyager,voyager,"Voyager 2 is an interactive data exploration and visualization tool that blends manual chart specification with automated assistance (e.g., wildcard partial specifications and related-view recommendations). This repo hosts an alpha migration of Voyager 2 to a React/Redux application and also provides an embeddable library (published as `datavoyager`).",1500,data visualization|visual analytics|exploratory data analysis|Vega-Lite|React|TypeScript|JupyterLab,7,"The repository provides a visual analytics / exploratory data analysis tool (Voyager 2) that helps users explore datasets and generate/compare visualizations via mixed-initiative workflows (manual specification plus automated suggestions). While it is not an ML training or modeling framework, it is directly useful in data science workflows for understanding data, finding patterns, and communicating insights through visualization. Its integration/embedding options (including a `datavoyager` library and references to JupyterLab usage) increase practical applicability for data practitioners, warranting a moderately high relevance score rather than a core-ML score.",success
https://github.com/PrefectHQ/ControlFlow,ControlFlow,"ControlFlow is a Python framework for building agentic AI workflows by defining observable tasks, assigning specialized LLM-powered agents to those tasks, and orchestrating them into flows with structured/validated outputs and observability integrations. The repository is archived, and its next-generation engine has been merged into the Marvin agentic framework.",1400,llm-agents|agentic-workflows|python|workflow-orchestration|prefect|pydantic|observability,7,"This repository provides an agentic workflow framework for coordinating LLM-based agents via task/flow abstractions, including structured results (via typed/validated outputs) and workflow observability. It is directly applicable to ML/AI engineering for building LLM agent systems and reproducible AI workflows, but it is not a general-purpose ML training or data processing library. The repo is also archived and the core engine has moved elsewhere (Marvin), which reduces its long-term practical value despite strong relevance to LLM application development.",success
https://github.com/TA-Lib/ta-lib,ta-lib,"TA-Lib (Core C Library) is a C/C++ technical analysis library providing a large collection of indicators and functions for financial time-series analysis (e.g., moving averages, RSI, MACD). It serves as the core implementation used by various language bindings and integrations.",1400,technical analysis|quant finance|trading indicators|time series|C library|C++|financial data,7,"This repository provides the core TA-Lib implementation in C/C++ for computing technical analysis indicators and related functions over financial time-series. It is directly useful in data science workflows for feature engineering and signal generation in quantitative trading, forecasting, and time-series modeling pipelines. While it is not an ML framework itself (no model training/inference), its indicators are widely used as inputs to ML models and as baseline analytics, giving it solid practical value for ML/data practitioners.",success
https://github.com/andresvourakis/data-scientist-handbook,data-scientist-handbook,"A curated handbook of data science resources (free and paid) aimed at helping aspiring and practicing data scientists learn core concepts, prepare for the job market, and connect with the community. The repository is primarily a structured README with categorized links (e.g., YouTube channels, blogs, newsletters, podcasts, books, and interview/portfolio resources).",1400,data science|machine learning|learning resources|career development|interview prep|curated list|education,7,"This repository is a curated collection of learning and career resources for data scientists, organized into sections like learning materials (YouTube, blogs, newsletters, books) and job-market preparation (technical interviews, portfolios, resumes). It relates to ML/data workflows indirectly: it doesn’t provide code, datasets, or runnable ML tooling, but it can materially improve a practitioner’s skills and knowledge via high-signal references. Community adoption appears moderate (about 1.4k stars), supporting its usefulness as an educational index. I scored it a 7 because it is strongly relevant for learning and career progression in data science, but it is not a direct, integrated ML/data software tool or framework.",success
https://github.com/damklis/DataEngineeringProject,DataEngineeringProject,"An example end-to-end data engineering pipeline that ingests news from RSS feeds, processes it in micro-batches, and exposes the collected data via an API. It orchestrates scraping with Airflow and uses Kafka-based streaming/connectors to persist and synchronize data across MongoDB, Elasticsearch, and MinIO.",1400,data engineering|data pipeline|Apache Airflow|Apache Kafka|Kafka Connect|MongoDB|Elasticsearch|Docker Compose,7,"This repository is primarily a data engineering reference project demonstrating a real-world ingestion and serving pipeline for news data (RSS scraping, Kafka topics/connectors, storage in MongoDB/Elasticsearch/MinIO, and an API layer). While it is not an ML framework or modeling library, it is directly relevant to ML/data workflows because it shows how to collect, validate, store, and serve data reliably—steps that are foundational for downstream analytics and ML model training. Its practical architecture (Airflow scheduling, Kafka Connect, CDC via Debezium, and search-ready indexing in Elasticsearch) makes it moderately valuable for ML engineers building data platforms. It scores a 7 due to strong educational and integration value for data pipelines, but lower direct applicability to model training/inference itself.",success
https://github.com/data-forge/data-forge-ts,data-forge-ts,"Data-Forge is a JavaScript/TypeScript toolkit for transforming and analyzing tabular and time-series data, inspired by Pandas and LINQ. It provides immutable, lazily-evaluated data pipelines and utilities for loading, shaping, aggregating, and exporting data (with optional filesystem support via a companion package).",1400,data-wrangling|dataframe|typescript|javascript|data-analysis|etl|csv-json|time-series,7,"This repository provides a Pandas/LINQ-inspired DataFrame/Series-style library for JavaScript/TypeScript focused on data loading (CSV/JSON), transformation, grouping/aggregation, and exporting, with lazy evaluation and immutable datasets. It is directly useful in data-science-adjacent workflows (ETL, feature engineering, time-series preprocessing) in the JS/TS ecosystem, but it is not an ML framework and does not center on model training/inference. Community adoption is solid (about 1.4k GitHub stars), suggesting meaningful real-world use, but the ML-specific ecosystem integration appears secondary to general data manipulation. Overall, it’s a strong data-processing utility for ML/data work in JavaScript/TypeScript, warranting a moderately high score rather than a top-tier ML score.",success
https://github.com/datapane/datapane,datapane,"Datapane is a Python library for building interactive, shareable data reports by composing “blocks” from objects like pandas DataFrames, plots (Altair/Bokeh/Plotly/Folium), Markdown, files, and forms, and exporting them (e.g., to standalone HTML). The repository is marked as no longer actively maintained, with the final release noted as 0.17.0 focused on free local report saving.",1400,python|data-reporting|dashboards|data-visualization|pandas|interactive-reports|html-export,7,"This repository provides a Python-first framework for assembling interactive data reports from common data-science artifacts (DataFrames, plots, text, and files) and exporting them for sharing, making it directly useful for communicating ML/data analysis results. It is not an ML training/inference framework, but it fits well into DS/ML workflows as a reporting and visualization layer for notebooks and scripts. Community adoption appears moderate (about 1.4k GitHub stars), but its value is tempered by the project being explicitly noted as no longer actively maintained, reducing long-term integration confidence.",success
https://github.com/enthought/mayavi,mayavi,"Mayavi is a cross-platform Python package for interactive 2D/3D scientific data visualization built on VTK, providing both a GUI application (mayavi2) and a high-level scripting interface (mlab) for rapid 3D plotting and visualization pipelines.",1400,scientific-visualization|3d-visualization|python|vtk|data-visualization|gui|scientific-computing,7,"This repository provides Mayavi, a Python toolkit for interactive 3D scientific visualization (including the mlab interface and the mayavi2 app), built on top of VTK and intended for visualizing scalar/vector/tensor datasets and common scientific file formats. It is directly useful in data science/ML workflows for exploratory analysis, debugging, and communicating results for 3D/spatial data (e.g., volumetric data, meshes, vector fields), but it is not an ML modeling/training framework itself. Its relevance is strengthened by its mature feature set and integration into Python scientific stacks, yet its primary focus remains visualization rather than core ML/data processing, so it fits best as a supporting tool rather than a central ML component.",success
https://github.com/lukasschwab/arxiv.py,arxiv.py,"A Python wrapper for the arXiv API that lets you search arXiv and iterate over results, access paper metadata, and download PDFs or source files via convenient Client/Search/Result abstractions.",1400,python|arxiv|arxiv-api|research-papers|literature-search|metadata-extraction|pdf-download|api-wrapper,7,"This repository provides a high-level Python interface to the arXiv API, making it easy to programmatically query arXiv, retrieve structured metadata, and download paper PDFs/sources. It’s directly useful in many ML/data workflows for literature review, dataset/paper collection, benchmarking curation, and building research-monitoring pipelines, even though it is not an ML modeling library itself. Community adoption appears solid (about 1.4k GitHub stars), and the API-centric design integrates well with typical Python data tooling. I rated it a 7 because it’s moderately-to-highly relevant for ML/data engineering around research content acquisition, but it doesn’t provide core ML algorithms or training infrastructure.",success
https://github.com/movingpandas/movingpandas,movingpandas,"MovingPandas is a Python library for movement data exploration and analysis, providing trajectory data structures and functions built on top of Pandas/GeoPandas with support for visualization and common trajectory analytics (e.g., stop detection, cleaning/smoothing, aggregation).",1400,geospatial|trajectory-analysis|movement-data|geopandas|pandas|gis|data-analysis|visualization,7,"This repository provides core data structures and algorithms for analyzing movement trajectories (tracking/trajectory analytics) using the Python geospatial stack (Pandas/GeoPandas) and visualization tools. It is directly useful in data science workflows for feature engineering, exploratory analysis, and preprocessing of spatiotemporal tracking datasets (e.g., AIS, GPS, video-tracked objects), even though it is not an ML model training framework itself. Its moderate-to-strong relevance to ML comes from enabling high-quality trajectory features and labels (stops, segments, smoothed paths, generalized tracks) that commonly feed downstream ML tasks, but it is primarily a geospatial analytics library rather than an ML library.",success
https://github.com/nivu/ai_all_resources,ai_all_resources,"A curated collection of links and learning materials for artificial intelligence, spanning mathematics, machine learning, deep learning, and related subfields (e.g., computer vision, reinforcement learning, GANs, data engineering, robotics). The repository is organized as a resource hub with topic folders and a comprehensive README pointing to courses, tutorials, talks, and communities.",1400,machine learning|deep learning|AI learning resources|computer vision|reinforcement learning|generative AI|data engineering|tutorials and courses,7,"This repository primarily functions as a curated index of AI/ML learning resources (courses, tutorials, talks, and community links) organized by topic areas like computer vision, GANs, reinforcement learning, and data engineering. It is directly useful for data scientists and ML engineers as an educational and reference hub, but it does not provide an executable library, datasets, or production ML tooling. The community adoption (stars/forks) indicates meaningful interest, and the breadth of topics gives it solid ongoing utility for ML learning and upskilling, justifying a moderately high score rather than a core-tool score.",success
https://github.com/opendatadiscovery/odd-platform,odd-platform,"ODD Platform is an open-source data discovery and data observability platform (a federated data catalog) that centralizes metadata, provides end-to-end lineage, and supports monitoring and governance features like data quality dashboards and compliance tagging. It is a reference implementation of the Open Data Discovery specification and integrates with many data/analytics/ML ecosystem tools.",1400,data catalog|data discovery|data observability|data lineage|metadata management|data quality|data governance|MLOps,7,"This repository primarily provides a data discovery/observability platform (federated data catalog) with features like metadata storage, end-to-end lineage, pipeline monitoring, tagging for governance, and data quality dashboards, plus broad integrations across the modern data stack. It is not an ML training framework, but it directly supports ML/data workflows by improving dataset/feature visibility, tracking ML-related entities (e.g., experiments, models as data consumers), and integrating with common ML-adjacent tooling (e.g., MLflow, Kubeflow, SageMaker/Feature Store). Given its strong relevance for production data operations and MLOps/data governance (but not being a core modeling library itself), a 7/10 reflects “moderately relevant” to ML/data practitioners with high integration potential.",success
https://github.com/sfirke/janitor,janitor,"An R package providing user-friendly functions to examine and clean messy data, especially data.frames. Key features include cleaning/standardizing column names (e.g., to snake_case), generating improved one-/two-/three-way frequency tables, and other helpers for common data-prep and exploration tasks in tidyverse workflows.",1400,r|data-cleaning|data-wrangling|data-preprocessing|tidyverse|tabulation|data-exploration,7,"This repository is the source for the R package ""janitor"", which focuses on practical data cleaning and early-stage data exploration (e.g., standardizing column names with clean_names/make_clean_names, creating formatted frequency tables, and other helpers for messy data.frames). These capabilities are directly useful in ML/data science workflows because most modeling projects require substantial preprocessing and consistent feature/column naming before analysis, feature engineering, or training. It is not an ML modeling framework itself, but it is a widely applicable, workflow-accelerating utility commonly used alongside the tidyverse/readr/readxl ecosystem, making it moderately-to-highly valuable for data science work.",success
https://github.com/tidyverse/tidyr,tidyr,"tidyr is an R package for creating tidy data by providing tools to reshape and clean tabular data. It includes core verbs for pivoting (long/wide), rectangling nested data (e.g., JSON) into tibbles, nesting/unnesting, and handling missing values.",1400,R|tidyverse|data-wrangling|data-cleaning|data-transformation|data-reshaping|statistics,7,"This repository contains the source code for the tidyr R package, which focuses on tidying and reshaping data (e.g., pivoting between long and wide formats, converting nested structures into rectangular tables, and managing missing values). These capabilities are directly useful in data science and ML workflows because data preparation and feature engineering typically require extensive reshaping and cleaning before modeling. While it is not an ML framework and does not provide modeling/training algorithms, it is widely adopted in the R data ecosystem (tidyverse) and is a common dependency in practical analytics pipelines, justifying a moderately high score.",success
https://github.com/uwdata/visualization-curriculum,visualization-curriculum,A data visualization curriculum consisting of interactive notebooks that teach visualization concepts using Vega-Lite and Altair. Materials are provided as Python-based Jupyter notebooks (published as a Jupyter Book and runnable on platforms like Colab) with corresponding JavaScript notebooks available on Observable.,1400,data visualization|educational curriculum|Jupyter notebooks|Altair|Vega-Lite|Python|interactive notebooks,7,"This repository is primarily an educational curriculum for data visualization, delivered via interactive notebooks using Vega-Lite and Altair. While it is not an ML framework or modeling toolkit, it is directly useful in data science workflows for exploratory data analysis (EDA), communicating results, and building visualization literacy. Its emphasis on practical notebook-based visualization and broad usability (Jupyter Book/Colab/Observable) makes it moderately relevant and valuable to data scientists, but it does not cover core model training, MLOps, or ML-specific pipelines—hence a 7 rather than an 8-10.",success
https://github.com/LongOnly/Quantitative-Notebooks,Quantitative-Notebooks,"A small collection of educational Jupyter notebooks for quantitative finance and algorithmic trading, including dynamic asset allocation, pairs trading, and a simple ML-based pairs trading example using decision tree regressors. The repo is archived (read-only) and focuses on idea generation/learning rather than production-ready strategies.",1300,quantitative finance|algorithmic trading|jupyter notebooks|python|data science|machine learning|pairs trading|asset allocation,7,"This repository provides educational quantitative-finance notebooks that fetch and analyze market data (e.g., via Yahoo Finance) and demonstrate trading/portfolio ideas like pairs trading and asset allocation. It includes a concrete ML example (decision tree regressors for pairs trading), making it directly relevant for learning applied ML/data analysis in finance, though it is not a general-purpose ML library or pipeline tool. Community adoption is moderate (about 1.3k GitHub stars), but the repo is archived and the included market data notes indicate it is not actively maintained, which limits its practical workflow integration. Overall it is a solid learning resource for data science in trading/finance, hence a 7/10.",success
https://github.com/PatMartin/Dex,Dex,"Dex (The Data Explorer) is a desktop data exploration and visualization tool built with Groovy/Java on JavaFX, supporting data ingestion from multiple sources, ETL-style transformations, and publishing web-based visualizations. It also supports applying machine learning via SMILE and integrates with R for advanced analytics workflows.",1300,data-visualization|data-exploration|etl|java|groovy|javafx|machine-learning|r-integration,7,"This repository provides an end-to-end data exploration application: ingesting data, transforming it, visualizing it (50+ visualization types), and exporting results. It relates to ML/data workflows through its explicit support for applying machine learning (via SMILE) and R integration, which can be used for modeling/analysis alongside visualization and ETL. It scores a 7 (moderately relevant) because it is a practical data science tool, but it is not a widely adopted core ML framework and is more focused on exploratory analysis/visualization than model training at scale.",success
https://github.com/acgeospatial/awesome-earthobservation-code,awesome-earthobservation-code,"A curated, community-maintained “awesome list” of tools, tutorials, code, and project links for Earth Observation / remote sensing and geospatial satellite imagery workflows (including Python/R tooling, cloud-native geospatial, STAC/COG, and ML/DL resources). It primarily serves as a discovery index rather than a single executable library.",1300,earth observation|remote sensing|geospatial|satellite imagery|python|machine learning resources|stac|cloud-native geospatial,7,"This repository is a curated directory of Earth Observation and geospatial resources (tools, tutorials, projects, datasets/platform links), not a standalone ML package. It is still valuable for ML/data workflows because EO/remote-sensing ML practitioners can use it to discover preprocessing tools, analysis-ready data resources, cloud-native data formats (e.g., STAC/COG), and ML/DL references to plug into pipelines. The repo shows meaningful community adoption for a niche index (about 1.3k stars) and has solid educational value, but direct integration is limited because most content is outbound links rather than reusable code modules.",success
https://github.com/alan-turing-institute/CleverCSV,CleverCSV,"CleverCSV is a Python package for handling messy CSV files, providing a drop-in replacement for Python’s built-in csv module with improved CSV dialect (delimiter/quote/escape) detection. It also includes a command-line toolkit to detect dialects, standardize CSVs toward RFC-4180, and generate import code or load data into Pandas.",1300,data processing|data wrangling|CSV parsing|Python|pandas|command-line tool,7,"CleverCSV’s primary use case is data wrangling: automatically inferring CSV dialects and reliably loading “messy” real-world CSV files that commonly break standard parsers, with both a Python API and CLI utilities. This is directly useful in data science workflows because it improves ingestion and cleaning steps (including loading into Pandas) before any modeling occurs, but it is not itself a modeling/training framework. The project has meaningful adoption (notable GitHub stars) and strong practical utility/educational value for robust data ingestion, which supports a moderately high (7/10) ML/data relevance score.",success
https://github.com/amphi-ai/amphi-etl,amphi-etl,"Amphi ETL is a self-hostable, low-code visual data preparation and transformation tool that generates native Python code for building ETL/data pipelines. It can run as a standalone app (via an `amphi start` command) and is also available as a JupyterLab-based extension, targeting analysts, data scientists, and data engineers.",1300,etl|data-engineering|data-preparation|data-transformation|low-code|python|jupyterlab|pandas,7,"This repository provides a visual, low-code interface for building data transformation/ETL pipelines and can generate deployable Python code (notably leveraging common data libraries like pandas and DuckDB), which makes it directly useful for data preparation and feature engineering workflows. While it is not an ML model training framework itself, it supports key upstream steps in ML/data science (cleaning, transforming, and pipeline creation) and integrates naturally with Python/Jupyter-based data work. Its community traction (on the order of ~1.3k GitHub stars) suggests meaningful adoption for data pipeline work, but its focus is broader ETL/analytics rather than core ML algorithms—hence a moderately high score rather than 9–10.",success
https://github.com/apache/hop,apache/hop,"Apache Hop (Hop Orchestration Platform) is an open-source data and metadata orchestration platform for designing and running data pipelines and workflows. It provides a GUI (Hop UI) plus runtime engines and plugins to execute, integrate, and manage data integration/orchestration tasks.",1300,data orchestration|data integration|etl|data pipelines|workflow orchestration|java|apache,7,"This repository is the Apache Hop Orchestration Platform, focused on building and running data pipelines/workflows and orchestrating data and metadata processes. While it is not an ML framework (it doesn't primarily provide model training/inference APIs), it is directly useful in ML/data science workflows for ETL/ELT, feature/data preparation, and operationalizing repeatable data pipelines. Its plugin-based ecosystem and execution engines make it practical for data engineering tasks that commonly precede or support ML, justifying a moderately high score rather than a core-ML score.",success
https://github.com/datazip-inc/olake,olake,"OLake is an open-source database replication tool that syncs data from transactional sources (e.g., PostgreSQL, MySQL, MongoDB, Oracle, Kafka) into open data lakehouse table formats—primarily Apache Iceberg—supporting full loads and CDC with an optional web UI and a CLI for automation.",1300,data engineering|data ingestion|change data capture|ETL/ELT|Apache Iceberg|lakehouse|Go,7,"This repository provides infrastructure for replicating operational database data into lakehouse storage (notably Apache Iceberg) with support for full loads and CDC, making it a practical building block for analytics platforms. While it is not an ML library, it directly supports ML/data workflows by enabling reliable, near-real-time feature/analytics data landing in open table formats that are commonly used for training datasets and downstream pipelines. Its usefulness is strongest for data engineers and ML platform teams building lakehouse-centric stacks, rather than for model training or experimentation itself. The relatively strong community adoption (on the order of ~1.3k GitHub stars) supports a moderately high score, but it is not a core ML framework.",success
https://github.com/eliasdabbas/advertools,advertools,"A Python package providing productivity, automation, and analysis utilities for online marketing workflows (especially SEO/SEM), including tools for crawling websites, handling URLs/sitemaps/robots.txt, generating keywords and ads, and returning results in pandas-friendly tabular formats.",1300,python|seo|sem|digital-marketing|web-crawling|data-analysis|pandas,7,"advertools is primarily a digital marketing analytics/productivity library for SEO/SEM tasks (e.g., crawling, sitemap/robots handling, URL/text utilities, and campaign keyword/ad generation), with outputs designed to fit common data-science tooling like pandas DataFrames. It is not an ML framework, but it is directly useful for data collection, cleaning, and feature extraction for marketing analytics and can feed downstream modeling (e.g., clustering keywords, forecasting performance, building attribution/SEO insights). Its workflow focus and pandas integration make it moderately-to-highly relevant for data practitioners, but it lacks core capabilities for training/evaluating ML models, so it does not score in the 8–10 range.",success
https://github.com/google/neuroglancer,neuroglancer,"Neuroglancer is a WebGL-based web application for interactive visualization of large volumetric datasets, supporting arbitrary cross-sectional views plus 3D meshes and skeleton/line-segment models. It is commonly used to explore connectomics and other microscopy-derived volumes in the browser.",1300,volumetric-data-visualization|WebGL|neuroscience|connectomics|microscopy|3D-visualization|typescript,7,"This repository provides an interactive WebGL viewer for large volumetric datasets (e.g., microscopy/connectomics), including 2D cross-sections and 3D mesh/skeleton overlays. While it is not an ML training framework, it is highly useful in ML/data workflows for inspection, debugging, and qualitative evaluation of model outputs such as segmentations and reconstructions on large 3D data. It is widely recognized and adopted in neuroscience imaging pipelines, giving it strong practical value for ML practitioners working with volumetric imaging data, but less direct applicability for general-purpose ML beyond that domain.",success
https://github.com/holoviz/hvplot,hvplot,"hvPlot is a high-level, Pandas-like plotting API that adds a convenient `.hvplot` interface to common PyData objects (e.g., pandas, dask, xarray, networkx, polars) for interactive and composable visualizations. It is built on the HoloViz ecosystem and supports multiple backends including Bokeh, Matplotlib, and Plotly.",1300,data-visualization|python|pandas|xarray|dask|holoviz|bokeh|plotly,7,"This repository provides a high-level visualization interface for popular data structures used heavily in data science workflows, making exploratory data analysis and reporting significantly easier. While it is not an ML modeling library, it is directly applicable to ML/data work for understanding datasets, feature distributions, and results, and integrates well with common PyData tooling (pandas/dask/xarray) and interactive app/dashboard stacks in the HoloViz ecosystem. Its relevance and utility for data science are strong, but it is not core model-training or MLOps infrastructure, so a 7/10 best reflects its role as a broadly useful DS visualization tool rather than an ML framework.",success
https://github.com/jrieke/best-of-streamlit,best-of-streamlit,"A curated, ranked gallery of Streamlit apps built by the community. It organizes Streamlit app projects into multiple categories and ranks them primarily by GitHub stars, with guidance for contributing new or updated entries.",1300,streamlit|python|curated-list|data-apps|machine-learning|nlp|computer-vision,7,"This repository is primarily a curated directory of Streamlit apps, grouped into categories (including multiple ML-focused ones) and ranked by popularity (GitHub stars). While it is not an ML library itself, it is directly useful to data scientists and ML engineers as a discovery/benchmarking resource for real-world Streamlit-based ML/data apps and components. Its value comes from educational inspiration and quick access to example implementations rather than providing reusable ML algorithms or data tooling. Given its practical relevance to ML/data app development but indirect role in model training/production pipelines, a 7/10 is appropriate.",success
https://github.com/kaushikb11/awesome-llm-agents,awesome-llm-agents,"A curated “awesome list” of LLM agent frameworks and agent development tools, organized as a README with links and brief feature highlights for each project. It also tracks basic popularity/health metrics (e.g., stars/forks) for the listed frameworks and is periodically updated.",1300,large language models|LLM agents|agent frameworks|NLP|RAG|developer tools|awesome-list,7,"This repository is primarily a curated directory of LLM agent frameworks and tooling rather than a library you import, but it’s directly useful for ML engineers and data scientists evaluating agent stacks (e.g., orchestration, RAG, memory, tool use). Its value is strong for discovery, comparison, and learning the ecosystem, though it does not itself provide modeling code, datasets, training pipelines, or MLOps components. Community adoption is moderate-to-strong for an “awesome list” (about 1.3k stars), supporting a solid but not top-tier score.",success
https://github.com/ropensci/drake,drake,"drake is an R-focused pipeline toolkit for reproducible, high-performance data analysis workflows: it builds a dependency graph of targets, skips up-to-date steps, and can orchestrate remaining work locally or with distributed computing. The repository is marked as superseded (since 2021-01-21) in favor of the targets package, which is the recommended successor.",1300,r|data-pipelines|reproducible-research|workflow-management|distributed-computing|data-science|high-performance-computing,7,"This repository provides a workflow/pipeline system for R that tracks dependencies between data analysis steps, supports caching and incremental rebuilds, and can scale execution via parallel/distributed backends. It is highly applicable to data science workflows (including ML training/evaluation pipelines) because it improves reproducibility, automation, and performance of multi-step analyses, but it is not itself an ML algorithm/framework. Community adoption appears solid (1.3k stars), though its practical value today is reduced by its superseded status and the recommendation to migrate to targets.",success
https://github.com/DaveSkender/Stock.Indicators,Stock.Indicators,"Stock Indicators for .NET is an open-source C#/.NET (NuGet) library that converts OHLCV market price quotes (equities, forex, crypto, commodities) into a wide range of technical indicators (e.g., SMA/EMA, RSI, MACD, Stochastics, Parabolic SAR) for use in trading, analysis, charting, and related tooling. The repository also includes a v3 (vNext) branch that adds streaming/incremental calculation patterns for real-time processing.",1200,dotnet|csharp|quantitative-finance|technical-analysis|algorithmic-trading|time-series|financial-data,7,"This repository is primarily a .NET technical-analysis/quant-fin library that computes many standard indicators from historical OHLCV time-series and (in v3) supports streaming/incremental computations for real-time pipelines. It is not an ML framework, but it is directly useful in ML/data workflows as a feature-engineering component for financial time-series models (e.g., producing RSI/MACD features, labeling signals, and powering backtests). The relatively strong community adoption (notable GitHub stars and downstream usage) and practical integration potential for data pipelines justify a moderately high score, but it stops short of being a core ML platform or end-to-end modeling toolkit.",success
https://github.com/JuliaStats/Distributions.jl,Distributions.jl,"A Julia package that provides a comprehensive collection of probability distributions along with associated statistical functionality, including distribution properties (moments, entropy), density/mass evaluation (pdf/logpdf), sampling, and maximum-likelihood estimation.",1200,julia|statistics|probability-distributions|data-science|scientific-computing|bayesian-inference,7,"Distributions.jl is a core Julia statistics library that implements many probability distributions and the standard operations needed to work with them (evaluation, sampling, moments, and MLE). It is directly useful in ML/data workflows for probabilistic modeling, simulation, likelihood-based fitting, and as a dependency in Bayesian and statistical ML stacks in Julia. It is not itself an end-to-end ML framework (no model training pipelines), but its broad utility and ecosystem centrality make it moderately-to-highly valuable for data science and machine learning use cases.",success
https://github.com/Kotlin/kotlin-jupyter,kotlin-jupyter,"Kotlin kernel for Jupyter/IPython that lets you run Kotlin code in Jupyter notebooks with interactive features like cell execution, basic code completion, error analysis, rich outputs, and convenient dependency/libraries integration.",1200,jupyter|kotlin|notebooks|repl|data-science|interactive-computing|ipython-kernel,7,"This repository provides the Kotlin Jupyter kernel, enabling Kotlin to be used directly inside Jupyter Notebook/Lab/Console environments and offering notebook-centric capabilities like rich outputs, error analysis, and dependency resolution. It is not an ML framework itself, but it is a strong enabler for ML/data workflows by making Kotlin a practical notebook language for exploration, visualization, reporting, and integration with JVM data/ML libraries. The community adoption appears solid (about 1.2k GitHub stars), and it has good educational and integration value for data science users who want a Kotlin/JVM-based notebook stack.",success
https://github.com/ResidentMario/geoplot,geoplot,"A high-level Python geospatial plotting library (akin to “seaborn for geospatial”) built on top of matplotlib and cartopy to make common cartographic visualizations and map projections easier. It integrates well with GeoPandas-style geospatial data workflows and focuses on providing a convenient, high-level API.",1200,geospatial|data-visualization|python|matplotlib|cartopy|geopandas|spatial-analysis,7,"This repository provides a high-level geospatial visualization API for Python, intended to simplify mapping and common cartographic plot types while leveraging matplotlib/cartopy and fitting into GeoPandas-centric workflows. It is directly useful in data science for exploratory spatial data analysis (ESDA), feature understanding, and communicating geospatial results, but it is not an ML framework nor a modeling/training tool. Community adoption appears solid (about 1.2k GitHub stars), and its educational value for geospatial data visualization is meaningful, though the project is noted as being in a maintenance state rather than actively adding new features.",success
https://github.com/SmythOS/sre,sre,"SmythOS Runtime Environment (SRE) is an open-source, cloud-native runtime, SDK, and CLI for building, running, and managing production-grade agentic AI systems. It provides OS-like abstractions and a unified API across AI resources (e.g., LLMs, vector databases, storage, caching), with built-in security and observability.",1200,agentic ai|ai agents|runtime environment|typescript|sdk|cli|llm orchestration|cloud-native,7,"This repository focuses on infrastructure for agentic AI: a runtime kernel plus SDK/CLI to orchestrate and manage agents with unified abstractions over LLMs, vector databases, storage, and caching. It is not a model-training or data-science library, but it is directly applicable to ML/LLM application engineering (building agent workflows, integrating vector search/RAG components, and deploying/operating agents). Community adoption appears moderate (about 1.2k GitHub stars), and its educational value is meaningful for learning production agent architecture and tooling. Based on its strong relevance to LLM/agent workflows but indirect relevance to classic data science/model development, a 7/10 is appropriate.",success
https://github.com/arkflow-rs/arkflow,arkflow,"ArkFlow is a high-performance stream processing engine written in Rust (Tokio-based) for building real-time data pipelines with pluggable inputs, processors, buffers, and outputs. It supports common streaming/data-engineering primitives (e.g., Kafka/MQTT/HTTP/files, SQL/JSON/Protobuf/VRL processing, windowing/buffering) and is positioned to integrate AI/ML inference into streaming workflows.",1200,rust|stream-processing|data-engineering|real-time-pipelines|kafka|sql|apache-arrow|ml-inference,7,"ArkFlow’s primary use case is real-time stream/data pipeline processing (inputs→processors→outputs) with performance-focused Rust/Tokio foundations, making it directly applicable to data engineering tasks that often sit upstream of ML. It has meaningful relevance to ML workflows because it explicitly targets streaming + intelligent analysis use cases and supports processors commonly used in data prep (SQL/JSON/Protobuf/Arrow/VRL), which can feed feature generation, online inference, and anomaly detection pipelines. However, it is not itself an ML training framework and its community adoption appears smaller than established streaming platforms, so it scores below core ML/data platforms while remaining strongly useful for ML-adjacent streaming and real-time inference infrastructure.",success
https://github.com/dataquestio/solutions,solutions,"A collection of Dataquest project/mission solution files, primarily as Jupyter notebooks and other supporting code (e.g., SQL, Python, R Markdown). It serves as reference implementations for Dataquest learning-path exercises and projects.",1200,data science education|jupyter notebooks|python|sql|r-markdown|data analysis|machine learning (intro),7,"This repository is mainly a set of worked solutions for Dataquest projects/missions, with many Jupyter notebooks plus some SQL and R Markdown files, making it directly useful as a learning/reference resource for practical data analysis tasks. While it is not an ML framework or production tool, it can be valuable to data scientists for studying end-to-end analysis patterns, including some introductory machine learning workflows embedded in course projects. Community adoption is moderate (about 1.2k stars) and the strongest value is educational and workflow examples rather than reusable libraries or tooling. That combination supports a moderately high relevance score for ML/data work, but not in the 8–10 range reserved for core ML tooling or widely adopted pipelines.",success
https://github.com/kassambara/ggpubr,ggpubr,"An R package that provides easy-to-use functions to create and customize ggplot2-based, publication-ready plots. It includes helpers for common statistical graphics (e.g., boxplots, violin plots, density/histograms) and convenience features like group comparisons/p-value annotations.",1200,R|data visualization|ggplot2|statistics|exploratory data analysis|publication-ready plots|biostatistics,7,"This repository is an R visualization toolkit built on ggplot2 that streamlines creation of publication-ready statistical plots and adds conveniences like statistical comparisons and annotations. While it is not an ML modeling framework, it is directly useful in ML/data science workflows for exploratory data analysis, reporting, and communicating results. It appears widely adopted (1.2k GitHub stars), suggesting meaningful community usage among data analysts and researchers, justifying a moderately high relevance score.",success
https://github.com/langgraph4j/langgraph4j,langgraph4j,"LangGraph for Java: a library for building stateful, multi-agent (agentic) applications with LLMs using cyclical graphs, shared state, and explicit control flow. It is designed to integrate with LangChain4j and Spring AI and includes features like checkpointing, graph visualization, streaming/asynchronous execution, and a UI playground/studio.",1200,llm|ai-agents|agentic-workflows|java|langchain4j|spring-ai|orchestration,7,"This repository provides a Java framework for orchestrating LLM-powered, stateful multi-agent workflows using graph-based control flow (including cycles), with debugging/observability features like checkpoints and graph visualization, plus integrations with LangChain4j and Spring AI. It is directly applicable to ML engineering workflows focused on building agentic LLM applications (tool use, memory/state management, streaming), but it is not a core ML training/data-processing library. Community signals (e.g., ~1.2k GitHub stars and active releases such as 1.7.10 on Jan 04, 2026) indicate meaningful adoption in the Java LLM ecosystem, supporting a moderately high score rather than a top-tier (framework-level) ML score.",success
https://github.com/machow/siuba,siuba,"Siuba is a Python library that brings a dplyr-like (R tidyverse) verb-and-pipe syntax to pandas DataFrames and SQL backends. It lets you write the same tabular transformation code (e.g., select/filter/mutate/summarize/arrange with group_by and joins) and run it locally on pandas or lazily on databases via SQL translation.",1200,data-wrangling|pandas|sql|data-engineering|data-analysis|tidyverse|dsl,7,"This repository provides a high-level, dplyr-inspired data manipulation API for Python that targets pandas and SQL sources, enabling consistent transformation pipelines across in-memory and database-backed tables. While it is not an ML modeling framework, it is directly useful in ML/data science workflows for data cleaning, feature preparation, aggregation, and reproducible ETL-style transformations. Its relevance is therefore moderate-to-high for data work (especially preprocessing and analysis) but not core to training/inference, which is why it scores a 7 rather than 8–10.",success
https://github.com/ml-tooling/best-of-jupyter,best-of-jupyter,"A curated, ranked “best-of” list of Jupyter Notebook, JupyterHub, and JupyterLab projects (extensions, kernels, tools), automatically scored and updated on a weekly basis. It groups hundreds of Jupyter ecosystem projects into categories and ranks them by a calculated project-quality score.",1200,jupyter|jupyterlab|jupyterhub|data-science-tooling|awesome-list|curated-list|python-ecosystem|developer-tools,7,"This repository is primarily a curated and automatically ranked directory of Jupyter ecosystem projects (not a standalone ML library), focusing on notebooks, JupyterLab/JupyterHub extensions, kernels, and related tooling. It is strongly relevant to ML/data workflows because Jupyter is a core environment for exploratory data analysis, experimentation, and communication, and the list helps practitioners discover widely used notebook tooling and integrations. Community adoption appears solid (roughly ~1.2k GitHub stars) and the educational value is moderate-to-high as a map of the ecosystem. The score is not higher because it does not directly provide ML algorithms, data processing primitives, or MLOps functionality; it mainly aggregates and ranks other tools.",success
https://github.com/predict-idlab/plotly-resampler,plotly-resampler,"A Python library that makes Plotly scalable for large time-series/sequential datasets by dynamically resampling/aggregating data based on the current viewport (e.g., during zoom/pan) via Dash or widget callbacks. It leverages optimized downsampling/point-selection algorithms (e.g., via tsdownsample; default MinMaxLTTB) to keep interactions responsive even with very large datasets.",1200,python|data-visualization|plotly|time-series|downsampling|dash|jupyter,7,"This repository provides dynamic resampling/aggregation wrappers (FigureResampler/FigureWidgetResampler and registration helpers) to efficiently visualize very large sequential/time-series data in Plotly, keeping interactive zoom/pan responsive. While it is not an ML model training or MLOps tool, it is directly useful in data science and ML workflows for exploratory data analysis, model diagnostics, and monitoring where long signals/logs must be inspected interactively. Its focus on large-scale time-series visualization and integration with Plotly/Dash/Jupyter makes it moderately-to-strongly relevant for ML/data practitioners, hence a 7/10.",success
https://github.com/rasbt/matplotlib-gallery,matplotlib-gallery,"A curated collection of Matplotlib plotting examples provided as IPython/Jupyter notebooks, organized by plot type and formatting topics to help users create and customize common scientific/data-visualization charts.",1200,data-visualization|matplotlib|python|jupyter-notebook|scientific-plotting|examples|data-science,7,"This repository primarily provides ready-to-browse Jupyter notebooks demonstrating many Matplotlib plot types (e.g., histograms, heatmaps, 3D plots, formatting and publication-ready figures). It is directly useful in ML/data workflows because visualization is a core step in exploratory data analysis, experiment reporting, and communicating results, even though it does not implement ML algorithms or pipelines. Community adoption is moderate (on the order of ~1.2k stars), and the educational value is high for learning practical plotting patterns and figure customization. Based on being a strong data-visualization/EDA resource rather than a core ML framework, a 7/10 fits best.",success
https://github.com/rsvp/fecon235,fecon235,"A collection of Python/Jupyter notebooks for financial economics that retrieves and analyzes macro/market time-series (e.g., FRED and other data sources) using the scientific Python stack. It includes utilities for data retrieval, time-series munging, econometric/statistical analysis (including forecasting), and visualization, with notebooks housed primarily under the `nb` directory.",1200,financial-economics|econometrics|time-series-analysis|jupyter-notebooks|python|data-retrieval|pandas|forecasting,7,"This repository is primarily aimed at applied financial economics research workflows using Python and Jupyter notebooks, with a strong focus on pulling real-world economic/financial time-series (notably from FRED) and performing analysis and visualization. It is directly useful to data scientists for time-series wrangling, exploratory analysis, forecasting (e.g., Holt-Winters), and econometrics/statistical modeling, though it is not a general-purpose ML framework. The project also mentions “statistical machine learning” techniques and includes notebook-based, reproducible research examples, making it educational and practically relevant for ML-adjacent data work in macro/finance.",success
https://github.com/sajal2692/data-science-portfolio,data-science-portfolio,"A personal portfolio of data science projects, primarily delivered as Jupyter notebooks (plus some R Markdown projects via RPubs). It covers machine learning, NLP, and exploratory data analysis/visualization projects with common Python DS tooling and a few end-to-end components (e.g., ETL/ML pipeline + simple web app).",1200,data-science-portfolio|machine-learning|natural-language-processing|exploratory-data-analysis|data-visualization|jupyter-notebook|scikit-learn|python,7,"This repository is primarily a curated collection of ML/NLP/EDA projects (mostly notebooks) intended for learning and showcasing work, rather than a reusable library or production-grade tool. It is directly relevant to ML/data workflows as a set of worked examples using standard DS tools (e.g., scikit-learn, pandas, visualization libraries) and includes at least one project with an ETL pipeline, model training pipeline, and a simple web app interface. Community adoption is moderate (around 1.2k stars) but the main value is educational and portfolio/reference use rather than plug-and-play integration, so a 7/10 fits best.",success
https://github.com/shobrook/BitVision,BitVision,"BitVision is a terminal-based, real-time Bitcoin charting and trading dashboard for the Bitstamp exchange. It includes an automated trading bot that uses a machine-learning forecasting model (logistic regression) trained on historical price/technical-indicator/blockchain features to place risk-adjusted daily trades.",1200,cryptocurrency|bitcoin|algorithmic-trading|terminal-dashboard|time-series-forecasting|machine-learning|python|nodejs,7,"The repository’s primary purpose is a CLI dashboard and trading tool for Bitcoin on Bitstamp, with supporting data retrieval (prices, indicators, blockchain metrics, and news) and an automated trading engine. It is meaningfully related to ML/data workflows because it implements a concrete end-to-end pipeline: feature construction from time-series data and technical indicators, model training (logistic regression), daily prediction, and execution of trades. However, the ML component is not a general-purpose library and is tightly coupled to the Bitstamp use case and this specific application architecture, which limits broad reuse and community adoption as an ML tool. This makes it moderately valuable for learning and adapting ML-driven trading/forecasting patterns, but not a core ML/data framework.",success
https://github.com/uwdata/mosaic,mosaic,"Mosaic is an extensible framework for linking databases and interactive data views (visualizations, tables, widgets) by pushing computation to DuckDB (server-side or in-browser via DuckDB-WASM) for scalable interactive exploration of very large datasets. It coordinates cross-filtering and linked interactions by having components publish declarative query needs that are managed and optimized through a central coordinator.",1200,data visualization|interactive analytics|duckdb|sql|dashboarding|jupyter|webassembly,7,"This repository provides a scalable interactive data exploration architecture (including visualization, table, and input components) that pushes query processing to DuckDB locally or via DuckDB-WASM, enabling responsive analysis over millions to billions of rows. While it is not an ML model training framework, it is directly useful in data science workflows for exploratory data analysis, building interactive analytic apps/dashboards, and integrating notebook-based data exploration (including via a Jupyter widget). Its relevance is therefore strong for data/analytics and moderate for ML specifically, warranting a 7/10.",success
https://github.com/ChawlaAvi/Daily-Dose-of-Data-Science,Daily-Dose-of-Data-Science,"A curated collection of short, practical data-science code snippets and notebooks accompanying the “Daily Dose of Data Science” Substack publication. It organizes tips and examples by topic (e.g., Pandas, NumPy, plotting, sklearn, statistics, optimization) for quick reference and learning.",1100,data-science|machine-learning|python|pandas|numpy|scikit-learn|jupyter-notebook|data-visualization,7,"This repository primarily serves as an educational and reference library of data-science tips, examples, and code snippets (often notebook-oriented) curated from the author’s Daily Dose of Data Science publication. It is directly useful for ML/data workflows as a practical cookbook for common tasks in Python data work (Pandas/NumPy), visualization, debugging, and sklearn usage, but it is not a production-grade framework or an end-to-end pipeline tool. Community adoption appears solid (about 1.1k GitHub stars) for a learning/reference repo, supporting a moderately high score rather than a top-tier tooling score.",success
https://github.com/Emsu/prophet,prophet,"A Python microframework for financial markets analysis focused on modeling trading strategies, portfolio management, and running/analyzing backtests with a small, flexible API.",1100,quantitative-finance|algorithmic-trading|backtesting|portfolio-management|financial-data|python|pandas,7,"This repository provides a Python framework for financial market research, including building strategy logic, running backtests, and computing portfolio performance analytics (e.g., Sharpe, returns, volatility). It is directly useful for data science workflows in quantitative finance (time series, trading strategy evaluation, and performance measurement), but it is not a general-purpose ML training framework and does not appear to focus on model fitting/ML algorithms as its core feature set. Community adoption appears moderate (about 1.1k GitHub stars) and its design/quickstart suggests practical applicability and educational value for systematic trading experimentation.",success
https://github.com/SciRuby/daru,daru,"daru (Data Analysis in RUby) is a Ruby library for storing, manipulating, analyzing, and visualizing data. It provides core data structures like Daru::DataFrame and Daru::Vector, plus integrations/plugins for I/O and plotting (e.g., daru-io and daru-view).",1100,ruby|data-analysis|dataframe|data-manipulation|data-visualization|statistics|time-series,7,"This repository provides pandas-like data structures (DataFrame/Vector) and a set of data manipulation, indexing, grouping, pivoting, and time-series features for Ruby, plus optional acceleration and visualization tooling. It’s directly useful for data science workflows—especially exploratory data analysis, feature preparation, and basic statistics—in Ruby environments (including notebooks via IRuby). It is not a full ML framework for model training/deployment, but it supports ML-adjacent workflows and includes example notebooks/case studies (e.g., logistic regression via related SciRuby tooling), which justifies a moderately high score rather than an 8–10.",success
https://github.com/Teradata/kylo,kylo,"Kylo is an enterprise data lake management platform/framework that helps build and operate scalable data lakes on big-data technologies such as Apache Spark, Hadoop, and Teradata. It focuses on operationalizing data ingestion and enforcing best practices around metadata management, governance, and security, with integrations (e.g., NiFi) and a UI plus REST services.",1100,data lake|data engineering|big data|apache spark|hadoop|apache nifi|metadata management|data governance,7,"Kylo’s primary purpose is managing and operationalizing enterprise data lakes (ingestion, metadata, governance, and security) across big-data stacks like Spark/Hadoop, with integrations and a UI/services architecture. This is directly relevant to ML/data workflows because data scientists and ML engineers depend on reliable ingestion, catalog/metadata, lineage/governance, and secure access to curated datasets. However, it is not an ML framework (no core focus on model training/serving), so its value is strongest upstream in data preparation and platform operations rather than in building models. Based on this indirect-but-substantial applicability to ML pipelines and data platform engineering, it merits a moderately high score.",success
https://github.com/abhishek-ch/around-dataengineering,around-dataengineering,"A curated knowledge hub for data engineering and machine learning, organized as a long-form learning path and collection of notes/resources. It includes topic guides and artifacts (e.g., docs, sketchnotes, and examples) spanning orchestration, streaming, lakehouse tools, and related ecosystem technologies.",1100,data engineering|machine learning|learning resources|apache airflow|apache spark|kubernetes|data orchestration|data streaming,7,"This repository primarily serves as a curated, educational “knowledge hub” and learning roadmap around data engineering and machine learning, with organized notes and links plus some practical artifacts (e.g., folders like dags and spark-kubernetes). It is directly useful for data/ML practitioners as a reference for building and operating data pipelines, orchestration, and distributed processing foundations that commonly support ML workflows. However, it is not a core ML library for model training/inference; its value is strongest for learning and for adjacent infrastructure/pipeline concepts rather than providing reusable ML code components at scale. Community adoption appears solid for an educational resource (about 1.1k GitHub stars), supporting a moderately high score.",success
https://github.com/alishobeiri/thread,thread,"Thread is an AI-powered, local-first alternative to Jupyter Notebook that adds an AI copilot for generating and editing code cells, fixing/explaining errors, and chatting with notebook context. It can run for free with Ollama or with your own LLM API key and integrates with Jupyter via a server extension and web UI.",1100,jupyter|data-science|ai-copilot|ollama|python|react|notebook,7,"This repository provides an AI-assisted notebook environment (a Jupyter alternative) focused on interactive data work: generating cells from natural-language prompts, performing context-aware Q&A, and automatically diagnosing/fixing errors. It is directly applicable to ML/data workflows because notebooks are a primary interface for exploration, analysis, and experimentation, and the AI features can speed up coding and debugging. However, it is not itself an ML framework, training library, or data pipeline system, and its value depends on how well the AI assistant integrates with a user's data/LLM setup rather than offering novel ML algorithms. Based on strong relevance to day-to-day data science usage but limited scope as an enablement tool (not core ML infrastructure), a 7/10 is appropriate.",success
https://github.com/apache/amoro,apache/amoro,"Apache Amoro (incubating) is a lakehouse management system built on open data lake formats. It provides a management service (AMS), unified catalog, optimizers, plugins, and tooling (e.g., Web UI/SQL) to integrate with engines like Flink, Spark, and Trino and to automate table optimization and lifecycle tasks.",1100,data engineering|lakehouse|data lake|Apache Iceberg|Apache Flink|Apache Spark|Trino|table optimization,7,"Amoro is primarily a data platform/lakehouse management and optimization system (not an ML library), focused on managing open table formats and providing services like unified catalogs, self-optimizing/compaction, and operational tooling. It is moderately valuable for ML/data workflows because it improves the reliability, performance, and manageability of large analytical datasets that ML pipelines often read from (e.g., Iceberg-based feature/label tables) and integrates with major compute engines (Flink/Spark/Trino). It is less directly applicable to model training/inference compared to core ML frameworks, but can be an important enabling layer for production-grade data lakes used by ML teams.",success
https://github.com/astronomer/astronomer-cosmos,astronomer-cosmos,"Cosmos lets you run dbt Core (and dbt Fusion) projects as Apache Airflow DAGs and Task Groups with minimal code. It focuses on orchestrating dbt runs in Airflow, including mapping Airflow connections to dbt profiles and turning dbt models/tests into Airflow tasks with scheduling, retries, and alerting.",1100,data engineering|workflow orchestration|apache airflow|dbt|ELT|python,7,"This repository primarily provides an orchestration/integration layer to execute dbt projects within Apache Airflow, turning dbt models/tests into Airflow tasks and enabling scheduling, dependency management, retries, and alerting. While it is not an ML library, it is highly applicable to data/analytics engineering workflows that commonly support ML pipelines (feature builds, training data refreshes, data quality tests). Its value for ML/data teams comes from operationalizing and scheduling data transformations reliably rather than doing modeling itself, which supports a moderately high score.",success
https://github.com/easystats/easystats,easystats,"The easystats project is a collection of interoperable R packages that provide a unified, consistent workflow for statistical modeling, effect sizes, model performance, visualization, and reporting. It aims to simplify post-model analysis, interpretation, and reporting while supporting many model types through shared infrastructure.",1100,R|statistics|statistical-modeling|data-analysis|bayesian-statistics|data-visualization|reporting,7,"This repository provides the umbrella R package and ecosystem entry point for easystats, which focuses on end-to-end statistical analysis workflows (model interpretation, effect sizes, diagnostics/performance metrics, visualization, and automated reporting). It is directly useful to data scientists for applied modeling and results communication, and it integrates well with common R modeling tools by offering consistent post-processing across many model classes. It is less of a core ML training framework (e.g., deep learning) and more of a statistics-oriented analysis/reporting toolkit, which is why it scores as moderately-to-highly relevant rather than a 9–10.",success
https://github.com/lakehq/sail,sail,"Sail (LakeSail) is an open-source, Rust-native distributed computation engine that aims to unify batch processing, stream processing, and compute-intensive AI workloads. It is Spark Connect compatible (Spark SQL and DataFrame API) and can be used from Python (pysail) as a drop-in backend for existing PySpark workloads.",1100,data engineering|distributed computing|big data|spark|apache arrow|sql|rust|pyspark,7,"This repository provides a Spark-compatible distributed compute engine (Rust-native, built on Arrow/DataFusion) intended for large-scale SQL/DataFrame workloads and AI-adjacent compute. It is directly relevant to ML/data workflows because many data science and ML pipelines depend on Spark-style ETL, feature engineering, and large-scale data preparation, and Sail can run existing Spark SQL/DataFrame code via Spark Connect. It is not primarily an ML framework (e.g., for model training like PyTorch/TensorFlow), but it can materially improve the data-processing layer that ML systems rely on, which justifies a moderately high score.",success
https://github.com/lakekeeper/lakekeeper,lakekeeper,"Lakekeeper is an Apache-licensed implementation of the Apache Iceberg REST Catalog specification, providing a secure and scalable catalog service (with UI) for managing Iceberg tables in lakehouse deployments. It is written in Rust and supports features like storage access management (e.g., vended credentials/remote signing for S3), OIDC authentication, and integrations with common query engines.",1100,data engineering|lakehouse|apache iceberg|data catalog|rust|kubernetes|security,7,"This repository provides an Apache Iceberg REST Catalog service (written in Rust) used to manage and govern Iceberg tables in lakehouse architectures, including authentication/authorization and cloud storage access controls. While it is not an ML library, it is directly useful for ML/data teams running Iceberg-based data lakes because it supports reliable table operations, multi-tenant governance, and integrations with engines and tools commonly used in data workflows (e.g., Spark and PyIceberg). It scores a 7 because it is a practical piece of data infrastructure that can underpin ML pipelines, but it is not focused on model training or MLOps itself and its community adoption is smaller than the most widely used data platforms.",success
https://github.com/matloff/fasteR,fasteR,"An instructional repository (“Fast Lane to Learning R!”) by Norm Matloff that teaches R from the ground up with a practical, problem-driven tutorial focused largely on base R and learning via hands-on exercises. The main course content is provided in the README, organized as a multi-lesson sequence from fundamentals through more advanced topics.",1100,R|data analysis|statistics|education|tutorial|base R|learning resources,7,"This repository is primarily a structured learning resource for becoming productive in R quickly, with lessons built around real data analysis problems and exercises (rather than being a reusable ML library). It is strongly relevant to data science workflows because R is a common environment for statistical computing, data cleaning, visualization, and regression-style modeling; however, its focus is broader R fundamentals and base R usage rather than modern ML training frameworks or MLOps tooling. The high star count indicates meaningful community adoption/interest, and its educational value for data practitioners is substantial, which supports a moderately high score.",success
https://github.com/nomic-ai/deepscatter,deepscatter,"Deepscatter is a browser-based visualization library for zoomable, animated scatterplots that can scale to extremely large datasets (up to billions of points) by loading tiled data on demand and rendering via WebGL/GPU. It uses Apache Arrow/Feather data (in a quadtree tiling format) and supports interactive exploration and transitions similar to a Vega-Lite-inspired grammar-of-graphics API.",1100,data-visualization|webgl|javascript|typescript|apache-arrow|large-scale-data|scatterplot,7,"This repository provides the core front-end engine for exploring very large embedded datasets as interactive, zoomable scatterplots in the browser (it is also used as the underlying graphics engine for Nomic Atlas). It is directly useful in ML/data workflows for visualizing high-dimensional embeddings (e.g., t-SNE/UMAP projections) and interactively inspecting clusters, labels, and metadata at scale. It is not an ML training/inference library, but it has strong practical value for exploratory data analysis and presenting ML embedding spaces, which warrants a moderately high score.",success
https://github.com/plotly/react-plotly.js,react-plotly.js,"A React component wrapper around plotly.js that lets you render interactive Plotly charts in React applications, with props and callbacks for updating plots, handling events, and managing layout/data changes.",1100,data-visualization|plotly|plotly.js|react|javascript|charting|frontend,7,"This repository provides a React component for embedding plotly.js interactive charts, focusing on client-side chart rendering, event handling, and update/state patterns in React. It is not an ML library, but it is directly useful in ML/data science workflows for building dashboards and exploratory data analysis UIs (e.g., visualizing model metrics, predictions, and distributions) within React apps. Plotly is widely used in the data community for visualization, and this wrapper improves integration in modern web frontends, which justifies a moderately high relevance score.",success
https://github.com/proplot-dev/proplot,proplot,"ProPlot is a Python library that wraps matplotlib to make it easier to create attractive, publication-quality plots with concise, high-level plotting and layout utilities. The repository notes that active development was indefinitely halted in summer 2023, with “ultraplot” positioned as its modern successor for newer matplotlib/cartopy/Python versions.",1100,python|data-visualization|matplotlib|plotting|scientific-computing|publication-quality-figures,7,"This repository provides a higher-level, more ergonomic interface on top of matplotlib aimed at producing publication-quality scientific graphics, which is a core need in data science workflows for EDA and communicating results. While it is not an ML framework or modeling toolkit, it is directly useful for ML/data practitioners for visualizing datasets, model diagnostics, and experiment outputs, and it has notable community adoption (about 1.1k GitHub stars). However, because development is stated to be halted since summer 2023 and a successor project is recommended for modern matplotlib versions, its practical ML/data value today is somewhat reduced versus actively maintained visualization libraries.",success
https://github.com/rhiever/datacleaner,datacleaner,"datacleaner is a Python library/CLI that automatically performs common dataset cleaning steps on pandas DataFrames to prepare data for analysis or modeling, including handling missing values and encoding categorical variables. It also supports a train/test (cross-validation) cleaning workflow to avoid data leakage by learning transformations on the training set and applying them to both splits.",1100,data-cleaning|data-preprocessing|python|pandas|scikit-learn|feature-encoding|missing-data,7,"This repository provides automated data cleaning utilities for pandas DataFrames (and a CLI), focusing on practical preprocessing tasks like missing-value imputation and categorical encoding, plus a CV-aware function to reduce train/test leakage. These steps are directly applicable to most ML workflows as part of feature preparation before modeling, and it integrates with common data science tooling (pandas and scikit-learn components). However, it is not an ML framework or end-to-end pipeline system, and its scope is limited to a small set of cleaning transformations, so it scores as moderately (not maximally) valuable for ML/data work.",success
https://github.com/scipipe/scipipe,scipipe,"SciPipe is a Go (Golang) library for building robust, flexible scientific workflows/pipelines that orchestrate command-line tools using flow-based programming concepts. It supports parallel execution, streaming between processes, reproducible runs with restart capability, and per-output-file audit/provenance logging.",1100,workflow-engine|data-pipelines|bioinformatics|cheminformatics|go|reproducible-research|dataflow|provenance,7,"This repository provides a workflow/pipeline programming library in Go for composing and executing complex pipelines of command-line tools with dataflow/flow-based programming patterns, including parallelism, streaming, and detailed audit/provenance logs. It is directly useful for data/ML workflows when experiments require parameter sweeps, branching pipelines, and reproducible orchestration of preprocessing/training/evaluation steps (especially in research-style pipelines). However, it is not an ML framework itself and adoption appears more niche compared to mainstream workflow systems, so it scores as moderately-high relevance rather than a core ML/data library.",success
https://github.com/thinh-vu/vnstock,vnstock,"A Python toolkit for Vietnamese financial market analysis and investing automation. It provides convenient functions to retrieve and work with market data (e.g., stocks, indices, derivatives, forex, crypto, news/events) typically returned as Pandas DataFrames/Series for further analysis and export.",1100,python|finance|quantitative-finance|stock-market-data|vietnam|pandas|data-analysis|trading,7,"vnstock is primarily a financial data access and analysis toolkit focused on Vietnam markets, designed to simplify collecting and manipulating market datasets in Python for research, dashboards, and automation workflows. It is directly useful for ML/data workflows because it produces structured tabular outputs (Pandas DataFrame/Series) that can feed feature engineering, backtesting research, and modeling pipelines, but it is not an ML framework itself (no core model training/serving). Community adoption appears solid for a niche domain (Vietnam market data), with ~1.1k GitHub stars and an actively released PyPI package (e.g., version 3.3.1 uploaded Dec 22, 2025), supporting the moderately-high score rather than an 8–10.",success
https://github.com/uhop/stream-json,stream-json,"A micro-library of Node.js stream components for building custom JSON processing pipelines with a minimal memory footprint. It provides streaming parsing (SAX-like token stream), filtering, and object streaming utilities to process JSON files far larger than available RAM.",1100,node.js|streaming|json|data-processing|etl|ndjson|jsonl|pipelines,7,"This repository provides streaming JSON parsing and composable stream components (parser/token stream, filters like pick/ignore/replace, and streamers like StreamValues/StreamArray/StreamObject) aimed at processing very large JSON with low memory usage. While it is not an ML library, it is directly useful in ML/data engineering workflows for building ingestion/ETL pipelines, preprocessing datasets, and converting/validating large JSON/JSONL/NDJSON inputs before training or analytics. Its strong applicability to large-scale data wrangling and pipeline construction justifies a moderately high score, though it lacks ML-specific modeling, training, or MLOps functionality.",success
https://github.com/apache/celeborn,apache/celeborn,"Apache Celeborn is an elastic, high-performance remote shuffle and intermediate-data service for big data compute engines (e.g., Spark/Flink/Hadoop). It decouples compute from shuffle/spill storage to improve performance, stability, and scalability via a master/worker/client architecture.",1000,data engineering|distributed systems|remote shuffle service|apache spark|apache flink|hadoop mapreduce|big data infrastructure|kubernetes,7,"Celeborn is primarily a data-infrastructure component (remote shuffle + spilled/intermediate data service) intended to accelerate and stabilize distributed data processing engines such as Spark and Flink. While it is not an ML library, it can materially benefit ML and data science workflows that rely on large-scale ETL/feature engineering/model training on Spark/Flink by improving shuffle performance and cluster elasticity. The score reflects strong indirect relevance and integration potential for ML/data platforms, but not direct model-building functionality or ML-specific APIs.",success
https://github.com/broadinstitute/cromwell,cromwell,"Cromwell is an open-source scientific workflow execution engine/workflow management system used heavily in bioinformatics. It runs workflows written in WDL (Workflow Description Language) across multiple backends (e.g., local, HPC schedulers, and cloud) to scale from one-off runs to large production executions.",1000,workflow engine|bioinformatics|WDL|pipelines|cloud computing|HPC|Scala,7,"This repository provides a production-grade workflow execution engine (Cromwell) that orchestrates data- and compute-intensive pipelines, especially in genomics/bioinformatics. While it is not an ML framework, it is highly applicable to ML/data workflows for running reproducible, scalable preprocessing/training/evaluation pipelines and managing execution across local/HPC/cloud environments. Its strong adoption in scientific computing (e.g., WDL-based genomics workflows) and integration potential with data tooling justify a moderately high score, but it scores below core ML libraries because it does not implement ML algorithms or model training APIs itself.",success
https://github.com/markwk/qs_ledger,qs_ledger,"QS Ledger is a Python 3 + Jupyter Notebook-based quantified-self toolkit that downloads and aggregates personal data from many self-tracking services into local storage, then provides starter notebooks/scripts for analysis and visualization (and some early predictive/ML exploration). It includes integrations such as Apple Health, Fitbit, Oura, Strava, RescueTime, Todoist, Toggl, Pocket, Goodreads, and others.",1000,python|jupyter-notebook|personal-data|quantified-self|data-analysis|data-visualization|data-aggregation|health-and-fitness,7,"This repository primarily provides data downloaders and analysis notebooks for aggregating quantified-self data (health, activity, time tracking, reading, etc.) from multiple services into local datasets, then exploring/visualizing them using common data-science tooling (e.g., Pandas/NumPy, Matplotlib/Seaborn; plus optional Dash/Plotly examples). It is not an ML framework, but it is directly useful for data-science workflows because it solves real-world data collection/cleaning/integration across heterogeneous personal-data sources and includes examples like correlation/regression exploration and mentions early predictive/forecasting work. Community adoption appears moderate (about 1k stars), and the educational value is solid for learning end-to-end personal analytics pipelines, so a moderately high score is appropriate.",success
https://github.com/pixiedust/pixiedust,pixiedust,"PixieDust is an open-source helper/productivity library for Jupyter notebooks (Python and Scala) that improves the data exploration experience. It provides a simple `display()` API for interactive visualizations (tables, charts, maps), notebook-embedded apps, Spark tooling (e.g., installing Spark packages), and related notebook utilities.",1000,jupyter|data-visualization|notebooks|pyspark|apache-spark|python|scala|interactive-widgets,7,"This repository primarily targets data exploration and presentation in Jupyter/Scala notebooks, offering interactive visualization via a single `display()` API plus extensibility for visualization/app plugins. It is directly useful in data science workflows (EDA, sharing insights, building notebook-based mini-apps), and includes Spark-focused utilities like installing Spark packages and monitoring Spark job progress. It is not an ML training/framework library, but it meaningfully improves the day-to-day notebook experience for data practitioners, hence a moderately high relevance score.",success
https://github.com/tidyverse/datascience-box,datascience-box,"Data Science Course in a Box: open-source teaching and learning materials for an introductory data science course using R, including slides, assignments, labs, exams, and a final project, plus instructor guidance on pedagogy and infrastructure.",1000,education|data-science|r|rstats|teaching|course-materials|quarto,7,"This repository primarily provides curriculum content (Quarto/R Markdown-style course materials) for teaching introductory data science in R rather than an ML library or framework. It is directly useful to data scientists, educators, and learners for building data analysis skills, reproducible workflows, and foundational statistical/data practices, but it does not focus on implementing or deploying machine learning models. Community adoption appears solid (around 1k GitHub stars), and its educational value for data/ML fundamentals is high, which supports a moderately high score.",success
https://github.com/tidyverse/readr,readr,"readr is an R package in the tidyverse that provides fast, user-friendly functions to read rectangular data from flat files such as CSV, TSV, fixed-width, and other delimited formats, with robust parsing and informative problem reporting.",1000,r|tidyverse|data-import|csv|data-wrangling|etl|data-science,7,"This repository implements the tidyverse 'readr' package, focused on efficient ingestion of rectangular data from common flat-file formats (e.g., CSV/TSV/fixed-width) into R with type parsing and diagnostics. While it is not an ML training framework, it is a core building block in data science/ML workflows because data loading and parsing are prerequisites for feature engineering and modeling. It is widely used in the R data community (as part of the tidyverse) and integrates smoothly with downstream analysis and modeling packages. The score reflects strong practical utility for data preparation, but only indirect ML functionality (no modeling algorithms or MLOps features).",success
https://github.com/leoncuhk/awesome-quant-ai,awesome-quant-ai,"A curated “awesome list” of resources for quantitative investing and trading, with an emphasis on applying AI/ML methods in finance. It organizes learning materials, tools/platforms, trading strategy concepts, books, and research papers related to quant AI.",136,quantitative finance|algorithmic trading|machine learning|artificial intelligence|reinforcement learning|NLP|research papers|awesome-list,7,"This repository is primarily a curated directory of AI/ML-in-quant-finance resources (papers, books, tools, and strategy overviews), rather than an executable ML library or dataset. It is directly useful for ML/data practitioners working in trading/quant research as a structured map of techniques (e.g., supervised learning, RL, generative models, and LLMs in finance) and pointers to tools and reading. Community adoption appears moderate (136 GitHub stars), which supports usefulness but not at the level of core ML tooling; hence a solid-but-not-top-tier score.",success
https://github.com/vinta/awesome-python,awesome-python,"A curated, opinionated “awesome list” of Python frameworks, libraries, software, and learning resources, organized by topic (e.g., data analysis, visualization, machine learning, NLP, web frameworks). It serves as a directory for discovering tools across the Python ecosystem.",277000,python|awesome-list|developer-resources|data-science|machine-learning|natural-language-processing|data-visualization,6,"This repository is primarily a curated index of Python tools and resources rather than a library/framework you install and use directly. It is still quite relevant to ML/data workflows because it includes dedicated sections for data analysis, data visualization, distributed computing, deep learning, machine learning, NLP, and recommender systems, making it a practical discovery and reference hub. The score reflects strong educational/discovery value and broad community adoption, but lower direct applicability compared with an actual ML/data toolkit or framework.",success
https://github.com/browser-use/browser-use,browser-use,"Browser-Use is a Python library for building LLM-powered browser agents that can navigate websites and automate online tasks. It provides an Agent/Browser abstraction (with optional cloud/stealth execution) plus quickstarts, templates, and examples for running automated workflows in a real Chromium browser.",75000,llm-agents|browser-automation|python|playwright-chromium|web-scraping|agent-tooling|automation,6,"The repository’s primary purpose is enabling LLM-driven web automation via a browser agent that can execute tasks on real websites (form filling, shopping flows, information lookup, etc.). While it is not a data-science library itself, it is directly useful in ML/data workflows for automated data collection, evaluation of agent behavior, and building agentic pipelines that need web interaction. Its strong community adoption (high stars) and clear agent/LLM integration make it valuable infrastructure for applied ML teams, but it’s not a core modeling/training framework, so it scores as moderately relevant rather than highly ML-specific.",success
https://github.com/grafana/grafana,grafana,"Grafana is an open and composable observability and data visualization platform used to build dashboards and alerts over metrics, logs, and traces. It connects to many data sources (for example Prometheus, Loki, Elasticsearch, InfluxDB, and Postgres) and provides a web UI for exploration and monitoring.",71600,observability|monitoring|data-visualization|dashboards|devops|metrics|logging|distributed-tracing,6,"This repository is the core Grafana platform for visualizing and alerting on operational data (metrics, logs, and traces) across many backends, making it a central tool in observability and monitoring. While it is not an ML framework, it is frequently used in data/ML-adjacent workflows to monitor data pipelines, feature stores, training jobs, inference services, and system performance, and to visualize time-series signals. Its broad adoption and strong integration ecosystem make it moderately valuable for data science and ML engineering operations, but it does not directly provide model training or data processing capabilities, which keeps the score below highly ML-specific tools.",success
https://github.com/freqtrade/freqtrade,freqtrade,"Freqtrade is a free, open-source cryptocurrency trading bot written in Python. It supports multiple exchanges and includes backtesting, plotting, risk/money management, a WebUI/Telegram control interface, and machine-learning-based strategy optimization (including its FreqAI module).",45800,cryptocurrency|algorithmic-trading|trading-bot|python|backtesting|machine-learning|reinforcement-learning|docker,6,"This repository primarily provides an automated crypto trading bot platform (execution, exchange integration, configuration, WebUI/Telegram control) with strong tooling for backtesting and strategy development. It is meaningfully related to ML/data workflows via built-in ML-driven strategy optimization and adaptive prediction modeling through FreqAI, plus data download/conversion utilities and hyperparameter optimization features. However, ML is not its sole or primary purpose (it is first a trading/execution framework), and it is not a general ML library used broadly outside trading contexts. For ML practitioners focused on quantitative finance, it offers solid practical and educational value, but it’s less directly applicable to general-purpose ML/data engineering use cases.",success
https://github.com/metabase/metabase,metabase,"Metabase is an open-source business intelligence and embedded analytics platform that lets teams connect to databases, explore data, and build dashboards and reports. It provides a web UI for querying (including a query builder and SQL), visualization, sharing, and embedding analytics into products.",45500,business intelligence|analytics|data visualization|dashboards|sql|embedded analytics|data exploration,6,"This repository contains Metabase, a widely used BI/analytics application for connecting to data sources and enabling interactive exploration, querying, and dashboarding. While it is not an ML framework or model-training tool, it is directly useful in data science workflows for data exploration, validation, stakeholder reporting, and monitoring datasets or model outputs via dashboards. Its broad adoption and integrations with many databases make it a practical data tool, but its contribution to core ML tasks (training, inference, MLOps) is indirect—hence a moderately relevant score.",success
https://github.com/ccxt/ccxt,ccxt,"CCXT is a multi-language cryptocurrency exchange trading library that provides a unified API to connect to and trade on 100+ crypto exchanges. It supports fetching standardized market data (tickers, order books, trades, OHLCV) and interacting with private trading/account endpoints across exchanges.",40500,cryptocurrency|trading-api|exchange-integration|market-data|algorithmic-trading|typescript|python,6,"This repository’s primary purpose is to provide a unified, normalized interface to many cryptocurrency exchange APIs for market-data retrieval and trading operations, which is foundational plumbing rather than an ML library. It is directly useful in ML/data workflows for acquiring historical and real-time market data, standardizing it across venues, and feeding it into feature engineering, backtesting, and modeling pipelines. It is widely adopted in crypto trading and quant communities, increasing its practical value for data science work in that domain. The score is not higher because it does not implement ML algorithms itself; it mainly enables data access and execution rather than modeling.",success
https://github.com/PostHog/posthog,posthog,"PostHog is an all-in-one, open-source product analytics and user insights platform. It includes product/web analytics, session replay, feature flags and experimentation, surveys, data warehouse/CDP capabilities, error tracking, and an AI assistant for debugging and product development.",30700,product analytics|event tracking|feature flags|experimentation|session replay|data warehouse|customer data platform|web analytics,6,"This repository powers PostHog, a product analytics platform focused on collecting, storing, and analyzing event/user behavioral data, plus experimentation and data warehouse/CDP features. It is not an ML framework, but it is highly relevant to data workflows because it provides large-scale event instrumentation, data pipelines, warehousing, and analytics that can feed ML/DS use cases (e.g., churn prediction, funnel analysis, growth modeling). Its direct ML applicability is mostly indirect (data collection/activation and experiment infrastructure rather than model training), which supports a mid-range score. Strong community adoption and broad data-feature surface area increase its practical value for data teams even when not explicitly “ML-first”.",success
https://github.com/e2b-dev/awesome-ai-agents,awesome-ai-agents,"A curated “awesome list” of AI autonomous agents, collecting links to agent projects and related resources in the AI agent ecosystem.",25000,artificial intelligence|autonomous agents|awesome list|llm|openai|gpt|python,6,"This repository is primarily a curated directory of AI autonomous agent projects rather than a library or framework you install and run. It’s moderately valuable for ML/data workflows because it helps practitioners discover agent implementations, tools, and approaches relevant to LLM-based automation and experimentation, but it does not itself provide datasets, training code, evaluation suites, or core ML infrastructure. The strong community adoption (high star count) increases its practical utility as a discovery and learning resource, which supports a mid-range score rather than a high one.",success
https://github.com/wshobson/agents,agents,"A production-ready marketplace of Claude Code plugins that provide intelligent automation and multi-agent orchestration for software development. It bundles dozens of focused plugins containing specialized agents, workflow orchestrators, reusable “agent skills,” and development tools that can be installed selectively to minimize context/token usage.",24700,AI agents|LLM tooling|Claude Code|developer productivity|workflow orchestration|automation|MLOps,6,"This repository is primarily a curated plugin/agent marketplace for Claude Code, aimed at orchestrating multi-agent workflows for modern software development (e.g., code review, security hardening, infrastructure operations) rather than being a standalone ML library. It includes explicit AI/ML and data-related plugin categories and mentions workflows like ML pipelines and MLOps, which can be useful for ML engineers as process/tooling support, but it does not appear to provide core model training/inference code or data science algorithms. Given its strong relevance to LLM-enabled developer workflows and moderate applicability to MLOps/data engineering tasks (but not core ML), a 6/10 reflects moderate relevance. Community adoption is significant (tens of thousands of stars), improving its practical value for teams adopting Claude Code-based automation.",success
https://github.com/humanlayer/12-factor-agents,12-factor-agents,"A public guide (in the spirit of 12 Factor Apps) that defines “12 factors”/principles for building reliable, production-ready LLM-powered agents and applications, including guidance on prompts, context windows, tool calls, control flow, and operational concerns like pause/resume and human-in-the-loop.",17600,llm|ai-agents|agent-engineering|prompt-engineering|context-engineering|production-ai|developer-guide,6,"This repository is primarily an engineering principles/architecture guide for building robust LLM-powered agent software (e.g., tool calling patterns, owning prompts/context, control flow, state management, and human-in-the-loop), rather than a dataset or a core ML training/inference library. It is still meaningfully relevant to ML/LLM practitioners because it directly addresses how to operationalize LLM systems in production—an important part of real-world ML workflows (reliability, observability patterns, agent execution design). The score is moderate because it provides high educational and integration value for applied LLM/agent development, but it is not a widely-adopted ML framework nor a data/algorithm-focused package.",success
https://github.com/nautechsystems/nautilus_trader,nautilus_trader,"NautilusTrader is an open-source, high-performance algorithmic trading platform and event-driven backtester designed for developing, backtesting, and deploying automated trading strategies with the same codebase. It targets production-grade, multi-asset, multi-venue trading with a Rust-powered core and Python-native workflow.",17200,algorithmic trading|quantitative finance|backtesting|event-driven systems|python|rust|high-frequency trading,6,"This repository primarily provides an event-driven trading engine/backtester for quantitative strategy research and live deployment, rather than a general-purpose ML framework. It is relevant to ML/data workflows because it can generate and consume market data streams, support systematic experimentation, and is explicitly positioned as fast enough for training AI trading agents (e.g., RL/ES) within a backtesting loop. However, ML is not the core focus of the project (it’s a trading platform first), and it does not appear to center on model training utilities comparable to mainstream ML/data libraries, so it scores as moderately relevant rather than highly ML-centric.",success
https://github.com/heibaiying/BigData-Notes,BigData-Notes,"A Chinese-language “big data” learning guide and notes collection covering common data engineering platforms and components (e.g., Hadoop/HDFS/YARN, Hive, Spark, Flink, Storm, HBase, Kafka, Zookeeper), with tutorials, conceptual explanations, and examples organized by topic.",16800,data engineering|big data|Apache Hadoop|Apache Spark|Apache Flink|Apache Kafka|distributed systems|tutorials,6,"This repository is primarily an educational notes/guide collection for big data and data engineering systems (Hadoop, Spark, Flink, Kafka, etc.), rather than a library for training or deploying ML models. It is still relevant to ML/data workflows because these technologies are commonly used for data ingestion, storage, batch/stream processing, and feature/data pipeline construction that support ML. Community adoption appears strong (high star count), boosting its value as a reference, but it is not a core ML framework and its direct ML applicability is indirect, so a mid-range score is appropriate.",success
https://github.com/prestodb/presto,presto,"PrestoDB is a distributed SQL query engine designed for fast, interactive analytics on big data. It can query data where it lives via connectors to multiple data sources (e.g., data lakes and databases) and execute queries in parallel across a cluster.",16600,distributed-sql|query-engine|big-data|data-warehousing|data-lake|java|analytics,6,"This repository contains PrestoDB, a high-performance distributed SQL engine used to run interactive analytics queries across large datasets and heterogeneous data sources. While it is not an ML framework, it is commonly used in data science and ML pipelines for feature extraction, dataset preparation, exploratory analysis, and querying data lakes/warehouses at scale. Its broad connector ecosystem and adoption in data engineering workflows make it materially useful to ML teams, but its primary focus is SQL analytics infrastructure rather than model training or MLOps, so a mid-high infrastructure relevance score is appropriate.",success
https://github.com/QuantConnect/Lean,Lean,"LEAN is QuantConnect’s open-source, event-driven algorithmic trading engine for strategy research, backtesting, optimization, and live trading across multiple asset classes. It’s modular and extensible, with built-in integrations for brokerages/data providers and supports writing algorithms in C# and Python.",15700,algorithmic trading|quantitative finance|backtesting|live trading|C#|Python|trading platform,6,"This repository is primarily an algorithmic trading engine (research/backtesting/live execution) rather than a dedicated machine learning framework, but it is highly relevant to data/ML practitioners working in quantitative finance. It provides a mature environment for ingesting market data, running large-scale experiments (backtests/optimizations), and deploying strategies—common tasks in financial data science workflows. However, ML model training and MLOps are not the core focus of the repo, so its value is strongest as infrastructure for data-driven trading research rather than as an ML toolkit itself.",success
https://github.com/apexcharts/apexcharts.js,apexcharts.js,"A modern JavaScript charting library for building interactive, responsive data visualizations (SVG-based) with a simple API and many ready-to-use chart types and examples. It supports direct script usage as well as integration via framework wrappers (e.g., React/Vue/Angular).",15000,data visualization|javascript|charting library|svg|frontend|dashboards|typescript types,6,"This repository primarily provides a frontend charting/visualization library (ApexCharts) used to render interactive charts in web applications and dashboards. While it is not an ML framework or data-processing toolkit, it is moderately valuable in ML/data workflows for communicating results (EDA summaries, model metrics, time series plots) in dashboards and reports. Its wide adoption and breadth of chart types make it a practical visualization component for data products, but it does not directly support model training, feature engineering, or pipelines, so it scores as moderately relevant rather than core ML/data infrastructure.",success
https://github.com/zhisheng17/flink-learning,flink-learning,"A comprehensive Apache Flink learning repository (Java/Maven) that collects tutorials and runnable examples covering Flink concepts, DataStream API, Table/SQL, connectors, metrics, performance tuning, and real-world project cases (e.g., PV/UV, log storage, large-scale deduplication, monitoring/alerting).",15000,apache-flink|stream-processing|data-engineering|real-time-analytics|java|flink-sql|connectors,6,"This repository is primarily an educational and example-driven codebase for Apache Flink (stream processing), including connectors and practical production-style streaming projects. It is valuable for ML/data workflows mainly as upstream data infrastructure (real-time ingestion, transformations, feature/event pipelines) rather than for model training or ML algorithms themselves. Community adoption appears strong (around 15k GitHub stars), and the learning materials and runnable demos can be directly useful to data engineers/ML engineers building streaming data pipelines. It earns a 6/10 because it is moderately relevant to ML/data work as a data processing foundation, but it is not an ML-centric library or MLOps/modeling toolkit.",success
https://github.com/andkret/Cookbook,Cookbook,"The Data Engineering Cookbook is a community-driven, markdown-based knowledge base and learning resource covering data engineering fundamentals, platform/pipeline design, tools, best practices, tutorials, case studies, and interview preparation materials.",14900,data engineering|data pipelines|ETL|big data|cloud platforms|learning resource|interview questions,6,"This repository is primarily an educational “cookbook” for data engineering, collecting structured notes and links on topics like data platforms, pipeline design, ingestion/buffering/processing/storage, and practical tooling. It supports ML/data workflows indirectly by helping practitioners build and operate the data infrastructure that ML projects typically depend on (data sources, pipelines, platform architecture, best practices). It is not an ML library for modeling/training, but its broad coverage and strong adoption (14.9k stars) make it a useful reference for data/ML engineers, warranting a moderately relevant score.",success
https://github.com/apache/doris,apache/doris,"Apache Doris is an MPP-based, real-time analytical (OLAP) database providing high-performance SQL analytics with low-latency queries, designed for scenarios like reporting, ad-hoc analysis, and lakehouse query acceleration. It emphasizes ease of use, MySQL protocol compatibility, and unified analytics across data warehouse/lake sources.",14900,analytics database|olap|data warehouse|lakehouse|sql|mpp|real-time analytics|big data,6,"This repository implements Apache Doris, a distributed MPP analytical database optimized for fast SQL queries over large datasets (real-time analytics, reporting, ad-hoc queries, and lakehouse acceleration). While it is not an ML framework, it is directly useful in ML/data workflows as a high-performance analytical store for feature exploration, aggregation, BI, and serving analytical queries that support modeling and monitoring. Its strong fit for data engineering and analytics infrastructure makes it moderately valuable for data science/ML teams, but it does not provide core model training/inference capabilities, so it scores below dedicated ML tools.",success
https://github.com/AstrBotDevs/AstrBot,AstrBot,"AstrBot is an open-source agentic IM chatbot infrastructure that connects to many instant-messaging platforms and integrates multiple LLM providers. It supports plugins, a Web UI, and AI features like multimodal chat, agents/MCP, and knowledge-base workflows.",14800,chatbot|llm|agentic-ai|mcp|python|docker|im-platform-integration|plugin-system,6,"AstrBot’s primary purpose is to provide a production-oriented chatbot/agent platform that integrates IM channels (e.g., Telegram/Slack/QQ) with LLM providers and extensibility via plugins and a Web UI. It is ML-adjacent rather than an ML library: data scientists can use it to deploy and orchestrate LLM-based agents, knowledge-base chat, and multimodal features, but it is not focused on model training, evaluation, or core data processing. The strong LLM/agent integration and ecosystem make it moderately valuable for applied ML/LLM productization and experimentation, hence a mid-range score.",success
https://github.com/bulletphysics/bullet3,bullet3,"Official C++ source repository for the Bullet Physics SDK, providing real-time collision detection and multi-physics simulation (rigid body dynamics, constraints, etc.) used in VR, games, visual effects, robotics, and related simulation workloads. The repo also references and supports Python bindings via PyBullet for easier use in robotics and reinforcement learning workflows.",14100,physics-simulation|collision-detection|rigid-body-dynamics|robotics|reinforcement-learning|c-plus-plus|pybullet,6,"Bullet3’s primary purpose is real-time physics simulation (collision detection and multi-physics) rather than data science/ML, but it is widely used as a simulation backend for robotics and reinforcement learning via PyBullet. This makes it practically useful for ML workflows that rely on simulated environments (training RL agents, generating synthetic trajectories, benchmarking control policies). It is not an ML framework and doesn’t provide modeling/training utilities itself, so its value is moderate and mainly as an enabling simulation component rather than a core ML/data tool.",success
https://github.com/apache/druid,apache/druid,"Apache Druid is an open-source, high-performance real-time analytics (OLAP) database designed for sub-second queries on streaming and batch data at scale. It supports fast ingestion (including native Kafka ingestion), high-concurrency interactive queries, and a web console for managing ingestion and querying.",13900,real-time analytics|OLAP database|data engineering|streaming ingestion|Apache Kafka|distributed systems|SQL analytics|time-series,6,"This repository implements Apache Druid, a real-time analytics database focused on fast ingestion and sub-second OLAP-style queries at scale rather than model training. It is moderately valuable for ML/data workflows because it can serve as a high-performance analytics store for feature monitoring, operational dashboards, exploratory analysis, and powering data products, with common integrations like Kafka-based streaming ingestion and SQL querying. It is widely adopted in data engineering/analytics contexts, but it is not an ML framework and does not directly provide modeling algorithms, training pipelines, or MLOps tooling, which is why it scores a 6 rather than 8+.",success
https://github.com/anthropics/claude-quickstarts,claude-quickstarts,"A collection of deployable starter projects (quickstarts) for building applications with the Claude API. It includes multiple example apps such as a customer support agent, a financial data analyst with interactive visualization, computer-use and browser-automation demos, and an autonomous coding agent built with the Claude Agent SDK.",13400,Claude API|LLM|AI agents|Python|TypeScript|agent SDK|browser automation|data analysis,6,"This repository is primarily a set of application quickstarts demonstrating how to build agentic apps on top of the Claude API (e.g., support agent, coding agent, computer use, browser tools). It is moderately relevant to ML/data workflows because it helps data/ML practitioners operationalize LLM-powered systems and includes a “financial data analyst” quickstart that uses interactive visualization for analysis, but it is not a core ML training/modeling library. The relatively high GitHub adoption (13.4k stars) and practical, deployable examples increase its educational and integration value for teams building LLM-enabled data products, which supports a mid-range score rather than a low one.",success
https://github.com/triggerdotdev/trigger.dev,trigger.dev,"Trigger.dev is an open-source platform for building and deploying AI agents and workflows in TypeScript. It provides durable, long-running background tasks with retries, queues, observability/monitoring, and elastic scaling.",13200,ai-agents|workflow-orchestration|background-jobs|typescript|developer-tools|observability|queues,6,"This repository is primarily a developer platform for orchestrating and running long-lived AI workflows/agents (durable tasks, retries, queues, monitoring) rather than an ML algorithm library. It can be very useful in ML/LLM applications for productionizing and operating agentic systems, model-calling pipelines, and other long-running data/AI jobs (e.g., batch inference, tool-using agents, human-in-the-loop flows). However, it is not itself a data-processing framework or model-training toolkit, so its relevance is moderate and mostly on the MLOps/workflow side rather than core data science.",success
https://github.com/agent0ai/agent-zero,agent-zero,"Agent Zero is a personal, prompt-driven agentic AI framework designed to be transparent and highly customizable, with persistent memory, multi-agent collaboration, and the ability to use the computer (terminal/code execution) as a tool to complete tasks. It includes a Web UI and Docker-based setup, and supports isolated “Projects” workspaces with separate prompts, files, memory, and secrets.",13100,ai agents|llm|agentic framework|multi-agent|automation|python|docker|web ui,6,"This repository provides an agentic LLM framework focused on building a general-purpose personal assistant that can execute code/terminal actions, manage persistent memory, and coordinate multiple agent instances, with an interactive Web UI and Docker deployment. It relates to ML/data workflows mainly as a practical orchestration layer for LLM-powered research, automation, and data-analysis tasks, rather than as a library for model training or core data processing. Community adoption appears strong (13.1k stars), which increases its practical value for ML engineers experimenting with agent workflows. The score is 6 because it is moderately relevant to ML/data work (useful tooling around LLM applications) but not a primary ML framework or dataset/feature engineering library.",success
https://github.com/jpmorganchase/python-training,python-training,"A J.P. Morgan-authored Python training course aimed at business analysts and traders, introducing numerical computing and data visualization through Jupyter notebooks. The repo is designed for instructor-led sessions and includes datasets plus a Binder/JupyterLab-friendly setup for running the materials interactively.",12500,python|jupyter-notebook|data-science|data-visualization|numerical-computing|finance|binder|jupyterlab,6,"This repository is primarily an educational Python course for analysts/traders, focused on numerical computing and data visualization via Jupyter notebooks rather than building ML models or ML infrastructure. It is relevant to data workflows because it teaches core Python data-science tooling patterns (interactive notebooks, datasets, visualization), which are foundational for many ML and analytics tasks. However, it appears more general/introductory and finance-analytics oriented than ML-specific (e.g., no clear emphasis on model training, MLOps, or ML frameworks). The high star count suggests strong community adoption for training purposes, boosting its practical educational value for data practitioners.",success
https://github.com/mapbox/mapbox-gl-js,mapbox-gl-js,"Mapbox GL JS is a JavaScript library for building interactive, highly customizable vector maps in the browser. It renders Mapbox-styled vector tiles using WebGL and includes tooling, tests, and shared fixtures used across the Mapbox GL ecosystem.",12100,geospatial|web-mapping|data-visualization|javascript|typescript|webgl|vector-tiles,6,"This repository provides a high-performance WebGL-based mapping and geospatial visualization engine for the browser, primarily aimed at building interactive maps and rendering vector tiles/styles. While it is not an ML library, it is moderately valuable for ML/data workflows because it is widely used to visualize spatial datasets, model outputs (e.g., predictions over geography), and large-scale geospatial features interactively on the web. Its ecosystem support for heatmaps, clustering, and styling of data-driven layers makes it a practical companion for presenting and exploring geospatial analytics results, but it does not provide core ML training/inference capabilities.",success
https://github.com/The-Pocket/PocketFlow-Tutorial-Codebase-Knowledge,PocketFlow-Tutorial-Codebase-Knowledge,"A Pocket Flow tutorial project that builds an AI agent to crawl a GitHub repository (or local codebase), construct a knowledge base from the code, and generate beginner-friendly tutorials (with visualizations) that explain the codebase’s core abstractions and how they interact.",12000,LLM|AI agents|code understanding|documentation generation|GitHub crawler|Python|developer tools,6,"This repository is primarily a developer-tooling project: it analyzes source code from GitHub/local directories and uses an LLM to produce structured, beginner-friendly tutorials about how a codebase works. It relates to ML workflows mainly as an applied LLM/agent pipeline (prompting, orchestration, caching, and automation) rather than as a data science or model-training library. The score reflects moderate relevance: it can be useful for ML engineers building LLM-powered internal tools (e.g., repo analysis, documentation, knowledge-base generation), but it is not a core data/ML framework and is not directly focused on datasets, training, evaluation, or MLOps.",success
https://github.com/antvis/G6,G6,"G6 is an AntV graph visualization engine/framework in TypeScript/JavaScript for building interactive graph (network) visualization and analysis applications. It includes rendering (Canvas/SVG/WebGL), layouts, interactions, animations, themes, and a plugin/extensibility system.",11900,graph visualization|network analysis|data visualization|typescript|javascript|webgl|frontend,6,"This repository provides a graph visualization and interaction framework (rendering + layouts + behaviors + plugins) aimed at building graph analytics/visualization applications in the browser or Node.js. It’s moderately relevant to ML/data workflows because graph data is common in ML (e.g., knowledge graphs, entity networks) and G6 can be used to explore, debug, and present relational datasets and graph-analysis outputs, but it is not a modeling/training library. Its adoption in visualization/front-end ecosystems and its support for multiple renderers and graph layouts make it practically useful for data science communication and tooling, warranting a mid-to-high relevance score rather than a core-ML score.",success
https://github.com/FormidableLabs/victory,victory,"Victory is an ecosystem of composable React components for building interactive data visualizations (charts) using a declarative API. It supports common chart types (e.g., pie charts) and is designed to be used in React applications (with a closely related Victory Native offering for React Native).",11200,react|data-visualization|charts|d3|frontend|javascript|typescript,6,"This repository provides reusable React components for creating interactive data visualizations (e.g., charts like pies, axes, etc.) in web apps. While it is not an ML library, data scientists and ML engineers often need to present and explore model outputs and datasets, and Victory can be used to build dashboards and analytic UIs for that purpose. Its relevance is therefore moderate: it’s directly useful for communicating data/ML results, but it does not help with data processing, modeling, training, or MLOps.",success
https://github.com/Jack-Cherish/PythonPark,PythonPark,"A curated, tutorial-style collection for learning Python and related topics, organized as a “self-study programming path” with learning guides and resource links. It includes sections covering data structures/algorithms, web scraping, and hands-on machine learning/deep learning materials and references.",11100,python|learning-resources|machine-learning|deep-learning|data-structures-and-algorithms|web-scraping|tutorials,6,"PythonPark is primarily an educational/curation repository: it organizes a self-study roadmap and aggregates links/materials across Python fundamentals, algorithms, and AI topics (including machine learning and deep learning). It can be valuable for learners and for discovering ML/DL resources, but it is not a focused ML library, framework, dataset, or production-grade tooling for model training/pipelines. Its relatively large community interest (11.1k stars) suggests strong adoption as a learning hub, which raises its educational value for ML/data workflows, but direct integration and practical ML engineering utility are moderate rather than high.",success
https://github.com/bytedance/trae-agent,trae-agent,"Trae Agent is an LLM-based CLI agent for general-purpose software engineering tasks, capable of interpreting natural-language instructions and executing workflows via tools like file editing and bash. It supports multiple LLM providers (e.g., OpenAI, Anthropic, Azure, OpenRouter, Ollama, Google Gemini) and includes features like interactive mode, trajectory recording, and flexible YAML-based configuration.",10500,llm-agents|cli|software-engineering|developer-tools|python|agentic-workflows|mcp,6,"This repository primarily provides an LLM-powered software-engineering agent (a CLI tool) rather than a data-science library or ML training framework. It is still meaningfully relevant to ML/DS workflows because it integrates with many LLM providers and can automate coding, experimentation, and evaluation-style workflows (e.g., reproducible runs and trajectory logging), which ML engineers may leverage in research or tooling. Community adoption appears strong (about 10.5k GitHub stars), but its direct applicability to core data tasks (ETL, modeling, training, MLOps pipelines) is indirect, so a mid-range score is appropriate.",success
https://github.com/esimov/caire,caire,"Caire is a Go content-aware image resizing library/CLI implementing seam carving (energy-map + dynamic programming) to shrink or enlarge images while preserving salient content. It includes features like GUI progress/preview, directory batch processing, masks, and optional face detection to avoid deforming faces.",10500,computer vision|image processing|seam carving|content-aware resizing|golang|cli tool|face detection,6,"This repository primarily provides a computer-vision image processing algorithm (seam carving) packaged as a Go library and command-line tool for content-aware resizing. It’s relevant to ML/data workflows insofar as it can be used for dataset preparation/augmentation (e.g., resizing while preserving important regions) and includes optional face detection integration, but it is not an ML training/inference framework itself. The project appears widely adopted for its niche (notably high GitHub stars), and it has educational value for understanding energy-map based optimization in vision, which supports a moderately relevant score rather than a core-ML score.",success
https://github.com/leeoniya/uPlot,uPlot,"uPlot is a small, fast, memory-efficient Canvas 2D charting library focused on rendering time series, lines, areas, OHLC, and bar charts with excellent interactive performance (zoom/cursor) and a plugin-friendly API.",9700,javascript|data-visualization|charting|time-series|canvas|web-development|performance,6,"This repository provides a high-performance JavaScript plotting library optimized for interactive time-series and related charts, emphasizing small bundle size and fast rendering rather than data processing. It is moderately relevant to ML/data workflows because data scientists and ML engineers often need lightweight, responsive visualization for exploratory analysis and monitoring dashboards, but uPlot explicitly avoids built-in statistics/aggregation and expects pre-processed data. The project appears widely adopted (thousands of stars) and can integrate well into ML observability and analytics front-ends, but it is not a core ML or data-engineering toolkit, which keeps the score in the mid range.",success
https://github.com/c3js/c3,c3,C3.js is a reusable JavaScript charting library built on top of D3 that generates interactive SVG charts for deeper integration into web applications. It provides a higher-level API than raw D3 for common chart types and interactions.,9400,data visualization|javascript|d3|charting library|svg|web development|interactive visualizations,6,"This repository provides a D3-based charting library (C3.js) focused on producing interactive charts for the web using a simpler API than directly using D3. It is moderately relevant to ML/data workflows because visualization is a common part of data analysis and model evaluation, and C3 can be used to present results in dashboards and web apps. However, it is not an ML library, does not provide data processing/modeling functionality, and is primarily aimed at front-end chart rendering rather than data science computation. The score reflects strong usefulness for communicating and exploring results visually, but indirect applicability to core ML tasks.",success
https://github.com/je-suis-tm/quant-trading,quant-trading,"A collection of Python scripts and small projects for quantitative trading research, primarily focused on backtesting technical-indicator strategies (e.g., MACD, RSI, Bollinger Bands) plus a few options/quantamental/stat-arb style experiments (e.g., VIX calculator, pair trading, Monte Carlo). The repository is oriented toward historical backtesting/forward testing with simplified assumptions (e.g., frictionless trading) rather than a production-grade trading system.",8900,quantitative finance|algorithmic trading|backtesting|python|technical analysis|options|statistical arbitrage,6,"This repository is primarily a set of Python research/backtesting scripts and mini-projects for quantitative trading strategies (technical indicators, some options work like a VIX calculator, and some statistical/quantamental projects). It’s relevant to data science because it involves time-series market data handling, feature/indicator engineering, and empirical evaluation via backtests, but it is not an ML-focused toolkit (no clear model training framework, standardized datasets, or MLOps-style integration). Educational value is moderate-to-high for learning practical quant backtesting patterns and strategy prototyping, but community adoption is mainly as a reference repo rather than a widely used library—supporting a mid-range score. ",success
https://github.com/rawgraphs/rawgraphs-app,rawgraphs-app,"RAWGraphs App is the web application for creating custom, editable vector-based data visualizations in the browser on top of the RAWGraphs core (built around d3.js). It focuses on turning tabular data (CSV/spreadsheets, etc.) into SVG visualizations that can be further edited in tools like Illustrator or Inkscape, with client-side (no-server) data processing.",8900,data visualization|d3.js|svg|javascript|web application|charting|frontend,6,"This repository provides the RAWGraphs web interface for importing tabular data and generating a wide range of customizable, vector-based visualizations. It is strongly relevant to data science workflows for exploratory analysis and communication (rapid chart prototyping, exporting SVG for publication-quality refinement), but it does not provide ML algorithms, model training, or MLOps capabilities. The score reflects high usefulness for data visualization and presentation in data workflows, with indirect (rather than core) ML applicability.",success
https://github.com/pymupdf/PyMuPDF,PyMuPDF,"PyMuPDF provides high-performance Python bindings to MuPDF for working with PDF and other document formats, including fast rendering, text/image extraction, and document manipulation. It supports tasks like converting documents, accessing annotations/links/metadata, and optional OCR integrations.",8800,python|pdf-processing|document-parsing|text-extraction|ocr|data-extraction|document-conversion|table-extraction,6,"This repository is primarily a fast PDF/document processing and manipulation library (rendering, extraction, conversion, and related utilities), rather than an ML framework. It is nonetheless highly useful in ML/data workflows because PDF parsing and reliable text/table extraction are common prerequisites for NLP pipelines, RAG/LLM ingestion, and document analytics. Community adoption appears strong (thousands of stars and tens of thousands of dependent repos), but its core value is data preparation/ingestion rather than modeling—so it rates as moderately relevant rather than a core ML tool.",success
https://github.com/risingwavelabs/risingwave,risingwave,"RisingWave is a real-time event streaming platform for ingesting, transforming, and serving streaming data at scale. It offers a Postgres-compatible SQL interface plus a DataFrame-style Python interface, and includes built-in support for Apache Iceberg tables for lakehouse ingestion and management.",8700,stream processing|real-time analytics|event streaming|data engineering|lakehouse|apache iceberg|postgresql-compatible|rust,6,"This repository implements RisingWave, a streaming data platform that continuously ingests events, performs incremental computations (e.g., joins/materialized views), and serves low-latency analytical queries, with first-class Apache Iceberg support. It is not an ML framework, but it is directly useful in ML/data workflows for building real-time feature pipelines, streaming ETL, and maintaining fresh datasets/features in a lakehouse or serving layer. Community adoption appears solid (thousands of GitHub stars), and the SQL + Python interfaces increase integration potential for data teams, but it remains primarily data infrastructure rather than model training/inference, so a mid-to-high relevance score fits.",success
https://github.com/anvaka/city-roads,city-roads,"A browser-based visualization tool that renders every road in a selected city using OpenStreetMap data. It supports fast loading via a cached dataset for ~3,000 cities and includes a scripting/scene API for programmatic map-based generative art.",8500,geospatial|OpenStreetMap|data-visualization|webgl|generative-art|javascript|vue,6,"city-roads primarily visualizes city road networks by fetching and caching OpenStreetMap/Overpass data and rendering it in the browser (often via GPU/WebGL), with optional scripting to automate scenes and exports. While it is not an ML library, it is moderately valuable for data/ML workflows as a practical tool for acquiring and visualizing geospatial road-network data, prototyping spatial analyses, and generating datasets/figures for exploratory analysis or presentations. Community adoption is solid (8.5k stars), but it lacks ML-specific features like model training, feature engineering, or direct integration with ML frameworks, which keeps the score in the mid range.",success
https://github.com/redpanda-data/connect,connect,"Redpanda Connect is a high-performance, resilient stream processor for building declarative data pipelines that connect many sources and sinks and apply transformations (hydration/enrichment/filtering) in-flight. It’s designed to be easy to deploy and operate (static binary or Docker), with built-in observability (health checks, metrics, tracing) and a dedicated mapping language for transformations.",8500,data engineering|stream processing|ETL/ELT|Kafka|connectors|Go|observability,6,"This repository provides an operational stream-processing and connector framework for moving and transforming data between many systems (cloud services, Kafka/NATS, databases, object stores, HTTP, etc.) in a declarative pipeline model. While it is not an ML library, it is directly useful in ML/data workflows for building real-time ingestion, feature/metadata enrichment, and routing/normalization pipelines feeding warehouses, feature stores, or online inference services. The strong integration surface (many inputs/outputs, transformation language, and production-oriented monitoring/tracing) makes it moderately valuable for data/ML engineers, but it is not primarily focused on model training or ML-specific capabilities. ",success
https://github.com/visgl/react-map-gl,react-map-gl,"A suite of React components that provides a React-friendly, reactive wrapper for Mapbox GL JS and MapLibre GL JS, enabling fully controlled maps and map UI components (e.g., markers, popups, controls) in React applications. It is part of the vis.gl ecosystem and is designed to integrate well with WebGL visualization layers such as deck.gl.",8400,react|web-mapping|geospatial-visualization|mapbox-gl|maplibre-gl|webgl|typescript|data-visualization,6,"This repository primarily provides React components/wrappers for interactive web maps using Mapbox GL JS and MapLibre GL JS, focusing on UI integration, reactive state management, and extensibility rather than ML algorithms. It is moderately relevant to ML/data workflows because it is commonly used to visualize geospatial datasets, model outputs, and analytic results (e.g., spatial predictions, clustering, trajectories) in web dashboards, often in combination with visualization tools like deck.gl. The score reflects strong utility for geospatial data visualization in data science products, but limited direct support for data processing, modeling, training, or MLOps.",success
https://github.com/YaoFANGUK/video-subtitle-extractor,video-subtitle-extractor,"Video-subtitle-extractor (VSE) is a GUI tool that extracts hard-coded subtitles (hardsubs) from video frames using local deep-learning OCR (no third-party OCR API required) and generates subtitle files such as .srt (and optionally .txt). It includes subtitle-region detection, text recognition, duplicate-line removal, and supports batch processing and many languages.",8300,computer vision|ocr|subtitle extraction|video processing|deep learning|python|gui tool,6,"This repository provides an end-to-end pipeline for extracting text from video (subtitle region detection + OCR) and exporting structured subtitle outputs (e.g., SRT). It is directly useful in ML/data workflows for building datasets from video, preprocessing media for NLP (transcripts/subtitles), or benchmarking OCR/subtitle detection, but it is primarily an applied tool rather than a general ML framework. The use of deep-learning OCR and computer-vision components makes it moderately relevant for data/ML practitioners, though its core value is as a utility application rather than broadly reusable ML infrastructure.",success
https://github.com/antvis/F2,F2,"F2 is a lightweight, interactive charting/visualization library optimized for mobile, supporting rich chart types and flexible customization (shapes, animations, interactions). It targets H5/mobile web and also supports multiple runtime environments (e.g., Node and various mini-program environments) with a data-driven grammar-of-graphics approach.",8000,data visualization|charting|javascript|typescript|mobile web|canvas|antv,6,"This repository provides a mobile-focused charting and visualization library (F2) for building interactive charts from JSON-like data using a grammar-of-graphics style API. While it is not an ML library, it is directly useful in data science workflows for exploratory data analysis, dashboards, reporting, and presenting model outputs (predictions/metrics) in web or mobile contexts. Its relevance is moderate because it helps visualize data and ML results, but it does not provide modeling, training, or MLOps capabilities, and its primary audience is front-end/mobile visualization rather than ML practitioners.",success
https://github.com/LibrePhotos/librephotos,librephotos,"LibrePhotos is a self-hosted, open-source photo management backend (a Google Photos-style alternative) that scans local media, organizes it in a timeline, supports photos/videos/RAW formats, and provides AI-powered features like face recognition, object/scene detection, and semantic search.",7900,self-hosted|photo-management|computer-vision|machine-learning|django|python|semantic-search,6,"The repository is primarily a self-hosted photo management backend, but it includes multiple ML-driven capabilities (face detection/classification, image captioning, scene classification, and semantic search) that are central to its feature set. It’s moderately useful for ML/data workflows because it integrates common ML/CV components (e.g., face_recognition, scikit-learn, Places365) into an end-to-end application, offering practical examples of deploying ML for media indexing and retrieval. However, it is not a general-purpose ML framework or dataset tool, and its ML components are embedded within a product-focused system rather than exposed as reusable ML libraries or pipelines. This combination makes it educational and integration-relevant, but not a core ML/data engineering dependency for most practitioners.",success
https://github.com/kernc/backtesting.py,backtesting.py,"A lightweight Python framework for backtesting algorithmic trading strategies on historical candlestick data, with a simple Strategy API, optimization, and interactive visualizations. It supports multiple asset classes (e.g., stocks/forex/crypto) and is indicator-library agnostic (works with TA-Lib, pandas-ta, etc.).",7800,algorithmic trading|quant finance|backtesting|python|pandas|strategy optimization|data visualization,6,"This repository is primarily a quantitative finance/backtesting framework for evaluating trading strategies on historical price data, including performance statistics, optimization workflows, and interactive plotting. While it is not an ML training framework, it is directly useful in data-science workflows for feature/indicator engineering, strategy research, and evaluating ML-driven trading signals using time series data. It also includes documentation/tutorials that explicitly cover trading with machine learning, which raises its relevance beyond pure rule-based backtesting, but its core focus remains trading simulation rather than general ML.",success
https://github.com/cheahjs/free-llm-api-resources,free-llm-api-resources,"A curated list of legitimate services that provide free access (or free credits) for LLM inference via API, often including usage limits, requirements (e.g., phone verification), and example supported models. It focuses on practical options for getting API-based LLM usage without paying upfront while discouraging abuse and excluding illegitimate/reverse-engineered services.",7700,LLM|API|generative AI|inference|developer resources|cloud providers|NLP,6,"This repository is primarily a curated reference list of free or credit-based LLM inference APIs (with limits/notes) rather than an ML library or dataset. It is moderately useful in ML/data workflows because it helps practitioners quickly find low-cost endpoints for prototyping, evaluation, and integration testing of LLM-powered applications. The strong practical value and apparent community adoption (thousands of stars) raise its usefulness, but it does not provide core ML functionality like training, data processing, or modeling code—hence a mid-range score.",success
https://github.com/linyqh/NarratoAI,NarratoAI,"NarratoAI is an all-in-one tool for automated film/TV commentary creation and video editing, using LLMs to generate scripts, then producing edited videos with voiceover and subtitles. It supports workflows such as one-click processing via a Streamlit Web UI and Docker-based deployment.",7700,LLM|video-editing|video-generation|text-to-speech|subtitles|streamlit|python|moviepy,6,"NarratoAI is primarily an AI-assisted content-creation application that orchestrates LLM-driven script writing plus automated video editing, voiceover (TTS), and subtitle generation, rather than a research or model-training repository. It is moderately relevant to ML/data workflows because it integrates and operationalizes foundation models (via model-provider management like LiteLLM) and automates multimedia processing pipelines that ML engineers may adapt for production use. However, it does not appear to provide datasets, novel ML algorithms, or training/evaluation code, and its main value is as an end-user application and integration example rather than a core ML library.",success
https://github.com/jesse-ai/jesse,jesse,"Jesse is an advanced, self-hosted crypto trading framework written in Python for researching and building your own strategies, with support for backtesting, optimization (including Optuna-based parameter tuning), and live/paper trading across multiple symbols and timeframes.",7300,algorithmic trading|crypto trading|quantitative finance|backtesting|strategy optimization|Python|Optuna,6,"This repository is primarily a Python-based crypto algorithmic trading framework focused on strategy research, backtesting, and running strategies live/paper with built-in metrics, indicators, and an optimization mode that uses Optuna. It is relevant to data/ML workflows because systematic trading often involves data analysis, experimentation, and hyperparameter optimization, and the project provides a structured environment to run these experiments. However, it is not a general-purpose ML library nor a core MLOps/data engineering tool, and its ML components are secondary to its trading/backtesting focus. The relatively strong adoption (7.3k stars) and the presence of optimization tooling raise its practical value for quantitative researchers, but it remains domain-specific.",success
https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment,ChatGPT-Micro-Cap-Experiment,"A Python-based, live-trading experiment repository where ChatGPT is used as the decision engine to manage a real-money micro-cap stock portfolio. It includes automated trading/portfolio management scripts, stop-loss automation, and transparent performance tracking via daily-updated CSVs plus weekly research reports.",7200,algorithmic trading|python|finance|LLM|pandas|yfinance|portfolio management|data analysis,6,"The repository’s primary use case is algorithmic trading automation and performance tracking, with an LLM (ChatGPT) used to select trades, supported by Python scripts and structured CSV logs. It’s relevant to ML/data workflows because it contains repeatable data collection/tracking artifacts and an LLM-in-the-loop decision pipeline that can be extended for evaluation, backtesting, or experimentation. However, it is not a general-purpose ML framework nor a widely adopted ML/data library, and it appears more like an applied experiment/blueprint than a reusable ML toolkit. This makes it moderately valuable for data science (especially applied finance/LLM evaluation) but not “core” ML infrastructure, warranting a mid-level score.",success
https://github.com/growthbook/growthbook,growthbook,"GrowthBook is an open-source platform for feature flagging and A/B testing/experimentation, including advanced experiment analysis and statistics, plus SDKs for many languages. It can be self-hosted (e.g., via Docker Compose) and integrates with existing data stacks for measuring experiment results.",7200,feature flags|a-b-testing|experimentation-platform|product-analytics|statistics|web-development|devops,6,"This repository’s primary purpose is product experimentation: feature flags, experiment management, and robust A/B test analysis (including advanced statistical methods like CUPED, sequential testing, Bayesian options, and SRM checks). It is not an ML framework, but it is meaningfully relevant to data science workflows because experiment design/analysis is a core analytics function and it supports exporting reports (e.g., as a Jupyter Notebook) and working with existing data stacks. The score reflects strong practical value for experimentation analytics while being less directly applicable to model training, MLOps, or typical ML pipelines.",success
https://github.com/guess-js/guess,guess,"Guess.js is a set of libraries and tools for building predictive, data-driven user experiences on the web—most notably by using analytics/ML-informed predictions to prefetch likely-next navigations and related JavaScript bundles. It includes a Webpack plugin and supporting modules to learn navigation patterns (e.g., via Google Analytics) and automate predictive fetching.",7100,web-performance|prefetching|webpack|javascript|typescript|machine-learning|google-analytics|predictive-analytics,6,"This repository’s primary purpose is improving web UX and performance using predictive analytics (and potentially ML) to anticipate next-page navigations and prefetch resources. It relates to ML/data workflows by consuming structured analytics data (e.g., Google Analytics) and applying probabilistic predictions, but it is not a general ML framework for model training or experimentation. The repo can be useful to ML/data practitioners working on product analytics, personalization, or online prediction integration, yet its main audience and adoption are closer to web performance/engineering than core data science, justifying a moderately relevant score.",success
https://github.com/reactchartjs/react-chartjs-2,react-chartjs-2,"React components (wrappers) for Chart.js that let you render common chart types (e.g., Doughnut, Line, Bar) as React components. The project supports Chart.js v4 and v3 and provides documentation, examples, and migration guides.",6900,react|chart.js|data-visualization|charting|frontend|typescript|web-development,6,"This repository provides React component wrappers around Chart.js to build interactive charts in web applications, primarily for frontend data visualization. While it is not an ML library, it is directly useful in ML/data workflows for presenting model metrics, experiment results, dashboards, and exploratory plots in React-based UIs. Its popularity and broad adoption (widely used in the React ecosystem) increase practical value, but it does not include ML algorithms, training, or data processing features—hence a moderate relevance score.",success
https://github.com/covid19india/covid19india.github.io,covid19india.github.io,"Source code for the COVID-19 India dashboard (covid19india.org), a web app that visualizes and tracks COVID-19 impact in India and links to the project’s public data/API.",6800,covid-19|india|data-visualization|dashboard|web-development|javascript|public-health-data,6,"This repository primarily contains a JavaScript/SCSS web dashboard for tracking and visualizing COVID-19 statistics in India, rather than ML model training or inference code. It is still useful for data science workflows because it demonstrates real-world epidemiological data presentation patterns and references an API/data source that can be consumed for analysis. However, it does not provide core ML components (datasets packaged for ML, feature engineering pipelines, model code, or MLOps tooling), so its value is moderate rather than high.",success
https://github.com/robinhood/faust,faust,"Faust is a Python stream/event processing library inspired by Kafka Streams, designed for building high-throughput real-time applications and data pipelines with asyncio. It includes features like agents for stream processing, local persistent state via RocksDB-backed tables, and Kafka-based changelogging for recovery; however, this Robinhood repository is deprecated in favor of the community-maintained fork faust-streaming/faust.",6800,stream processing|event-driven|Apache Kafka|data engineering|real-time analytics|python|asyncio|distributed systems,6,"This repository provides a stream processing framework for building distributed, real-time event/data pipelines on top of Kafka concepts (Kafka Streams-style) in Python, with durable local state (tables) and recovery via Kafka changelogs. It is not an ML library itself, but it can be directly useful in ML/data workflows for real-time feature computation, online aggregation, and streaming ETL feeding training or inference systems. The score is moderated because it is infrastructure rather than modeling, and this particular upstream repository is explicitly deprecated (reducing practical adoption today), even though the core functionality is very relevant for data engineering in ML systems.",success
https://github.com/apache/storm,apache/storm,"Apache Storm is a distributed real-time computation system that provides general primitives for processing data streams (real-time/low-latency) in a fault-tolerant, scalable way. It’s often compared to Hadoop’s batch model, but focused on continuous stream processing and can be used from multiple programming languages.",6700,stream processing|real-time data|distributed systems|big data|data engineering|Java|Apache,6,"This repository implements Apache Storm, a mature distributed stream-processing engine primarily used to build real-time data pipelines and event-processing applications. While it is not an ML framework, it can be an important piece of ML/data workflows by powering streaming feature computation, online aggregation, and real-time ETL feeding downstream storage, analytics, or model serving. Its value for ML practitioners is moderate: it’s most useful for data engineering and production streaming infrastructure rather than model training or core ML development, which supports a score of 6/10.",success
https://github.com/paperswithbacktest/awesome-systematic-trading,awesome-systematic-trading,"A curated “awesome list” of resources for systematic/quantitative trading, including libraries/packages for backtesting and live trading, strategy references, books, videos, blogs, and courses. It organizes tools and learning materials across areas like broker APIs, data sources, analytics, machine learning, time series analysis, and visualization.",6700,systematic-trading|quantitative-finance|algorithmic-trading|backtesting|data-sources|machine-learning|time-series-analysis|awesome-list,6,"This repository is primarily a curated directory of systematic trading resources (libraries, strategies, and educational materials) rather than a single ML/data library. It is meaningfully relevant to ML/data workflows because it catalogs data sources, analytics tooling, and dedicated sections for machine learning and time series analysis used in quant research and trading pipelines. However, its direct applicability is indirect (pointers to tools rather than providing datasets/models/code itself), which limits it from scoring in the 8–10 range. The strong breadth and community adoption (high star count) increase its practical and educational value for data scientists working in quantitative finance.",success
https://github.com/pa7/heatmap.js,heatmap.js,"heatmap.js is a JavaScript library for rendering dynamic heatmaps in the browser using HTML5 canvas. It supports density-style visualizations and includes integrations/overlays for common mapping libraries (e.g., Google Maps, Leaflet, OpenLayers).",6400,javascript|data-visualization|heatmap|html5-canvas|web-development|geospatial|leaflet|google-maps,6,"This repository provides a browser-side heatmap rendering engine (HTML5 canvas) primarily aimed at visualizing intensity/density data (including map overlays). It is not an ML library, but it is directly useful in ML/data workflows for exploratory data analysis, presenting model outputs (e.g., spatial densities, attention/intensity maps), and building interactive dashboards. Its widespread adoption (thousands of GitHub stars) and visualization-focused utility make it moderately valuable to data science practitioners, but it does not provide data processing, modeling, or ML integrations by itself.",success
https://github.com/MaterializeInc/materialize,materialize,"Materialize is a real-time data integration platform (“live data layer”) that incrementally maintains SQL views over streaming and transactional data, providing up-to-date, consistent query results with low latency. It ingests data from systems like Postgres/MySQL replication streams and Kafka, and serves results via a PostgreSQL-compatible SQL interface.",6200,real-time analytics|stream processing|database|SQL|data integration|change data capture (CDC)|Rust,6,"This repository implements Materialize, a streaming SQL system that incrementally maintains materialized views over continuously changing data, aimed at powering operational analytics, integration hubs, and fresh context for applications (including AI/RAG pipelines). It is not an ML framework, but it is strongly relevant to ML/data workflows as real-time data infrastructure for feature generation, online/nearline aggregation, and maintaining continuously updated datasets/views that downstream training or serving systems can query. The score reflects high indirect-to-moderate relevance: it’s valuable for data engineering and real-time data foundations used by ML teams, but it does not provide modeling/training functionality itself.",success
https://github.com/riccardoscalco/textures,textures,"Textures.js is a JavaScript library (built on top of d3.js) for generating reusable SVG pattern “textures” (e.g., lines, shapes) that can be applied as fills/strokes in visualizations to improve categorical distinction and accessibility.",6100,javascript|d3|svg|data-visualization|patterns|accessibility|frontend,6,"This repository provides a practical SVG-pattern generation toolkit meant for data visualization (especially D3-based charts), enabling textured fills that help differentiate groups when color alone is insufficient. While it is not an ML library, it is directly useful in data-science workflows for exploratory analysis and reporting where chart readability and accessibility matter. Community adoption appears strong (thousands of stars and hundreds of dependents), which increases its practical value for visualization-heavy data work. It earns a 6/10 because it is moderately relevant: highly useful for presenting/communicating data, but not for modeling, training, or core ML pipelines.",success
https://github.com/ricequant/rqalpha,rqalpha,"RQAlpha is an extensible Python algorithmic trading framework for running strategy backtests and supporting simulation/live-style trading workflows across multiple security types. It provides a modular “Mod” extension system plus built-in components for order APIs, risk checks, scheduling, simulation matching, and performance analysis outputs.",6100,algorithmic-trading|quantitative-finance|backtesting|python|trading-systems|portfolio-analysis|financial-data,6,"This repository primarily implements a quantitative trading backtesting and execution framework (strategy research, simulation, risk checks, and analysis/reporting). It is relevant to ML/data workflows because it supports data acquisition/handling and systematic evaluation of strategies, and can be used as an experimentation harness for ML-driven signals (feature engineering, labeling, walk-forward testing), even though it is not an ML library itself. Community adoption appears solid (thousands of GitHub stars) and it has educational value for understanding end-to-end quant research pipelines. The score is 6/10 because it is moderately valuable for data science in finance, but it is not a general-purpose ML framework or a dedicated model training/MLOps tool.",success
https://github.com/apache/nifi,apache/nifi,"Apache NiFi is an open-source system for building, operating, and monitoring dataflows to automate the movement, processing, and distribution of data between systems. It provides a browser-based UI, scalable clustered execution, data provenance/lineage tracking, secure-by-default configuration, and an extensible processor/plugin architecture (including native Python processors) with a REST API for orchestration.",5900,data engineering|data integration|ETL|dataflow orchestration|stream processing|data lineage|MLOps|Apache,6,"This repository hosts Apache NiFi, a general-purpose dataflow automation and data integration platform used to ingest, route, transform, and deliver data across heterogeneous systems via a visual UI and extensible processors. While it is not an ML framework itself, it is directly useful in ML/data workflows for reliable data ingestion, feature/data pipeline orchestration, governance via provenance/lineage, and integrating with downstream analytics/ML tooling through connectors and APIs. It has broad adoption in data engineering and can support MLOps-style pipelines (including generative AI data pipelines), but model training/inference is not its primary focus, keeping it below core-ML-tool scores. The score reflects strong relevance as pipeline infrastructure rather than as an ML library.",success
https://github.com/spotify/pedalboard,pedalboard,"Pedalboard is Spotify’s Python library for working with audio—reading/writing files, rendering, and applying studio-quality effects. It includes built-in effects and audio I/O utilities, and can also host third-party VST3 and (on macOS) Audio Unit plugins, with support for use in TensorFlow pipelines for tasks like audio data augmentation.",5900,audio-processing|python|digital-signal-processing|audio-effects|vst3|audio-unit|machine-learning-data-augmentation,6,"This repository primarily provides high-performance audio I/O plus a rich set of audio effects, including the ability to load professional third-party plugins (VST3/AU) from Python. While it is not an ML framework, it is directly useful in ML/data workflows for audio—especially for generating augmented training data and integrating into TensorFlow input pipelines. Its adoption and documentation suggest it’s a practical tool for audio ML practitioners, but its core focus is audio processing rather than model training, so it rates as moderately relevant rather than core ML.",success
https://github.com/evidence-dev/evidence,evidence,"Evidence is an open-source “business intelligence as code” framework for building data products (reports, dashboards, decision-support tools) using SQL inside Markdown files. It renders interactive web pages and visualizations from query results, acting as a code-driven alternative to drag-and-drop BI tools.",5800,business intelligence|data visualization|dashboards|sql|analytics engineering|svelte|duckdb|markdown,6,"This repository provides a developer-focused framework to create interactive analytics sites and dashboards by embedding SQL queries in Markdown and rendering charts/components from the results. It is strongly relevant to data workflows (analytics engineering, reporting, exploratory analysis, and sharing insights), and supports connecting to common data sources/warehouses and local files, which can be useful in data science contexts. However, it is not an ML training/inference framework and does not primarily target model development or MLOps, so its ML-specific applicability is indirect rather than core—hence a moderate score.",success
https://github.com/vi3k6i5/flashtext,flashtext,Python library implementing the FlashText algorithm to efficiently extract keywords from text or replace keywords in sentences using a KeywordProcessor API.,5700,python|nlp|text-processing|keyword-extraction|string-replacement|information-extraction|flashtext-algorithm,6,"This repository provides a fast keyword extraction and keyword replacement utility for text based on the FlashText algorithm, exposed through a simple KeywordProcessor API. It’s not a model-training or ML framework, but it is directly useful in many ML/data workflows for NLP preprocessing (e.g., entity/term normalization, rule-based tagging, dictionary matching before/after model inference). Its relatively strong community adoption (thousands of GitHub stars) and practical applicability in data cleaning/feature engineering justify a moderate-to-high relevance score, but it’s limited to rule-based string matching rather than statistical/ML methods.",success
https://github.com/Klavis-AI/klavis,klavis,"Klavis is an open-source MCP (Model Context Protocol) integration platform that provides prebuilt tool connectors (MCP servers/clients) with OAuth support, enabling AI agents to reliably access external services at scale. It supports cloud-hosted usage via Klavis APIs as well as self-hosting via Docker images and local tooling (e.g., Strata).",5600,model-context-protocol|ai-agents|tool-calling|mcp-server|oauth2|docker|developer-tools|integration-platform,6,"This repository’s primary use case is infrastructure for AI agents: it provides MCP servers/clients plus an integration layer (including OAuth and Dockerized servers) so agents can use external tools like GitHub and others reliably. While it is not a modeling/training library, it is directly applicable to ML/LLM engineering workflows where tool-using agents, RAG + actions, evaluation, or agent deployments require robust integrations and authentication handling. The score is moderate (6/10) because it meaningfully supports real-world ML/LLM systems and agent tooling, but it is not a core data-science library (e.g., not focused on datasets, training loops, or analytics) and community adoption, while strong in stars, is still niche relative to foundational ML frameworks.",success
https://github.com/yyhsong/iDataV,iDataV,"A collection of large-screen (dashboard) data visualization demos and templates, showcasing common “big screen” BI-style layouts using charting libraries (notably ECharts) plus integrations/examples with platforms like Alibaba Cloud DataV and Baidu Sugar. Includes multiple case directories demonstrating maps, 3D charts, heatmaps, and various chart components, with a hosted demo site via GitHub Pages.",5600,data visualization|dashboard|large-screen visualization|echarts|javascript|web frontend|gis-mapping,6,"This repository primarily provides front-end dashboard/“big screen” visualization demos and templates (maps, charts, 3D visuals, heatmaps) geared toward presenting data rather than modeling it. It can be moderately valuable to data practitioners for communicating results and building monitoring/BI-style views, especially where geospatial or real-time-style dashboards are needed. However, it does not focus on ML model training, data pipelines, or statistical/ML algorithms, and community adoption is more in the visualization/template space than core ML tooling—hence a mid-range score.",success
https://github.com/airbnb/knowledge-repo,knowledge-repo,"A curated knowledge-sharing platform aimed at data scientists and other technical roles, centered on publishing and managing “knowledge posts” from familiar formats like Markdown, Jupyter notebooks, and R Markdown to encourage reproducible research. It supports GitHub-based submission workflows and a built-in editor for composing, updating, and sharing posts.",5500,data-science|knowledge-management|documentation|jupyter-notebook|reproducible-research|python|markdown,6,"This repository provides an internal-style knowledge publishing platform designed for data science teams to share analyses and technical write-ups, especially via notebooks and Markdown, with an emphasis on reproducibility and discoverability. While it is not an ML framework or modeling library, it directly supports data/ML workflows by helping teams publish, version, and disseminate analysis artifacts (e.g., Jupyter/R Markdown posts) in a structured way. It has clear relevance and educational value for data organizations, but limited direct applicability to model training/inference compared to core ML tooling, so a mid-to-high score is appropriate.",success
https://github.com/lightdash/lightdash,lightdash,"Lightdash is an open-source, self-serve BI platform positioned as a Looker alternative, designed to let teams explore data, build charts/dashboards, and share insights. It integrates closely with dbt so metrics/dimensions and metadata can be defined and synced from a dbt project, enabling governed self-serve analytics.",5400,business intelligence|analytics|data visualization|dbt|metrics layer|dashboards|self-serve analytics|data engineering,6,"This repository provides a BI and analytics application (an open-source Looker alternative) focused on governed self-serve exploration, charting, dashboards, and metric definitions synced from dbt. It is not an ML framework or modeling library, but it is directly useful in data science and ML-adjacent workflows for metric standardization, analysis, and communicating results via dashboards and scheduled sharing. Its strong fit with dbt and analytics engineering makes it moderately valuable for ML/data teams, mainly on the analytics and reporting side rather than model training or MLOps, which supports a score of 6/10.",success
https://github.com/nhn/tui.chart,tui.chart,"TOAST UI Chart is a JavaScript data visualization library for creating a wide variety of interactive, customizable charts (e.g., line, bar/column, area, pie, scatter, heatmap, treemap, gauge). It includes responsive/zoomable features, live data updates, theming, export options, and offers plain JS plus React and Vue wrapper packages.",5400,data visualization|javascript|charting library|frontend|react|vue|typescript,6,"This repository primarily provides a front-end charting/data-visualization library (TOAST UI Chart) for rendering interactive charts in web applications, including wrappers for React and Vue. While it is not an ML framework or data processing toolkit, it is directly useful in ML/data workflows for exploratory data analysis dashboards, experiment/result reporting, and visualizing metrics (e.g., time series, distributions, heatmaps). The score reflects moderate relevance: strong utility for presenting and monitoring data/ML outputs, but limited direct support for model training, feature engineering, or data pipelines, and adoption is more general web-dev oriented than ML-specific.",success
https://github.com/Superalgos/Superalgos,Superalgos,"Superalgos is a free, open-source platform for building and running algorithmic cryptocurrency trading bots with a visual design environment. It includes integrated charting, data-mining, backtesting, paper trading, and supports multi-server bot deployments.",5200,algorithmic trading|cryptocurrency|trading bots|data mining|backtesting|data visualization|node.js|fintech,6,"This repository is primarily an end-to-end crypto algorithmic trading and research platform (visual strategy design, data-mining, backtesting, and execution), rather than a dedicated machine-learning framework. It is still meaningfully valuable for data/ML workflows because it centers on collecting/structuring market data, generating indicators/features, and running systematic experiments/backtests that data scientists can use for quantitative research. Community adoption appears solid (about 5.2k GitHub stars), but the core focus is trading automation and infra rather than model training, so it scores as moderately relevant rather than core ML.",success
https://github.com/dsdanielpark/Bard-API,Bard-API,"An unofficial Python wrapper for interacting with Google Bard (now Gemini) by reverse-engineering web requests and authenticating via browser cookie values (e.g., __Secure-1PSID). The repository is archived (read-only) and the author directs users to a newer Gemini-API replacement.",5200,python|llm|generative-ai|google-bard|google-gemini|api-wrapper|reverse-engineering,6,"This repository provides a Python interface to a generative AI chatbot (Google Bard/Gemini) by emulating the web client using authentication cookies, enabling programmatic prompt/response workflows. It can be useful in ML/data workflows for rapid prototyping of LLM-powered analysis, data labeling, text generation, and prompt experimentation, but it does not implement ML models, training, or core data-processing primitives itself. Community adoption appears strong (about 5.2k GitHub stars), but the repo is archived/inactive and relies on fragile, unofficial authentication and reverse-engineered behavior, limiting reliability for production ML/data pipelines. For these reasons it is moderately relevant rather than a core ML/data tool.",success
https://github.com/infinyon/fluvio,fluvio,"Fluvio is a distributed event/data streaming platform written in Rust for collecting, transporting, and transforming “data in motion” to build responsive, data-intensive applications. It provides a local or clustered runtime plus CLI tooling and a stream-processing model (e.g., SmartModules/Stateful DataFlow) for in-stream transformations.",5100,event streaming|stream processing|data engineering|rust|kubernetes|messaging|real-time data|distributed systems,6,"This repository implements Fluvio, a Rust-based distributed event streaming and stream-processing system (Kafka-like in the broad sense) focused on moving and transforming real-time data. It is not an ML framework, but it can be highly useful in ML/data workflows for ingesting events, building real-time feature pipelines, streaming ETL, and online inference data delivery. Its relevance is strong for data engineering infrastructure and real-time analytics, but direct ML training/modeling functionality is outside its core scope, so it scores as moderately relevant rather than a core ML tool.",success
https://github.com/sshuair/awesome-gis,awesome-gis,"A curated “awesome list” of GIS/geospatial resources, including GIS and remote sensing software, web map servers, spatial databases, geospatial libraries (by language), datasets, communities/conferences, courses, news, and related references.",5100,GIS|geospatial|awesome-list|remote-sensing|geospatial-data|spatial-databases|data-resources,6,"This repository is primarily a curated directory of GIS and geospatial tools, libraries, datasets, and learning resources rather than an executable ML library or pipeline. It is moderately relevant to ML/data workflows because geospatial data science commonly relies on the kinds of tooling and datasets it indexes, and it includes a dedicated “Deep Learning” section (frameworks and datasets) alongside broader geospatial resources. However, it does not directly provide ML models, training code, or data processing components; its value is mainly discovery and education rather than direct integration into ML systems. The community adoption (thousands of stars) and breadth of resources make it useful for geospatial data practitioners, supporting a mid-range score.",success
https://github.com/edp963/davinci,davinci,"Davinci is a DVaaS (Data Visualization as a Service) platform for building and sharing dashboards and visual components from CSV files or JDBC-accessible databases. It emphasizes configurable “views” and “widgets,” supports interactive filtering/control, sharing, and enterprise permissions (row/column security and LDAP integration).",5000,data-visualization|dashboard|bi-analytics|data-platform|react|typescript|java,6,"This repository provides an end-to-end data visualization and dashboarding platform (DVaaS), aimed at data analysts/engineers/scientists and business users, with data-source connectivity (CSV/JDBC), configurable data views, and interactive widgets/dashboards. It is relevant to data workflows because it can sit downstream of analytics/ML pipelines to explore data and communicate results, but it is not primarily a model training/serving or MLOps tool. Community adoption appears decent for a niche OSS BI platform (about 5k GitHub stars), yet its direct ML feature set is limited compared to dedicated ML libraries/frameworks. Therefore it scores as moderately valuable for data/ML practitioners mainly as a visualization layer rather than core ML tooling.",success
https://github.com/SpiderClub/weibospider,weibospider,"A distributed Sina Weibo crawler built with Celery and Requests. It supports crawling user profiles, keyword search results (incremental), a user’s original posts, comments, and repost/forward relationships, with storage/backing services configured via MySQL and Redis and optional Django Admin UI for configuration.",4800,web-scraping|crawler|weibo|python|celery|requests|distributed-systems|data-collection,6,"This repository is primarily a distributed data-collection system for Sina Weibo, providing robust scraping and parsing workflows (via Celery workers) rather than ML modeling. It is moderately valuable for ML/data science because it can be used to build datasets (e.g., social-media text corpora for NLP, monitoring, or downstream analytics) and includes features like keyword-based incremental crawling and relationship crawling that are useful for data acquisition. However, it does not provide core ML algorithms, training pipelines, or standard ML integrations, so its value is mostly in data gathering and preprocessing rather than modeling, keeping the score in the mid range.",success
https://github.com/Jannchie/Historical-ranking-data-visualization-based-on-d3.js,Historical-ranking-data-visualization-based-on-d3.js,A (deprecated) D3.js-based data visualization project that turns historical ranking time-series data (CSV) into animated “bar chart race” style dynamic bar charts for making ranking visualization videos. Users can open the included HTML and load a CSV file to generate the animation with configurable styling options.,4700,data-visualization|d3.js|javascript|bar-chart-race|time-series|csv|frontend,6,"This repository’s primary purpose is data visualization: it converts historical ranking data (typically time-series in CSV form) into animated bar chart race graphics using D3.js. It’s moderately relevant to ML/data workflows because it can be used to visualize model metrics, leaderboards, feature trends, or other ranked time-series outputs, but it does not provide ML modeling, training, or data-processing pipelines itself. The project has meaningful community adoption (thousands of stars), and it has educational value for learning D3-based animated visualizations. The score reflects strong utility for communicating data/ML results, but limited direct integration with core ML tooling.",success
https://github.com/sacridini/Awesome-Geospatial,Awesome-Geospatial,"A curated “awesome list” of geospatial analysis tools and resources, organized by categories such as databases, GIS software, web mapping, remote sensing (radar/lidar), data sources, and language-specific libraries.",4700,geospatial|GIS|remote sensing|data sources|spatial analysis|geospatial software|awesome-list,6,"This repository is primarily a curated directory of geospatial tools, libraries, platforms, and learning resources rather than an executable codebase. It is moderately valuable for ML/data workflows because geospatial datasets, spatial databases, and remote-sensing tooling are common inputs to data science and geospatial ML (and the list includes areas like “Deep Learning” and “Geographic Data Mining”). However, its direct applicability is indirect (it helps you discover tools rather than providing a pipeline/library itself), and community adoption appears solid for an awesome-list, so a mid-high score is appropriate.",success
https://github.com/gbeced/pyalgotrade,pyalgotrade,"PyAlgoTrade is an event-driven Python algorithmic trading library focused on strategy backtesting, with support for paper/live trading integrations (notably Bitstamp) plus technical indicators and performance metrics. The repository is archived (read-only) and marked as deprecated by the author.",4600,algorithmic trading|backtesting|quant finance|event-driven|python|technical analysis|time series,6,"This repository provides an event-driven trading framework for backtesting and (limited) paper/live trading, including built-in technical indicators and performance analytics such as Sharpe ratio and drawdown. It is relevant to data science workflows because it operates on financial time-series data and supports indicators/metrics frequently used in quantitative research, but it is not an ML framework and does not center on model training. Its practical ML/data value is moderated by the project being archived and explicitly deprecated, which reduces integration and community momentum despite decent adoption (stars/forks).",success
https://github.com/Integuru-AI/Integuru,Integuru,Integuru is an AI agent that generates runnable Python integration code by reverse-engineering a platform’s internal APIs from captured browser network traffic (HAR + cookies). It builds a dependency graph of requests needed to perform a desired action and then produces code to execute those requests programmatically.,4500,llm-agents|api-integration|reverse-engineering|python|automation|har|developer-tools|openai-api,6,"This repository’s primary purpose is developer automation: using an LLM-driven agent to infer and generate integration code for “unofficial”/internal web APIs by analyzing HAR network captures and cookies. It is ML-adjacent rather than a data-science library, but it can be directly useful in ML/data workflows for building data ingestion/extraction integrations (e.g., pulling documents or records from web portals into pipelines) and for agent/tooling experimentation. Community adoption appears moderate-to-strong (thousands of stars), but it is not a core ML framework or a general-purpose data processing library, which keeps the score below the 8–10 range.",success
https://github.com/waditu/czsc,czsc,"CZSC is a Python quantitative trading/technical analysis toolkit based on Chan theory (缠论), providing automated identification of key market structures (e.g., fractals and strokes), a signal–factor–event–trade modeling system, multi-timeframe decision analysis (CzscTrader), and related research/streamlit components.",4400,quantitative trading|algorithmic trading|technical analysis|Chan theory (缠论)|python|financial time series|trading signals|backtesting,6,"The repository primarily targets quantitative trading research and technical analysis workflows (signal generation, rule-based strategy logic, multi-timeframe analysis) rather than model training. It is relevant to data science because it operates on financial time-series data and offers structured feature/signal engineering components that can feed ML models or be used for systematic research/backtesting. However, it does not appear to be a general-purpose ML framework and community adoption seems centered on quant trading/Chan-theory users rather than the broader ML ecosystem, so it scores as moderately relevant rather than core ML.",success
https://github.com/wooorm/franc,franc,"JavaScript/TypeScript (ESM) language identification library that detects the most likely language of a given text string, with optional ranked guesses. Ships in multiple language-coverage variants (e.g., franc-min, franc, franc-all) and also has a CLI (via franc-cli).",4400,natural language processing|language detection|NLP|JavaScript|TypeScript|Node.js|CLI,6,"This repository provides a practical NLP utility for automatic language identification from raw text, exposed as JS APIs (franc/francAll) and supported by a separate CLI package. It’s directly useful in data/ML workflows for preprocessing (e.g., filtering multilingual corpora, routing texts to language-specific models, or labeling datasets), but it is not an ML training framework and primarily implements heuristic/statistical detection rather than end-to-end model training. The score reflects strong applicability as a common data-cleaning/ingestion component and good adoption, while being narrower in scope than core ML libraries.",success
https://github.com/apache/streampark,apache/streampark,"Apache StreamPark is an open-source streaming application development framework and cloud-native operations platform that simplifies building, deploying, monitoring, and managing real-time stream processing jobs. It provides unified support for Apache Flink and Apache Spark across environments like Standalone, YARN, and Kubernetes.",4300,stream processing|data engineering|Apache Flink|Apache Spark|real-time analytics|Kubernetes|MLOps-infrastructure,6,"StreamPark primarily targets data engineering workflows by providing a development framework and an operational platform for real-time stream processing (not an ML library). It is valuable to ML/data teams as infrastructure for streaming feature generation, real-time data pipelines, and production data operations around Flink/Spark jobs, which commonly sit upstream of ML training and online inference systems. However, it does not directly provide model training, inference, or core ML algorithms, so its ML value is moderate rather than high. Community indicators (e.g., several thousand GitHub stars) suggest meaningful adoption for streaming/data platform use cases. ",success
https://github.com/mangiucugna/json_repair,json_repair,"A lightweight Python library that repairs malformed JSON strings (commonly produced by LLMs) by fixing common syntax issues and returning valid JSON. It can be used as a drop-in replacement for json.loads/json.load via json_repair.loads/load, or as a string repair utility via repair_json().",4300,python|json|data-cleaning|llm|parsing|developer-tools,6,"This repository provides a practical utility to repair invalid JSON, with explicit motivation around cleaning up malformed JSON outputs from LLMs and offering json.loads/json.load-compatible helpers. In ML/data workflows, it’s directly useful for robustly parsing structured outputs from models/agents and for preprocessing noisy JSON-like logs or scraped/LLM-generated payloads. However, it is not an ML library itself (no modeling, training, or analytics), so its relevance is primarily as a reliability/data-ingestion helper rather than a core ML/data science toolkit.",success
https://github.com/rowboatlabs/rowboat,rowboat,"RowboatX is a local-first, open-source CLI for creating and scheduling background AI agents with full shell access, designed to automate everyday workflows. It supports connecting MCP servers/tools and configuring multiple LLM providers (e.g., OpenAI-compatible, Anthropic, Google, Ollama) for agent execution.",4300,ai-agents|llm|agent-orchestration|mcp|automation|cli|generative-ai|developer-tools,6,"This repository primarily provides a local-first CLI and related tooling to build, run, and schedule AI agents that can use external tools (via MCP) and execute shell commands for automation. It is relevant to ML/data workflows mainly as an LLM/agent orchestration layer (useful for building data-collection, summarization, RAG-adjacent, and automation pipelines), rather than a library for model training or core data processing. Community signals (thousands of stars) suggest meaningful adoption, but its focus is on agent-driven automation instead of data science primitives, so it earns a moderately relevant score.",success
https://github.com/swimlane/ngx-charts,ngx-charts,"A declarative charting framework for Angular that renders animated, customizable SVG charts using Angular for rendering and d3 for math/scales/axes/shape generation. It provides many built-in chart types (bar, line, area, pie, gauge, heatmap, treemap, sankey, etc.) and supports building custom charts from exposed components.",4300,data visualization|angular|charts|d3|svg|typescript|frontend,6,"This repository is primarily an Angular UI library for building interactive data visualizations (SVG charts) in web applications, using Angular for rendering and d3 for chart math/scales. It is not an ML library, but it is moderately useful in ML/data workflows for presenting and exploring model outputs, metrics, dashboards, and analytic results in Angular-based frontends. Its value is mainly in visualization/communication rather than training, data processing, or MLOps, which is why it scores as moderately (not highly) relevant.",success
https://github.com/nucleuscloud/neosync,neosync,"Neosync is an open-source, developer-first platform for detecting and anonymizing PII and generating synthetic data, with tooling to sync/subset production-like datasets across environments for safer testing and debugging. It includes a web UI plus CLI/automation-oriented workflows (e.g., GitOps-style configs) and focuses on preserving referential integrity during data transformations.",4100,data anonymization|PII detection|synthetic data|data engineering|DevSecOps|Go|developer tooling|data privacy,6,"This repository primarily targets data privacy and environment replication: it anonymizes production data, generates synthetic datasets, and synchronizes/subsets data for dev/staging/CI use cases, with an emphasis on referential integrity and automation. It is relevant to ML/data workflows when teams need privacy-preserving datasets for model training, evaluation, or prompt/LLM safety (PII redaction) and when building compliant data pipelines. However, it is not an ML framework or modeling library; its value is as a supporting data-security and data-prep/orchestration layer, and the repo is archived and no longer actively maintained, which limits long-term adoption and integration momentum.",success
https://github.com/Mai-with-u/MaiBot,MaiBot,"MaiBot (MaiCore) is a multi-platform, LLM-powered social/chat agent (“cyber friend”) focused on group chat interaction. It emphasizes human-like prompting, behavior planning, style/expression learning, slang learning, a plugin system, and emotion/expression features, with deployment options including Docker and platform-specific adapters.",4000,LLM-agent|chatbot|multi-agent|Python|plugin-system|group-chat|AI-assistant|Docker,6,"The repository’s primary purpose is building and running an LLM-based interactive agent/bot for group chats, with modular components (planning, memory/learning, emotion, plugins) and multiple deployment paths. It is moderately relevant to ML workflows because it integrates LLM capabilities and agent architecture concepts (prompting, orchestration, extensions), which can be useful for applied LLM engineering and experimentation. However, it is not primarily a general-purpose ML/data science library for model training, dataset work, or core data processing, so its direct utility for typical data science tasks is limited compared to dedicated ML frameworks.",success
https://github.com/antvis/L7,L7,"L7 is a large-scale, WebGL-powered geospatial data visualization and visual analytics engine for the web. It focuses on high-performance 2D/3D rendering of massive spatial datasets and supports common GIS/BI mapping layers (points/lines/polygons/heatmaps/rasters) with multiple basemap integrations.",4000,geospatial|data-visualization|webgl|gis|maps|typescript|geojson|mapbox,6,"This repository provides a WebGL-based geospatial visualization/visual-analytics engine (primarily for rendering and interacting with large spatial datasets in 2D/3D on the web). It’s relevant to ML/data workflows because it can be used to explore, present, and debug spatial datasets and model outputs (e.g., predictions over locations), but it is not a modeling/training framework itself. Its value to data science is therefore moderate: strong for geospatial visualization and communication, weaker for core ML tasks like feature engineering, training, and evaluation. The score reflects its direct utility for spatial data analysis/visualization, while acknowledging it’s not an ML-native toolkit.",success
https://github.com/denizsafak/abogen,abogen,"Abogen is a text-to-speech (TTS) tool that converts EPUB, PDF, text/markdown, or subtitle files into high-quality audio while generating synchronized captions/subtitles. It targets audiobook creation and short-form voiceover/video workflows, leveraging the Kokoro-82M TTS model.",4000,text-to-speech|audio-generation|subtitle-generation|python|pytorch|ebook-processing|kokoro-tts,6,"This repository is primarily an end-user TTS conversion application that turns documents (EPUB/PDF/text/markdown/subtitles) into audio with aligned subtitles, using the Kokoro-82M model. It is relevant to ML workflows because it packages and operationalizes neural TTS inference (with GPU acceleration options via PyTorch), which can be useful for dataset creation (synthetic speech), prototyping speech pipelines, or learning how to deploy TTS models. However, it is not a general-purpose ML framework or training library, and its scope is more application-focused than research/production MLOps, which keeps the score in the mid range.",success
https://github.com/adilkhash/Data-Engineering-HowTo,Data-Engineering-HowTo,"A curated learning roadmap and link collection for becoming a data engineer, covering foundational topics (SQL, programming, databases, distributed systems) and pointing to talks, books, courses, and key tools like Airflow, Spark, and Kafka.",3900,data engineering|learning resources|data pipelines|apache airflow|apache spark|apache kafka|distributed systems|sql,6,"This repository is primarily an educational, curated list of articles, talks, books, and courses aimed at learning data engineering from scratch, plus a toolbox section highlighting common DE platforms (e.g., Airflow, Spark, Kafka). It is strongly relevant to data workflows (ETL/ELT, orchestration, large-scale processing) that underpin many ML systems, but it does not provide ML algorithms, model training code, or reusable libraries. Community interest appears solid (thousands of stars and hundreds of forks), which increases its practical learning value. Based on being a high-value data/infra learning resource rather than a direct ML implementation/tool, a 6/10 is appropriate.",success
https://github.com/electricitymaps/electricitymaps-contrib,electricitymaps-contrib,Open-source repository for the Electricity Maps app and its data parsers. It fetches electricity production data from public/official sources and applies a flow-tracing algorithm to compute and visualize real-time and historical electricity carbon intensity (CO2e) for consumption/production across many regions worldwide.,3900,energy-data|carbon-intensity|electricity-grid|data-ingestion|data-parsing|python|sustainability,6,"This repository primarily powers Electricity Maps by collecting raw grid production/exchange data via country/region-specific parsers and transforming it into standardized signals like carbon intensity using a flow-tracing methodology. It is not an ML framework, but it is valuable for data science workflows because it provides a large-scale, real-world data ingestion and harmonization pipeline and supports analysis of electricity mixes and emissions over time. It has meaningful educational and integration value for climate/energy analytics (feature engineering, forecasting inputs, carbon-aware optimization), but ML is not the core focus and model-training tooling is not central here—hence a moderately relevant score.",success
https://github.com/markmarkoh/datamaps,datamaps,"Datamaps is a JavaScript library for building customizable, interactive SVG-based geographic map visualizations in the browser using D3.js and TopoJSON. It supports choropleths and bubble maps out of the box and can be extended via a plugin system for additional map overlays/visualizations.",3800,data-visualization|geospatial|interactive-maps|d3.js|javascript|choropleth|svg,6,"This repository provides a front-end geospatial visualization library (SVG maps with choropleths, bubbles, and extensible overlays) primarily intended for presenting geographic data on the web. It is relevant to ML/data workflows mainly in the exploration/communication phase (e.g., visualizing model outputs or aggregated metrics by region), but it is not an ML library and does not provide data processing, modeling, or pipeline capabilities. Community adoption appears solid for a visualization utility (thousands of GitHub stars), supporting a moderate relevance score rather than a core ML/data score.",success
https://github.com/britecharts/britecharts,britecharts,"Britecharts is a client-side, composable charting library built on reusable D3.js components. It provides multiple chart types (e.g., bar, line, donut, stacked area/bar, scatter) with a consistent API (width/height/margins, etc.) for building interactive visualizations in web apps.",3700,data-visualization|d3.js|javascript|charting-library|frontend|web-development,6,"This repository is primarily a JavaScript/D3-based charting and visualization library for building reusable, composable charts in web applications. It is moderately relevant to ML/data workflows because data scientists and ML engineers often need to visualize datasets, model metrics, and experiment results in dashboards or reports, and Britecharts can serve that purpose. However, it is not an ML or data-processing framework itself, and it does not provide modeling, training, or pipeline capabilities—its value is mainly in presenting and exploring data visually.",success
https://github.com/cuemacro/finmarketpy,finmarketpy,"finmarketpy is a Python library for analyzing financial market data and backtesting trading strategies via a simple API with prebuilt backtest templates. It also supports strategy performance analytics (returns, leverage, seasonality), event studies, and volatility-target/risk-weighting utilities, with data loading and charting delegated to companion libraries.",3700,quant-finance|algorithmic-trading|backtesting|market-data|event-study|python|pandas,6,"This repository primarily targets quantitative finance workflows: loading/processing market data and backtesting rule-based trading strategies, plus analytics like seasonality and event studies. It is strongly data-science-adjacent (time series analysis, performance/risk analytics, notebook-based exploration) and integrates with common Python DS tooling (eg, pandas/numpy) and companion data/chart libraries, but it is not an ML training/modeling framework. The community footprint (thousands of stars) and the practical, reusable templates/examples make it valuable for DS users working in markets, but its relevance is moderate rather than core to general-purpose ML.",success
https://github.com/dataarts/webgl-globe,webgl-globe,"WebGL Globe is an open platform (created by the Google Data Arts Team) for visualizing latitude/longitude-based datasets as an interactive, animated 3D globe in the browser using WebGL and Three.js. It expects geo-data in a simple JSON format and renders points/columns by magnitude across one or more data series.",3700,webgl|three.js|javascript|data-visualization|geospatial|3d-graphics|interactive-visualization,6,"This repository primarily provides a WebGL/Three.js-based geospatial visualization component for rendering latitude/longitude datasets on an interactive 3D globe, rather than tooling for model training or analytics. It can be valuable in data science workflows for communicating results, exploring geo-distributed data, or building dashboards/demos that visualize model outputs on a globe. However, it does not include ML algorithms, data processing pipelines, or integrations with common ML frameworks, and it is archived/read-only (archived Apr 14, 2021), which limits ongoing adoption and maintainability for production ML use cases.",success
https://github.com/chrislusf/gleam,gleam,"Gleam is a fast, scalable distributed execution system in pure Go that supports MapReduce-style and DAG-based dataflows, running either locally (standalone) or in a distributed master/agent/executor setup. It emphasizes high performance, memory efficiency, and flexible execution with in-memory or optional on-disk data movement.",3600,distributed-computing|mapreduce|data-processing|dag-execution|golang|big-data|batch-processing|stream-processing,6,"This repository implements a distributed dataflow/MapReduce and DAG execution engine in Go, intended for scalable processing of datasets either locally or across a cluster. It is directly useful in data engineering workflows (ETL, large-scale aggregations, pipeline orchestration), which often underpin ML feature generation and preprocessing. However, it is not an ML framework and does not provide model training/inference primitives, so its ML value is mainly as infrastructure for preparing/transforming data rather than core machine learning functionality. The moderate score reflects strong relevance to data processing but limited ML-specific tooling and ecosystem integration compared with mainstream ML platforms.",success
https://github.com/plouc/mozaik,mozaik,"Mozaïk is a Node.js + React/Redux-based framework for building configurable, modular dashboards that display metrics and other data using D3/Nivo visualizations. It provides a scalable grid layout, themes, module extensibility, and optimized backend communication for dashboard data sources.",3600,dashboard|data-visualization|react|nodejs|d3|redux|metrics,6,"This repository is primarily a dashboarding/data-visualization framework for composing metric-driven dashboards using Node.js, React/Redux, and D3/Nivo. It can be useful in ML/data workflows to monitor experiments, pipelines, services, and business/data metrics, but it is not an ML library nor a data processing framework. Its value for data science is moderate because it helps with observability and presenting data, rather than model training, feature engineering, or analytics at scale. The star count and established ecosystem suggest reasonable adoption, but mostly within web/dashboarding contexts rather than core ML tooling.",success
https://github.com/chartbrew/chartbrew,chartbrew,"Chartbrew is an open-source web platform for building and sharing live reporting dashboards and charts from databases and APIs. It provides a chart builder and editable dashboards, supports embedding/sharing, and includes team/collaboration features.",3500,data visualization|business intelligence|dashboards|analytics|javascript|node.js|sql-databases|api-integration,6,"This repository primarily provides a self-hostable BI/dashboarding web app that connects to data sources (e.g., APIs and SQL/NoSQL databases) to create charts and live reporting dashboards. It is directly useful in data workflows for monitoring KPIs, exploratory analysis, and communicating results via dashboards/embeds, but it is not an ML framework and does not focus on model training, feature engineering, or MLOps. Its value to ML/data teams is moderate because it can operationalize and visualize outputs from ML systems or analytics databases, yet it does not itself provide ML algorithms or data science libraries.",success
https://github.com/nkaz001/hftbacktest,hftbacktest,A high-frequency trading (HFT) and market-making backtesting framework that replays full tick/order-book data and simulates execution with limit-order queue position and feed/order latencies. It also supports deploying a live crypto trading bot (Rust) with examples for Binance Futures and Bybit.,3500,algorithmic-trading|high-frequency-trading|backtesting|market-making|order-book|crypto-trading|rust|python,6,"This repository is primarily an HFT backtesting and live-trading framework focused on realistic market replay (tick data, L2/L3 order books) and execution modeling (latency + queue position), rather than an ML library. It can be valuable in ML/data workflows because it enables generating labels/features from order-book microstructure data and running rigorous strategy evaluation loops, which are common in quantitative research. However, it does not provide a core ML training/inference framework or standard ML pipeline components, so its relevance is moderate rather than central.",success
https://github.com/ai-boost/Awesome-GPTs,Awesome-GPTs,"A curated, category-organized list of custom GPTs available on the OpenAI/ChatGPT platform, with links and short descriptions for discovery and community contributions. The repository also highlights related open-sourced resources like their website and prompt releases referenced in the README.",3400,LLMs|ChatGPT|OpenAI GPTs|awesome-list|prompt-engineering|AI tools directory|curated resources,6,"This repository’s primary purpose is to catalog and recommend custom GPTs (by category) rather than provide an ML library, dataset, or training code. It is moderately relevant to ML/data workflows because it helps practitioners discover GPT-based tools that can support tasks like research, writing, and data analysis, but it does not itself offer reusable ML components, benchmarks, or pipelines. Community adoption appears fairly strong for an “awesome list” (thousands of stars), improving its practical value as a discovery resource. The score is 6 (moderately relevant) because it’s useful for applied AI/tooling awareness and productivity, but not a core data-science building block like a framework or data-processing library.",success
https://github.com/antonycourtney/tad,tad,"Tad is an Electron desktop application (with an embeddable React pivot-table component) for fast viewing and interactive analysis of tabular datasets like CSV and Parquet, plus SQLite/DuckDB database files. It performs pivots/filters/aggregations by generating SQL and executing it against an in-memory DuckDB-backed analytics engine.",3400,data-analysis|tabular-data|csv|parquet|duckdb|pivot-table|electron|react,6,"This repository provides a desktop data exploration tool and a reusable React pivot-table UI for analyzing large tabular datasets, with operations translated into SQL and executed via (in-memory) DuckDB. It is not an ML framework, but it is moderately valuable in ML/data workflows for quick EDA, inspecting datasets, and lightweight analytics on common data formats (CSV/Parquet) and database files. Community adoption appears solid (thousands of GitHub stars), indicating practical utility, but its focus is data viewing/analysis rather than model training, MLOps, or ML-specific integrations—supporting a mid-range score.",success
https://github.com/observablehq/framework,framework,"Observable Framework is an open-source static site generator for building data apps, dashboards, and reports. It supports interactive JavaScript front-ends (e.g., D3/Observable Plot) and uses build-time data loaders to precompute data snapshots so pages load quickly.",3308,static site generator|data visualization|dashboards|web development|TypeScript|D3|Observable,6,"This repository provides a framework/static site generator aimed at creating interactive data applications (dashboards, reports) with JavaScript-driven visualizations and build-time data loading. While it is not an ML framework and does not provide model training/inference capabilities, it is directly useful for data science and analytics workflows to publish, share, and deploy data-driven artifacts (exploratory results, monitoring dashboards, reporting sites). The score reflects moderate relevance: strong utility for communicating and operationalizing data outputs, but limited direct support for core ML tasks beyond integrating with whatever back-end analysis stack you choose.",success
https://github.com/VisActor/VTable,VTable,"VTable is a high-performance, canvas-based table/grid library for multidimensional data analysis and visualization, designed to render very large datasets efficiently. It includes core table components plus related packages such as a Gantt component, editors, plugins, export/search utilities, and React/Vue wrappers.",3300,data visualization|table grid|business intelligence|javascript|typescript|react|vue|gantt,6,"This repository provides a high-performance tabular/grid rendering and analysis component (including pivot-like multidimensional analysis features) aimed at presenting and interacting with large datasets. While it is not an ML framework, it is moderately valuable in data science workflows for exploratory data analysis dashboards, result inspection, and building data-intensive front-end apps (including integrations with charting). The ML/data relevance comes from visualization and handling large data tables rather than model training, MLOps, or direct integration with common ML toolchains, so it scores as moderately relevant rather than core.",success
https://github.com/christabor/flask_jsondash,flask_jsondash,"Flask JSONDash is a Flask blueprint for building configurable, UI-ready chart dashboards without writing front-end code. Dashboards are defined via JSON and can render charts from arbitrary API/JSON endpoints using supported visualization libraries.",3300,python|flask|dashboard|data-visualization|charts|json-configuration|web-development,6,"This repository provides a Flask blueprint to assemble interactive dashboards from JSON configurations and data served by arbitrary API endpoints, emphasizing visualization and dashboard composition rather than modeling. It can be useful in ML/data workflows for presenting metrics, monitoring experiments, or building lightweight analytic UIs on top of model outputs, but it does not provide core ML capabilities (training, inference, feature engineering) itself. Community adoption appears solid (about 3.3k GitHub stars), supporting a moderate score focused on data visualization utility rather than ML depth.",success
https://github.com/dotnet/interactive,dotnet/interactive,".NET Interactive is an engine and API for running and editing code interactively across multiple languages, powering notebooks and REPL experiences. It works as a Jupyter kernel and underpins the Polyglot Notebooks experience (e.g., in VS Code), enabling cross-language variable sharing and interactive tooling like completions and diagnostics.",3200,dotnet|jupyter|notebooks|interactive-computing|polyglot|data-science|csharp,6,"This repository provides the core runtime, tooling, and kernel support to execute code interactively (notebooks/REPLs) with .NET and other languages, including usage via Jupyter and VS Code’s Polyglot Notebooks. It is directly useful in data/ML workflows as an interactive computing environment where users can explore data, run experiments, and combine languages (e.g., C#/F#/Python/R/SQL/KQL) in a single notebook with variable sharing. However, it is not an ML library/framework itself (no native model training algorithms as the primary focus), so its value is as an enabling platform rather than a core ML tool. Given its strong relevance for experimentation, teaching, and multi-language data exploration but indirect role in actual ML modeling, a score of 6 is appropriate.",success
https://github.com/TuiQiao/CBoard,CBoard,"CBoard is a self-service open BI reporting and dashboard platform that enables drag-and-drop multidimensional (OLAP-style) analysis and interactive dashboard building. It supports multiple data sources (notably JDBC databases, Elasticsearch, and Apache Kylin) and provides role-based access control plus many chart and reporting features.",3100,business-intelligence|data-visualization|dashboarding|reporting|olap|java|angularjs|jdbc,6,"This repository implements a BI/reporting and dashboard platform focused on interactive multidimensional analysis, charting, and self-service report design over connected data sources (e.g., JDBC databases, Elasticsearch, and Kylin). While it is not an ML framework and does not primarily target model training or MLOps, it can be valuable in data workflows as a visualization/analytics layer for exploring and monitoring data and metrics. The score reflects moderate relevance to data science due to its strong analytics and visualization capabilities, but limited direct ML functionality and less central adoption within core ML tooling.",success
https://github.com/jdkato/prose,prose,"prose is an English-only natural language processing (NLP) library written in pure Go. It provides tokenization, sentence segmentation, part-of-speech tagging, and named-entity recognition/extraction via a document-oriented API.",3100,golang|nlp|text-processing|tokenization|pos-tagging|named-entity-recognition|sentence-segmentation,6,"This repository provides core NLP preprocessing capabilities in Go (tokenization, sentence segmentation, POS tagging, and named-entity extraction), which are directly useful in many ML/data text pipelines. However, it is archived (read-only since May 14, 2023) and is focused on traditional NLP feature extraction rather than modern model training/inference workflows, limiting its integration value for current ML stacks. Its community adoption is decent (about 3.1k stars), and it can still be educational and practical for Go-based text analytics, but the lack of ongoing maintenance reduces its suitability for production ML use.",success
https://github.com/Micro-sheep/efinance,efinance,"efinance is an open-source Python library for quickly fetching financial market data (e.g., stocks, funds, futures, bonds). It is aimed at supporting quantitative research workflows such as backtesting and personal trading systems.",3000,python|finance|quantitative-finance|market-data|stocks|backtesting|data-collection,6,"This repository provides a Python interface to retrieve financial time-series and related market data (stocks/funds/futures/bonds), which is a common input for data science and quantitative modeling. While it is not an ML framework, it is directly useful for ML/data workflows involving feature engineering, exploratory analysis, and building trading or forecasting datasets. Its strong adoption (about 3k GitHub stars) suggests meaningful community usage in quant/data contexts, justifying a moderately high relevance score.",success
https://github.com/dagu-org/dagu,dagu,"Dagu is a self-contained, lightweight workflow orchestration engine (an Airflow alternative) that lets you define DAG-based pipelines in declarative YAML and run them via a single binary. It includes a built-in Web UI and supports composing sub-workflows and distributing tasks across workers without requiring external databases or message brokers.",3000,workflow orchestration|data pipelines|DAG|Airflow alternative|DevOps|CLI|web UI|Go,6,"This repository provides a lightweight workflow orchestrator for running command-based DAG pipelines defined in YAML, with a built-in Web UI and a single-binary deployment model. While it is not an ML library itself, it can be directly useful in ML/data workflows for scheduling and orchestrating ETL jobs, feature generation, training/evaluation scripts, and batch inference pipelines. It earns a 6/10 because it is moderately relevant infrastructure for data/ML (pipeline orchestration), but it is not specifically tailored to ML frameworks or model lifecycle management (e.g., experiment tracking, model registry, serving) and its adoption appears broader than the ML community specifically.",success
https://github.com/datafold/data-diff,data-diff,"An open-source command-line tool and Python library for fast, value-level comparison (diffing) of rows and columns between two SQL datasets, including cross-database diffs to validate migrations, replication, and transformation changes. The repository is archived (read-only) and is no longer actively supported by Datafold as of May 17, 2024.",3000,data engineering|data quality|data validation|database diffing|SQL|Python|CLI tool|ETL/ELT testing,6,"This repository provides a practical data engineering utility to compare datasets across SQL databases at row/column/value granularity, commonly used for validating data migrations, replication pipelines, and regression testing of transformations. While it is not an ML library and does not directly support model training or inference, it is moderately valuable to ML/data science workflows by helping ensure upstream data correctness and consistency, which is critical for reliable features and analytics. The project shows meaningful community adoption (thousands of GitHub stars), but it is archived and no longer actively maintained, which reduces its long-term utility for production ML stacks.",success
https://github.com/gunnarmorling/awesome-opensource-data-engineering,awesome-opensource-data-engineering,"A curated “awesome list” compiling open-source projects and resources used in data engineering, organized by categories such as analytics, lakehouse, CDC, datastores, orchestration, formats, streaming, testing, and monitoring. It’s community-maintained via contributions and pull requests.",3000,data engineering|awesome-list|data pipelines|stream processing|data lakehouse|ETL/ELT|data orchestration|open source,6,"This repository is primarily a curated directory of open-source data engineering tools (not a library or runnable system itself), covering many parts of modern data stacks like processing engines, orchestration, governance, storage, and streaming. It relates to ML/data workflows indirectly: data scientists and ML engineers commonly rely on these underlying systems for ingestion, transformation, feature/analytics data preparation, and observability, but the repo does not provide ML algorithms, modeling code, or MLOps functionality directly. Its educational and discovery value is high (helpful for selecting tools and learning the ecosystem), while direct applicability in day-to-day ML coding is moderate—hence a mid-high relevance score rather than a top score.",success
https://github.com/hyperai/tvm-cn,tvm-cn,"A community-maintained Simplified Chinese translation/localization of the Apache TVM documentation, published as a Docusaurus-based docs website. It helps Chinese-speaking developers learn and track TVM documentation updates and contribute translations via issues/PRs.",3000,documentation|translation|apache-tvm|machine-learning|deep-learning|compiler|docusaurus|gpu,6,"This repository primarily hosts a Simplified Chinese documentation site for Apache TVM, including translated docs content and the Docusaurus build/deployment setup. While it does not provide ML models, datasets, or training/inference code directly, it is still meaningfully useful for ML engineers because TVM is an ML compiler stack used to optimize and deploy deep learning workloads across hardware backends. The score reflects strong educational value and relevance to ML deployment/acceleration workflows, but lower direct applicability as a code library for data science compared to core ML frameworks.",success
https://github.com/montanaflynn/stats,stats,"A well-tested, dependency-free Go (Golang) statistics library providing common descriptive statistics and related utilities (e.g., mean/median/percentiles, correlation, regression, distances, entropy, rounding, and helpers for loading numeric data). It’s designed as a general-purpose stats toolkit for Go applications and data processing workflows.",3000,golang|statistics|data-analysis|descriptive-statistics|regression|correlation|math,6,"This repository is a comprehensive statistics package for Go, offering many foundational statistical functions (descriptive measures, correlation/regression, distances, entropy, and related helpers) with no external dependencies. It is directly useful in data/ML workflows for feature engineering, exploratory data analysis, metrics, and lightweight numeric utilities in Go services or pipelines, though it is not an ML training framework. Community adoption appears solid (about 3k stars), and it has good educational value for learning/using classical statistics in Go, which supports a moderate-to-strong relevance score rather than a core ML-framework score.",success
https://github.com/PeerDB-io/peerdb,peerdb,"PeerDB is an open-source Postgres-first ETL/ELT and replication system that streams data from PostgreSQL to data warehouses, queues, and storage using modes like CDC/log-based replication, cursor-based sync, and XMIN-based sync. It focuses on low-latency, cost-effective movement at scale, with support for Postgres-native features like rich data types, TOAST columns, and schema changes.",2900,data engineering|ETL|ELT|change data capture|PostgreSQL|data replication|data warehouse|streaming,6,"This repository provides infrastructure for moving and syncing data out of PostgreSQL into analytics systems (warehouses/queues/storage), emphasizing real-time or low-latency replication and scalable initial loads. It is not an ML library, but it is directly useful in ML/data science workflows because it helps build and maintain reliable, timely datasets and feature tables in downstream analytical stores. Community adoption appears solid for a specialized data-engineering tool (thousands of GitHub stars), but it is not a dominant, general-purpose ML framework—hence a moderately relevant score.",success
https://github.com/apache/incubator-devlake,incubator-devlake,"Apache DevLake is an open-source dev data platform that ingests and normalizes data from DevOps/developer tools (e.g., GitHub, GitLab, Jira, Jenkins), then enables analysis and visualization (e.g., via prebuilt Grafana dashboards) to produce engineering productivity and delivery-performance insights such as DORA metrics.",2900,devops-analytics|data-pipeline|etl|engineering-productivity|dora-metrics|grafana|data-integration|observability,6,"This repository is primarily a DevOps/engineering analytics data platform: it extracts data from SDLC tools, transforms it into standardized models, and supports dashboards/metrics for delivery performance and productivity insights. While it is not an ML framework, it is directly useful for data/ML workflows as a ready-made pipeline to collect and model high-value software engineering datasets (issues, PRs, CI results) that can be used for forecasting, anomaly detection, or team/process analytics. Its relevance is strengthened by its plugin-based integrations and strong community adoption (thousands of GitHub stars), but it remains indirect for core ML tasks (no primary focus on model training/inference), hence a mid-to-high score rather than 8+.",success
https://github.com/explorerhq/sql-explorer,sql-explorer,"SQL Explorer is a Django-based SQL reporting and lightweight BI tool for writing, sharing, and scheduling SQL queries in a web UI, with conveniences like schema helpers, query history, and visualization summaries. It supports connecting to databases Django supports and can also query user-uploaded CSV/JSON/SQLite, with optional LLM-powered SQL assistance via an API key.",2900,sql|business-intelligence|data-analysis|django|reporting|data-visualization|llm|postgresql-mysql-sqlite,6,"This repository provides a web-based SQL editor/reporting layer (built on Django) that helps teams run, share, and operationalize queries (e.g., scheduled snapshots, parameterized query UIs, exports/API-style outputs). It is not an ML framework, but it is directly useful in data science workflows as an internal analytics/query tool, a lightweight BI interface, and a way to quickly explore datasets (including uploaded CSV/JSON) before/alongside modeling. The optional LLM SQL assistant can speed up query authoring/debugging, which can indirectly accelerate data preparation and feature extraction. The score is 6/10 because it’s solidly data-centric and practically useful for analytics, but not specifically focused on model training, MLOps, or ML algorithms, and its “community adoption” signal is moderate rather than industry-defining. ",success
https://github.com/jamesmawm/High-Frequency-Trading-Model-with-IB,High-Frequency-Trading-Model-with-IB,"A Python-based high-frequency trading (HFT) example model built on the Interactive Brokers (IB) API (via ib_insync), focused on statistical arbitrage concepts like pairs trading and mean reversion, including live tick handling and order placement.",2900,algorithmic-trading|high-frequency-trading|interactive-brokers|ib-insync|pairs-trading|mean-reversion|python|statistical-arbitrage,6,"This repository is primarily an algorithmic trading execution/strategy example for Interactive Brokers, implementing statistical arbitrage ideas (pairs selection, beta/mean estimation, resampling time series, and signal generation on tick data) in Python. It is meaningfully related to data/ML workflows because it involves time-series data handling, parameter estimation, and quantitative modeling concepts commonly used in data science for finance, but it is not a general-purpose ML library nor a modern model training framework. Community adoption appears moderate (thousands of stars), and it can be educational for learning practical market-data ingestion and basic quant modeling, but it has limited direct reuse for broader ML tasks beyond this domain.",success
https://github.com/jeeliz/jeelizFaceFilter,jeelizFaceFilter,"A lightweight JavaScript/WebGL library for real-time face detection and tracking from a webcam (WebRTC) to power augmented-reality face filters. It outputs face presence, position/scale, rotation (Euler angles) and supports features like mouth-opening detection and multi-face tracking with integrations/helpers for engines like Three.js and Babylon.js.",2900,computer vision|face tracking|augmented reality|webgl|javascript|webrtc|three.js,6,"This repository provides a production-oriented, browser-based face detection/tracking system (with bundled pretrained neural-network JSON models) designed primarily for real-time AR face filters rather than model training or dataset work. It is moderately useful to ML/data practitioners because it demonstrates a practical deployment of neural nets for vision in the web stack and can be integrated into CV prototypes or demos, but it is not a general ML framework and does not focus on training, evaluation pipelines, or data processing. Community adoption (stars) suggests meaningful usage, especially among web/AR developers, which boosts its practical value despite limited direct ML workflow integration.",success
https://github.com/rougier/matplotlib-cheatsheet,matplotlib-cheatsheet,"A Matplotlib 3.1 cheat sheet repository containing a ready-to-use PDF/PNG cheatsheet plus the Python source scripts used to generate/reference plotting elements (e.g., lines, markers, colormaps, tick locators/formatters). The README also points users to newer official cheatsheets hosted in the matplotlib/cheatsheets repository.",2900,python|matplotlib|data-visualization|dataviz|cheatsheet|scientific-visualization|data-science,6,"This repository’s primary purpose is educational: it provides a concise Matplotlib cheat sheet (PDF/PNG) and supporting Python scripts that summarize plotting primitives and configuration options. It’s not an ML library, but it is directly useful in ML/data workflows because visualization is a common step for EDA, diagnostics, and communicating results. Community adoption appears solid (thousands of stars), and the content is practical and immediately applicable for data practitioners, hence a moderately relevant score rather than a high ML-specific score.",success
https://github.com/CartoDB/cartodb,cartodb,"CARTO (CartoDB) is a location intelligence and geospatial data visualization platform for uploading, querying (e.g., via SQL), styling (CartoCSS), and publishing geospatial datasets and interactive maps/apps. Note: this repository is marked as deprecated and applies to previous CARTO products (the current platform was released in October 2021).",2800,geospatial|GIS|data visualization|location intelligence|web mapping|PostGIS|Ruby on Rails|JavaScript,6,"This repository contains the (deprecated) open-source CARTO/CartoDB platform for managing geospatial datasets and building interactive maps and geospatial applications, including data upload, SQL querying, and API-based access. It is quite valuable for data workflows involving spatial data engineering, visualization, and geospatial analytics infrastructure, but it is not an ML framework and does not primarily focus on model training/inference. The score reflects strong relevance to data science in the geospatial domain and moderate integration potential (data access/visualization), tempered by its deprecated status and indirect connection to core ML tasks.",success
https://github.com/Djdefrag/QualityScaler,QualityScaler,"QualityScaler is a Windows GUI app (written in Python) that uses AI models to enhance, upscale, and denoise images and videos locally (privacy-focused, no internet required). It supports many image/video formats and features options like multi-GPU acceleration, automatic tiling to reduce VRAM issues, and video upscaling stop/resume.",2800,computer-vision|image-upscaling|video-upscaling|image-denoising|onnxruntime|pytorch|windows-app|python,6,"This repository primarily provides an end-user Windows application for AI-based image/video upscaling and denoising (using models such as BSRGAN, Real-ESRGAN, and IRCNN), rather than a library aimed at training or evaluating ML models. It is still relevant to ML/data workflows because it applies established super-resolution/denoising models (via PyTorch/ONNX/onnxruntime-directml) and can be useful for dataset preparation, media enhancement, and practical inference deployment examples. However, it appears less focused on core data-science tasks like model development, experimentation, or MLOps, and its value is more in applied inference and tooling than in reusable ML research code.",success
https://github.com/TalkingData/inmap,inmap,"inMap is a Baidu-Maps-based geospatial big-data visualization library for rendering large point datasets using layers such as scatter, heatmaps, grids, and clustering, with support for GeoJSON and theming.",2800,geospatial|data-visualization|javascript|baidu-maps|webgl-canvas|big-data|geojson,6,"This repository provides a front-end geospatial visualization library focused on efficiently rendering large location datasets on Baidu Maps (e.g., scatter/heatmap/grid/cluster layers and GeoJSON support). It is moderately relevant to ML/data workflows because data scientists commonly need to explore, validate, and communicate spatial datasets and model outputs (e.g., predictions, anomalies, demand heatmaps) through interactive maps. However, it is not an ML framework and does not include model training/inference or core data-processing pipelines, so its value is primarily in visualization and presentation rather than ML methodology itself. The score reflects useful applicability for geospatial data analysis/communication but limited direct ML functionality.",success
https://github.com/huggingface/knockknock,knockknock,"Knock Knock is a small Python library that sends notifications when a long-running job (commonly model training) finishes or crashes, typically by adding a simple decorator around your main function. It supports multiple notification backends (e.g., email, Slack, Telegram, Microsoft Teams, SMS, Discord, desktop, and others) and also offers a command-line interface.",2800,python|machine-learning|deep-learning|training-monitoring|notifications|mlops|cli,6,"This repository provides lightweight notifications (success/failure, optional return value) around long-running Python tasks via decorators and a CLI, which is especially useful for model training runs that may take hours and can crash unexpectedly. It is not an ML library for modeling/training itself, but it fits naturally into ML/data workflows as a productivity/MLOps utility for monitoring experiments and training jobs. Community adoption appears solid (thousands of GitHub stars), indicating it is a commonly recognized helper tool in the ML ecosystem. The score reflects moderate relevance: high practical utility for ML practitioners, but indirect impact on core data/ML computation.",success
https://github.com/ivanseidel/IAMDinosaur,IAMDinosaur,"A Node.js-based AI that learns to play Google Chrome's offline Dinosaur game by reading on-screen pixels and controlling key presses. It uses a neural network trained via a simple genetic algorithm (selection, crossover, mutation) to decide when to jump/duck.",2800,genetic-algorithm|neural-network|reinforcement-learning|game-ai|nodejs|robotjs|synaptic|computer-vision,6,"This repository is an educational game-AI project that evolves small neural networks with a genetic algorithm to control the Chrome Dino game using screen-pixel inputs and simulated key presses. It’s clearly ML-related (neural networks + evolutionary optimization) and useful for learning core concepts, but it is not a general-purpose ML library and doesn’t integrate into typical data science workflows (datasets, model deployment, experiment tracking, etc.). Community adoption is decent for a demo project (thousands of stars), yet its practical applicability is mostly as a learning/reference implementation rather than a reusable ML tool, so a mid-range score fits.",success
https://github.com/readbeyond/aeneas,aeneas,"aeneas is a Python/C library and set of command-line tools for forced alignment: automatically synchronizing an audio narration with its corresponding text fragments to produce time-aligned mappings in formats like JSON, SRT/WebVTT, and SMIL (EPUB 3).",2800,forced-alignment|speech-processing|audio-text-synchronization|NLP|Python|C|subtitle-generation|EPUB3,6,"This repository provides tooling for forced alignment between audio and text, producing timestamped segment mappings useful for subtitles, EPUB3 media overlays (SMIL), and speech/audio dataset preparation. It is not an ML training framework, but it is directly applicable in ML/data workflows that need aligned audio-text pairs (e.g., building/cleaning ASR or TTS datasets, generating labels, or preprocessing corpora). Community adoption appears solid (about 2.8k GitHub stars), and the project has clear practical/educational value for speech and text-audio alignment tasks, justifying a moderately relevant score.",success
https://github.com/taishi-i/awesome-ChatGPT-repositories,awesome-ChatGPT-repositories,"A curated, categorized awesome-list of open-source GitHub repositories related to ChatGPT and the OpenAI API, continuously updated with new additions. It also points to a Hugging Face Spaces search tool for exploring the indexed repositories.",2800,awesome-list|LLM|ChatGPT|OpenAI API|developer-tools|NLP|agentic-ai,6,"This repository is primarily an organized directory of ChatGPT/OpenAI-related open-source projects rather than an ML library itself. It’s moderately valuable for ML/data workflows because it helps practitioners discover relevant tools, demos, datasets, and tutorials across the ecosystem, which can accelerate experimentation and learning. However, it does not directly provide models, datasets, training code, or data-processing components, so its direct applicability is indirect compared to core ML frameworks.",success
https://github.com/apache/gravitino,gravitino,"Apache Gravitino is an open data catalog / metadata lake that provides high-performance, geo-distributed, federated metadata management. It unifies metadata access for data and AI assets across multiple sources, types, and regions, and includes connectors for common data engines.",2600,data catalog|metadata management|data engineering|data governance|lakehouse|Apache Spark|Apache Flink|Trino,6,"This repository provides a federated, geo-distributed metadata lake (open data catalog) intended to unify metadata access across multiple systems and regions, which is core infrastructure for organizing and governing data assets. While it is not an ML framework, it is meaningfully relevant to ML/data workflows because metadata/catalog systems are commonly used to discover, govern, and operationalize datasets and related AI assets in production. Its connectors (e.g., Spark/Flink/Trino) improve integration potential with data platforms often used in ML pipelines, but it is more indirect infrastructure than an ML-specific tool, so a mid-range score is appropriate.",success
https://github.com/curran/screencasts,screencasts,"A collection of example projects, demos, and supporting code that accompanies Curran Kelleher’s screencasts (notably around D3.js/data visualization and related web technologies). It includes many small, topic-focused folders used as code & presentation materials for individual videos.",2600,data visualization|d3.js|javascript|web development|educational|interactive graphics|front-end,6,"This repository primarily provides educational JavaScript examples that accompany screencasts, with a heavy emphasis on D3.js and browser-based data visualization demos. It is useful for data practitioners who need to learn or prototype interactive visualizations, including basics like parsing CSV data and fetching data for charts, but it is not an ML library or a data-processing framework. Community adoption appears solid (thousands of stars), yet its applicability is strongest for visualization and web-based exploratory/communicative data work rather than model training or MLOps. Therefore, it scores as moderately relevant to data science workflows due to its strong visualization and teaching value.",success
https://github.com/justinzm/gopup,gopup,"GoPUP is a Python (3.7+) data-access library that provides convenient APIs to fetch a wide range of publicly available Chinese internet and macro datasets (e.g., Weibo/Baidu/Google indices, macroeconomic indicators, interest rates, FX, hotlists, news transcripts, box office, university lists, and COVID-related data). Some endpoints require a token obtained via the gopup.cn website.",2600,python|data-collection|web-scraping|economic-data|social-media-analytics|data-apis|time-series,6,"This repository provides a unified Python interface for collecting many real-world public datasets (trend indices, macro/finance indicators, and various informational datasets), typically returning tabular/time-series outputs that are directly usable for analysis. While it is not an ML framework and doesn’t focus on model training, it can be quite useful for ML/data workflows as a data acquisition layer for feature generation, forecasting, or social/economic analytics. Its relatively strong adoption (2.6k GitHub stars) suggests meaningful community use, but its primary value is data access rather than ML-specific tooling, so it scores as moderately relevant rather than core ML.",success
https://github.com/AmberSahdev/Open-Interface,Open-Interface,"Open Interface is a desktop app/script that lets an LLM (e.g., GPT-4o, Gemini, or other OpenAI-API-compatible models) control your computer by planning steps from your request and executing them via simulated keyboard/mouse input while using screenshots to course-correct.",2500,llm agents|computer use|desktop automation|openai api|gemini|python|gui application|multimodal,6,"This repository primarily provides an LLM-powered “computer control”/automation interface: it sends user requests to an LLM backend, uses screenshots for feedback, and executes actions through keyboard/mouse simulation. It is relevant to ML workflows mainly as an applied agentic/multimodal automation tool and as a reference implementation for building LLM agents that interact with GUIs, rather than as a data-science library for analysis, training, or modeling. Community adoption appears moderate (thousands of GitHub stars), but its direct value for typical DS/ML tasks (data prep, modeling, evaluation) is indirect, so it scores as moderately relevant rather than core ML/data infrastructure.",success
https://github.com/OpenStitching/stitching,stitching,"A Python package for fast, robust image stitching/panorama creation built on OpenCV’s stitching module. It provides a CLI, a Docker image, and a Python API (e.g., Stitcher/AffineStitcher) with options for verbose debugging and analysis utilities.",2500,computer vision|image stitching|panorama|opencv|python|image processing,6,"This repository is primarily a computer-vision utility for stitching multiple overlapping images into a single panorama, exposing both a CLI and a Python API on top of OpenCV’s stitching pipeline. It is not an ML training framework, but it is directly useful in data/ML workflows as a preprocessing and dataset-generation tool (e.g., building large mosaics/panoramas for downstream analysis, robotics, mapping, or inspection). Its relevance comes from practical CV pipeline integration and debugging/visualization utilities rather than ML model development, so it rates as moderately relevant rather than core ML.",success
https://github.com/arpanghosh8453/garmin-grafana,garmin-grafana,"A Dockerized Python-based setup that periodically fetches Garmin health/fitness data from Garmin Connect and writes it into an InfluxDB database for long-term visualization and dashboards in Grafana. It supports automated syncing and historical backfilling across many Garmin metrics (sleep, HR, stress, body battery, activities, GPS, etc.).",2500,garmin|grafana|influxdb|docker|time-series|health-data|data-visualization|python,6,"This repository is primarily a self-hosted data collection and time-series visualization stack: it extracts Garmin wearable metrics and stores them in InfluxDB for analysis and Grafana dashboards. While it is not an ML framework, it is quite relevant to data/ML workflows because it creates a structured personal health dataset suitable for downstream feature engineering, trend analysis, and exporting (e.g., CSV) to Python notebooks for modeling. Community adoption appears strong (about 2.5k GitHub stars), which increases practical value as a data source/pipeline, but the repo itself focuses more on ingestion/monitoring than on ML methods, keeping it at a mid-high relevance score.",success
https://github.com/kevmo314/magic-copy,magic-copy,Magic Copy is a browser extension (primarily for Chrome) that uses Meta's Segment Anything Model (SAM) to extract a foreground object from an image and copy the cut-out result to the clipboard. It also documents how to self-host the SAM embedding service (server-example) for users who prefer not to send images to third-party services.,2500,chrome extension|computer vision|image segmentation|image processing|segment anything model|typescript|figma plugin,6,"This repository provides an end-user image-editing workflow (copying a segmented foreground object from an image) built on top of Meta's Segment Anything Model, plus guidance and an example service for running the embedding step yourself. It is ML-adjacent rather than an ML framework: it applies a pretrained model for interactive segmentation and includes a simple server example that can be useful for practitioners integrating SAM into tooling. The score reflects moderate relevance to ML/data workflows (computer vision inference + deployment pattern), but it is not a general-purpose training, evaluation, or data-processing library and is primarily aimed at browser/UX use.",success
https://github.com/mpquant/MyTT,MyTT,"MyTT is a lightweight pure-Python technical analysis indicator library that ports indicator formulas (e.g., Tongdaxin/THS/Wenhua) to Python using NumPy/Pandas, implementing common indicators like MACD, RSI, BOLL, ATR, KDJ, CCI, and more without relying on TA-Lib. It is designed for quant trading/market analysis workflows across stocks, futures, and crypto, with a compact core module (e.g., MyTT.py) and example scripts.",2500,quantitative-finance|technical-analysis|trading-indicators|python|pandas|numpy|crypto-trading,6,"This repository primarily provides a compact technical analysis/indicator toolkit (e.g., MA/EMA, MACD, RSI, Bollinger Bands, ATR, KDJ) implemented in pure Python on top of NumPy/Pandas, intended to help translate common trading-platform indicator formulas into Python for quant analysis and automated trading. It is directly useful in data-science workflows for market/price time-series feature engineering (creating indicator features for research, backtesting, and model inputs), but it is not an ML training framework and does not focus on model development, MLOps, or general-purpose data pipelines. Given its strong relevance to financial time-series preprocessing and feature generation but indirect relation to core ML, it merits a moderately relevant score rather than a high ML-framework score.",success
https://github.com/yunabe/lgo,lgo,lgo is a Go (Golang) Jupyter Notebook kernel and interactive REPL that lets you write and execute Go code interactively (with features like completion/inspection and rich output display). It integrates with Jupyter (and JupyterLab via an extension) and also supports console-based REPL usage.,2500,golang|jupyter|jupyter-kernel|repl|interactive-computing|notebooks|developer-tools,6,"This repository provides an interactive Go kernel for Jupyter plus a REPL, enabling notebook-style workflows (exploration, prototyping, documentation) in Go. While it is not an ML library itself, Jupyter notebook integration can be moderately valuable for data-science workflows (experimentation, reports, teaching) if your data tooling is in Go. Its relevance is limited by being primarily a language/runtime integration tool (and the README notes Go toolchain regressions impacting usability on newer Go versions), so it’s not a core ML/data framework but can support ML/data work in a Go-centric stack.",success
https://github.com/ErickWendel/semana-javascript-expert07,semana-javascript-expert07,Course/project repository for JS Expert Week 7.0 that builds a browser-based “gesture controller” to control a streaming-style UI using webcam-based eye blink detection and hand gesture recognition. It emphasizes running ML inference in the browser (including via Web Workers) and drawing interactive hand overlays on a canvas.,2400,javascript|web development|tensorflowjs|mediapipe|computer vision|hand tracking|eye blink detection|web workers,6,"This repository is primarily an educational/web app project demonstrating real-time computer vision interactions (hand detection and eye-blink control) in the browser using tools like TensorFlow.js and MediaPipe. While it is not a data science repo for training models or building datasets, it is directly relevant to applied ML engineering because it shows how to integrate on-device inference into a production-like UI and offload processing to Web Workers. Its value for ML/data workflows is moderate: strong for learning/integration patterns and ML-in-the-browser prototyping, but limited for model development, evaluation, or data pipeline work.",success
https://github.com/Hedgehog-Computing/hedgehog-lab,hedgehog-lab,"Hedgehog Lab is an open-source, in-browser scientific computing environment for JavaScript, supporting matrix operations (with GPU/WebGL acceleration), TeX/LaTeX rendering, data visualization, and symbolic/computer algebra. It provides a web-based workflow to run/compile/execute scientific JavaScript directly in the browser (see hlab.app).",2400,scientific-computing|javascript|typescript|data-visualization|webgl|gpu-acceleration|symbolic-computation|computer-algebra,6,"This repository is primarily a browser-based scientific computing and visualization environment for JavaScript, emphasizing matrix operations (including GPU/WebGL acceleration), TeX/LaTeX support, and symbolic computation. It is relevant to ML/data workflows because it can support numerical computing, matrix math, and interactive visualization in a lightweight, client-side setting, which can be useful for experimentation, demos, and education. However, it does not appear to be a dedicated ML framework or MLOps/pipeline tool with broad ML ecosystem integration, so its direct applicability to production ML work is moderate rather than core.",success
https://github.com/JesperLekland/react-native-svg-charts,react-native-svg-charts,"A React Native charting library that renders customizable SVG-based charts (e.g., line, bar, area, pie) on iOS and Android, with a compatibility layer for web. It builds chart paths and scales using d3 and is designed to be extensible via “decorator” child components.",2400,react-native|data-visualization|charts|svg|d3|mobile-development,6,"This repository provides reusable chart components for React Native using SVG rendering (via react-native-svg) and d3 for scales/shapes, aimed at building data visualizations in mobile apps. While it is not an ML library, it is directly useful in ML/data workflows for presenting time series, distributions, and model/experiment metrics inside React Native dashboards or apps. The score reflects solid relevance as a visualization tool (common in data science), but limited applicability to core ML tasks like training, inference, feature engineering, or MLOps.",success
https://github.com/geekyouth/SZT-bigdata,SZT-bigdata,"A Shenzhen Metro (Shenzhen Tong card-swipe) passenger-flow big data analysis system demonstrating an end-to-end data pipeline and analytics stack. It combines ETL, streaming, warehousing, and storage/search components (e.g., Flink, Kafka, Hive/Spark, HBase, Elasticsearch, ClickHouse) to study metro transport capacity and support operational optimization.",2400,big data|data engineering|ETL|Apache Flink|Apache Kafka|Apache Spark|data warehousing (Hive/HDFS)|real-time analytics,6,"This repository is primarily a big-data engineering project that builds a multi-component pipeline to ingest and analyze Shenzhen Tong metro card-swipe data for passenger-flow insights. It is highly relevant to data science workflows on the data preparation and analytics infrastructure side (ETL, streaming ingestion, warehousing, and query/serving layers), but it does not appear to focus on ML model training or MLOps as a core deliverable. The educational value is strong for learning modern data platform components and how they integrate, while community adoption is moderate (about 2.4k stars) relative to major ML libraries.",success
https://github.com/visgl/luma.gl,luma.gl,"luma.gl is a high-performance GPU toolkit for the web that provides WebGPU/WebGL2-friendly APIs for rendering and GPU compute, focused on large-scale data visualization. It includes shader/module tooling, WebGL object wrappers, and higher-level engine constructs used as a foundation in the vis.gl ecosystem (e.g., deck.gl).",2400,webgl|webgpu|gpu-compute|data-visualization|geospatial-visualization|typescript|3d-rendering,6,"This repository is a GPU rendering and compute toolkit (WebGPU/WebGL2) primarily built to support high-performance, large-scale data visualization (not model training). It can be valuable in ML/data workflows when you need fast, interactive visualization of large datasets (including geospatial), GPU-based transforms, or custom rendering for analytics dashboards. However, it is not an ML framework, does not provide core ML algorithms, and does not directly integrate with common ML stacks beyond visualization/compute primitives, so its relevance is moderate rather than central.",success
https://github.com/lana-k/sqliteviz,sqliteviz,"Sqliteviz is an offline-first single-page PWA for fully client-side visualization and exploration of SQLite databases and imported CSV/JSON/NDJSON data. It lets you run SQL queries in the browser and turn results into Plotly charts/graphs, pivot tables, and exports (CSV and modified SQLite DBs).",2300,data visualization|SQLite|SQL|browser-based analytics|offline-first PWA|Plotly|Vue.js|data exploration,6,"This repository provides a browser-based, offline-first tool to query SQLite (and import CSV/JSON/NDJSON into SQLite) and visualize results with charts and pivot tables, which is directly useful for exploratory data analysis. While it is not an ML framework and does not focus on model training, it can support many ML/data workflows as a lightweight way to inspect datasets, run ad-hoc SQL, and create quick visualizations without a server. Community adoption appears solid (about 2.3k GitHub stars) and it has clear educational/practical value for data exploration and analysis tooling, warranting a moderately relevant score.",success
https://github.com/running-elephant/datart,datart,"Datart is a next-generation, open and extensible data visualization/BI platform for building and sharing reports, dashboards, large-screen displays, and interactive analytics applications, with plugin-style extensibility and embeddable integration into other systems.",2200,business-intelligence|data-visualization|dashboards|analytics|react|typescript|d3|data-engineering,6,"This repository provides a full BI/data visualization platform (reports, dashboards, SQL editor, and interactive visual analytics) intended for building and distributing data applications. It is relevant to ML/data workflows mainly as a downstream tool for exploratory analysis, KPI monitoring, and communicating results, rather than for model training, MLOps, or core ML algorithms. Community adoption appears moderate (about 2.2k GitHub stars), suggesting practical usefulness but not ML-framework-level ubiquity. These factors make it moderately valuable for data science work, particularly for visualization and analytics delivery, hence a score of 6.",success
https://github.com/ucg8j/awesome-dash,awesome-dash,"A curated “awesome list” of resources for Plotly Dash, including deployment options, tutorials, component libraries, example apps, galleries, cheat sheets, talks, books, and community links.",2200,python|dash|plotly|data-visualization|dashboarding|web-apps|awesome-list,6,"This repository is primarily a curated index of Plotly Dash resources (tutorials, components, examples, deployment guides), rather than a library that provides ML algorithms or datasets. It is moderately useful for data science and ML workflows because Dash is commonly used to build interactive analytics/model-monitoring dashboards and data visualization apps. The repo’s value comes from educational and integration support (finding components and examples quickly), but it does not directly offer ML training, evaluation, or MLOps functionality itself.",success
https://github.com/DKirwan/calendar-heatmap,calendar-heatmap,"A reusable D3.js calendar heatmap component for visualizing daily time-series counts in a GitHub-contributions style grid. It supports configuration options like color ranges, tooltips, legends, click callbacks, and locale/custom units.",2100,javascript|d3.js|data-visualization|heatmap|time-series|calendar-visualization|frontend,6,"This repository provides a D3-based calendar heatmap chart for visualizing daily aggregated time-series data, similar to GitHub’s contribution graph, primarily for frontend data visualization. While it is not an ML library and does not provide modeling/training capabilities, it can be directly useful in data science workflows for exploratory analysis, reporting, and dashboards where temporal density patterns matter. Its applicability is moderate because it focuses on visualization rather than data processing/ML, but it can integrate well into analytics products that present model outputs or event counts over time.",success
https://github.com/karthik/wesanderson,wesanderson,"An R package that provides Wes Anderson–inspired color palettes for data visualization. It includes a set of named palettes and helper functions (e.g., to return discrete or continuous color vectors) that can be used directly in base R and ggplot2 workflows.",2100,R|data-visualization|color-palettes|ggplot2|data-science|plotting,6,"This repository is an R package supplying curated Wes Anderson color palettes and functions to retrieve them for use in plots, including ggplot2 integrations via manual scale values. While it is not an ML library, it is directly useful in data science workflows for exploratory data analysis and presentation-quality visualization. Its popularity (thousands of GitHub stars) and straightforward drop-in use for plots make it moderately valuable for ML/data practitioners, primarily on the communication/visualization side rather than modeling or data processing.",success
https://github.com/minimaxir/facebook-page-post-scraper,facebook-page-post-scraper,"Python scripts to scrape public Facebook Page (and open Group) posts, reactions, and optionally comments/metadata via Facebook’s API endpoints, exporting the results to CSV for analysis. The repo accompanies a tutorial on collecting Facebook post data for statistical/semantic analysis.",2100,web scraping|facebook|social media analytics|data collection|python|csv export|graph api,6,"This repository’s primary purpose is data acquisition: scraping public Facebook page/group posts (plus reactions and comments) and exporting them to CSV for downstream analysis. It’s directly useful in ML/data workflows as a dataset-building utility for tasks like NLP/semantic analysis, sentiment modeling, and engagement/reaction modeling, but it does not include modeling/training code itself. Community interest appears solid (thousands of stars), yet the repo is archived and the README notes historical limitations/bugs affecting completeness of scraped posts, which reduces reliability for production-grade ML pipelines.",success
https://github.com/reugn/go-streams,go-streams,"A lightweight stream processing framework for Go with a concise DSL for building declarative data pipelines from composable Sources, Flows, and Sinks. It includes common stream operators (map/filter/reduce, batching, throttling, windowing) and optional connectors for systems like Kafka, Pulsar, NATS, Redis, WebSocket, and cloud storage.",2100,go|stream-processing|data-pipelines|etl|event-streaming|kafka|windowing,6,"This repository is primarily a Go stream-processing/data-pipeline library, offering a DSL and building blocks (sources/flows/sinks) plus operators like batching, throttling, and windowing, with connectors to common streaming systems (e.g., Kafka/Pulsar/NATS/Redis). It is not an ML framework, but it is directly useful for ML/data workflows when you need real-time feature generation, online ETL, streaming aggregation/windowing, or moving data into/out of systems used by ML stacks. Community adoption appears solid for a Go library (about 2.1k stars), supporting a moderately high score for data engineering relevance rather than core ML modeling.",success
https://github.com/BlankerL/DXY-COVID-19-Crawler,DXY-COVID-19-Crawler,"A COVID-19 (2019-nCoV) realtime data crawler that scrapes outbreak statistics from DXY (3g.dxy.cn), stores historical snapshots (e.g., in MongoDB), and previously exposed the collected data via a public API for downstream visualization/analysis. The repository is archived (read-only) and notes that upstream data sources stopped updating and the hosted API has been taken offline.",2000,web-scraping|data-collection|covid-19|api|python|mongodb|public-health-data,6,"This repository’s primary purpose is data acquisition: it crawls COVID-19 case statistics from DXY and maintains historical data snapshots, and it historically provided an API for consuming that data. That makes it moderately useful for ML/data workflows as a data source and reference implementation for building a scraper + storage + API pipeline, but it is not an ML library and does not provide modeling/training code. Its practical value today is reduced because the project is archived (as of June 1, 2025) and the hosted API is offline, though the code and historical dataset can still be useful for retrospective analyses and education.",success
https://github.com/FormidableLabs/victory-native,victory-native,"A React Native charting library providing Victory chart components (e.g., based on Victory) for building data visualizations in mobile apps. The repository has been archived (read-only) and its README indicates the project has moved/been renamed to “Victory Native XL”.",2000,react-native|react|charts|data-visualization|d3|mobile-development|javascript,6,"This repository provides charting/visualization components for React Native, enabling developers to render plots and charts from data in mobile applications. While it is not an ML framework and does not directly support model training or data pipelines, it is moderately valuable in ML/data workflows for presenting and monitoring data and model outputs (dashboards, metrics, inference results) on-device. The score reflects its strong fit for data visualization (useful to data practitioners) but limited direct integration with core ML tooling; additionally, the repo is archived and has moved, which reduces ongoing utility compared to an actively maintained package.",success
https://github.com/danijar/handout,handout,"Python Handout is a small library that turns normal Python scripts into shareable HTML “handouts” by collecting Markdown comments and inline outputs like images, videos, and matplotlib figures. It aims to be an alternative to Jupyter notebooks without hidden state, while working from any text editor.",2000,python|data-science|research|reproducible-reporting|markdown|matplotlib|notebook-alternative|html-reporting,6,"This repository provides a reporting/handout tool that lets you write regular Python scripts and generate an HTML document that interleaves Markdown and computed outputs (figures, images, videos). It is not an ML training or modeling library itself, but it is directly useful in ML/data workflows for experiment logging, communicating results, and producing reproducible reports without notebook state issues. The score reflects strong practical and educational value for data scientists, but limited direct ML functionality and comparatively modest adoption relative to core ML frameworks.",success
https://github.com/legions-developer/evilcharts,evilcharts,"A TypeScript-based React/Next.js chart UI website/library that provides beautiful, animated, interactive, and responsive chart components (e.g., bar/line/area/pie/radar) built on top of shadcn/ui and Recharts.",2000,data visualization|charts|react|next.js|typescript|recharts|shadcn-ui|frontend,6,"This repository focuses on providing reusable, visually polished chart components and a chart UI site for React/Next.js, emphasizing animation, interactivity, and customization. It’s relevant to ML/data workflows primarily as a presentation layer for exploring and communicating metrics, model results, dashboards, and experiment tracking visuals rather than for data processing or model training. Community adoption appears moderate (about 2k GitHub stars), indicating usefulness as a visualization UI resource. I rated it a 6 because data visualization is a common need in ML/data work, but the repo is not an ML framework or data pipeline tool and does not directly handle modeling or large-scale analytics.",success
https://github.com/opensearch-project/OpenSearch-Dashboards,OpenSearch-Dashboards,"Open source visualization and analytics UI for OpenSearch, used to explore data, build dashboards, and manage/operate OpenSearch-related features via a web interface.",2000,data visualization|dashboards|opensearch|search analytics|observability|log analytics|web development|typescript,6,"OpenSearch-Dashboards is primarily a web-based visualization and analytics front-end for OpenSearch, enabling users to explore indexed data, create charts/dashboards, and support operational analytics use cases. While it is not an ML library or training framework, it can be valuable in ML/data workflows for exploratory analysis, monitoring data pipelines, and visualizing metrics/logs/features stored in OpenSearch. Its relevance is strongest for data/ML teams doing observability and analytics around search or time-series/log data rather than model development, hence a moderately relevant score.",success
https://github.com/owocki/pytrader,pytrader,A cryptocurrency trading robot built (originally in 2016) to predict price movements with machine-learning models and sometimes execute trades on the Poloniex exchange. It includes experimentation scripts for model/parameter sweeps and a Django-based admin UI for monitoring trades and tuning predictors.,2000,cryptocurrency|algorithmic-trading|machine-learning|scikit-learn|quant-finance|django|trading-bot,6,"This repository implements an ML-driven crypto trading system that trains/tests models (e.g., scikit-learn classifiers and PyBrain neural networks) on historical price-movement data to make buy/sell/hold decisions and optionally place trades on Poloniex. It relates to ML/data workflows via supervised learning experiments, parameter sweeps, and evaluation against real market data, making it useful as an educational example of applied ML in quantitative finance. However, it appears to be an older project (noted as put on ice in 2017) and is narrowly focused on a specific exchange and architecture, limiting modern production applicability and community relevance compared with current ML/data tooling.",success
https://github.com/AgentOps-AI/tokencost,tokencost,Client-side token counting and USD cost estimation for LLM prompts and completions across 400+ models. Provides simple functions to count tokens and estimate API usage cost while tracking model pricing changes over time.,1900,LLM|tokenization|cost-estimation|python|OpenAI|Anthropic|MLOps,6,"This repository is a Python utility that counts tokens and estimates dollar cost for LLM API usage (prompt and completion), with a large, maintained pricing table across many models/providers. It is not a model training or data processing library, but it is directly useful in ML/LLM engineering workflows for budgeting, monitoring, and optimizing inference/agent costs (a common concern in production LLM systems). Community adoption appears solid (about 1.9k GitHub stars), supporting practical relevance, but its scope is narrower than core ML/data frameworks—hence a mid-to-high score rather than 8+.",success
https://github.com/faust-streaming/faust,faust,"Faust-Streaming is a community-maintained fork of the original Faust project: a Python stream/event processing library (inspired by Kafka Streams) for building real-time applications and data pipelines on Apache Kafka, with support for stateful processing via embedded key-value stores (e.g., RocksDB) and windowed aggregations.",1900,stream processing|event-driven architecture|apache kafka|python|data pipelines|stateful processing|asyncio,6,"This repository provides a Python-based, Kafka-backed stream processing framework for building real-time, stateful event-processing services and data pipelines (agents, topics, tables, and windowed aggregations). It is not an ML library, but it is moderately relevant to ML/data workflows because it can be used to ingest, transform, aggregate, and feature-engineer streaming data in real time before training or online inference. Its direct ML integration is mostly “bring your own” (you can use libraries like NumPy/Pandas/PyTorch in processors), so it scores below dedicated data/ML frameworks while remaining practically useful for streaming data engineering in ML systems.",success
https://github.com/jrothschild33/learn_backtrader,learn_backtrader,"A Chinese-language tutorial/notes repository for the Python Backtrader quantitative trading backtesting framework, covering core concepts like data feeds, indicators, orders/brokers, strategy construction, and visualization. Includes lesson scripts (Lesson1.py–Lesson7.py) and a detailed README that links to the corresponding tutorial chapters.",1900,quantitative trading|algorithmic trading|backtesting|backtrader|python|financial time series|trading strategies|education,6,"This repository is primarily an educational guide for Backtrader, a Python framework used to backtest and run systematic trading strategies, with lesson scripts and extensive written notes. It is relevant to data science workflows because quant research and strategy backtesting commonly involve time-series data handling, feature/indicator computation, and evaluation/analysis, but it does not focus on machine learning model training or ML tooling itself. Community adoption appears moderate-to-strong for a tutorial repo (about 1.9k stars), which increases its practical learning value, yet its scope remains more quant/backtesting than core ML.",success
https://github.com/little-book-of/linear-algebra,linear-algebra,"An open-source, concise, beginner-friendly introduction to the core ideas of linear algebra, published as a web-readable “little book” with accompanying content in Jupyter Notebook/TeX.",1900,linear algebra|mathematics|education|machine learning fundamentals|jupyter notebook|tex|open textbook,6,"This repository is primarily an educational resource (a short book) teaching foundational linear algebra concepts, with content authored largely in Jupyter Notebooks and TeX. Linear algebra is central to many ML/data science workflows (e.g., vectors, matrices, transformations, decompositions), so the material is broadly useful for learning prerequisites. However, it is not a library/tool for data processing, modeling, or MLOps, and it does not appear to provide ML-specific code APIs or integrations, which limits direct day-to-day workflow applicability—hence a moderately relevant score.",success
https://github.com/yomorun/yomo,yomo,"YoMo is an open-source, serverless AI agent framework focused on LLM function-calling, designed to run over a geo-distributed edge infrastructure with low-latency communication (via QUIC) and strong security (TLS 1.3). It provides tooling (including a CLI) to build, deploy, and operate scalable, strongly-typed AI agent “tools” and agent-to-server communications, including an OpenAI-API-compatible endpoint option.",1900,ai-agents|llm-function-calling|edge-computing|serverless|quic|golang|developer-tools,6,"This repository primarily provides infrastructure and a framework for building and operating AI agents with LLM function-calling, emphasizing low-latency networking (QUIC), security, and serverless-style deployment/operations rather than implementing ML algorithms or training code. It is moderately relevant to ML workflows because ML/AI engineers can use it to serve/integrate LLMs (e.g., via OpenAI-compatible endpoints and providers like vLLM/Ollama) and to package/host tools that agents call in production. The score reflects strong practical applicability for deploying LLM-powered systems, but limited direct value for data science tasks like data analysis, feature engineering, model training, or evaluation compared to core ML libraries.",success
https://github.com/crystaldba/postgres-mcp,postgres-mcp,"Postgres MCP Pro is an open-source Model Context Protocol (MCP) server that gives AI assistants/agents configurable and safe access to a PostgreSQL database. It adds database performance and operations features like index tuning, EXPLAIN plan analysis, health checks, schema-aware SQL generation, and access-controlled SQL execution over stdio or SSE transports.",1800,postgresql|mcp|ai-agents|database-tooling|query-optimization|index-tuning|python,6,"This repository provides an MCP server that lets AI agents interact with PostgreSQL with guardrails (restricted/unrestricted modes) and adds DBA-style capabilities like index tuning, EXPLAIN plan inspection, and database health diagnostics. It is not an ML framework, but it can be very useful in ML/data workflows because teams frequently rely on Postgres for datasets, feature stores, analytics tables, and ETL/ELT, and this tool can help agents safely explore schemas, generate SQL, and troubleshoot query performance. Community adoption appears solid (about 1.8k GitHub stars), but its primary value is infrastructure/DB operations rather than model training or experimentation, which is why it scores mid-range rather than high.",success
https://github.com/neo4j-contrib/neovis.js,neovis.js,"Neovis.js is a browser-based graph visualization library that combines Neo4j (via Cypher queries/live connection) with vis.js to render interactive network graphs. It supports configurable label/relationship styling, node sizing/coloring/grouping, images, and popovers based on Neo4j properties.",1800,graph-visualization|neo4j|cypher|javascript|typescript|data-visualization|visjs,6,"This repository’s primary purpose is interactive visualization of graph data stored in Neo4j, driven by user-defined Cypher queries and property-based styling. It is not an ML library, but it is useful in data/ML workflows for exploratory analysis, presenting graph-analytics outputs (e.g., PageRank/community labels stored as properties), and building dashboards or demos around graph datasets. The score reflects strong relevance to data visualization and graph analytics communication, but limited direct support for model training, feature engineering, or ML pipelines.",success
https://github.com/warpstreamlabs/bento,bento,"Bento is a high-performance, resilient stream processing tool (written in Go) for building declarative data pipelines that connect many sources and sinks while performing transformations, enrichments, filters, windowing, and multiplexing. It is designed to be operationally simple to deploy (static binary/Docker/serverless) with at-least-once delivery guarantees and strong observability support.",1800,stream processing|data engineering|ETL/ELT|Kafka|connectors|Go|event-driven architecture|cloud native,6,"This repository provides a general-purpose streaming data pipeline/processing framework that connects to many data systems (e.g., Kafka, Pub/Sub, S3, databases) and supports transformations and enrichments via a mapping language and processors. While it is not an ML library, it is directly useful for ML/data workflows as infrastructure for ingestion, real-time feature/event pipelines, and moving data into analytics/warehouse/feature-store destinations. Community adoption appears meaningful (around 1.8k GitHub stars) and it offers practical educational value for designing reliable streaming pipelines, but it is not focused on model training, evaluation, or MLOps orchestration—hence a moderately relevant score.",success
https://github.com/apache/fluss,apache/fluss,"Apache Fluss (Incubating) is a streaming storage system for real-time analytics that serves as a real-time data layer for Lakehouse architectures. It focuses on low-latency, high-throughput ingestion and streaming reads/writes and integrates with compute engines such as Apache Flink (with additional engines planned).",1700,streaming|streaming-storage|real-time-analytics|lakehouse|big-data|apache-flink|data-engineering,6,"This repository implements a streaming storage layer aimed at real-time analytics and lakehouse-style architectures, emphasizing sub-second latency, high-throughput ingestion, changelog generation, and lookup queries. While it is not an ML library, it is directly useful in ML/data workflows as infrastructure for reliable low-latency feature ingestion, streaming ETL, and real-time analytical/operational data access (e.g., feeding online features or near-real-time aggregates). The project’s focus is squarely on data engineering and streaming analytics rather than model training/inference, which limits its ML-specific applicability, but it can be a strong enabling component in production ML systems that require real-time data pipelines.",success
https://github.com/austin-starks/NextTrade,NextTrade,"NextTrade is an algorithmic trading system for creating, backtesting, optimizing (via genetic algorithms), and deploying trading strategies and portfolios. It includes a web UI and supports live deployment via broker integration (e.g., Tradier), with MongoDB/Node-based local setup instructions.",1700,algorithmic-trading|quant-finance|backtesting|genetic-algorithms|portfolio-management|nodejs|mongodb|trading-strategies,6,"This repository primarily provides an end-to-end algorithmic trading platform: users can compose rule-based strategies, backtest them on historical market data, and deploy them for live trading. Its strongest ML-adjacent component is parameter optimization using a genetic algorithm (plus optimization targets like Sharpe/Sortino), which can be useful for quant research workflows. However, it is not a general ML framework and does not appear focused on model training/inference pipelines or standard ML tooling, so its ML/data value is moderate rather than core.",success
https://github.com/ericdrowell/ElGrapho,ElGrapho,"El Grapho is a high-performance WebGL graph (network) data visualization engine for the browser, designed to render and interact with very large graphs (potentially millions of nodes and edges). It provides an API for building interactive graph visualizations such as force-directed graphs, trees, and other network layouts.",1700,webgl|graph-visualization|network-graphs|data-visualization|javascript|browser,6,"This repository provides a WebGL-based engine for rendering and interacting with large-scale graph/network visualizations in the browser, emphasizing performance and scalability. While it is not an ML library, graph visualization is commonly used in data science workflows (EDA for relational/graph data, presenting results, inspecting embeddings/clusters, and exploring network structures). Its value for ML/data work is moderate because it can be used directly to visualize graph-structured datasets, but it does not provide modeling, training, or data-processing capabilities itself.",success
https://github.com/iphysresearch/DataSciComp,DataSciComp,"A curated collection of data science challenges/competitions, presented with tags and countdown timers to track entry deadlines. The repo also includes a (Flask-based) website/app setup and YAML datasets that define competitions and hosts.",1700,data science|machine learning|competitions|challenge listing|dataset curation|flask|yaml,6,"This repository primarily aggregates and structures metadata about data-science/ML competitions (including deadlines, tags, and links) and provides a site/app to browse them, making it useful as a reference/curation tool rather than a modeling library. It can support ML/data workflows indirectly by helping practitioners discover relevant competitions and datasets, but it does not provide core ML algorithms, training pipelines, or MLOps capabilities. Community adoption appears moderate-to-strong (about 1.7k stars), but the repository is archived/read-only (archived by the owner on Nov 21, 2021), limiting ongoing updates. These factors place it in the “moderately relevant” range for ML/data work.",success
https://github.com/mbadry1/Top-Deep-Learning,Top-Deep-Learning,"A curated, periodically generated list of the top deep learning GitHub repositories (top 200) ranked by star count, produced using a GitHub Search API query for deep-learning-related keywords.",1700,deep learning|machine learning|awesome-list|github-search-api|curation|python,6,"This repository primarily provides a curated ranking/list of popular deep-learning-related GitHub projects, generated from GitHub Search API results, rather than implementing ML models or a training/inference framework. It’s useful for ML practitioners as a discovery and reference resource to find widely adopted libraries, tutorials, and tools, which can support learning and tooling selection. However, it has limited direct applicability in ML workflows beyond repository discovery and doesn’t provide datasets, model code, or MLOps functionality, so it scores as moderately relevant.",success
https://github.com/CyberPunkMetalHead/Binance-News-Sentiment-Bot,Binance-News-Sentiment-Bot,"A Python Binance trading bot that scrapes recent headlines from the top 100 crypto news feeds, performs sentiment analysis per coin, and places buy orders when aggregated sentiment is positive (then sells ~99.5% of purchased coins to avoid exceptions).",1600,cryptocurrency|trading-bot|binance|binance-api|sentiment-analysis|nlp|python,6,"This repository implements an automated crypto trading workflow driven by headline sentiment: it collects news headlines from many crypto feeds, analyzes sentiment, aggregates results by coin, and triggers Binance trades based on the sentiment signal. It is meaningfully related to ML/data workflows because it performs text/sentiment analysis and includes a data-collection pipeline that could be repurposed for NLP feature engineering or backtesting. However, it appears to focus on application logic for a specific trading bot rather than providing reusable ML models, datasets, evaluation, or MLOps components, and its broader ML community adoption seems limited compared with dedicated NLP/ML libraries. That mix makes it moderately valuable for ML/data practitioners (especially as an end-to-end example), but not a core ML tool.",success
https://github.com/Hiflylabs/awesome-dbt,awesome-dbt,"A curated “awesome list” of dbt (data build tool) resources, collecting links to guides, best practices, integrations, data quality tools, CI/CD patterns, orchestration options, utilities, packages, snippets, and sample projects for analytics engineering with dbt.",1600,data engineering|analytics engineering|dbt|data transformation|ELT|data quality|CI/CD,6,"This repository is primarily a curated directory of dbt learning materials and ecosystem tools rather than a runnable ML library. It is strongly relevant to data science/ML workflows indirectly because dbt is commonly used to build reliable, tested transformation layers that feed feature tables and training/serving datasets. The score reflects moderate usefulness for ML/data practitioners (education + tooling discovery for data pipelines), but limited direct ML functionality and no model training/inference components.",success
https://github.com/MobilityData/awesome-transit,awesome-transit,"A community-maintained “awesome list” curating open public-transit technology resources, including data standards (e.g., GTFS/GTFS-RT), APIs, tools, libraries, datasets, apps, and research. It serves as a central index for producing, sharing, and using transit and multimodal data/software.",1600,public transit|GTFS|GTFS Realtime|open data|datasets|data standards|awesome-list|transportation,6,"This repository is primarily a curated directory of transit-related standards, datasets, APIs, and tools rather than an ML library or runnable data pipeline. It’s moderately useful for data science because it helps practitioners discover GTFS/GTFS-RT resources, data archives, validators, and tooling that can feed analytics, forecasting, routing research, or downstream ML feature engineering. However, it does not itself provide models, training code, or end-to-end ML workflows, so its direct applicability to ML engineering is indirect despite strong relevance to transportation data work.",success
https://github.com/avhz/RustQuant,RustQuant,"RustQuant is a Rust library for quantitative finance, providing building blocks for pricing and modeling (instruments, curves/term structures, stochastic process simulation, and time/calendar utilities) plus supporting math, optimization, and automatic differentiation. It also includes a small ML module (e.g., linear/logistic regression and k-NN) and data IO utilities (CSV/JSON/Parquet) including downloading market data from Yahoo Finance.",1600,rust|quantitative-finance|financial-engineering|stochastic-processes|derivatives-pricing|monte-carlo-simulation|statistics|machine-learning,6,"RustQuant’s primary focus is quantitative finance infrastructure—models, stochastic simulation, instruments/pricing, curve/data structures, and time conventions—rather than being an ML-first framework. It is nonetheless meaningfully useful for data/ML workflows because it provides statistics/math utilities, optimization (e.g., gradient descent/Newton-Raphson), automatic differentiation, data ingestion/serialization, and a small built-in ML module (linear/logistic regression and k-NN). Community adoption appears moderate (about 1.6k GitHub stars), indicating real usage, but the ML coverage is limited compared with dedicated ML ecosystems; this supports a mid-to-upper score rather than an 8–10.",success
https://github.com/chunqiuyiyu/ervy,ervy,"Ervy is a JavaScript library that renders charts directly in the terminal using ASCII/colored characters. It supports multiple chart types (e.g., bar, pie, bullet, donut, gauge, scatter) for quick console-based visualization.",1600,javascript|cli|terminal|ascii-art|data-visualization|charts|console,6,"This repository provides terminal-based chart rendering (ASCII/colored output) and is primarily aimed at CLI/console visualization rather than machine learning itself. It can still be useful in data/ML workflows for quick exploratory summaries, monitoring, and lightweight reporting in terminal-first environments (e.g., SSH sessions, logs, CI pipelines). Community adoption appears moderate (about 1.6k GitHub stars), but it is not an ML framework nor a data-processing library. Given its direct utility for visualization in data workflows but lack of core ML functionality, a score of 6 is appropriate.",success
https://github.com/getdozer/dozer,dozer,"Dozer is a real-time data movement tool that uses change data capture (CDC) to stream data from multiple sources into multiple sinks, with support for stateless transformations. It is primarily used to move operational data into analytics/warehouse systems (e.g., ClickHouse) and to power downstream data APIs.",1600,data-engineering|change-data-capture|streaming|etl|data-pipelines|rust|clickhouse|sql,6,"This repository provides a CDC-based, real-time data movement/ETL system for ingesting from sources like Postgres/MySQL/Snowflake and sinking into systems like ClickHouse/BigQuery, aimed at operational-to-analytics data flows. It is not an ML framework, but it is directly useful in ML/data workflows by building reliable, low-latency feature/analytics data pipelines and feeding warehouses/lakes that ML systems depend on. Community adoption appears moderate (about 1.6k GitHub stars), and its practical integration value for data teams is strong, so it merits a mid-high score rather than a core-ML score.",success
https://github.com/hadley/stats337,stats337,"Course repository for Stanford's Stats 337 (Spring 2018), providing a curated syllabus of readings in applied data science. It organizes weekly reading lists and supporting materials/resources for class discussion.",1600,data science education|statistics|course materials|reading list|reproducible research|data ethics|software engineering,6,"This repository is primarily an educational reading list/syllabus for an applied data science discussion course, organized by weekly topics (e.g., data collection/collaboration, software engineering, DevOps, reproducibility, ethics). It is useful to data scientists and ML practitioners as curated guidance on best practices and concepts that support ML/data workflows (reproducibility, technical debt, collaboration), but it does not provide a reusable ML library, models, datasets, or pipelines. Community adoption appears moderate for a course reading repo (about 1.6k stars), supporting a mid-range score rather than a high score reserved for core ML tools.",success
https://github.com/iam-abbas/Reddit-Stock-Trends,Reddit-Stock-Trends,"Fetches currently trending stock tickers on Reddit, then analyzes their stock performance (e.g., via Yahoo Finance) and outputs results (CSV/JSON) that can be visualized in included web frontends (Vue and React).",1600,reddit|stock-market|sentiment-analysis|data-collection|python|yfinance|vue|react,6,"This repository builds a pipeline to collect ticker mentions from Reddit (via the Reddit API/PRAW), compute trending tickers, and analyze market performance using finance data (e.g., yfinance), exposing results as files and optionally a JSON API with web visualizations. It’s directly useful for data workflows (scraping/ETL + basic analytics + visualization) and can serve as a starting point for ML/NLP tasks like sentiment analysis or predictive modeling, but it doesn’t appear to provide a full ML model training/evaluation framework out of the box. The moderate score reflects strong practical data engineering/analytics relevance, but limited explicit ML components and unclear community-standard ML integration beyond being a popular repo.",success
https://github.com/kantord/just-dashboard,just-dashboard,"A tool for building and hosting simple, shareable dashboards defined in YAML or JSON, rendering charts and layout elements in the browser (powered by D3). It supports hosting dashboards via files (including GitHub Gists) to quickly publish data-driven visualizations without writing a custom web app.",1600,dashboard|data-visualization|d3.js|yaml|json|business-intelligence|data-engineering|github-gist,6,"just-dashboard is primarily a lightweight dashboarding/visualization project that turns YAML/JSON definitions into chart-based dashboards (using D3) and supports easy hosting/sharing (including via GitHub Gists). It is not an ML framework or modeling tool, but it can be directly useful in data workflows for quickly visualizing and communicating results, metrics, or summaries from analyses. The repo is moderately relevant to data science due to its visualization and reporting utility, but it lacks core ML/data processing functionality (e.g., feature engineering, training, evaluation, MLOps).",success
https://github.com/karlicoss/HPI,HPI,"Human Programming Interface (HPI) is a Python package (named `my`) that unifies, parses, and exposes your personal data from many services (e.g., social, reading, notes/todos, health, location, photos, browser history, messaging) as importable Python objects. It abstracts away data discovery, parsing, error handling, and caching so you can analyze and build tools on top of your own “lifelog” data using standard Python workflows.",1600,python|personal-data|lifelogging|quantified-self|data-extraction|data-processing|etl,6,"HPI’s primary purpose is personal data unification: it provides many connectors/parsers that turn disparate personal data sources into structured Python objects for querying and analysis. While it is not an ML framework, it is directly useful for data science workflows because it simplifies data ingestion/ETL, normalization, and access patterns across heterogeneous personal datasets. It can be a strong foundation for downstream analytics/visualization and for creating ML-ready datasets (e.g., time series, text, behavioral logs), but it lacks built-in modeling/training capabilities and is more niche (personal lifelogging) than broadly adopted ML tooling.",success
https://github.com/nanxstats/awesome-shiny-extensions,awesome-shiny-extensions,"A curated “awesome list” of R and Python packages that extend Shiny with additional UI components, widgets, visualization tools, backend helpers, deployment options, and developer tooling. It serves as a categorized directory to discover Shiny ecosystem extensions for both R Shiny and Shiny for Python.",1600,R|Python|Shiny|data visualization|web applications|UI components|awesome-list,6,"This repository is primarily a curated index of Shiny extensions (widgets, visualization libraries, theming, backend integrations, deployment and developer tools) rather than an ML library itself. It is moderately valuable to data science and ML workflows because Shiny is commonly used to build interactive dashboards, data exploration apps, and model demos, and this list helps practitioners find the right components to present and operationalize analytics. However, it does not directly provide ML algorithms, training utilities, or MLOps infrastructure, so its relevance is mostly in app-building and visualization around data/ML outputs rather than core modeling.",success
https://github.com/nerevu/riko,riko,"riko is a pure-Python stream processing engine (inspired by Yahoo! Pipes) for analyzing and transforming streams of structured data. It provides synchronous and asynchronous APIs, supports parallel execution, includes a modular “pipes” workflow system, and ships with a CLI for running flows.",1600,python|data-processing|stream-processing|etl|workflow|rss|cli,6,"This repository provides a Python stream-processing/workflow framework for ingesting and transforming structured data (e.g., CSV/XML/JSON/HTML) and working with RSS/Atom feeds via modular pipeline “pipes,” with optional async and parallel execution. That makes it moderately useful for data science workflows as a lightweight ETL/data-wrangling tool, especially for scraping/feeds and feature-prep style transformations. However, it is not an ML framework and does not focus on model training, evaluation, or MLOps integrations, and its community adoption appears modest compared with mainstream data tooling—so it scores as moderately (not highly) relevant.",success
https://github.com/ptyadana/SQL-Data-Analysis-and-Visualization-Projects,SQL-Data-Analysis-and-Visualization-Projects,"A curated collection of SQL-focused data analysis and visualization practice projects, spanning MySQL, PostgreSQL, and SQLite, with some Tableau and Spark/PySpark components. It includes multiple end-to-end mini projects and query challenges for building analytics skills.",1600,sql|data analysis|data visualization|mysql|postgresql|sqlite|tableau|pyspark,6,"This repository is primarily an educational collection of SQL analytics projects (plus some Tableau and Spark/PySpark work) meant to practice querying, exploratory analysis, and reporting-style questions. It is useful for data workflows because SQL is foundational for data extraction, feature/label creation, and dataset exploration prior to modeling, and Spark/PySpark can be relevant for larger-scale data processing. However, it does not appear to provide ML model training code, reusable ML libraries, or MLOps tooling, and its community adoption is modest relative to core ML/data tools. For those reasons it is moderately valuable for data science learning and day-to-day data prep, but not a core ML repository.",success
https://github.com/siddhi-io/siddhi,siddhi,"Siddhi Core Libraries is an open-source, cloud-native stream processing and complex event processing (CEP) engine that uses Streaming SQL to ingest events from diverse sources, detect patterns/conditions, and emit results to various sinks in real time. It provides core components such as siddhi-core, query API/compiler, and annotations, and can run embedded (Java/Python) or as microservices (Docker/Kubernetes).",1600,stream processing|complex event processing|streaming SQL|real-time analytics|data engineering|event-driven architecture|Java,6,"This repository provides a stream processing and complex event processing engine (Siddhi) centered around a SQL-like streaming query language, intended for real-time data ingestion, transformation, pattern detection, and routing. It is not an ML framework, but it is moderately relevant to ML/data workflows because it can act as a real-time data-processing layer for feature/metric computation, online analytics, and feeding downstream ML systems (and the repo topics include online learning). The score reflects strong applicability for streaming data engineering and real-time pipelines, but limited direct support for model training/inference compared with dedicated ML platforms.",success
https://github.com/soroushchehresa/awesome-coronavirus,awesome-coronavirus,"A curated “awesome list” aggregating COVID-19 (coronavirus) resources and community projects, including APIs, datasets/statistics, models, learning materials, maps, apps/bots, and other tools. It also powers a companion site (corona.js.org) and provides contribution guidelines for adding new items.",1600,awesome-list|covid-19|datasets|data-sources|epidemiology|public-health|apis|data-visualization,6,"This repository is primarily a curated index of COVID-19 resources rather than a standalone ML library or data-processing tool, but it includes substantial pointers to datasets, statistics sources, and modeling-related resources. It can be directly useful to data scientists for discovering data sources and example projects/models to build upon, especially for epidemiology/public-health analytics. Its value is therefore moderate for ML/data workflows: high for discovery and education, but limited for direct integration because it is not itself an ML framework or pipeline.",success
https://github.com/BemiHQ/BemiDB,BemiDB,BemiDB is an open-source Snowflake + Fivetran alternative that syncs data from multiple sources into compressed columnar files on S3/object storage and exposes a Postgres-compatible analytical query engine for fast querying. It ships as a single Docker image with built-in connectors and separates storage from compute.,1500,analytics database|data warehouse|ELT|data ingestion|PostgreSQL-compatible|columnar storage|Iceberg|S3,6,"BemiDB primarily targets analytics/data warehousing: it replicates/syncs data from sources (e.g., Postgres and SaaS connectors) into compressed columnar storage on S3 and provides a Postgres-compatible analytical query layer for BI and large analytical queries. This is strongly relevant to data engineering workflows that support ML (feature generation, offline analytics, dataset extraction), but it is not an ML framework and does not directly provide model training/inference capabilities. The value to ML practitioners is indirect but meaningful: it can simplify building and querying large analytical datasets used downstream for ML pipelines, hence a moderately relevant score.",success
https://github.com/DataBrewery/cubes,cubes,"Cubes is a (now not maintained) lightweight Python OLAP framework for multidimensional modeling and browsing/aggregating data (“data cubes”), including a logical cube model layer and an optional HTTP OLAP server (Slicer) built on Flask with SQL backends via SQLAlchemy.",1500,python|olap|data-warehouse|multidimensional-analysis|data-modeling|sqlalchemy|data-analysis|analytics-server,6,"This repository provides an OLAP/multidimensional analytics toolkit (cube modeling, dimensions/hierarchies, and aggregate query/browsing) primarily aimed at reporting and analytical applications over relational data sources. It’s relevant to data workflows because it helps structure analytical datasets and serve/query aggregates—useful for BI, feature aggregation, and exploratory analysis—though it is not an ML training or modeling framework. Community adoption appears moderate (about 1.5k stars), but the project is explicitly marked as NOT MAINTAINED, which reduces practical value for modern ML/DS stacks. Overall, it’s moderately valuable for data engineering/analytics use cases, less so for current ML pipelines due to maintenance status and ecosystem shift.",success
https://github.com/Vespa314/chan.py,chan.py,"An open Python framework implementing Chan theory (缠论) for quantitative trading/technical analysis. It supports multi-timeframe K-line combination, morphologic/dynamic buy-sell point analysis, interval-nesting strategies, visualization/plotting, multiple data sources, strategy development, and integration with trading systems (with some advanced components not included in the public code).",1500,quantitative finance|algorithmic trading|technical analysis|chanlun (缠论)|time series|python|data visualization,6,"This repository is primarily a quantitative trading/technical analysis framework (Chan theory) focused on computing market structure elements and buy/sell points, with multi-timeframe K-line handling and plotting/visualization. It is relevant to ML/data workflows because it can generate structured signals/features from financial time-series data and the README explicitly discusses strategy integration with machine-learning frameworks, but the public release notes indicate that models/AutoML and some higher-level strategy components may not be included. Community adoption appears solid (around 1.5k GitHub stars), supporting moderate ML/data relevance rather than being a core ML library.",success
https://github.com/beizhedenglong/rough-charts,rough-charts,"A responsive, composable React charting library that renders charts with a hand-drawn (roughjs-style) aesthetic. Written in TypeScript and designed to let you combine chart series components to build custom visualizations.",1500,react|typescript|data-visualization|charting-library|roughjs|d3|storybook|frontend,6,"This repository provides a React charting/data-visualization library with a sketchy, hand-drawn style built on top of d3 and roughjs, intended for frontend chart rendering rather than ML itself. It can be directly useful in data science workflows for communicating results (dashboards, reports, model metric visualizations) but does not include data processing, modeling, training, or MLOps capabilities. Community adoption appears decent for a niche visualization library (around 1.5k GitHub stars), supporting moderate relevance for data practitioners focused on presentation and exploratory visualization.",success
https://github.com/ecomfe/awesome-echarts,awesome-echarts,"A community-maintained “awesome list” curating resources, extensions, wrappers, language bindings, and tools related to Apache ECharts. It organizes links to learning materials (docs/videos) and ecosystem projects (framework components and integrations).",1500,data-visualization|apache-echarts|awesome-list|javascript|charting|frontend|ecosystem,6,"This repository is primarily a curated directory of Apache ECharts resources and ecosystem projects (wrappers, extensions, and bindings), rather than an ML library or dataset. It is moderately relevant to ML/data workflows because visualization is a core part of exploratory data analysis, dashboards, and communicating model results, and the list includes tooling and integrations that can be used in data products. However, it does not provide ML algorithms, training/inference tooling, or data pipelines itself, so its value is indirect—useful for presenting data/ML outputs rather than building models.",success
https://github.com/ivopetiz/algotrading,algotrading,"A Python-based algorithmic trading framework focused on cryptocurrency markets, providing tools to build and run trading bots, backtest strategies, and implement risk controls like stop-loss and trailing stop-loss. It supports realtime, tick-by-tick, and backtesting modes using data from exchange APIs, databases (e.g., InfluxDB), or CSV files.",1500,algorithmic trading|cryptocurrency|python|trading bots|backtesting|time series data|influxdb|quant finance,6,"This repository is primarily an algorithmic trading framework for crypto, with features for collecting/using market time-series data and running strategies in realtime or backtest modes. It is relevant to data workflows because it uses common data-science tooling (e.g., pandas/numpy-style analysis implied by the dependencies and backtesting/plotting focus) and provides a practical environment for experimenting with signal generation on historical price/volume data. However, it is not an ML framework and does not appear to focus on model training, evaluation, or MLOps; ML could be added by users as a strategy component rather than being the core purpose. The relatively strong GitHub adoption (about 1.5k stars) improves its educational and practical value for quant/data practitioners, but it remains more of a trading/bot framework than a dedicated ML/data platform.",success
https://github.com/locationtech/geomesa,geomesa,"GeoMesa is an open-source suite for large-scale geospatial querying and analytics on distributed systems, providing spatio-temporal indexing on top of Accumulo, HBase, and Cassandra. It also supports near real-time streaming geospatial data via Kafka and integrates with tools like GeoServer (OGC WFS/WMS) and Apache Spark for distributed analytics.",1500,geospatial|spatiotemporal-indexing|big-data|distributed-datastore|apache-spark|apache-kafka|geoserver,6,"This repository primarily provides a distributed geospatial data store and analytics toolkit (spatio-temporal indexing, querying, and stream processing) rather than ML algorithms or model-training code. It is still quite valuable to ML/data workflows because it enables scalable storage, feature retrieval, and geospatial joins/filters that commonly precede modeling, and it integrates with Apache Spark for distributed analytics. Its relevance is strongest for teams doing geospatial data engineering and geospatial feature pipelines feeding ML systems, but it is not itself an ML framework—hence a moderate score rather than a high one.",success
https://github.com/nschloe/awesome-scientific-computing,awesome-scientific-computing,"A curated “awesome list” of software, libraries, and resources for scientific computing and numerical analysis. It organizes tools by area (e.g., linear algebra, FEM, meshing, solvers, visualization) and links to their homepages and repositories.",1500,scientific computing|numerical analysis|awesome-list|linear algebra|finite element method|PDE solvers|HPC,6,"This repository is primarily a curated directory of scientific computing and numerical analysis software, rather than a runnable ML library or dataset. It is still moderately valuable for ML/data workflows because many ML and data science stacks depend on numerical computing foundations (linear algebra, optimization, sparse solvers, visualization) and the list can help practitioners discover robust underlying tools. Community adoption appears solid for a niche list (about 1.5k GitHub stars), but the repo’s direct ML applicability is indirect because it focuses on general scientific computing resources rather than model training, MLOps, or ML-specific frameworks.",success
https://github.com/pyper-dev/pyper,pyper,"Pyper is a pure-Python framework for building concurrent and parallel data-processing pipelines using functional, composable tasks. It unifies threading, multiprocessing, and asyncio behind a single pipeline abstraction (e.g., for ETL, data microservices, and data collection).",1500,python|data-engineering|data-pipelines|data-processing|concurrency|multiprocessing|asyncio|etl,6,"This repository provides a framework for concurrent/parallel data-processing and pipeline construction (task-based composition across asyncio, threads, and processes), which is directly useful for data engineering workloads like ETL and data collection. While it is not an ML modeling library, it can support ML/data workflows by improving throughput and structuring preprocessing/feature-generation pipelines. Its relevance is therefore moderate: strong for data processing infrastructure, but indirect for training/inference and core ML algorithms.",success
https://github.com/vasturiano/three-globe,three-globe,"A reusable Three.js WebGL globe object for building interactive, layer-based data visualizations on a 3D Earth (e.g., points, arcs/links, polygons, paths, heatmaps, hex bins, tiles, labels, and custom layers). It’s inspired by WebGL Globe and is designed to be added to a standard Three.js scene.",1500,data visualization|three.js|webgl|3d graphics|geospatial|javascript,6,"This repository provides a Three.js-based 3D globe component focused on rendering multiple geographic data layers (points, arcs, heatmaps, hex binning, polygons, etc.) for interactive visualization. While it is not an ML library, it is moderately valuable in ML/data workflows as an effective front-end visualization layer for geospatial datasets and model outputs (e.g., predictions by location, flows, clusters). Its adoption and polish (examples, multiple supported layers) increase practical usefulness, but it does not include data processing, modeling, or ML integrations, which keeps it below high-ML tooling scores.",success
https://github.com/MultiQC/MultiQC,MultiQC,"MultiQC scans analysis output directories for supported bioinformatics tool logs/results, parses them, and aggregates the metrics into a single interactive HTML report (with accompanying tabular/JSON/YAML data exports) across many samples and pipeline steps.",1400,bioinformatics|NGS|quality-control|reporting|data-visualization|python|genomics,6,"MultiQC is primarily a bioinformatics reporting and QC aggregation tool: it consolidates outputs from many genomics/NGS analyses into a single interactive report and structured data files, which is directly useful for monitoring data quality and pipeline health. While it is not an ML framework or modeling library, it is frequently used in data-intensive workflows to validate datasets before downstream statistical analysis or ML (e.g., filtering low-quality samples, detecting batch effects). Its high adoption in genomics pipelines and strong integration into common bioinformatics tooling makes it moderately valuable to data science/ML practitioners working with sequencing data, but it is less applicable outside that domain.",success
https://github.com/alexsosn/iOS_ML,iOS_ML,"A curated list of machine learning resources for iOS developers, covering Core ML, ML/deep learning libraries, and applied areas like computer vision, NLP, speech, OCR, and related learning materials.",1400,ios|machine-learning|core-ml|swift|objective-c|computer-vision|nlp|curated-list,6,"This repository is primarily an educational/curation resource: it compiles links to iOS-friendly ML libraries, frameworks (including Core ML tooling), and domain-specific resources (CV, NLP, speech, OCR), rather than providing a single ML library or dataset itself. It’s moderately valuable to ML engineers and data scientists who need to deploy models on iOS or survey mobile-ML options, but it’s less directly applicable for model training, data processing, or end-to-end ML workflows. Community adoption appears decent for a niche list (about 1.4k stars), but the README indicates the list itself was last updated in January 2018, which reduces practical up-to-date usefulness compared with actively maintained ML tooling.",success
https://github.com/apache/carbondata,apache/carbondata,"Apache CarbonData is an indexed columnar data store and file format designed to accelerate analytics workloads on big data platforms such as Apache Hadoop and Apache Spark. It stores data together with multi-level indexes to reduce IO scans and improve query performance, and supports features like compression, complex data types, and various access patterns (OLAP, scans, random access).",1400,data engineering|big data|columnar storage|data lake|Apache Spark|Apache Hadoop|analytics|indexing,6,"This repository implements a high-performance indexed columnar storage format and related components (including Spark/Hadoop integrations) aimed at speeding up large-scale analytics and data processing workloads. While it is not an ML framework, it is directly relevant to ML/data science pipelines as a storage layer that can improve feature/Training-data reads, filtering, and data preparation efficiency on big-data platforms. Its applicability is strongest for organizations running Spark/Hadoop-based data engineering stacks (where faster data access can materially help ML workflows), but it is less directly useful for model training/inference compared to dedicated ML tooling, leading to a mid-high infrastructure relevance score.",success
https://github.com/bjornd/jvectormap,jvectormap,"jVectorMap is a vector-based, cross-browser and cross-platform JavaScript component for interactive geography-related data visualization on the web. It supports features like smooth zooming/panning, customizable styling, markers, labels, and tooltips.",1400,javascript|jquery|data-visualization|geospatial|interactive-maps|choropleth|web-development,6,"This repository provides a JavaScript (jQuery) library for rendering interactive vector maps in the browser, commonly used for geography-related data visualization such as choropleths and marker overlays. It can be directly useful in data workflows for presenting and exploring spatial/region-aggregated results (e.g., model outputs by country/state) in dashboards or reports, but it is not an ML library and does not provide data processing, modeling, or training capabilities. The score reflects moderate relevance: strong for visualization/communication of data, limited for core ML tasks, despite being broadly used for web-based mapping.",success
https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources,getting-started-with-genomics-tools-and-resources,"A curated, beginner-friendly collection of links, notes, and reference materials for getting started with genomics/bioinformatics and data science using Unix command-line tools, R, and Python (including topics like reproducible research, visualization, and machine learning resources).",1400,bioinformatics|genomics|data-science|R|python|unix-shell|reproducible-research|data-visualization,6,"This repository is primarily a curated knowledge base of tools, courses, and references for genomics and computational biology workflows (Unix, R, and Python), rather than a standalone software library. It is moderately relevant to ML/data work because it includes data-science topics (e.g., statistics, visualization, and a section on machine learning) and supports practical data analysis in genomics, but it does not provide an ML framework, datasets, or reusable training/inference code. Its strong educational value and community adoption (high star count) raise its usefulness for data scientists working in bioinformatics, which justifies a mid-to-high score rather than a low one.",success
https://github.com/datawrapper/datawrapper,datawrapper,"A collection of shared JavaScript/TypeScript utility libraries developed for Datawrapper, a web-based tool for creating charts, maps, and tables. The repo focuses on reusable functions supporting modern, client-side responsive data visualization within the Datawrapper ecosystem.",1400,data-visualization|typescript|javascript|mapping|utility-library|frontend|charts,6,"This repository provides utility functions used to build Datawrapper’s responsive charting/mapping/table visualization capabilities, primarily as reusable JS/TS libraries rather than an end-user visualization app. It is relevant to data workflows because data scientists and analysts often need to publish or embed interactive visualizations, and these utilities can support building/maintaining visualization tooling and frontends. However, it is not an ML library, does not provide modeling/training functionality, and is mainly focused on visualization infrastructure rather than analytics or machine learning. Therefore, it earns a moderately relevant score (6/10) as a practical visualization/tooling codebase that can complement data science work, but is not core ML/data processing software.",success
https://github.com/dbt-labs/metricflow,metricflow,"MetricFlow is a semantic layer for defining and managing business metrics in code, compiling metric definitions into optimized, reusable, engine-specific SQL. It supports complex metric logic (e.g., ratios, expressions, cumulative metrics), multi-hop joins across fact/dimension sources, and time-grain aware aggregations, typically used alongside a dbt project.",1400,data engineering|analytics engineering|semantic layer|metrics|dbt|sql generation|business intelligence,6,"This repository implements a metrics semantic layer and SQL query compilation/rendering system designed to ensure consistent metric definitions and results across analytics use cases, commonly in conjunction with dbt. While it is not an ML framework and does not provide model training/inference capabilities, it is quite relevant to data science and ML-adjacent workflows because it standardizes feature/metric computation and improves the reliability of analytical datasets feeding experimentation, reporting, and downstream ML. The moderate score reflects strong utility in data/analytics pipelines and interoperability, but limited direct focus on core ML tasks.",success
https://github.com/griffithlab/rnaseq_tutorial,rnaseq_tutorial,"An educational RNA-seq analysis tutorial and demonstration pipeline (cloud-focused) covering key RNA-seq informatics topics such as file formats, reference genomes/annotations, alignment, expression and differential expression, alternative splicing, visualization, and interpretation. The README notes this repository/tutorial version is deprecated in favor of the current course hosted at rnabio.org.",1400,bioinformatics|RNA-seq|computational biology|NGS analysis|differential expression|AWS|R,6,"This repository primarily provides an educational RNA-seq analysis tutorial and example pipelines/scripts rather than machine-learning model training code. It is strongly relevant to data science workflows in genomics (data processing, QC, alignment, quantification, differential expression, visualization), which are common upstream steps for many ML applications in biology. However, it is not centered on ML methods, frameworks, or MLOps, and the README indicates this specific version of the course is deprecated, which limits its practical adoption compared to actively maintained ML/data tooling.",success
https://github.com/kotartemiy/pygooglenews,pygooglenews,"A Python wrapper around Google News RSS feeds that lets you fetch top stories, topic headlines, geo-specific headlines, and run advanced Google News search queries (including date ranges and query helpers). It also parses related/sub-articles within feeds for easier downstream processing.",1400,python|google-news|rss|news-data|feedparser|web-scraping|data-collection|nlp,6,"This repository provides a convenient Python interface for collecting and parsing Google News RSS content (top news, topic feeds, geo feeds, and advanced search queries), including extracting sub-articles that are commonly grouped under a story. It is not an ML library itself, but it is directly useful for ML/data workflows as a data acquisition component for tasks like media monitoring and building datasets for NLP (e.g., headline classification, topic modeling, trend detection). Community adoption appears decent (about 1.4k GitHub stars), and the library can integrate easily into data pipelines, but it does not include modeling, labeling, evaluation, or training utilities—hence a moderately relevant score rather than a high one.",success
https://github.com/mikeroyal/Photogrammetry-Guide,Photogrammetry-Guide,"A curated, documentation-style guide to photogrammetry, covering core concepts (e.g., SfM, point clouds, LiDAR, NeRF) and compiling tools, libraries, frameworks, and learning resources for building photogrammetry workflows.",1400,photogrammetry|computer vision|3d reconstruction|lidar|point clouds|remote sensing|machine learning|educational resources,6,"This repository is primarily a curated guide (not an executable ML library) that organizes photogrammetry concepts and links to relevant tools, libraries, and resources. It is moderately relevant to ML/data workflows because photogrammetry and 3D reconstruction commonly intersect with computer vision and ML (e.g., segmentation, object detection, NeRF) and can inform tool selection and learning paths. However, it does not appear to provide a dedicated dataset, training code, or a reusable ML pipeline itself, limiting direct integration into typical ML engineering workflows compared with purpose-built ML frameworks.",success
https://github.com/wgzhao/Addax,Addax,"Addax is an extensible open-source ETL (Extract, Transform, Load) tool (fork/evolution of Alibaba DataX) for offline data synchronization between heterogeneous data sources. It uses a framework + plugin architecture with JSON-defined jobs and supports 20+ SQL/NoSQL systems plus file/object storage connectors, with Docker-based deployment options.",1400,etl|data-integration|data-engineering|data-pipelines|java|database|sql|nosql,6,"This repository provides a general-purpose ETL and data synchronization framework, primarily aimed at moving and transforming data between many SQL/NoSQL databases and storage systems via a plugin-based architecture and JSON job configs. It is not an ML model training/inference library, but it is directly useful in ML/data workflows for building reliable data ingestion, extraction, and offline batch pipelines that feed feature stores, warehouses, or training datasets. The score reflects strong relevance to data engineering for ML (pipeline utility), but limited direct ML functionality and comparatively narrower ML-community adoption than core ML frameworks.",success
https://github.com/writer/writer-framework,writer-framework,Writer Framework is an open-source framework for building AI/data applications with a visual (no-code) UI editor on the front end and a Python backend. It provides a structured way to build interactive apps with UI components and backend business logic separated for easier testing and maintenance.,1400,python|ai-applications|data-apps|ui-framework|no-code|data-visualization|websockets|developer-tools,6,"This repository is primarily a framework for building AI/data applications with a drag-and-drop UI builder and a Python backend, which makes it useful for creating interactive tooling around data and models. While it is not an ML training library itself, it can be directly applied to ML/data workflows as an app layer for demos, internal tools, dashboards, and AI-enabled interfaces (e.g., RAG/LLM apps) built in Python. Community adoption appears moderate (about 1.4k GitHub stars), suggesting meaningful but not dominant usage in the ML/data ecosystem. Overall, it is moderately relevant to ML/data work as an application framework rather than a core modeling or data-processing toolkit.",success
https://github.com/DTStack/Taier,Taier,"Taier is a distributed big data development and scheduling platform that provides one-stop task submission, DAG-based workflow scheduling, operations/monitoring (O&M), and indicator/metrics display. It supports multiple task types (batch/stream) and integrations across common big-data engines and SQL/data-sync workloads (e.g., Hadoop, Flink, Spark, Hive, DataX).",1300,data engineering|workflow orchestration|job scheduling|ETL|big data|Hadoop|Flink|Spark,6,"Taier is primarily a big-data task development and orchestration/scheduling system (DAG workflows, task submission, monitoring/O&M, and indicator display) rather than an ML framework. It is relevant to ML/data workflows because it can orchestrate and operationalize data pipelines (ETL, SQL jobs, batch/stream tasks) that commonly feed feature engineering and model training. However, it does not appear to focus on model training, experimentation, or MLOps-specific capabilities, so its value is moderate for data science/ML engineers and higher for data engineering teams. Community signals (e.g., ~1.3k GitHub stars) suggest meaningful adoption, but not at the level of core ML tooling.",success
https://github.com/Image-Py/imagepy,imagepy,"ImagePy is an open-source, plugin-based image processing framework and GUI application in Python (similar in spirit to ImageJ). It provides a wxPython UI with NumPy-based image structures and supports extensible plugins that integrate with common scientific imaging libraries such as SciPy, scikit-image, OpenCV, and SimpleITK.",1300,image-processing|computer-vision|scientific-python|wxpython|numpy|scikit-image|opencv|plugin-framework,6,"This repository primarily provides a desktop GUI and plugin framework for image processing and bioimage analysis workflows, built on NumPy with a wxPython interface and designed to integrate with libraries like SciPy and scikit-image. It is moderately relevant to ML/data work because image preprocessing, segmentation, measurement, and feature extraction are common steps in computer-vision pipelines, but the repo is not itself an ML training/inference framework. Its value is strongest for preparing and analyzing image datasets (especially in scientific/bioimaging contexts) and for building custom processing plugins rather than end-to-end machine learning.",success
https://github.com/datavane/tis,tis,"TIS is an enterprise data integration/DataOps platform that provides a Web UI to build and operate end-to-end data synchronization pipelines across batch (DataX) and streaming (Flink-CDC, Chunjun/FlinkX) workloads, aiming to reduce scripting/configuration complexity and errors.",1300,data-integration|etl|dataops|apache-flink|flink-cdc|datax|chunjun|web-ui,6,"This repository focuses on building and operating data integration pipelines (batch + streaming) with a UI-driven DataOps experience, integrating components like DataX, Flink-CDC, and Chunjun. It is not an ML framework, but it is directly useful in ML/data workflows for ingestion, CDC-based replication, and moving data into warehouses/lakes/feature stores, which are common prerequisites for training and analytics. Its relevance is therefore moderate: strong for data engineering and pipeline operations, indirect for modeling/training, and it does not appear to be a widely adopted core ML library on the scale of major ML ecosystems.",success
https://github.com/hrbrmstr/hrbrthemes,hrbrthemes,"An R package that provides opinionated, typography-centric themes and theme components for ggplot2, including multiple theme variants (e.g., theme_ipsum) plus matching color scales, palettes, and font helpers to improve chart aesthetics.",1300,R|ggplot2|data visualization|plot themes|typography|color palettes|data science,6,"This repository is primarily a data visualization theming package for R/ggplot2, focused on typographic styling, palettes, and opinionated scale defaults rather than machine learning algorithms. It is moderately valuable for ML/data workflows because it directly improves the presentation and communication of analytical and model results (e.g., EDA plots, performance charts), which is a common need in data science. However, it does not provide modeling, training, feature engineering, or MLOps functionality, so its ML relevance is supportive rather than core, justifying a mid-range score.",success
https://github.com/jsxgraph/jsxgraph,jsxgraph,"JSXGraph is a pure JavaScript, cross-browser library for interactive mathematics visualizations in the browser, including geometry construction, function plotting, charting, and general data visualization using SVG/canvas/VML without external dependencies.",1300,javascript|interactive-visualization|data-visualization|math|geometry|function-plotting|charting|web-development,6,"This repository provides a client-side JavaScript library focused on interactive mathematical visualizations (geometry, plotting, and charting) in web browsers, primarily for education and interactive content rather than ML modeling. It can still be valuable in data/ML workflows as a lightweight way to build interactive visual explanations, exploratory plots, and demos (e.g., illustrating model behavior or mathematical concepts) directly in the browser. It’s not an ML framework and does not provide data processing/model training features, but its visualization capabilities make it moderately relevant to data science communication and teaching, which supports a mid-range score.",success
https://github.com/nowthis/sankeymatic,sankeymatic,"SankeyMATIC is a browser-based Sankey (flow) diagram builder that lets users describe flow data in plain text, customize the diagram interactively, and export results as PNG and SVG. It also supports exporting/importing editable work-in-progress as readable plain text files.",1300,data visualization|sankey diagrams|diagram generator|d3.js|svg|web application|javascript,6,"This repository provides a web-based tool for creating Sankey flow diagrams from text-described data, with interactive styling and export to SVG/PNG. While it is not an ML library or data pipeline tool, it is directly useful for data science workflows as a practical visualization utility for communicating flows (e.g., energy, finances, feature/label transitions, funnel movement). Its value is primarily in visualization and reporting rather than modeling, training, or MLOps, which supports a moderately relevant score.",success
https://github.com/okfn-brasil/querido-diario,querido-diario,"Repository from the Querido Diário ecosystem responsible for scraping Brazilian government gazette (""diário oficial"") publisher websites. It provides a Scrapy-based framework, templates, and spiders to collect gazette documents and store the scraped outputs locally for further processing/search.",1300,web scraping|Scrapy|Python|open government data|civic tech|data collection|ETL,6,"This repository’s primary purpose is large-scale data collection: it implements Scrapy spiders and tooling to scrape and collect Brazilian official gazettes from municipal/state publisher sites. While it is not an ML library, the output (structured gazette documents and metadata) is directly useful for downstream NLP/IR workflows such as entity extraction, topic classification, search indexing, and dataset creation. Its value to data science comes from enabling reproducible data acquisition and standardization rather than modeling, so it fits as a moderately relevant data engineering component rather than a core ML framework.",success
https://github.com/wq/django-rest-pandas,django-rest-pandas,"Django REST Pandas (DRP) generates and serves pandas DataFrames from Django REST Framework views/serializers, allowing API consumers to download data as CSV and other tabular formats for visualization (e.g., D3/Plotly-based tooling) or offline analysis (e.g., spreadsheets). It provides serializers that convert DRF output to DataFrames and renderers that emit multiple export formats using pandas.",1300,django|django-rest-framework|pandas|data-export|csv|data-visualization|rest-api|python,6,"This repository is a Django REST Framework extension that converts API outputs into pandas DataFrames and renders them into CSV and other data formats, primarily to support data downloads and visualization workflows. It is directly useful for data/analytics teams building “data APIs” to move tabular data into notebooks, BI tools, or client-side charts, but it does not provide ML algorithms, training/inference pipelines, or MLOps functionality. The project has meaningful adoption for a niche utility (about 1.3k GitHub stars), which supports a moderate relevance score for data engineering/analytics-centric ML workflows rather than core ML.",success
https://github.com/Abhinandan-Kushwaha/react-native-gifted-charts,react-native-gifted-charts,"A React Native charting library for rendering highly customizable Bar, Line, Area, Pie/Donut, Stacked Bar, Population Pyramid, and Radar charts with support for 2D/3D effects, gradients, animations, interactivity, and live data updates.",1200,react-native|mobile-development|data-visualization|charts|ui-components|typescript|svg,6,"This repository primarily provides a UI/charting component library for React Native apps, focused on rendering interactive and customizable visualizations (bar/line/area/pie/donut/radar, etc.). It is not an ML library, but it is directly useful in data science workflows for presenting and monitoring data, metrics, and model outputs inside mobile dashboards or analytics apps. Its value for ML/data comes from visualization and reporting rather than modeling/training or data processing, which is why it scores as moderately relevant rather than high.",success
https://github.com/BlakeRMills/MetBrewer,MetBrewer,"MetBrewer is a color palette package inspired by works at the Metropolitan Museum of Art, providing many named palettes for data visualization along with utilities like colorblind-friendliness checks. It’s primarily an R package (available on CRAN/GitHub) and also includes a Python implementation under the repository’s Python/ directory.",1200,r|python|data-visualization|color-palettes|ggplot2|design|accessibility,6,"This repository provides curated, named color palettes and related helpers (including colorblind-friendly checking) intended for use in plotting and visualization workflows. While it does not implement machine learning algorithms or data pipelines, it is directly useful for data science/ML practitioners when communicating results through clear, consistent, and accessible visualizations (e.g., in ggplot2 and similar tooling). Its popularity (about 1.2k GitHub stars) suggests meaningful community adoption for visualization use, supporting a moderately relevant score rather than a core ML score.",success
https://github.com/amcharts/amcharts4,amcharts4,"Official repository for amCharts 4, an advanced JavaScript/TypeScript data visualization library for building interactive charts, graphs, and maps. It includes TypeScript source code plus compiled ES2015 modules and standalone script builds.",1200,data-visualization|charting-library|javascript|typescript|svg|maps|web-development|dataviz,6,"This repository provides the amCharts 4 charting and mapping library for JavaScript/TypeScript applications, aimed at building interactive visualizations rather than performing ML. It is moderately valuable for ML/data workflows because data scientists and ML engineers often need high-quality client-side visualization for dashboards, experiment tracking, and communicating results, and this library can render complex charts/maps from model outputs. However, it does not provide data processing, modeling, or MLOps capabilities, so its ML value is primarily as a visualization layer rather than a core ML tool. Its solid adoption and broad visualization feature set support a mid-range score.",success
https://github.com/egbertbouman/youtube-comment-downloader,youtube-comment-downloader,"A Python CLI/library for downloading YouTube video comments without using the official YouTube Data API. It outputs comments as line-delimited JSON (optionally pretty-printed) and supports limiting, language selection, and sorting by popular vs recent.",1200,python|web-scraping|youtube|comment-mining|data-collection|jsonl|cli-tool,6,"This repository’s primary purpose is data acquisition: collecting YouTube comments and exporting them in machine-friendly JSON/JSONL formats. It is not an ML library itself, but it is directly useful in ML/data workflows as a lightweight tool for building text datasets for NLP tasks like sentiment analysis, topic modeling, or toxicity classification. Community adoption appears solid (about 1.2k GitHub stars), which increases its practical value as a dependable data collection utility, but it does not provide modeling, labeling, or ML pipeline components—hence a mid-range score.",success
https://github.com/foolcage/fooltrader,fooltrader,"A quantitative trading/analysis framework focused on market data ingestion and standardization (schema + connectors), providing APIs and tooling for scraping, cleaning, structuring, computing, visualization, backtesting, and trading across multiple asset classes (stocks, futures, forex, crypto, macro). The README notes the project is no longer maintained and points users to a successor project (zvtvz/zvt).",1200,quantitative trading|financial data|data engineering|python|backtesting|web scraping|time series,6,"The repository is primarily a quantitative finance framework that emphasizes building a standardized market-data schema and importing data via connectors, plus utilities for cleaning/structuring data and running analysis/backtests. This is moderately valuable for data science workflows because it can help collect and organize time-series financial data and support research pipelines, but it is not primarily an ML library and does not appear centered on model training/evaluation tooling. Community adoption is decent (around 1.2k GitHub stars), but the repo is explicitly marked as discontinued, which reduces practical ML/data utility today.",success
https://github.com/pomber/covid19,covid19,"Transforms the Johns Hopkins CSSE COVID-19 time-series dataset into a single per-country JSON time series (confirmed, deaths, recovered) and publishes it as a hosted JSON file. The dataset is updated automatically multiple times per day via GitHub Actions.",1200,dataset|covid-19|time-series|public-health|json|data-engineering|github-actions|javascript,6,"This repository’s primary purpose is to provide a clean, easy-to-consume COVID-19 time-series dataset (per country, per day) by converting the Johns Hopkins CSSE source data into a single JSON file and keeping it updated via automation. It is directly useful for data science workflows such as exploratory analysis, forecasting, and dashboarding because it offers a ready-made, standardized time-series format, but it does not include ML models, feature engineering utilities, or training/evaluation pipelines. The strong adoption (notable stars/forks) increases its practical value as a data source, but its scope is primarily data publishing rather than ML tooling, supporting a moderately relevant score.",success
https://github.com/reaviz/reaviz,reaviz,"Reaviz is a modular data visualization/chart component library for React that renders natively with React while using D3.js for calculations. It provides many built-in chart types (e.g., bar, line, area, scatter, pie, sankey, heatmap, treemap) with strong customization and interaction features (tooltips, legends, gestures, animations, SSR).",1200,data visualization|react|d3|charts|typescript|storybook|frontend,6,"This repository is primarily a React charting/data visualization library (with D3.js under the hood) aimed at building interactive charts in web applications. It is moderately relevant to ML/data workflows because data scientists and ML engineers often need to visualize datasets, metrics, and model outputs in dashboards or reports, and Reaviz can be directly used for that purpose in React-based tools. However, it does not provide ML algorithms, data processing, model training, or MLOps capabilities, so its value is mainly in presentation/communication rather than core ML work. The score reflects strong usefulness for visual analytics and dashboards, but limited scope beyond visualization.",success
https://github.com/slavakurilyak/awesome-ai-agents,awesome-ai-agents,"A curated “awesome list” of 300+ agentic AI resources and projects, tracking and organizing popular AI agents/frameworks/tools with supporting metadata and periodic updates. The repo includes machine-readable lists (JSON/YAML) and scripts to maintain and generate the catalog.",1200,ai agents|llm|awesome-list|agentic workflows|developer tools|python|resource curation,6,"This repository primarily curates and tracks agentic AI projects (tools, frameworks, and related resources) rather than providing a standalone ML library or dataset. It’s useful for ML engineers and data scientists as a discovery/landscape map for selecting agent frameworks, toolchains, and related components, and it includes structured JSON/YAML that can be consumed programmatically. However, it has limited direct “drop-in” ML workflow functionality (e.g., training/evaluation code or datasets) beyond curation and metadata, so it rates as moderately relevant rather than a core ML/data tool.",success
https://github.com/wireservice/agate,agate,"Agate is a Python data analysis library optimized for human-friendly, readable code. It aims to solve real-world data wrangling/analysis tasks and positions itself as an alternative to NumPy and pandas for certain workflows.",1200,python|data-analysis|data-wrangling|tabular-data|data-science|pandas-alternative|jupyter-notebook,6,"This repository provides a general-purpose Python data analysis library focused on tabular data manipulation and analysis with a “humans first” API. While it is not an ML framework and does not focus on model training, it can be useful in ML/data workflows for data cleaning, preprocessing, exploratory analysis, and working with datasets before modeling. Its relevance is moderate because it overlaps with common data-science tasks (similar problem space to pandas), but it is not specifically designed for ML pipelines or MLOps, and community adoption appears smaller than mainstream data tooling.",success
https://github.com/Jannchie/anichart.js,anichart.js,"A TypeScript-based data visualization animation library for creating animated charts and rendering/exporting them as videos or PNG frame sequences. It provides a programmable canvas-driven framework (e.g., Stage/Chart components) and supports browser usage plus Node.js-based rendering workflows.",1100,data-visualization|animation|typescript|javascript|canvas|charting|video-export,6,"This repository is primarily a data visualization animation framework for generating animated charts and exporting them as video/frames, rather than an ML library. It is moderately valuable to data science workflows because it can be used to present and communicate time-series or ranking data (e.g., animated bar chart race-style outputs) and could be integrated into automated reporting pipelines (including via Node.js rendering/export). The score is not higher because it does not provide ML/analytics functionality, model training, or data-processing primitives; its main contribution is visualization and video rendering rather than machine learning.",success
https://github.com/akfamily/aktools,aktools,AKTools is a Python package that exposes AKShare (a financial data interface library) through an HTTP API service. It uses FastAPI (and a Typer-based CLI) so users in any language can query AKShare data via REST endpoints and parameters.,1100,python|fastapi|rest-api|financial-data|akshare|data-access|cli,6,"This repository primarily provides an HTTP API wrapper/service around AKShare, enabling programmatic access to financial/market datasets over REST (rather than being an ML library itself). It is directly useful in data science workflows for data acquisition and integration (e.g., feeding financial time series into analysis, feature engineering, or model training pipelines), especially for non-Python stacks. However, it does not focus on modeling, training, evaluation, or MLOps capabilities, and its ML value depends on the user’s downstream analytics stack rather than offering ML methods natively.",success
https://github.com/caicloud/cyclone,cyclone,"Cyclone is a Kubernetes-native workflow engine and end-to-end pipeline solution that runs as native Kubernetes resources (no extra dependencies). It supports DAG-based workflow orchestration and provides higher-level CI/CD and “AI DevOps” pipeline capabilities via templates and extensible, pluggable APIs.",1100,kubernetes|workflow-orchestration|DAG|CI/CD|MLOps|pipeline|DevOps,6,"This repository primarily provides Kubernetes-native workflow orchestration and pipeline execution (DAG scheduling, triggers, integrations, lifecycle management), with built-in support for CI/CD pipelines and an “AI DevOps”/AI pipeline use case. It is relevant to ML/data workflows as infrastructure for orchestrating and operationalizing training/inference pipelines (i.e., MLOps), rather than offering ML algorithms or data processing libraries itself. The score reflects moderate applicability for ML engineers running pipelines on Kubernetes, but limited direct data science/ML functionality and comparatively narrower adoption than major MLOps/orchestration projects.",success
https://github.com/hazelcast/hazelcast-jet,hazelcast-jet,"Hazelcast Jet is an in-memory, distributed stream and batch processing engine for building low-latency data pipelines and stateful computations on a cluster. The repository is archived (read-only) and Jet development has moved into the core Hazelcast repository starting with Hazelcast 5.0.",1100,stream processing|batch processing|data engineering|distributed systems|java|data pipelines|event processing,6,"This repository provides a distributed batch and stream processing engine (Hazelcast Jet) focused on building scalable, low-latency data pipelines and stateful computations across a cluster. While it is not an ML framework, it is directly useful in ML/data workflows for feature computation, streaming ETL, and feeding real-time or batch data into downstream model training/serving systems. Its relevance is moderated by the fact that the repo was archived on Jan 31, 2025 and ongoing development moved to the core Hazelcast repository, reducing its standalone momentum for new ML/data users.",success
https://github.com/highfestiva/finplot,finplot,"finplot is a high-performance finance plotting library for Python designed for backtesting workflows, offering fast interactive candlestick/indicator charting (zoom/pan, overlays, multiple synchronized charts, real-time updates) built on PyQtGraph.",1100,python|data-visualization|quant-finance|trading|backtesting|time-series|pyqtgraph,6,"This repository provides an interactive, high-performance charting library focused on financial time-series visualization (e.g., candlesticks, indicators like MACD/RSI, overlays, and real-time updates) for backtesting and analysis. It is not an ML framework, but it can be directly useful in ML/data workflows for exploratory data analysis, feature/label inspection, and visual validation of model inputs/outputs on market data. Community adoption appears solid (about 1.1k GitHub stars), suggesting practical utility, but its scope is primarily visualization rather than core ML modeling or pipelines—hence a moderate relevance score.",success
https://github.com/jacksu/utils4s,utils4s,"A Scala/Spark learning and utilities collection that aggregates demo code, test cases, and documentation for common Scala libraries and Big Data tools (notably Apache Spark modules like core, streaming, SQL, and ML-related examples). It serves primarily as a hands-on reference repo with runnable examples and curated study materials.",1100,scala|apache-spark|spark-streaming|spark-sql|big-data|data-engineering|akka|tutorials-and-demos,6,"This repository is mainly a Scala/Spark demo-and-notes collection, including Spark-related modules (core/streaming/SQL) and references to Spark machine learning content, so it is directly useful for learning and experimenting with data processing workflows. It is not a dedicated ML framework or end-to-end ML tooling, but it can support ML/data engineers through practical Spark examples and surrounding ecosystem utilities. Community adoption is decent (about 1.1k stars), which indicates ongoing interest, but the repo’s primary value is educational/reference rather than production-grade ML infrastructure, leading to a moderate relevance score.",success
https://github.com/jf-tech/omniparser,omniparser,"Omniparser is a native Go (Golang) streaming ETL parser/transform library that ingests multiple input formats (e.g., CSV, fixed-width text, JSON, XML, and EDI/X12/EDIFACT) and transforms them into desired JSON output using a JSON-defined schema. It includes a CLI and supports advanced schema-driven extraction/filtering and custom functions (including JavaScript).",1100,golang|etl|data-parsing|data-transformation|streaming|csv|json|xml|edi,6,"This repository is primarily an ETL ingestion/parsing and schema-driven transformation toolkit (not an ML library), focused on reliably converting heterogeneous raw data formats into structured JSON. It can be directly useful in ML/data workflows as a data engineering component for preparing and normalizing training/analytics data, especially when dealing with enterprise formats like EDI, fixed-width files, or XML in streaming mode. However, it does not provide modeling, feature engineering, or MLOps capabilities, and its community adoption appears moderate (about 1.1k stars), so it’s better categorized as a supportive data pipeline utility than a core ML tool.",success
https://github.com/mariusandra/insights,insights,"Insights is an open-source, self-hosted business intelligence tool for visually exploring PostgreSQL databases, focused on building time-based graphs and performance analytics. It auto-detects schemas/foreign keys, supports multiple databases, and provides an interactive data explorer with filters and saved views.",1100,business-intelligence|data-analytics|postgresql|data-visualization|dashboarding|self-hosted|react|nodejs,6,"This repository provides a self-hosted BI/analytics application for exploring and charting data from PostgreSQL, aimed at business performance monitoring rather than model building. It can be directly useful in data workflows for exploratory analysis, KPI tracking, and communicating results via dashboards/graphs, but it is not an ML framework or MLOps tool. Community adoption appears moderate (about 1.1k GitHub stars), and its value is strongest for analytics/visualization rather than machine learning itself, which supports a mid-high relevance score.",success
https://github.com/mbtaviz/mbtaviz.github.io,mbtaviz.github.io,"A GitHub Pages site containing an interactive, web-based data visualization project exploring MBTA (Boston subway) system behavior and performance, including turnstile entries/exits and train delay/congestion views. The repo includes the site’s HTML/JS/CSS (Less) source, preprocessed visualization datasets, and links to downloadable raw data releases.",1100,data visualization|transportation analytics|d3.js|javascript|github pages|open data|web development,6,"This repository primarily delivers an interactive data visualization website for MBTA subway data, with client-side JavaScript code and bundled/preprocessed datasets. It’s relevant to data science workflows because it demonstrates real-world data exploration, visualization design, and handling of transit/turnstile time-series data, but it is not a machine-learning library or modeling toolkit. Community adoption appears moderate (about 1.1k GitHub stars), and its strongest value for ML/data practitioners is educational and practical visualization patterns rather than training or deploying models, which supports a mid-range score.",success
https://github.com/oeljeklaus-you/UserActionAnalyzePlatform,UserActionAnalyzePlatform,"An e-commerce user behavior analysis big-data platform built on Apache Spark. It analyzes user sessions, page single-step conversion rates, offline hot-product statistics, and real-time ad traffic metrics using Spark Core/SQL/Streaming, with results typically stored in MySQL and visualized via reporting tools.",1100,big data|apache spark|spark streaming|spark sql|user behavior analytics|e-commerce analytics|batch processing|real-time analytics,6,"This repository is primarily a Spark-based data engineering/analytics project for analyzing e-commerce clickstream-style user actions (sessions, funnel-like conversion rates, top products, and real-time ad traffic). It is quite relevant to data workflows because it demonstrates end-to-end large-scale data processing patterns (batch + streaming), ETL-style aggregation, and performance/optimization considerations in Spark. However, it is not focused on model training or ML algorithms, and it does not appear to provide reusable ML components or MLOps tooling; its value is mainly as a practical big-data analytics reference rather than an ML library.",success
https://github.com/plotly/react-pivottable,react-pivottable,"A React-based, drag-and-drop pivot table UI for exploring tabular datasets, with outputs as pivot tables and optional Plotly.js charts via injectable renderers. It is a React port of PivotTable.js and is intended for interactive data exploration in web apps.",1100,react|javascript|pivot-table|data-visualization|plotly|business-intelligence|web-development,6,"This repository provides an interactive pivot table UI component for summarizing and exploring datasets in the browser, including table renderers and optional Plotly.js chart renderers. While it is not an ML library (no modeling/training), it is directly useful in data science workflows for exploratory data analysis (EDA), quick aggregation, and stakeholder-facing dashboards. Its relevance is moderate because it helps with data exploration and visualization rather than core ML, but it can integrate well into analytics apps built with React.",success
https://github.com/sib-swiss/training-collection,training-collection,"A curated collection of free bioinformatics training materials (primarily Markdown-based) that link out to external GitHub/GitLab repositories, organized by topics like scripting, computational pipelines, omics analysis, data management, and statistics/machine learning.",1100,bioinformatics|training-materials|life-sciences|curated-list|omics|data-management|statistics|machine-learning,6,"This repository primarily serves as an index/curated catalog of bioinformatics training resources rather than providing an ML library, dataset, or runnable ML pipeline itself. It is still meaningfully useful for data science and ML practitioners in life sciences because it aggregates learning materials across statistics, data science, machine learning, and related computational methods. The value is mainly educational and discovery-oriented (finding relevant courses/tutorials), not direct workflow integration or tooling, which is why it scores as moderately relevant rather than highly relevant.",success
https://github.com/spring-attic/spring-cloud-dataflow,spring-cloud-dataflow,"Spring Cloud Data Flow is a microservices-based toolkit for building and orchestrating streaming and batch data processing pipelines on Cloud Foundry and Kubernetes, using Spring Cloud Stream and Spring Cloud Task apps. This repository is archived (read-only) and the project is no longer maintained as an open-source project by Broadcom, Inc.",1100,data-pipelines|stream-processing|batch-processing|data-engineering|microservices|kubernetes|cloud-foundry|spring,6,"This repository provides infrastructure for defining, deploying, and operating streaming and batch data pipelines (e.g., import/export, event streaming), including a server with REST APIs plus clients like a shell/CLI and dashboard. It is relevant to ML/data workflows mainly as a data engineering/orchestration layer that can feed features and training data pipelines, but it is not an ML framework and does not focus on modeling/training. The score is moderated by the fact that it is archived and no longer maintained as open source, which reduces practical adoption and integration value for new ML projects.",success
https://github.com/youngwookim/awesome-hadoop,awesome-hadoop,"A curated ""awesome list"" of Hadoop and Hadoop-ecosystem resources, covering core Hadoop, YARN, storage, SQL-on-Hadoop, ingestion, workflow, monitoring, security, and related big-data tooling. It serves as a categorized directory of projects and learning resources rather than an executable software package.",1100,big data|hadoop|data engineering|distributed systems|data processing|hadoop ecosystem|resource list,6,"This repository is primarily a curated index of Hadoop and ecosystem tools/resources (e.g., storage, SQL engines, ingestion, workflow orchestration, monitoring), not a library or framework you run directly. It is moderately relevant to ML/data workflows because Hadoop infrastructure and adjacent components are often used for large-scale data preparation, ETL, and analytics feeding ML systems. The score is not higher because it does not provide ML algorithms, model training utilities, or MLOps functionality itself—its value is mainly educational and as a discovery guide for big-data tooling.",success
https://github.com/TIBCOSoftware/snappydata,snappydata,"SnappyData (aka TIBCO ComputeDB) is a distributed, in-memory optimized analytics database that embeds a hybrid database layer inside Apache Spark to support unified workloads (streaming, transactions, SQL analytics) in a single cluster. It focuses on high-throughput, low-latency, high-concurrency analytics with options for in-memory columnar and row storage and broad connectivity to external data sources.",1000,data engineering|distributed database|in-memory analytics|apache spark|sql analytics|stream processing|olap,6,"This repository implements SnappyData/TIBCO ComputeDB, an in-memory, distributed analytics database built around Apache Spark for unified analytics workloads (SQL queries, streaming, and transactional/mutable data). It is directly relevant to ML/data workflows as a data storage/compute layer that can accelerate feature extraction, interactive analytics, and large-scale ETL/analytics alongside Spark. However, it is not an ML framework itself (no core model-training algorithms) and the repository is explicitly marked as legacy/for informational purposes with no updates (including security updates), reducing practical adoption and suitability for new production ML stacks.",success
https://github.com/compdemocracy/polis,polis,"Polis is an open-source, AI-powered platform for collecting large-scale open-ended feedback and mapping how groups of people align and differ across statements, offering a more organic alternative to surveys and lower-effort alternative to focus groups. It includes multiple web clients (participation, admin, reports) plus server and analytics components, and provides Docker-based setup for development and deployment.",1000,civic-tech|deliberation|opinion-mapping|sentiment-analysis|machine-learning|data-visualization|docker|web-platform,6,"This repository primarily provides the full Polis application stack (clients, server, and supporting services) for running large-scale opinion gathering and analysis, rather than being a standalone ML library. It is meaningfully related to data/ML workflows because it centers on statistically/ML-enabled analysis of participant voting data and produces structured outputs (e.g., clustering/opinion-space mapping) that analysts can use, but most users will interact with it as a product/platform. The score reflects moderate relevance: valuable for applied social data analysis and researchers running deliberation exercises, but less directly reusable as an ML toolkit compared with general-purpose ML/data frameworks and libraries.",success
https://github.com/josonle/Coding-Now,Coding-Now,"A personal learning-archive repo collecting study notes, curated blogs/sites/tools, and shared eBooks/video resources. Topics span big data ecosystems (e.g., Hadoop/Spark/Flink), Python data analysis and machine learning, Linux/OS, algorithms, networking, and more.",1000,machine learning|data analysis|big data|Hadoop ecosystem|Spark|Flink|Linux|learning notes,6,"This repository is primarily a curated knowledge base: study notes plus collections of learning resources (articles, sites, tools) and materials related to big data and Python-based ML/data analysis. It can be useful for data/ML learners as an index of topics and references (and may include practical notes for setting up environments and studying ML/data concepts), but it is not a focused, reusable ML library or pipeline/tooling package. Community adoption appears moderate (around 1k stars), which suggests educational value, yet direct workflow integration for professional ML/data engineering is limited—hence a mid-range score.",success
https://github.com/moshi4/pyCirclize,pyCirclize,"pyCirclize is a Python package (built on matplotlib) for creating circular visualizations such as Circos plots, chord diagrams, and radar charts. It also includes utilities for bioinformatics-focused circular visualizations like genome and phylogenetic tree plots.",1000,data-visualization|matplotlib|circos-plot|chord-diagram|bioinformatics|genomics|python,6,"pyCirclize’s primary purpose is circular data visualization (Circos plots, chord diagrams, radar charts) and it additionally provides genomics/phylogenetics visualization helpers, which are common needs in bioinformatics analysis workflows. While it is not an ML framework or modeling tool, it can be directly useful for exploratory data analysis and communicating ML/data results (especially for biological sequence/comparative genomics contexts). Community adoption appears moderate (about 1k GitHub stars) and it integrates well into typical Python data stacks via matplotlib, leading to a moderately relevant ML/data score rather than a core-tool score.",success
https://github.com/quarkfin/qf-lib,qf-lib,"QF-Lib is a modular Python library for quantitative finance that includes an advanced event-driven backtesting engine for evaluating custom trading/investment strategies. It also provides finance-focused data containers and reporting tools, and integrates with multiple market data vendors/brokers across asset classes (e.g., crypto, stocks, futures).",843,quantitative finance|algorithmic trading|backtesting|event-driven architecture|python|pandas|financial data|portfolio analytics,6,"This repository is primarily a quantitative finance/backtesting framework (event-driven strategy simulation, data sourcing integrations, specialized data containers, and reporting). It is useful for data-science workflows in finance (research, feature engineering on market data, strategy evaluation, experiment tracking/report generation), but it is not primarily an ML library (no core model training/inference framework). The moderate star count suggests meaningful adoption in its niche, and its design makes it a solid foundation for ML-driven trading research, hence a mid-to-high relevance score rather than a core-ML score.",success
https://github.com/apache/samza,apache/samza,"Mirror of Apache Samza, a distributed stream processing framework for building stateful real-time applications. It commonly uses Apache Kafka for messaging/log storage and Apache Hadoop YARN (and other environments) for execution, fault tolerance, and resource management.",834,stream-processing|distributed-systems|data-engineering|apache-kafka|yarn|stateful-processing|java|scala,6,"Apache Samza is primarily a distributed stream processing framework for building stateful, fault-tolerant real-time applications on streaming data (often from Kafka). While it is not an ML library, it is useful in ML/data workflows for online feature computation, real-time aggregations, streaming ETL, and feeding training/serving systems with processed events. Community adoption appears moderate (hundreds of GitHub stars) and it integrates with common data infrastructure, but it’s less central to day-to-day model training than core ML frameworks—hence a mid-range score.",success
https://github.com/data-burst/data-engineering-roadmap,data-engineering-roadmap,"A community-maintained set of visual roadmaps (including a cloud-focused variant) that guides learners through data engineering concepts, tools, and best practices from beginner to advanced levels. The repo includes YAML sources for the roadmaps plus a guide and contribution workflow for updating them.",475,data engineering|learning roadmap|cloud data engineering|AWS|Azure|GCP|career guide|educational resources,6,"This repository’s primary purpose is educational: it provides structured roadmaps (and YAML definitions) covering data engineering topics and cloud equivalents. It is relevant to ML/data workflows because strong data engineering foundations (data ingestion, storage, transformation, orchestration, and cloud tooling) are critical for building reliable ML pipelines, even though the repo itself does not provide ML algorithms or training tooling. Community adoption appears moderate (hundreds of stars), supporting its value as a learning reference. I scored it a 6 because it’s useful and applicable for ML practitioners from a data-pipeline perspective, but it is not a direct ML framework or hands-on library.",success
https://github.com/shlomikushchi/zipline-trader,zipline-trader,"Zipline Trader is an on-premise algorithmic trading platform built on Quantopian's Zipline, supporting backtesting, paper trading, and live trading. It integrates with brokers such as Interactive Brokers and Alpaca.",327,algorithmic trading|quant finance|backtesting|live trading|python|zipline|broker integration,6,"This repository provides a Pythonic algorithmic trading/backtesting engine (Zipline-based) with paper/live trading support and broker integrations (e.g., Interactive Brokers, Alpaca). It is relevant to data/ML workflows because it can be used to generate features, run historical simulations, and evaluate ML-driven trading signals in a realistic execution/backtesting environment. However, it is primarily a trading infrastructure/tool rather than an ML framework, and it does not focus on model training, MLOps, or ML-specific utilities, so its ML value is moderate rather than core.",success
https://github.com/goex-top/awesome-go-quant,awesome-go-quant,"A curated “awesome list” of Go (Golang) libraries, packages, and learning resources for quantitative finance, including numerical computing, statistics, indicators, trading/backtesting frameworks, market data access, plotting, and related tooling.",276,golang|quantitative-finance|algorithmic-trading|backtesting|market-data|statistics|numerical-computing|machine-learning,6,"This repository is primarily an awesome-list style index of Go resources for quant finance (dataframes, numerical/stats libraries, market data clients, charting, trading/backtesting, and some ML-related links). It can be useful to data/ML practitioners as a starting point for Go-based data analysis and finance pipelines, but it is not itself a core ML framework or dataset—most value comes from the external libraries it links to. The score reflects moderate relevance: strong overlap with data manipulation/analysis in finance and some ML entries, but limited direct, turnkey ML workflow capability on its own.",success
https://github.com/quantstart/qstrader,qstrader,"QSTrader is an open-source, event-driven backtesting platform for systematic equities trading strategies. It provides a modular architecture (signals/portfolio construction/risk/execution/accounting) and generates performance “tearsheet” analytics for strategy evaluation.",135,algorithmic-trading|quant-finance|backtesting|event-driven|portfolio-analytics|python,6,"This repository is primarily an event-driven trading backtesting engine aimed at systematic equities strategy research, including support for bar and tick-resolution data and built-in performance tear sheets. It is relevant to data science workflows because it directly supports time-series financial data handling, strategy experimentation, and evaluation/analytics, which are common in quant research. However, it is not an ML framework and does not focus on model training/inference pipelines, so its value to ML is moderate rather than core. The score reflects strong applicability for financial data analysis/backtesting, but limited direct ML tooling and comparatively modest community adoption.",success
https://github.com/AlgoTrading101/VectorBT-AlgoTrading101,VectorBT-AlgoTrading101,A small tutorial-style repository demonstrating how to use the vectorbt Python library for algorithmic trading research and backtesting. It primarily contains a Jupyter notebook and README that accompany an AlgoTrading101 guide on VectorBT.,36,algorithmic-trading|backtesting|python|jupyter-notebook|vectorbt|quant-finance|technical-analysis,6,"This repository is focused on quantitative finance workflows (data retrieval/handling, indicator computation, and strategy backtesting) using vectorbt, delivered mainly as an educational notebook. While it is not an ML framework or model-training repo, it is directly useful for data-oriented experimentation (time series analysis, feature/indicator engineering, and evaluating trading rules) and can be extended into ML-driven strategies. Community adoption appears modest (tens of stars), but its instructional value for data-centric financial backtesting merits a moderately relevant score.",success
https://github.com/IrBigDta/Awesome-Modern-Open-Source-Data-Engineering,Awesome-Modern-Open-Source-Data-Engineering,"A curated “awesome list” of modern open-source tools and resources for data engineering and data science, organized by categories such as storage systems, processing, analytics, and related infrastructure.",5,data engineering|awesome list|open source|data pipelines|databases|analytics|streaming,6,"This repository is primarily a curated directory of open-source data engineering and data science tools (not a library/framework itself), making it most useful as a discovery and reference resource. It relates to ML/data workflows indirectly by helping data scientists and ML engineers identify components for data storage, ingestion, processing, orchestration, and analytics that often underpin model development and MLOps. Community adoption appears relatively small based on the current star count, but the educational and integration value can still be meaningful because it centralizes tooling options across the modern data stack. Therefore, it scores as moderately relevant rather than a core ML tool.",success
https://github.com/wanaxe/awesome-quant-1,awesome-quant-1,"A fork of wilsonfreitas/awesome-quant that curates links to libraries, packages, and learning resources for quantitative finance. It organizes tools by language and topic (e.g., pricing, trading/backtesting, risk, time series, data sources).",3,quantitative-finance|algorithmic-trading|backtesting|financial-data|time-series|python|awesome-list,6,"This repository is primarily an “awesome list” of quantitative finance resources rather than a codebase providing ML models or datasets. It is still moderately valuable for ML/data workflows because it aggregates commonly used data/analysis libraries (e.g., pandas, statsmodels) and finance-focused tools for time-series analysis, factor research, and backtesting that data scientists can incorporate into pipelines. However, it has limited direct integration as a standalone ML tool and relatively low community adoption for this fork (3 stars), so it doesn’t reach the highest tiers.",success
https://github.com/src-d/hercules,hercules,"Hercules is a fast, customizable Git repository history analysis engine written in Go. It runs a DAG of analysis tasks over a repo’s full commit history and can be paired with the companion Python tool “labours” to generate plots/visualizations from the collected metrics.",,git|repository-mining|software-analytics|data-analysis|devops-analytics|go|python,6,"This repository focuses on mining and analyzing Git commit history (e.g., burndown, churn, ownership, coupling, sentiment) and exporting results that can be plotted via a companion Python tool, making it directly useful for software analytics and engineering productivity datasets. It is not an ML framework, but it can generate structured time-series and graph-like features that are commonly used in ML/data science workflows (e.g., risk prediction, defect prediction, team dynamics). Community adoption appears solid (thousands of stars and an established toolchain), but it’s primarily an analytics extractor rather than a model training/serving library, which is why the score is moderate rather than high.",success
https://github.com/public-apis/public-apis,public-apis,"A community-curated directory of free public APIs across many categories, organized in a single README with metadata like auth method, HTTPS availability, and CORS support. It serves as a discovery hub for developers to quickly find APIs for building applications and prototypes.",390000,public-apis|api-directory|developer-resources|open-data|rest-apis|data-sources,5,"This repository is primarily a manually curated list of publicly available APIs, intended as a developer discovery resource rather than a machine learning library or dataset. It can be useful in ML/data workflows as a starting point to locate data sources (e.g., open data, finance, geocoding, text analysis, and even a machine learning category), but it does not provide modeling code, datasets, or tooling itself. Community adoption is very high (large star count), which increases its practical value for sourcing data, but the relevance is indirect—hence a mid-range score.",success
https://github.com/zhayujie/chatgpt-on-wechat,chatgpt-on-wechat,"A large-model-based chatbot/AI application framework that can be deployed across multiple channels (e.g., WeChat Official Accounts, WeCom, Feishu, DingTalk, and web) and switch among many LLM providers. It supports multimodal messages (text/voice/image/files), plugin-based extensions (including web search and tool/agent access), and enterprise knowledge-base customization.",40500,LLM|chatbot|WeChat|agent-tools|multimodal|Python|plugins|knowledge-base,5,"This repository is primarily an LLM-powered chatbot and extensible AI application framework for integrating multiple model providers into popular communication/collaboration platforms, with plugins, multimodal IO, and agent/tool access. It is relevant to ML/AI workflows mainly for application integration, orchestration, and deployment of existing foundation models rather than training models, building datasets, or core data science pipelines. The large community adoption (high GitHub stars) and practical examples for LLM integration add educational and integration value for ML engineers building AI products, but its direct utility for data science/model development is moderate, hence a mid-range score.",success
https://github.com/seaweedfs/seaweedfs,seaweedfs,"SeaweedFS is a fast, scalable distributed storage system for blobs/objects/files and data-lake workloads, designed to handle billions of files. It provides an object store plus an optional “Filer” layer with features like S3 compatibility, POSIX/FUSE mounting, Kubernetes integration, cross-DC replication, and erasure coding.",29400,distributed storage|object storage|s3-compatible|data lake|kubernetes|golang|filesystem|data engineering,5,"This repository primarily implements a distributed storage system (object/blob/file storage) rather than an ML library. It is indirectly relevant to ML/data workflows because ML teams often need scalable storage for datasets, feature stores, and data-lake-style access (including S3 and Hadoop/Spark ecosystem integration). I rated it 5/10 because it can be an important enabling component in data/ML infrastructure, but it does not provide ML algorithms, training tooling, or MLOps features directly.",success
https://github.com/apache/rocketmq,apache/rocketmq,"Apache RocketMQ is a cloud-native distributed messaging and streaming platform designed for building event-driven applications. It provides low-latency, high-throughput message delivery with features such as pub/sub and request-reply patterns, high availability, tracing, protocol support (e.g., gRPC/MQTT/JMS/OpenMessaging), and ecosystem integrations.",22300,messaging|message-broker|event-driven-architecture|streaming|distributed-systems|java|cloud-native|data-infrastructure,5,"This repository implements Apache RocketMQ, a distributed message broker/streaming platform primarily used to decouple services and move events/messages reliably at scale. While it is not an ML library, it is often used as infrastructure in data and ML pipelines for event ingestion, streaming feature updates, online/offline processing triggers, and integrating with big-data/streaming ecosystems. It earns a mid-range score because it is broadly applicable to ML/data engineering workflows as a transport layer, but it does not provide ML algorithms, modeling utilities, or core data science functionality itself.",success
https://github.com/vectordotdev/vector,vector,"Vector is a high-performance, end-to-end observability data pipeline (agent and aggregator) for collecting, transforming, and routing logs and metrics to a wide variety of destinations. It focuses on reliability and speed (implemented in Rust) and supports flexible pipelines via sources, transforms, and sinks.",21100,observability|logging|metrics|data pipeline|DevOps|Rust|ETL|telemetry,5,"This repository provides an infrastructure-focused observability pipeline that moves and transforms event data (logs/metrics) across systems, rather than an ML or analytics library. It is indirectly relevant to ML/data workflows because it can be used to collect, enrich, and route telemetry or operational data into storage/streaming systems that data teams may analyze, and it can support data engineering-style ETL patterns. However, it does not provide ML modeling, feature engineering, training, or MLOps capabilities directly, so its value for ML is mainly as upstream data/telemetry plumbing rather than a core ML tool.",success
https://github.com/apache/shardingsphere,apache/shardingsphere,"Apache ShardingSphere is a distributed SQL and database middleware ecosystem that adds sharding, read/write splitting, SQL federation, security (encryption/masking/audit), and governance/observability capabilities on top of existing heterogeneous databases. It provides both a Java JDBC-layer framework (ShardingSphere-JDBC) and a transparent database proxy (ShardingSphere-Proxy) to scale and manage database access without replacing underlying databases.",20600,distributed-sql|database-sharding|database-proxy|jdbc|middleware|data-governance|java,5,"This repository provides distributed SQL middleware (JDBC adapter and a database proxy) focused on sharding, read/write splitting, SQL federation, and security/governance features across heterogeneous databases. While it is not an ML library, it is often relevant to data/ML workflows as infrastructure for scalable data storage/access patterns, multi-tenant architectures, and performance/availability of OLTP systems that may feed analytics and feature pipelines. It earns a mid-range score because it can materially support data engineering and production data access, but it is not directly used for model training, ML experimentation, or core ML tooling.",success
https://github.com/postgres/postgres,postgres,"Mirror of the official PostgreSQL source code repository, containing the full database server and related components (including contrib modules and client C bindings). PostgreSQL is an advanced object-relational database management system implementing an extended subset of SQL with features such as transactions, foreign keys, triggers, and user-defined types/functions.",19500,database|postgresql|sql|rdbms|oltp|systems-programming|c-language,5,"This repository is the core source code for PostgreSQL, a widely used open-source relational database. While it is not an ML library, PostgreSQL is foundational infrastructure in many data science and ML workflows for storing, querying, and transforming structured data (including feature stores, analytics staging, and training data extraction via SQL). Its adoption and integration potential across data platforms is extremely high, but its primary purpose is general database management rather than ML-specific functionality, which is why it scores as indirectly relevant rather than a core ML/data tool.",success
https://github.com/questdb/questdb,questdb,"QuestDB is a high-performance, open-source time-series database focused on ultra-low-latency SQL queries and very high ingestion throughput. It provides a multi-tier storage engine (including WAL and Parquet), supports PostgreSQL wire protocol and REST, and includes time-series SQL extensions for analytics.",16360,time-series database|database|sql|data engineering|real-time analytics|columnar storage|observability,5,"This repository implements QuestDB, a production-grade time-series database optimized for fast ingestion and low-latency analytical queries (SQL with time-series extensions, plus Postgres wire protocol/REST access). While it is not an ML library, it can be a valuable component in ML/data workflows as a scalable store for telemetry, market, or sensor data feeding feature engineering, monitoring, and real-time analytics. Its relevance is indirect but meaningful for data science teams working with high-frequency time-series data, which fits a mid-range score rather than a core ML score.",success
https://github.com/ComposioHQ/awesome-claude-skills,awesome-claude-skills,"A curated collection of reusable “Claude Skills” (customizable workflows) plus related resources/tools to enhance productivity across Claude.ai, Claude Code, and the Claude API. It organizes skills by categories (e.g., document processing, development tools, data & analysis, security) and includes guidance for using and creating skills.",16300,LLM tools|Claude|agent workflows|prompt engineering|developer productivity|automation|curated list,5,"This repository primarily serves as an “awesome list”/collection of Claude Skills—structured prompt-and-workflow packages meant to standardize and reuse common tasks across Claude products. It is relevant to ML/AI practitioners mainly as an applied resource for LLM workflow design, agent tooling patterns (including MCP-related skills), and productivity/automation use cases rather than as a data-science or model-training library. It can help ML engineers build better LLM-assisted processes, but it doesn’t provide core ML algorithms, datasets, or training/evaluation infrastructure, so its value for data science/ML is indirect and moderate.",success
https://github.com/debezium/debezium,debezium,Debezium is an open-source change data capture (CDC) platform for streaming row-level changes from a variety of databases. It provides connectors (commonly used with Apache Kafka/Kafka Connect) to capture and publish database changes as events for downstream consumers and data pipelines.,12300,change-data-capture|data-engineering|streaming|apache-kafka|kafka-connect|databases|event-driven-architecture,5,"This repository implements Debezium, a CDC system that captures database changes (e.g., inserts/updates/deletes) and streams them as events, typically through Kafka Connect connectors. It is not an ML library, but it is highly relevant to data/ML workflows because it can power real-time feature ingestion, incremental dataset updates, and event-driven pipelines feeding data lakes/warehouses used for training and monitoring. The score reflects strong indirect utility for data science and ML engineering via reliable data movement and streaming integration, rather than direct modeling or ML-specific functionality.",success
https://github.com/mysql/mysql-server,mysql-server,"Source code for MySQL Server (Community Edition) and MySQL Cluster, implementing a widely used open-source relational database management system (RDBMS) and related components (server, client tools, storage engines, replication, etc.).",11951,database|relational-database|mysql|sql|database-engine|c-plus-plus|data-infrastructure|replication,5,"This repository is the core MySQL Server codebase (plus MySQL Cluster), i.e., a production-grade relational database used to store and query structured data at scale. While it is not an ML library or training framework, it is highly relevant to ML/data workflows as foundational data infrastructure (feature stores, ETL staging, metadata tracking, offline/online serving backends, analytics workloads, etc.). It has broad adoption in industry and can be an important component of data pipelines, but its direct applicability to day-to-day modeling (training/inference code) is indirect and requires substantial operational/DB expertise, which keeps the score at a mid-range level.",success
https://github.com/tadata-org/fastapi_mcp,fastapi_mcp,"FastAPI-MCP auto-generates and mounts a Model Context Protocol (MCP) server on top of an existing FastAPI application, exposing FastAPI endpoints as MCP tools for LLM/agent clients. It preserves request/response schemas and endpoint documentation and supports authentication via standard FastAPI dependency patterns.",11400,fastapi|mcp|model-context-protocol|llm-tools|openapi|authentication|python,5,"This repository is primarily an API/agent-integration utility: it converts FastAPI endpoints into MCP tools and provides an MCP server interface (including authentication) for clients like LLM agents. It’s not an ML/data library itself, but it can be quite useful in ML/LLM workflows for tool-calling (wrapping data/ML services behind a FastAPI app and making them accessible to agents). The score reflects solid indirect relevance and practical integration value for LLM app development, but limited direct contribution to core data science tasks (training, evaluation, pipelines, modeling) and adoption mainly in the MCP/agent ecosystem rather than general ML/data tooling.",success
https://github.com/lauris/awesome-scala,awesome-scala,"A community-driven curated list of useful Scala libraries, frameworks, and software, intended as a starting point for exploring the Scala ecosystem. The README is auto-generated from a template and the list is organized by categories (e.g., Big Data, AI, Science and Data Analysis, Web Frameworks).",9200,scala|awesome-list|curated-resources|scala-libraries|functional-programming|big-data|data-science,5,"This repository is an 'awesome list' (curated index) of Scala libraries and tools across many categories, rather than an ML/data library itself. It is indirectly useful for ML/data workflows because it helps practitioners discover Scala ecosystem options relevant to data engineering/analytics (e.g., Big Data, Artificial Intelligence, Science and Data Analysis sections). The community adoption appears strong (high star count), increasing its practical value as a discovery/learning resource, but you cannot directly run it to perform ML tasks—hence a mid-range score.",success
https://github.com/pdm-project/pdm,pdm,"PDM is a modern Python package and dependency manager designed around pyproject.toml and the latest Python packaging PEP standards. It provides fast dependency resolution, lockfiles, environment management, a PEP 517 build backend, and an extensible plugin system for Python development workflows.",8500,python|package-management|dependency-management|packaging|build-backend|dev-tools|virtual-environments|pyproject-toml,5,"This repository provides PDM, a general-purpose Python package/dependency manager and packaging tool (lockfiles, dependency resolution, environment management, PEP 517 build backend, and plugins). It is not an ML/data library itself, but it is commonly useful in ML/data workflows for managing large scientific/ML dependencies, reproducible environments, and consistent builds across teams and CI. The score reflects strong indirect relevance and high practical utility for ML engineers/data scientists, but a non-ML primary purpose.",success
https://github.com/PowerJob/PowerJob,PowerJob,"PowerJob is an open-source distributed computing and enterprise job scheduling framework. It provides a web UI plus multiple scheduling strategies (e.g., CRON/fixed rate/fixed delay), multiple execution modes (standalone/broadcast/Map/MapReduce), and workflow (DAG) support for orchestrating and monitoring jobs across worker nodes.",7700,job-scheduling|distributed-systems|mapreduce|workflow-orchestration|java|spring-boot|cron,5,"This repository primarily provides distributed job scheduling and execution infrastructure (including Map/MapReduce-style distributed execution modes and DAG workflows), aimed at enterprise task orchestration rather than ML itself. It can be useful in ML/data workflows as a scheduler/orchestrator for batch jobs, feature generation, periodic ETL, or distributed data processing tasks, but it does not provide ML modeling, training, or native MLOps capabilities. Its relevance is therefore indirect-to-moderate: valuable as supporting infrastructure for data/ML pipelines, but not a core data science library.",success
https://github.com/turbot/steampipe,steampipe,"Steampipe is a zero-ETL tool that lets you query live data from APIs and services using SQL by mapping each service's API resources into relational tables. It runs as a single CLI binary and supports a plugin ecosystem (e.g., AWS, Azure, GCP, GitHub, Kubernetes) to expose many data sources for interactive queries and automation use cases.",7600,SQL|data-integration|API-querying|PostgreSQL|DevOps|cloud|observability|security,5,"This repository provides a zero-ETL SQL interface over live APIs via a plugin system, enabling analysts and engineers to query operational and cloud/service data as relational tables without building ingestion pipelines. It is not an ML framework, but it can be quite useful in ML/data workflows for extracting, auditing, and joining metadata from SaaS/cloud systems (e.g., asset inventories, governance, telemetry-like data) that may feed feature stores or monitoring/ops datasets. Community adoption appears solid (thousands of GitHub stars) and it integrates well with common data tools through SQL/Postgres compatibility, but its primary use case is infrastructure/operations querying rather than model training or data science algorithms—hence a mid-range score.",success
https://github.com/xixu-me/Xget,Xget,"Xget is an ultra-high-performance, secure, all-in-one acceleration/proxy engine that speeds up access to developer resources across many platforms (code hosting, package registries, container registries, model/dataset hubs, and some AI inference APIs). It provides a unified “URL prefix/rewriting” style interface (plus tooling like a URL converter) and is commonly deployed on edge platforms (e.g., Cloudflare Workers) to improve download reliability and throughput.",7500,developer-tools|networking|proxy|download-acceleration|cloudflare-workers|package-registry|container-registry|ml-model-hosting,5,"Xget’s primary use case is accelerating and stabilizing downloads/API access for many developer ecosystems (Git hosting, package managers, container registries, and model/dataset hubs) via a unified acceleration endpoint and URL conversion approach. It is not an ML library, but it can be directly useful in ML/data workflows by speeding up retrieval of models and datasets (e.g., Hugging Face) and dependencies in constrained network environments. Community adoption appears strong (thousands of GitHub stars), suggesting practical utility, but its value to ML is indirect (infrastructure/tooling rather than modeling, training, or data processing), which is why it scores mid-range rather than high.",success
https://github.com/marcelscruz/public-apis,public-apis,"A collaboratively maintained directory of free/public APIs for developers, organized by category with metadata such as authentication method, HTTPS support, and CORS availability.",7400,public APIs|API directory|developer resources|open data|community-maintained list|web development,5,"This repository primarily provides a curated catalog of publicly available APIs across many categories (including Open Data and Machine Learning), serving as a discovery/reference resource rather than an ML library. It can be useful in data science workflows as a starting point to find data sources and programmatic endpoints for data collection, enrichment, or dataset creation. However, it does not provide ML models, training code, datasets, or data-processing tooling directly, so its value is indirect rather than core to ML/DS execution. The solid community adoption and breadth of listed data-relevant APIs justify a mid-range score.",success
https://github.com/alirezamika/autoscraper,autoscraper,"AutoScraper is a lightweight Python library for automatic web scraping that learns extraction rules from example “wanted” values (text/URLs/attribute values) taken from a page. After building a scraper from samples, you can reuse it on similar pages/URLs and save/load the learned scraping model.",7100,python|web-scraping|scraping-automation|html-parsing|data-extraction|crawler|rule-learning,5,"This repository provides a practical Python utility for extracting structured data from web pages by learning selectors/rules from example target values, then reapplying those rules to similar pages and saving/loading the learned configuration. It is not an ML framework or modeling library, but it is directly useful for data science workflows as a data acquisition tool (collecting text/links/attributes from web sources) and has notable community adoption (about 7.1k GitHub stars). The approach is “ML-like” in that it infers scraping rules from samples, but its primary value is web data extraction rather than training or deploying machine learning models.",success
https://github.com/cxli233/FriendsDontLetFriends,FriendsDontLetFriends,"An opinionated guide on good vs. bad practices in data visualization, with many illustrative examples. Includes R Markdown scripts (in the Scripts/ directory) used to generate the figures shown in the README/tutorial materials.",7000,data visualization|R|RMarkdown|scientific communication|data analysis|best practices|tutorial,5,"This repository is primarily an educational resource about effective (and ineffective) data visualization patterns, with example figures and R/RMarkdown code used to reproduce them. It is relevant to data science workflows because visualization is a core part of exploratory data analysis, reporting, and communicating ML results, but it does not provide ML models, training pipelines, or data-engineering infrastructure. Community adoption appears strong (about 7k stars), suggesting significant educational value, but its direct ML tooling applicability is moderate rather than high.",success
https://github.com/hazelcast/hazelcast,hazelcast,"Hazelcast is a unified real-time data platform that combines distributed in-memory data storage with stateful stream processing and SQL querying for building low-latency, real-time applications. It supports connectors (e.g., Kafka, Hadoop, S3, RDBMS), messaging patterns, and operational features such as fault tolerance and rolling upgrades.",6500,real-time data platform|distributed systems|in-memory data grid|stream processing|sql|java|kafka-connectors|caching,5,"This repository implements Hazelcast’s core distributed data store and real-time stream processing engine, aimed at building low-latency, stateful, fault-tolerant applications with SQL and connector-based ingestion/egress. It is not an ML framework, but it can be useful in ML/data workflows as infrastructure for real-time feature serving, streaming ETL, and operationalizing data pipelines (including stated integration for deploying ML models with Python into processing pipelines). Given its strong relevance to data engineering/stream processing but indirect focus on model development/training, it merits a mid-range score.",success
https://github.com/cloudquery/cloudquery,cloudquery,"CloudQuery is a high-performance ELT/data pipeline framework for extracting cloud configuration, security, and related data from AWS/Azure/GCP and many SaaS sources and loading it into databases/data warehouses for analysis (e.g., asset inventory, CSPM, FinOps, vulnerability management). It provides a plugin-based architecture and a CLI to run syncs on your own infrastructure.",6300,data engineering|ELT|ETL|cloud security|CSPM|FinOps|Go,5,"This repository primarily provides a developer-focused ELT framework (CLI + plugin system) to move cloud/SaaS configuration and security data into analytical destinations (e.g., databases/warehouses) for querying and governance. It is not an ML library, but it can be an important upstream component in ML/data workflows by reliably sourcing and structuring operational/security data for analytics and feature engineering. Its relevance is strongest for data engineering, observability/security analytics, and building datasets rather than for model training or MLOps, which is why it scores as indirectly relevant rather than highly ML-specific.",success
https://github.com/dpkp/kafka-python,kafka-python,"A pure-Python client library for Apache Kafka that provides high-level Producer and Consumer APIs (similar to the official Java client) plus a lower-level protocol layer for interacting with Kafka brokers. It supports common Kafka features like consumer groups (on newer brokers), compression, metrics, and transactions.",5900,apache-kafka|python|stream-processing|data-engineering|messaging|event-streaming|distributed-systems,5,"This repository provides a Python client for producing to and consuming from Apache Kafka, enabling applications to build event-driven and streaming data systems. While it is not an ML library, Kafka is frequently used in ML/data workflows for ingesting training data, streaming features/events, and connecting ETL/ELT or real-time processing components. Its value to ML practitioners is therefore indirect but practical (infrastructure/pipeline integration rather than modeling), which fits a mid-range score.",success
https://github.com/Drakkar-Software/OctoBot,OctoBot,"OctoBot is a free, open-source cryptocurrency trading bot (Python) with a visual interface that lets users automate strategies (e.g., grid, DCA, baskets), connect to TradingView signals, and run paper trading, live trading, and built-in backtesting/optimization across 15+ exchanges. It also supports “AI connectors” to trade using LLMs (e.g., OpenAI/Ollama models) and can be extended via a plugin (“tentacles”) architecture.",5100,cryptocurrency trading|algorithmic trading|python|backtesting|tradingview|LLM integration|technical analysis,5,"This repository’s primary purpose is automated crypto trading (strategy execution, exchange connectivity, paper/live trading, and backtesting/optimization) rather than ML model training or data science. It has some ML-adjacent value because it is explicitly “AI ready” (Python-based and designed to integrate with ML/AI libraries) and includes connectors for using LLMs as part of strategies, plus backtesting workflows that are relevant to quantitative experimentation. However, it is not a general ML framework or dataset/toolkit for building models; ML use is optional and typically implemented by users via strategy plugins, so its direct applicability to mainstream ML/data workflows is moderate rather than high.",success
https://github.com/ag2ai/faststream,faststream,"FastStream is an asynchronous Python framework for building services that produce/consume event streams via brokers like Kafka, RabbitMQ, NATS, and Redis. It provides a unified developer-friendly API with built-in serialization/validation (e.g., Pydantic or msgspec), dependency injection, testing support, and automatic AsyncAPI documentation generation.",4900,python|asyncio|event-streaming|microservices|kafka|rabbitmq|nats|redis,5,"This repository provides infrastructure for building async, event-driven microservices over common message brokers (Kafka/RabbitMQ/NATS/Redis), with strong ergonomics (typed APIs, DI, test tooling) and built-in message validation/serialization. It is not an ML library, but it is relevant to data/ML engineering because streaming ingestion and event-driven processing are common in real-time data pipelines feeding feature stores, model inference services, and monitoring/telemetry workflows. The score reflects solid indirect applicability to ML/data workflows and broad integration usefulness, but limited direct ML functionality.",success
https://github.com/mgramin/awesome-db-tools,awesome-db-tools,"A community-driven “awesome list” curating tools that make working with databases easier for DBAs, developers, and DevOps. It organizes links across categories like IDE/GUI/CLI clients, schema migration and documentation, monitoring/performance, backup/HA, Kubernetes/DevOps, and data tooling (e.g., lineage, masking, profiling).",4900,databases|data engineering|DevOps|SQL|database administration|data tools|awesome-list,5,"This repository is primarily a curated directory of database-related tools (clients, schema/migrations, monitoring, backup/HA, Kubernetes/DevOps, and data tooling) rather than an ML library or dataset. It’s indirectly valuable for ML/data workflows because many ML systems depend on reliable database operations, data governance, and data management tools (e.g., profiling, lineage, masking) that are listed here. Its usefulness comes from discoverability and educational breadth, not from providing code for modeling/training, so it merits a mid-range score.",success
https://github.com/pywebio/PyWebIO,PyWebIO,"PyWebIO is a low-code Python framework for building interactive web apps in a script/imperative style, using Python functions for browser-based input/output without writing HTML/JavaScript. It can run standalone and integrates with popular web frameworks (e.g., Flask, Django, Tornado, aiohttp, FastAPI) and supports async/coroutines plus third-party visualization libraries.",4808,python|web-development|low-code|rapid-prototyping|dashboarding|data-visualization|gui,5,"PyWebIO’s primary purpose is building lightweight interactive web UIs (forms, dashboards, simple apps) directly from Python scripts, not performing ML or data processing itself. It can still be useful in ML/data workflows as a quick way to wrap models, demos, internal tools, and exploratory visualizations into shareable web interfaces (including integration with plotting libraries), which gives it indirect-to-moderate relevance. It is not an ML framework, pipeline tool, or core data library, so it doesn’t score higher, but its practicality for presenting/serving results and building simple model front-ends supports a mid-range score.",success
https://github.com/clidey/whodb,whodb,"WhoDB is a lightweight, fast database management/data explorer tool with a modern UI and chat-based interface. It supports multiple databases (including Postgres, MySQL, SQLite, MongoDB, Redis, MariaDB, Elasticsearch, and ClickHouse) and includes features like a data grid, schema exploration, and natural-language-to-SQL via integrations such as Ollama, OpenAI, and Anthropic.",4400,database-client|data-exploration|sql|data-management|ai-chat-interface|golang|react,5,"This repository is primarily a database management and data exploration client (UI + tooling) for querying, browsing, and editing data across many popular databases, with an added chat interface that can translate natural language to SQL. It can be useful in ML/data workflows indirectly because data scientists and ML engineers often need to explore datasets, validate tables, and run ad-hoc queries during feature engineering and debugging. However, it is not an ML library, training framework, or data pipeline system, and its core value is general database productivity rather than ML-specific functionality. The presence of NL-to-SQL/chat integrations increases relevance for data work, but overall it remains an infrastructure/productivity tool rather than a core ML/data platform.",success
https://github.com/shinnytech/tqsdk-python,tqsdk-python,"TqSdk (TianQin Quant) is an open-source Python SDK for quantitative trading that provides real-time market data, historical data, backtesting, simulated trading, and live trading workflows across futures/options/stocks, integrating with brokerage/CTP-style trading connectivity.",4400,quantitative trading|algorithmic trading|fintech|market data|backtesting|futures|python,5,"This repository is primarily a quantitative trading SDK focused on acquiring real-time/historical market data and executing trades (including backtesting and paper/live trading), rather than an ML library. It can be useful in data science workflows because it streamlines data collection (tick/K-line data) and supports analysis-friendly integrations (e.g., pandas/numpy), enabling feature engineering and dataset building for trading research. However, it does not center on model training, ML algorithms, or MLOps tooling, and its applicability is strongest for finance/trading data pipelines rather than general ML tasks. Therefore, it earns a mid-level score for indirect but practical relevance to ML/data work in quantitative finance.",success
https://github.com/rudderlabs/rudder-server,rudder-server,"RudderStack Server is an open-source, privacy- and security-focused Customer Data Platform (CDP) / Segment alternative. It ingests event data via Segment-compatible APIs, supports transformations, and routes data to warehouses and other downstream destinations (warehouse-first architecture), with a Go backend and React-based UI.",4300,customer-data-platform|data-pipeline|event-streaming|data-engineering|etl-elt|data-integration|golang,5,"This repository implements a production-grade CDP/event pipeline that collects, transforms, and delivers behavioral/event data to data warehouses and analytics/business tools, acting as core data infrastructure. While it is not an ML library and does not provide model training/inference capabilities, it can be highly useful in ML/data workflows by reliably moving and shaping event data that can become features or training data in a warehouse/lake. Its relevance is therefore indirect but meaningful for data scientists and ML engineers working on analytics, feature generation, and data quality/observability around event data pipelines, warranting a mid-range score rather than a low one.",success
https://github.com/pydantic/logfire,logfire,"Pydantic Logfire is an observability SDK and platform integration for Python (and beyond) built on OpenTelemetry, providing traces, logs, metrics, and SQL-based querying with first-class Python/Pydantic-friendly insights. This repository contains the open-source Python SDK and documentation; the hosted/enterprise backend UI and server are closed source.",3900,observability|opentelemetry|python|logging|distributed-tracing|metrics|fastapi|pydantic,5,"This repository provides an OpenTelemetry-based observability SDK for instrumenting applications, capturing traces/logs/metrics, and integrating with popular Python frameworks (e.g., FastAPI) and Pydantic models. While it is not an ML/data library, it is indirectly valuable to ML and data teams for monitoring model-serving APIs, tracking LLM/agent workloads, debugging pipeline services, and analyzing production behavior via telemetry and SQL queries. The score reflects strong operational relevance (MLOps/LLMOps observability) but limited direct applicability to core data science tasks like training, feature engineering, or modeling.",success
https://github.com/Ly0n/awesome-robotic-tooling,awesome-robotic-tooling,"A curated “awesome list” of tools and resources for professional robotics software and hardware development, with emphasis on C++/Python workflows and related domains like ROS, autonomous driving, and aerospace. It organizes tooling across areas such as development environment, simulation, perception, SLAM, planning/control, operations, and datasets.",3700,robotics|ROS|C++|Python|autonomous driving|robotics tooling|simulation|perception,5,"This repository is primarily an “awesome list” that catalogs robotics development tooling across the full stack (from dev environment and simulation to perception/SLAM/planning and datasets), rather than providing an ML library or dataset itself. It has indirect but meaningful value for ML/data workflows in robotics because it includes sections like Machine Learning, perception pipelines, and datasets, helping practitioners discover relevant tools and infrastructure. However, since it’s a directory of links (not a directly runnable ML framework or pipeline) and its impact depends on what users choose from it, its direct applicability to day-to-day ML engineering is moderate rather than core.",success
https://github.com/thi-ng/umbrella,umbrella,"A large monorepo (“anti-framework”) of independently versioned @thi.ng TypeScript libraries and tools, designed to be mixed-and-matched for functional, reactive, and data-driven development. It includes hundreds of packages spanning FP primitives, data structures, stream/dataflow utilities, parsing/DSL tooling, geometry/graphics/WebGL, and many example projects.",3700,TypeScript|functional-programming|reactive-programming|data-structures|transducers|dataflow-streams|graphics-geometry|WebGL,5,"thi-ng/umbrella is primarily a broad general-purpose ecosystem of composable TypeScript libraries (an “anti-framework”), with strong emphasis on functional programming, reactive streams/dataflow, and reusable data structures. While it is not an ML framework, several components (e.g., transducers, iterators/streams, parsers, data structures, numeric/geometry utilities, visualization/graphics tooling) can be useful for data processing and building data-driven systems. The score reflects solid indirect relevance and integration potential for data engineering-style tasks, but limited direct ML training/inference focus and relatively niche adoption specifically within mainstream ML workflows.",success
https://github.com/fastai/fastpages,fastpages,"A GitHub Pages blogging platform that uses GitHub Actions to convert Jupyter Notebooks (plus Markdown and Microsoft Word documents) into Jekyll blog posts, supporting rich code outputs and interactive elements. The repository has been archived and is deprecated in favor of Quarto.",3500,blogging|github-pages|jekyll|github-actions|jupyter-notebook|static-site-generator|technical-writing,5,"fastpages is primarily a publishing tool: it turns notebooks (and other formats) into blog posts for GitHub Pages using GitHub Actions and Jekyll. It’s useful for data scientists because it streamlines sharing analyses and tutorials from Jupyter Notebooks (including code and outputs), but it is not itself an ML/data processing library or training framework. Community adoption appears solid (thousands of stars), yet the project is archived (read-only) and explicitly deprecated, which reduces its practical value for new ML/data workflows today.",success
https://github.com/my8100/scrapydweb,scrapydweb,"ScrapydWeb is a web application for managing a Scrapyd cluster and Scrapy spider jobs, with features like log analysis/visualization, auto packaging, scheduled (timer) tasks, monitoring/alerts, and a mobile-friendly UI.",3400,web scraping|scrapy|scrapyd|job orchestration|monitoring|log analysis|python|web UI,5,"This repository provides operational tooling (a web UI) for managing distributed Scrapy/Scrapyd web-scraping workloads, including job control plus log/statistics analysis and visualization. It is not an ML library, but it can be useful in data/ML workflows as part of data acquisition and pipeline operations (running and monitoring crawlers that collect training or analytics data). Community usage appears solid (thousands of GitHub stars), which increases its practical value for data engineering adjacent to ML, but it does not directly support model training, feature engineering, or MLOps model lifecycle tasks—hence a mid-range score.",success
https://github.com/superstreamlabs/memphis,memphis,"Memphis.dev is an open-source data streaming and message-brokering platform aimed at helping backend teams build event-driven and real-time systems quickly. It includes a production-ready broker plus UI/CLI/SDKs, observability features, dead-letter queues, schema management (e.g., Protobuf/JSON/GraphQL/Avro), and Kubernetes/Docker deployment options.",3400,data streaming|message broker|event-driven architecture|real-time systems|kubernetes|observability|schema management|golang,5,"This repository provides a scalable data streaming/message-broker platform (Memphis.dev) for building event-driven and real-time backend systems, with operational tooling like UI/CLI/SDKs, observability, dead-letter queues, and schema governance. It is not an ML library, but it can be useful in ML/data workflows as infrastructure for ingesting, buffering, validating, and routing streaming data (e.g., events feeding feature pipelines or online inference services). Its value for ML practitioners is therefore indirect and depends on whether they operate streaming data systems, which supports a mid-range score rather than a high ML-specific rating.",success
https://github.com/mhallsmoore/qstrader,qstrader,"QSTrader is an open-source Python backtesting simulation engine for systematic trading strategies (notably long/short equities and ETF-based portfolios). It uses a modular, schedule-driven design with realistic trading mechanics, and is intended to be extended or replaced module-by-module for custom research/backtest workflows.",3300,algorithmic trading|quant finance|backtesting|systematic trading|portfolio analytics|python,5,"This repository is primarily a quant trading backtesting framework: it simulates portfolio construction and trading/execution mechanics and produces performance/tearsheet statistics. It is relevant to data science workflows because it supports data-driven strategy research and evaluation, but it is not an ML framework and does not focus on model training, feature engineering, or MLOps. Its value for ML practitioners is mainly indirect (using ML-generated signals inside a backtesting pipeline), hence a mid-range score rather than a high one.",success
https://github.com/googleapis/google-cloud-node,google-cloud-node,Monorepo containing the official Node.js client libraries for Google Cloud services. It provides idiomatic TypeScript/JavaScript SDKs (published to npm) for interacting with a wide range of Google Cloud APIs from Node.js applications.,3100,google cloud|node.js|typescript|cloud sdk|api clients|gcp|monorepo,5,"This repository primarily provides Node.js client libraries for Google Cloud Platform services, enabling applications to call Google Cloud APIs. It is indirectly relevant to ML/data workflows because it includes clients commonly used in data/ML systems (e.g., BigQuery, Pub/Sub, Storage, and various AI/ML-related APIs), but it is not itself an ML framework or data processing engine. Its value for ML/data engineers is mainly integration and orchestration—building pipelines, moving data, and calling managed services—rather than core modeling or analytics, which supports a mid-range score.",success
https://github.com/GoogleCloudPlatform/professional-services,professional-services,"A large collection of reference solutions, examples, and reusable tools created by Google Cloud's Professional Services team across many Google Cloud products (e.g., BigQuery, Dataflow, GKE/Anthos, Cloud Composer). It is explicitly described as not an officially supported Google product.",3000,google-cloud|cloud-architecture|bigquery|data-engineering|devops|kubernetes|terraform|mlops,5,"This repository is primarily a broad grab-bag of Google Cloud Professional Services solutions and tooling, spanning infrastructure, operations, and application examples rather than being a single ML-focused library. It includes multiple data/ML-adjacent components (e.g., BigQuery utilities, audit log anomaly detection examples, pipelines using ML APIs, and Colab notebooks), which can be directly useful to data engineers and ML engineers in GCP-centric workflows. However, ML is not the repo’s core purpose and the contents are heterogeneous, so its adoption/value for ML is more indirect compared to dedicated ML frameworks or MLOps platforms—hence a mid-range score.",success
https://github.com/Mathieu2301/TradingView-API,TradingView-API,"A Node.js/TypeScript library that emulates TradingView’s websocket/scripting behavior to fetch real-time market prices and indicator values, plus related data like technical analysis, screeners, hotlists, and replay/backtesting utilities. It includes examples and supports features such as multiple simultaneous indicators and accessing invite-only indicators (where available).",2700,algorithmic-trading|market-data|tradingview|stocks|crypto|javascript|typescript|backtesting,5,"This repository’s primary purpose is programmatic access to TradingView-derived real-time prices, indicator outputs, and related trading data (e.g., screeners/hotlists) via a Node.js/TypeScript API wrapper/emulation layer. It can be useful in ML/data workflows as a data-collection and feature-generation component (e.g., using indicator values as model features, building datasets from replay/backtesting ranges), but it is not an ML library and does not provide modeling/training functionality. Community usage appears solid for a niche trading-data tool (thousands of stars, many forks, and reported downstream users), supporting a mid-range score rather than a core ML score.",success
https://github.com/scrtlabs/catalyst,catalyst,"Catalyst is a Python-based algorithmic trading library for crypto-assets, designed for expressing and backtesting trading strategies on historical market data (daily/minute) and for live trading on supported exchanges. It builds on the Zipline API and provides performance analytics via Pandas-friendly outputs.",2600,algorithmic-trading|cryptocurrency|backtesting|quant-finance|python|zipline|pandas,5,"This repository is primarily an algorithmic crypto trading/backtesting framework (Zipline-derived) that helps users run strategies, ingest historical pricing data, and compute performance analytics. It is relevant to data science workflows because it produces results in Pandas DataFrames and can be paired with statistical/ML libraries (e.g., sklearn) for research, feature engineering, and strategy evaluation, but ML is not its core purpose. Community interest exists (2.6k stars), yet the project is archived (read-only) and noted as not actively maintained since the end of 2018, reducing practical value for modern ML/data production use.",success
https://github.com/emptymalei/awesome-research,awesome-research,"A curated “awesome list” of research and productivity tools (e.g., organization, note-taking, writing/publishing, programming, data visualization, LaTeX, and academic utilities). The repository is marked as deprecated in favor of a maintained companion website that hosts the list.",2500,awesome-list|research-tools|academic-productivity|note-taking|writing-and-publishing|data-visualization|LaTeX|scientific-computing,5,"This repository is primarily a curated directory of tools useful for research workflows rather than an ML library or dataset. It has moderate relevance to ML/data work because it includes categories like scientific computing, data tools, notebooks, and data visualization that data scientists commonly use, but it does not provide ML algorithms, training pipelines, or framework integrations itself. The strong community adoption (thousands of stars) and breadth of resources provide educational and practical value, but its indirect applicability keeps the score in the mid-range.",success
https://github.com/blankly-finance/blankly,blankly,"Blankly is a Python algo-trading framework for building, backtesting, paper trading, and deploying trading bots across multiple broker/exchange integrations (stocks, crypto, futures, and forex) with a unified API. It includes a CLI setup flow and supports switching between backtests and live execution with minimal code changes.",2400,algorithmic trading|quantitative finance|trading bot|backtesting|python|crypto|brokerage APIs|event-driven systems,5,"This repository primarily provides an algorithmic trading framework (unified exchange interfaces plus backtesting/paper/live execution tooling) rather than an ML library. It can be useful in ML/data workflows when you want to backtest or deploy ML-driven trading strategies (e.g., models producing signals) and to run experiments against market/alternative data, but it does not itself focus on model training, feature engineering, or core ML algorithms. Its relevance is therefore indirect-to-moderate: valuable as an execution/backtesting layer around ML strategies, but not a core ML/data science toolkit.",success
https://github.com/julien-duponchelle/python-mysql-replication,python-mysql-replication,"A pure-Python implementation of the MySQL replication protocol (built on top of PyMySQL) that lets you read MySQL/MariaDB binlog events (e.g., insert/update/delete and raw SQL queries) for building change data capture and replication pipelines.",2400,change-data-capture|mysql|mariadb|binlog|replication|data-engineering|python,5,"This repository provides a Python library for consuming MySQL/MariaDB replication/binlog events, enabling CDC-style streaming of database changes into downstream systems (e.g., search indexes, caches, analytics stores). It is not an ML library, but it is directly useful in data/ML workflows as ingestion infrastructure for building near-real-time feature pipelines, data sync to warehouses/lakes, and audit/observability streams. The score is mid-range because its core value is data engineering (reliable change capture and integration) rather than modeling, training, or ML-specific tooling, though it can be an important upstream component in ML production systems.",success
https://github.com/protontypes/open-sustainable-technology,open-sustainable-technology,"A curated directory and analysis of open-source projects focused on sustainability domains such as climate change, sustainable energy, biodiversity, and natural resources. It organizes projects into detailed topical categories and provides supporting metadata/resources to help discover and contribute to the ecosystem.",2400,sustainability|climate-tech|open-source-directory|renewable-energy|biodiversity|environmental-data|metadata-catalog,5,"This repository primarily serves as a curated directory and analysis of open-source sustainability projects, organized by domain areas (e.g., energy systems, emissions, biosphere, climate change) rather than as an ML library. It can still be valuable for ML/data workflows by helping practitioners discover relevant datasets, tools, and projects (including those involving modeling, forecasting, remote sensing, and data processing). However, it is not itself a framework for training models or building pipelines, and its direct applicability depends on what linked projects you choose to use. The moderate score reflects strong discovery/educational value for climate and environmental data science, but limited direct tooling for ML implementation.",success
https://github.com/supabase/supabase-py,supabase-py,"Python client/monorepo for Supabase that provides libraries to interact with Supabase services, including Postgres querying (via PostgREST), authentication, storage, edge functions, and realtime data streaming for use in frameworks like Flask, Django, and FastAPI.",2400,python|supabase|postgresql|postgrest|authentication|realtime|object-storage|backend-as-a-service,5,"This repository primarily provides Python client libraries for Supabase (a Postgres-centric backend-as-a-service), enabling programmatic access to databases, auth, storage, edge functions, and realtime features. It is not an ML library, but it can be quite useful in data/ML workflows as infrastructure glue: ingesting/querying datasets from Postgres, managing user/auth for data apps, and building data-driven APIs or internal tools. The score reflects indirect-to-moderate relevance for data science (as a database/API client and platform integration), rather than direct support for modeling, training, or MLOps.",success
https://github.com/tabixio/tabix,tabix,"Tabix is an open-source web UI that provides a SQL editor and simple business intelligence (BI) dashboards for the ClickHouse database, enabling users to run queries and visualize results in the browser.",2300,business-intelligence|clickhouse|sql-editor|dashboard|data-visualization|typescript|web-application,5,"This repository is primarily a browser-based BI/dashboard and SQL query editor focused on ClickHouse, aimed at interactive querying and visualization rather than machine learning. It can still be useful in data workflows for exploring datasets, validating transformations, and monitoring analytical tables that might feed ML pipelines. However, it does not provide ML algorithms, model training/inference features, or tight integration with ML frameworks, so its value to ML/data science is indirect.",success
https://github.com/confluentinc/examples,confluentinc/examples,"A curated collection of runnable demos and reference examples for Apache Kafka, Apache Flink, and the Confluent Platform/Confluent Cloud, covering end-to-end streaming use cases, connectors, stream processing, security, and deployment patterns.",2000,apache-kafka|event-streaming|data-engineering|stream-processing|confluent-platform|confluent-cloud|apache-flink|kafka-connect,5,"This repository primarily provides practical demos and sample projects for event streaming on Confluent Platform/Confluent Cloud (Kafka-centric pipelines, connectors, stream processing, and operational patterns), rather than ML model development. It is still relevant to ML/data workflows because Kafka-based ingestion and real-time data movement are common building blocks for feature pipelines, online/offline data synchronization, and streaming analytics that can feed ML systems. However, it does not focus on core ML tasks like training, evaluation, or MLOps tooling, and its applicability to ML is mainly as surrounding data infrastructure and educational examples for streaming data integration.",success
https://github.com/jmfernandes/robin_stocks,robin_stocks,"A Python library that provides an interface for interacting with brokerage/crypto APIs (notably Robinhood), enabling trading of stocks/options/crypto and retrieval of real-time quotes, portfolio performance, and related account data. It also includes modules for Gemini and TD Ameritrade integrations and example usage for building trading/automation scripts.",2000,python|algorithmic-trading|finance|brokerage-api|robinhood|cryptocurrency|options-trading|portfolio-analysis,5,"This repository primarily provides a Python API wrapper for brokerage/crypto services (Robinhood, plus modules for Gemini and TD Ameritrade), aimed at automating trading actions and pulling market/account data. It can be useful in ML/data workflows as a data acquisition layer (e.g., fetching quotes, holdings, and historical/related info to build datasets) and for deploying model-driven trading bots, but it is not an ML library and does not provide modeling/training utilities itself. Community adoption appears solid for its niche (notably a relatively high star count), which increases its practical value for data practitioners doing finance-focused projects. Overall, it’s moderately relevant as a supporting tool for ML/data pipelines in trading contexts rather than a core ML/data science toolkit.",success
https://github.com/pydoit/doit,doit,"doit is a Python-based CLI task runner and automation/build tool that lets you define tasks in Python, executes them with dependency management via a DAG, and supports incremental builds through caching/up-to-date checks. It includes a plugin architecture and extras like parallel execution, file-watching auto-runs, shell completion, DAG visualization, and IPython integration.",2000,task-runner|build-automation|workflow-orchestration|pipeline|python|CLI|incremental-builds|DevOps,5,"The repository provides a general-purpose Python task automation/build tool that models tasks as a DAG with caching and incremental execution, aimed at organizing and running project workflows. While it is not an ML/data library itself, it is directly useful for data/ML work to orchestrate repeatable data pipelines (ETL, feature generation, training/evaluation steps) and to speed iteration via up-to-date checks and parallel execution. It has practical integration points for data workflows (e.g., dynamic task generation and IPython/Jupyter-friendly usage patterns), but lacks ML-specific primitives, dataset tooling, or model training frameworks—hence a mid-range score.",success
https://github.com/alpacahq/alpaca-trade-api-python,alpaca-trade-api-python,"Python client library for Alpaca's Trading API that supports placing/managing orders and accessing account/portfolio endpoints via REST, plus streaming market/account updates via websockets. It also includes utilities for retrieving historical and live market data and returning results as lists or pandas DataFrames.",1900,python|algorithmic-trading|trading-api|market-data|finance|websockets|rest-api|pandas,5,"This repository is primarily a Python SDK for interacting with Alpaca’s trading and market data APIs (REST + streaming), aimed at algorithmic trading and data retrieval rather than ML itself. It can be useful in ML/data workflows as a reliable way to collect historical and live financial market data into Python (including DataFrame-friendly outputs) for feature engineering, backtesting, and model-driven trading systems. However, it does not provide ML algorithms, modeling utilities, or MLOps features, and it has been superseded by the newer official SDK (alpaca-py), reducing its forward-looking value for ML tooling despite still being practically useful for data acquisition.",success
https://github.com/brimdata/zui,zui,"Zui (a.k.a. SuperDB Desktop) is an Electron-based desktop application for ingesting, exploring, querying, and debugging data stored in local or remote Zed/SuperDB lakes. It supports drag-and-drop ingest, schema inference, rich table/inspector views for nested data, and query workflows (named queries, history, pivots/filters).",1900,desktop-app|electron|typescript|data-exploration|query-language|data-analytics|data-visualization|zed-superdb,5,"This repository primarily builds Zui/SuperDB Desktop, a GUI for ingesting and interactively querying/inspecting datasets in Zed/SuperDB lakes (including nested JSON, Parquet, Arrow IPC, and log-style data). It can be useful in data science workflows for exploratory data analysis, data wrangling, quick inspection/debugging of raw/heterogeneous data, and exporting results, but it is not an ML framework and does not focus on model training, evaluation, or MLOps. Because its core value is interactive data exploration/analytics rather than ML-specific capabilities (and adoption is more niche than mainstream DS tools), it fits as indirectly-to-moderately relevant for ML/data work.",success
https://github.com/fede1024/rust-rdkafka,rust-rdkafka,"A fully asynchronous, futures-enabled Apache Kafka client library for Rust built on top of the C library librdkafka. It provides both low-level and high-level producers/consumers (including StreamConsumer and FutureProducer), with support for features like consumer rebalancing, metrics, and exactly-once semantics.",1900,rust|apache-kafka|kafka-client|librdkafka|stream-processing|async|tokio|data-engineering,5,"This repository provides a production-grade Rust client for Apache Kafka (via librdkafka), enabling building Kafka producers/consumers and integrating with async Rust (including Tokio) for streaming applications. It is not an ML library, but it is commonly useful in data/ML workflows as infrastructure for ingesting, transporting, and processing event streams used in feature pipelines, real-time inference, and offline training data feeds. The score reflects strong relevance to data engineering and MLOps integration potential, but limited direct educational or algorithmic ML functionality.",success
https://github.com/protectwise/troika,troika,"Troika is a collection of JavaScript tools for building interactive graphics in the browser, focused on high-performance 3D/WebGL (via Three.js) and 2D Canvas rendering. It provides a declarative scene/framework layer plus reusable Three.js utilities (e.g., text rendering and instancing) optimized for data visualization and interactive experiences.",1900,javascript|webgl|threejs|data-visualization|webxr|canvas|graphics,5,"This repository is primarily a browser graphics framework/toolkit (3D via Three.js and 2D Canvas) intended to make interactive visualization scenes easier to build and manage. It is relevant to data science workflows mainly as a visualization layer for presenting or exploring data interactively (including WebGL performance tooling like instancing and high-quality text rendering), rather than for data processing, modeling, or training. Because it supports data visualization use cases but is not an ML/data pipeline library and is not a core ML framework, it merits an indirect-to-moderate relevance score.",success
https://github.com/zhp8341/flink-streaming-platform-web,flink-streaming-platform-web,"A lightweight, visual Apache Flink web client/platform that lets users create and manage real-time stream processing jobs via SQL in a browser. It provides job configuration and lifecycle controls (start/stop), SQL editing features (auto-complete/format/validation), logging, alerting, savepoints, and supports multiple deployment modes and Flink versions.",1900,apache-flink|stream-processing|data-engineering|real-time-analytics|sql|job-orchestration|web-platform,5,"This repository is primarily a web platform for authoring and operating Apache Flink streaming (and some batch) jobs through a SQL-centric UI, including deployments, monitoring/logs, alerts, and savepoint management. It is relevant to data workflows because Flink is commonly used to build real-time data pipelines and feature/metric streams that can feed ML systems, but it does not provide ML algorithms, training/inference tooling, or MLOps features directly. Its value to ML/data teams is mainly as infrastructure for streaming ETL and operational management rather than core ML development, so it earns a mid-range score.",success
https://github.com/jamubc/gemini-mcp-tool,gemini-mcp-tool,"A Model Context Protocol (MCP) server that lets AI assistants (e.g., Claude Code/Claude Desktop) invoke the Google Gemini CLI for large-file and whole-codebase analysis using Gemini’s large context window, including file/directory references via @-style paths and optional sandboxed execution.",1800,model-context-protocol|mcp-server|google-gemini|gemini-cli|claude|typescript|developer-tools|codebase-analysis,5,"This repository is primarily an integration/tooling project: it exposes Google Gemini CLI capabilities through an MCP server so other AI clients (notably Claude Code/Desktop) can delegate large-context analysis tasks and file/codebase understanding. It can support ML/data workflows indirectly by enabling LLM-assisted exploration of large datasets-as-files, notebooks, or codebases, but it is not a data processing/ML library and does not provide modeling, training, or evaluation components. The relatively strong adoption signals (notably ~1.8k GitHub stars) raise its practical utility for AI-assisted engineering, yet its value for core data science/ML tasks remains moderate rather than high.",success
https://github.com/teamclairvoyant/airflow-maintenance-dags,airflow-maintenance-dags,"A collection of Apache Airflow maintenance DAGs/workflows for operational housekeeping, such as metastore/database cleanup, log cleanup, configuration backups, removing missing/broken DAG entries, killing halted tasks, and generating SLA miss reports.",1800,apache-airflow|data-engineering|workflow-orchestration|devops|maintenance|python|data-pipelines,5,"This repository provides operational maintenance DAGs for Apache Airflow—primarily focused on reliability and hygiene tasks like cleaning the metastore, pruning logs, backing up configs, and reporting SLA misses. It is indirectly relevant to ML/data workflows because Airflow is commonly used to orchestrate data pipelines and MLOps jobs, and these DAGs can improve the stability and performance of those environments. However, it does not implement ML algorithms, feature engineering, model training, or dataset tooling directly, so its value is mainly infrastructural rather than core ML/data functionality.",success
https://github.com/andreaferretti/paths-js,paths-js,"Paths.js is a JavaScript library for generating SVG path data for geometric shapes and simple charts. It provides a functional, testable API with multiple abstraction levels (raw path building, shape primitives, and higher-level chart generators) and can be used in browsers or on Node.js.",1700,javascript|svg|svg-path|data-visualization|charting|geometry,5,"This repository focuses on generating SVG paths for shapes and chart primitives (e.g., pie, line, radar) rather than performing machine learning or data processing. It can be useful in ML/data workflows for building custom visualizations of model outputs, metrics, or exploratory plots, especially when you want full control over rendering in a frontend framework. However, it does not integrate with ML frameworks, provide statistical/ML functionality, or offer data pipeline features, so its relevance is indirect rather than core.",success
https://github.com/debezium/debezium-examples,debezium-examples,"A collection of runnable examples for Debezium change data capture (CDC), including connector configurations, Docker Compose setups, and platform templates (e.g., OpenShift) to stream database changes into messaging/streaming systems. The repo covers many end-to-end patterns such as outbox, monitoring, Kafka Streams/KSQL, and Debezium Server deployments.",1700,change-data-capture|data-engineering|apache-kafka|kafka-connect|docker-compose|streaming-data|debezium,5,"This repository primarily provides infrastructure and application examples for implementing CDC pipelines with Debezium (configs, Docker Compose environments, and deployment templates). It’s indirectly relevant to ML/data workflows because CDC and streaming integrations (Kafka/Kafka Connect, Debezium Server, etc.) are commonly used to feed feature stores, real-time analytics, and data platforms, but the repo’s main focus is not ML. It does include a couple of “machine-learning” examples (e.g., TensorFlow image classification and streaming k-means with Flink), which adds educational value, but ML is a small portion of the overall content, so a mid-range score is appropriate.",success
https://github.com/lf-edge/ekuiper,ekuiper,LF Edge eKuiper is a lightweight IoT data analytics and stream processing engine designed to run on resource-constrained edge devices. It provides an edge-side streaming framework with a rules engine that supports SQL-based (and graph-based) rules plus a pluggable Source/Function/Sink model for extensibility.,1700,stream-processing|iot|edge-computing|rules-engine|sql|golang|data-pipelines,5,"This repository implements an edge-focused stream processing and IoT analytics/rules engine (SQL/graph rules) intended for real-time data processing on constrained devices. It is not an ML framework, but it can be useful in ML/data workflows as upstream infrastructure for filtering/aggregating/transforming streaming sensor data and for invoking custom functions (including potential AI/ML calls) at the edge. The score reflects indirect but practical relevance for data engineering and edge analytics, with limited direct model training/inference tooling compared to dedicated ML platforms.",success
https://github.com/FrigadeHQ/trench,trench,"Trench is an open-source, self-hostable event tracking and real-time analytics infrastructure packaged as a production-ready Docker deployment. It is built on Kafka and ClickHouse, supports Segment-style APIs (Track/Group/Identify), and is intended as a foundation for product analytics dashboards, observability tooling, and related analytics products.",1600,analytics|event-tracking|clickhouse|kafka|real-time-analytics|data-infrastructure|docker,5,"This repository provides analytics/data infrastructure (event ingestion, storage, and querying) built on Kafka and ClickHouse, intended to power product analytics and other telemetry-driven platforms. It is not an ML library, but it is directly useful for ML/data workflows as a scalable source of event data (e.g., feature generation, behavioral analytics, and feeding downstream pipelines) and can support LLM/RAG-style analytics products via its event store and query layer. Community adoption appears solid for an infra project (about 1.6k GitHub stars), but its focus remains broader analytics infrastructure rather than ML-specific tooling, so it rates as indirectly relevant rather than core ML.",success
https://github.com/influxdata/chronograf,chronograf,"Chronograf is an open-source web application (Go backend + React UI) for monitoring and visualizing time-series data in InfluxDB, and for building dashboards and exploring data via query tools. It also provides a UI for creating and managing Kapacitor alerts/automation as part of the TICK stack.",1600,time-series|monitoring|observability|data-visualization|influxdb|dashboarding|devops,5,"This repository implements Chronograf, a monitoring and visualization UI for InfluxDB and related TICK stack components (including alerting via Kapacitor), focused on operational metrics and time-series exploration rather than ML model development. It can be indirectly useful in ML/data workflows for instrumenting experiments, tracking system/model-serving metrics, and building dashboards over time-series telemetry. However, it doesn’t provide ML algorithms, training utilities, or typical data-science libraries, so its value is mainly as supporting observability infrastructure rather than a core ML/data tool.",success
https://github.com/rodrigo-brito/ninjabot,ninjabot,"Ninjabot is a cryptocurrency trading bot framework written in Go that lets you implement custom trading strategies, run backtests on historical market data, and execute/live-simulate trades (including spot and futures, with Binance support). It also includes a CLI for downloading candle data and integrations like plotting and Telegram notifications.",1600,cryptocurrency|algorithmic-trading|trading-bot|backtesting|golang|binance|quant-finance,5,"This repository is primarily a Go framework for crypto algorithmic trading, focusing on strategy implementation, order execution, and backtesting over historical candle data, rather than ML model training. It can still be useful to data/ML practitioners as infrastructure for collecting market data, running reproducible backtests, and integrating quantitative signals (including ML-generated signals) into a trading workflow. However, it does not appear to provide built-in ML algorithms, feature engineering pipelines, or training/evaluation utilities typical of dedicated ML repositories, so its relevance is indirect rather than core.",success
https://github.com/mourner/flatbush,flatbush,"A very fast static spatial index for 2D points and rectangles in JavaScript, implementing a packed Hilbert R-tree. It enables efficient bounding-box and k-nearest-neighbor queries over very large datasets with a low-memory ArrayBuffer-based index representation.",1500,geospatial|spatial-indexing|r-tree|computational-geometry|javascript|data-structures|nearest-neighbor-search,5,"Flatbush is a high-performance JavaScript spatial indexing library (packed Hilbert R-tree) designed to speed up 2D range (bounding box) queries and k-nearest-neighbor searches on large sets of points/rectangles. While it is not an ML library, it can be directly useful in data/ML workflows that involve geospatial features, spatial joins, clustering pre-processing, or fast neighborhood lookups (e.g., feature engineering on location data). The value is moderate because its scope is narrow (2D spatial indexing) and it doesn’t integrate with ML frameworks directly, but it provides a core building block that can accelerate spatial data pipelines.",success
https://github.com/toluaina/pgsync,pgsync,"PGSync is a change data capture (CDC) tool that syncs data from PostgreSQL (and also MySQL/MariaDB) to Elasticsearch or OpenSearch in real time. You define the target document structure in JSON and PGSync handles denormalization, consistent ordering, and fault-tolerant syncing without custom ETL code.",1400,change-data-capture|postgresql|mysql|mariadb|elasticsearch|opensearch|data-engineering|search-infrastructure,5,"This repository provides a production-oriented CDC pipeline that streams changes from relational databases into Elasticsearch/OpenSearch, enabling fast search over denormalized documents while keeping the database as the system of record. It’s not an ML library, but it is directly useful in many ML/data workflows as a data-integration component (e.g., building searchable feature stores, retrieval layers for RAG, analytics/search indices, or operational data products). Community adoption appears solid (about 1.4k GitHub stars), but its primary focus is search/infrastructure rather than model training, evaluation, or MLOps—hence a mid-range score.",success
https://github.com/ib-api-reloaded/ib_async,ib_async,"A Python sync/async framework for the Interactive Brokers (IBKR) TWS/IB Gateway API that provides a modern, simpler interface than the callback-style native API and positions itself as a replacement for ib_insync. It supports asyncio-based workflows, market data/historical data access, and programmatic trading/portfolio tooling (including notebook-friendly usage).",1300,python|interactive-brokers|trading-api|algorithmic-trading|market-data|asyncio|quant-finance|jupyter,5,"This repository primarily provides an async-ready Python client/framework for interacting with Interactive Brokers (TWS/IB Gateway) to stream market data, request historical data, and place/monitor orders. It is not an ML library itself, but it can be a useful building block in ML/data workflows by enabling data collection (features/labels) and live integration for research or deployment of model-driven trading systems. The score is mid-range because its relevance to ML is indirect (data acquisition + execution plumbing) rather than providing modeling/analysis algorithms, though it can integrate well with notebooks and typical Python data stacks. Community adoption appears meaningful (about 1.3k GitHub stars), but it is niche to IBKR-based quant/trading use cases.",success
https://github.com/mining/mining,mining,"Open Mining is an archived (read-only) Python-based Business Intelligence (BI) application server focused on OLAP-style analytics. It includes services for running and scheduling cubes/queries and a web UI stack with dependencies like MongoDB, Redis, and Celery-oriented processes.",1300,business-intelligence|OLAP|data-analytics|python|application-server|data-warehouse|redis|mongodb,5,"This repository implements a BI/OLAP application server (""Business Intelligence (BI) in Python, OLAP"") intended for analytics dashboards and cube-style querying rather than machine learning model training. It can still be relevant to data workflows because OLAP, scheduling, and data-warehouse-adjacent infrastructure are commonly used around reporting and feature/metric exploration, but it does not provide ML algorithms, model training, or MLOps tooling. Additionally, it is archived (since June 2, 2021) and targets legacy components (e.g., Python 2.7), which reduces practical value for modern ML/data-science stacks despite its educational/architectural interest.",success
https://github.com/rwynn/monstache,monstache,"Monstache is a Go-based sync daemon that continuously indexes MongoDB collections into Elasticsearch in real time. It supports MongoDB change streams and direct reads for initial backfills, with options for transforms, filtering, and sharded-cluster aware operation.",1300,data engineering|ETL|MongoDB|Elasticsearch|change data capture|Go|realtime sync|search infrastructure,5,"This repository provides a production-oriented CDC/ETL-style pipeline that syncs operational MongoDB data into Elasticsearch for search, aggregations, and analytics-style querying. It’s not an ML library, but it can be an important enabling component in ML/data workflows by feeding searchable feature stores, logs, or datasets into Elasticsearch/OpenSearch for downstream analysis and monitoring. Community adoption appears solid (on the order of ~1.3k GitHub stars) and the tool integrates well into data platforms via Docker and configurable transforms, but it does not directly address model training, feature engineering frameworks, or MLOps lifecycle needs—hence a mid-range score.",success
https://github.com/Lumiwealth/lumibot,lumibot,"Lumibot is a Python library for building algorithmic trading bots with a unified workflow for both historical backtesting and live trading. It supports multiple asset classes (e.g., stocks, options, crypto, futures, forex) and is designed to help users create and test strategies efficiently before deploying them to trade.",1200,algorithmic-trading|backtesting|quantitative-finance|trading-bots|python|finance-data|crypto|stocks-options-futures-forex,5,"This repository primarily provides an algorithmic trading/backtesting framework rather than an ML-focused toolkit, centering on strategy development, historical simulation, and live execution across multiple markets. It can be useful in ML/data workflows indirectly (e.g., generating features, labels, and evaluation pipelines for predictive trading models, or integrating model outputs into trading strategies), but ML is not its core purpose. The moderate community adoption (as indicated by its star count) and educational value for quant/backtesting concepts justify a mid-range score rather than a high ML-specific rating.",success
https://github.com/kieran-mackle/AutoTrader,AutoTrader,"A Python-based platform for building automated trading systems, supporting strategy development across backtesting/paper trading, optimisation, and live trading. It includes a trading simulator (“virtual broker”), integrated market data feeds, custom indicators, and interactive visualisation (e.g., via Bokeh), with broker/exchange integrations such as Oanda and CCXT.",1200,algorithmic trading|quant finance|backtesting|paper trading|python|crypto|broker integration|data visualization,5,"This repository is primarily an algorithmic trading framework focused on building, testing, and deploying trading strategies (backtesting/paper trading and live trading), plus data retrieval and visualization. It can be useful in data workflows because it ingests market time-series data (e.g., OHLC), supports indicator calculation, and enables systematic experimentation/optimisation, but it is not an ML-first library (no core model training/evaluation framework is the main focus). Community adoption appears solid (notable stars/forks), and it offers educational value for quantitative strategy research, but ML integration would generally be something users add on top rather than a built-in central feature.",success
https://github.com/alpacahq/alpaca-py,alpaca-py,"The official Python SDK for Alpaca’s APIs, providing client libraries for trading, broker, and market data access over REST plus streaming via WebSocket/SSE. It includes typed request/response models (using Pydantic) and separate clients per API/asset class (e.g., stocks, crypto, options).",1100,python|fintech|algorithmic-trading|market-data|api-client|websockets|pydantic,5,"This repository is primarily a Python SDK for interacting with Alpaca’s trading, broker, and market data APIs (including streaming data), rather than an ML library. It can be directly useful in data/ML workflows as a data acquisition and live data streaming layer for research, feature generation, backtesting pipelines, and model-driven trading systems, but it does not provide modeling/training functionality itself. Community adoption appears solid for its niche (official SDK, ~1.1k GitHub stars), supporting moderate relevance for data science use cases but not core ML tooling.",success
https://github.com/autokitteh/autokitteh,autokitteh,"AutoKitteh is a developer platform for durable workflow automation and orchestration, positioned as a code-first alternative to no/low-code iPaaS tools. It lets you write workflows (primarily in Python) and runs them as reliable long-running executions with built-in integrations and API-first (gRPC/HTTP) interfaces.",1100,workflow-automation|orchestration|ipaas|temporal|python|devops|mlops|integrations,5,"This repository provides a durable workflow automation/orchestration platform (based on Temporal) intended to build and run long-running, reliable automations with many integrations and an API-first architecture. It is not an ML library, but it can support ML/data workflows indirectly by orchestrating data/ML jobs, schedules, triggers, and integrations (i.e., MLOps-style glue and automation). The score reflects solid indirect relevance and integration potential for ML teams, but limited direct ML functionality (no core modeling/training capabilities).",success
https://github.com/dbos-inc/dbos-transact-py,dbos-transact-py,"DBOS Transact for Python is an open-source library for building durable workflows and background queues backed by Postgres. It checkpoints workflow/step execution state so programs can automatically recover and resume after failures, without running a separate orchestration service.",1100,python|durable-workflows|workflow-orchestration|task-queues|postgresql|data-pipelines|reliability-engineering|observability,5,"This repository provides a Postgres-backed durable execution/workflow and queueing library for Python applications, focused on reliability (checkpointing and resuming work after crashes) and operational primitives like scheduling and background tasks. It is not an ML library, but it can be useful for ML/data workflows as infrastructure—e.g., running resilient data pipelines, long-running batch jobs, or AI-agent style workflows that call unreliable external APIs. Community adoption appears moderate (about 1.1k GitHub stars), suggesting some real-world use but not broad ML-community standardization. Because its value to ML/data is indirect (workflow/pipeline reliability rather than modeling), it merits a mid-range score.",success
https://github.com/garethdmm/gryphon,gryphon,"Gryphon is an open-source Python framework and application suite for building and running algorithmic cryptocurrency trading strategies across multiple exchanges. It includes a strategy execution engine, exchange abstractions, a market-data ingestion service, and dashboards for monitoring and visualization.",1100,algorithmic-trading|cryptocurrency|quant-trading|trading-strategies|market-data|python|exchange-integration|fintech,5,"This repository is primarily an algorithmic crypto trading framework (strategy engine + exchange integrations) rather than an ML library, but it includes infrastructure that is often adjacent to data/ML work (e.g., ingesting and persisting high-frequency market data). Its Gryphon Data Service is explicitly positioned to help build datasets that could be used for machine learning, which makes it indirectly useful for ML feature/data collection and backtesting workflows. However, it does not appear to focus on model training, ML evaluation, or integration with common ML frameworks as a core purpose, so its ML/data value is moderate rather than high.",success
https://github.com/piotrostr/listen,listen,"A Rust-based DeFi/DeFAI “Swiss Army Knife” that started as a Solana algorithmic trading toolkit and has evolved into a framework for AI-driven cross-chain portfolio management agents. It includes components for trading execution, data services (e.g., indexing and analytics), and agent tooling that can interact with on-chain systems.",1100,rust|solana|defi|algorithmic-trading|ai-agents|cross-chain|dex|blockchain-data,5,"This repository is primarily a DeFi trading/portfolio-management framework (with Solana and cross-chain integrations), including real-time monitoring, DEX swap execution, pricing/metrics, and a broader system architecture (engine + data service + agent kit). It has some ML-adjacent relevance because it explicitly targets “AI agents” (agent tooling and integrations) and provides data/analytics services that can feed decision-making. However, it is not an ML library or dataset-focused project (no core model training/inference focus), so its value to data science/ML workflows is mostly indirect—useful as an execution/data backbone for agentic trading systems rather than as a general-purpose ML tool.",success
https://github.com/santoshlite/EigenLedger,EigenLedger,"EigenLedger is a Python-based open-source quantitative investing and portfolio backtesting/analysis library. It provides a framework for portfolio management, performance and risk analytics, and portfolio optimization, acting as a wrapper around common finance libraries (e.g., QuantStats and PyPortfolioOpt).",1000,python|quantitative-finance|portfolio-backtesting|portfolio-optimization|portfolio-analysis|risk-analysis|fintech|investment-research,5,"EigenLedger’s primary purpose is quantitative finance: portfolio construction, backtesting, performance/risk analysis, and optimization, rather than general-purpose ML model training. It can still be useful in data-science workflows for financial data analysis and as a feature/metrics layer feeding ML models (e.g., factor research, strategy evaluation, benchmark comparisons). However, it is not a core ML framework and its community adoption appears centered on investing/backtesting use cases, so its ML/data value is moderate rather than high.",success
https://github.com/alpacahq/alpaca-backtrader-api,alpaca-backtrader-api,"A Python library that integrates the Alpaca Trading API with the Backtrader framework, enabling trading strategy development with both REST and streaming interfaces. It provides Backtrader-compatible store/broker/data components and example strategies for backtesting and (paper/live) trading.",678,python|algorithmic-trading|backtrader|alpaca-api|backtesting|quant-finance|trading-bot|stock-market-data,5,"This repository is primarily a trading integration layer that connects Alpaca’s brokerage/trading APIs to Backtrader so users can backtest strategies and run them in paper/live trading. It is indirectly relevant to ML/data workflows because it can be used to source market data and to operationalize signals from ML models inside a backtesting/trading loop, but it does not provide ML modeling, feature engineering, or training/evaluation tooling itself. Adoption is meaningful within the quant/backtrader community, yet its value for ML practitioners is mostly as infrastructure for strategy execution rather than a core ML/data science library. Therefore, it scores mid-range for ML/data usefulness (helpful for integrating data/strategies, but not an ML toolkit).",success
https://github.com/zvtvz/zvt-ccxt,zvt-ccxt,"A Python plugin that integrates the CCXT cryptocurrency exchange API library into the zvt framework, providing zvt-style domain objects and recorders to fetch and store crypto market metadata and OHLCV (kline) data from exchanges (e.g., Binance, Huobi).",11,cryptocurrency|quantitative-trading|ccxt|market-data|data-ingestion|python|zvt,5,"This repository is primarily a data ingestion/collection plugin for the zvt ecosystem that uses CCXT to pull cryptocurrency market metadata and historical price (OHLCV) data from exchanges and expose it through zvt domain/recorder abstractions. It is not an ML library, but it can be directly useful in ML/data science workflows by supplying standardized crypto datasets for downstream feature engineering, backtesting, and modeling. Community adoption appears modest (low star count), so its impact is more niche and ecosystem-specific rather than broadly used across ML. Given its clear utility for building datasets but lack of ML-specific modeling/training components, a mid-range score is appropriate.",success
https://github.com/avelino/awesome-go,awesome-go,"A community-maintained, curated “awesome list” of Go (Golang) frameworks, libraries, and software, organized by category to help developers discover Go tooling and ecosystems quickly.",162000,golang|awesome-list|curated-resources|go-libraries|software-development|web-development|developer-tools,4,"This repository is primarily a curated index of Go frameworks, libraries, and software rather than an ML/data library itself. It includes sections relevant to ML/data workflows (e.g., Machine Learning, Natural Language Processing, and Science and Data Analysis), which can help practitioners discover Go-based data tooling. However, its direct applicability is indirect (it points to tools instead of providing them), so its value for ML/data work is moderate rather than high despite strong community adoption.",success
https://github.com/ripienaar/free-for-dev,free-for-dev,"A community-maintained list of SaaS, PaaS, IaaS, and other online services that offer free tiers useful to developers (especially DevOps/infrastructure-focused use cases). It curates free-tier limits across many categories (e.g., cloud, CI/CD, monitoring, APIs) and is updated via pull requests.",117000,awesome-list|free-tier|developer-resources|devops|cloud-services|saas|paas|iaas,4,"This repository primarily curates and organizes free-tier offerings across a wide range of developer and infrastructure services, rather than providing an ML library or dataset. It has indirect relevance to ML/data workflows because it includes categories like analytics and ""APIs, Data and ML,"" which can help data teams find low-cost tools and hosting/services for experimentation. Its very large community adoption (high star count and ongoing contributions) increases its practical value as a reference, but it is not a direct ML/data tooling implementation—hence a moderate, indirect score.",success
https://github.com/photoprism/photoprism,photoprism,"PhotoPrism is a self-hosted, privacy-focused photo management app that automatically organizes, tags, and helps you search your photo library using AI (including content-based labels and face recognition). It runs locally or on private servers/cloud (commonly via Docker) and provides a web/PWA interface for browsing, search, maps, and metadata handling.",39100,self-hosted|photo-management|computer-vision|image-search|face-recognition|golang|docker|pwa,4,"This repository is primarily an end-user application for organizing and searching personal photo libraries (automatic labeling, face recognition, and metadata/geolocation features), rather than a general-purpose ML framework. It is indirectly relevant to ML/data workflows because it applies computer vision models and can be studied for practical ML-in-production patterns (indexing, labeling pipelines, deployment), but it is not designed as a reusable data-science library for model training or experimentation. Community adoption is strong as a self-hosted photo app, yet its direct applicability to typical ML engineer workflows is limited, so it fits best in the “indirect relevance” range.",success
https://github.com/gto76/python-cheatsheet,python-cheatsheet,"A comprehensive Python cheatsheet repository that serves as a large, structured reference of Python syntax, core types, standard-library utilities, and practical snippets. It also includes a rendered web version of the cheatsheet and related assets (e.g., web/ and pdf/ folders).",38100,python|cheatsheet|reference|programming-language|tutorial|standard-library|documentation,4,"This repository is primarily an educational/reference cheatsheet for the Python language and its ecosystem, offering many short examples across collections, types, syntax, system tasks, and selected libraries (including some data-oriented ones like NumPy and Pandas). It can be useful to data scientists as a general Python refresher and quick lookup, but it is not an ML/data-specific library, dataset, pipeline, or tooling package. Because its value to ML/data workflows is indirect (general Python proficiency plus a few data-related sections) and it is not designed as an ML-focused tool, it merits a moderate-low score rather than a core ML/data score.",success
https://github.com/docker/compose,compose,"Docker Compose is a tool for defining and running multi-container applications with Docker using the Compose file format (e.g., compose.yaml). It provides a CLI workflow (e.g., `docker compose up`) to build, start, stop, and manage related services together.",36800,Docker|Docker Compose|container orchestration|DevOps|CLI|Go|microservices,4,"This repository implements Docker Compose, a developer/DevOps tool for defining and running multi-container applications via a Compose YAML specification and a CLI (`docker compose`). It is not an ML/data library, but it is commonly used to stand up reproducible local environments for data/ML work (e.g., databases, message queues, experiment trackers, model servers) and for integration testing. The strong ecosystem adoption and workflow integration make it indirectly valuable for ML/data teams, but its primary purpose is general containerized application orchestration rather than data science or machine learning.",success
https://github.com/directus/directus,directus,"Directus is a flexible backend that turns any SQL database into a real-time platform with instant REST and GraphQL APIs, authentication, and an admin app/dashboard (headless CMS-style) for managing content and building apps.",33900,headless-cms|backend|api|graphql|rest|nodejs|sql-database,4,"This repository provides a Node.js-based backend layer and admin app that sits on top of SQL databases, exposing data through instant REST and GraphQL APIs and a no-code dashboard. While it is not an ML library, it can be useful in data/ML workflows as a data access and management layer (e.g., curating datasets, labeling/metadata management, exposing features via APIs, or powering internal tools). Its relevance is indirect: valuable infrastructure for data-centric applications, but it does not offer model training, inference, or core data-science algorithms, so it scores mid-low on ML/data specificity.",success
https://github.com/TheAlgorithms/C-Plus-Plus,TheAlgorithms/C-Plus-Plus,"A large, educational collection of algorithms and data structure implementations in C++ across many topics (e.g., graphs, dynamic programming, math, numerical methods), with documentation and CI-backed testing. It aims to serve as a learning resource and reference implementation set, generally using standard C++/STL without external dependencies.",33700,c++|algorithms|data-structures|competitive-programming|education|machine-learning (examples)|numerical-methods,4,"This repository’s primary purpose is to provide educational C++ implementations of general algorithms and data structures, organized by topic and intended for learning and reference. It includes some ML/data-science-adjacent material (e.g., a machine_learning folder and broad coverage of math/statistics/numerical methods), but it is not an ML framework, data pipeline tool, or library designed to plug directly into typical ML workflows. Its value for ML/data practitioners is mainly foundational/educational (understanding core algorithms) rather than operational integration, which justifies a below-moderate score.",success
https://github.com/bayandin/awesome-awesomeness,awesome-awesomeness,"A large curated “awesome list of awesome lists” that aggregates links to many topic-focused awesome lists across programming languages, tools, and general tech categories, serving as a directory for discovering high-quality resources.",33100,awesome-list|curated-resources|software-development|programming-languages|developer-tools|resource-collection,4,"This repository is primarily a meta-index of curated links (“awesome lists”) spanning many software and technology topics, rather than a library, dataset, or executable ML tool. It can still be useful to ML/data practitioners as a discovery hub because it includes categories like artificial intelligence and big data and points to specialized lists and learning/resources. However, it does not directly provide ML code, data processing utilities, or integrations, and its value depends on the external lists it links to—so its relevance is indirect rather than core.",success
https://github.com/ashishps1/awesome-system-design-resources,awesome-system-design-resources,"A curated collection of free resources for learning system design and distributed systems concepts, with structured links to core topics and common system design interview problems (plus diagrams and example implementations).",28900,system design|distributed systems|software architecture|interview preparation|scalability|networking|databases,4,"This repository is primarily an educational, curated list for system design and distributed systems interview preparation rather than an ML or data-science codebase. It is indirectly relevant to ML/data workflows because many ML systems depend on the same infrastructure concepts (scalability, caching, databases, messaging, microservices) covered here. However, it does not provide ML algorithms, datasets, model training utilities, or MLOps tooling directly, so its value is mainly foundational and architectural rather than hands-on ML.",success
https://github.com/rancher/rancher,rancher,Rancher is an open source container management platform that helps organizations run and manage Kubernetes clusters across on-prem and cloud environments. This repository contains the main Rancher 2.x codebase (a meta-repo used for packaging) along with installation and release information.,25000,kubernetes|container-management|DevOps|cloud-native|cluster-management|platform-engineering|Go,4,"This repository is primarily a Kubernetes/container management platform (Rancher 2.x) used to provision and manage clusters and related operational workflows, not a machine learning or data science library. It can be indirectly valuable to ML/data teams because it provides the infrastructure layer commonly used to run ML workloads (e.g., training/inference services on Kubernetes) and can support operational needs like multi-cluster management and governance. However, it does not provide core ML/data functionality (training, feature engineering, pipelines, model evaluation) and is generally used by platform/DevOps engineers rather than ML practitioners directly, so the relevance is moderate/indirect rather than central.",success
https://github.com/amark/gun,gun,"GUN is an open-source protocol and JavaScript library for syncing decentralized, realtime graph data across peers, enabling local-first and offline-capable apps. It supports end-to-end encryption and is often positioned as an open-source alternative to Firebase for peer-to-peer data synchronization.",18800,decentralized-database|graph-database|p2p|realtime-sync|offline-first|end-to-end-encryption|javascript|cybersecurity,4,"This repository provides a decentralized, realtime graph-data synchronization protocol/library (with local-first and end-to-end encryption), primarily aimed at building distributed applications rather than ML. It can be indirectly relevant to ML/data workflows as an application data layer (e.g., collecting/syncing event streams or collaborative annotations) and for experimentation with distributed data syncing. However, it is not a data science/ML framework, does not provide ML-specific primitives, and is not primarily adopted for model training, evaluation, or MLOps—hence a modest indirect-relevance score.",success
https://github.com/RunaCapital/awesome-oss-alternatives,awesome-oss-alternatives,"A curated “awesome list” of open-source startup products positioned as alternatives to well-known SaaS tools, organized by category. The repository includes contributor guidelines and scripts to help maintain/build the README and the accompanying website/docs.",18600,awesome-list|open-source|SaaS-alternatives|developer-tools|DevOps|startup-landscape|self-hosted|software-catalog,4,"This repository is primarily a curated catalog of open-source business software alternatives (an “awesome list”), not an ML/data library or framework. It can still be useful for ML/data practitioners indirectly by helping them discover open-source infrastructure commonly used in data/ML stacks (e.g., observability, databases, workflow tools) and by providing a structured way to compare options. However, it offers little in terms of ML algorithms, datasets, training code, or direct ML workflow integration, so its value for ML/data work is moderate-to-low.",success
https://github.com/usestrix/strix,strix,"Strix is an open-source, agentic penetration-testing tool that uses autonomous AI “hacker” agents to dynamically test applications and codebases, validate findings with real proof-of-concepts, and produce actionable security reports. It includes a developer-first CLI and supports CI/CD (including GitHub Actions) to run security scans on pull requests and block insecure changes.",18600,application-security|penetration-testing|ai-agents|cybersecurity|devsecops|cli|python|github-actions,4,"This repository is primarily an agentic security (pentesting) system: it orchestrates autonomous AI agents to run dynamic tests, identify vulnerabilities, and validate them via PoCs, with workflows geared toward developers and security teams. It relates to ML only indirectly because it depends on LLM providers and agent orchestration rather than providing ML models, datasets, or training/evaluation tooling. It can be useful to ML engineers mainly as a practical example of LLM-agent application design and automation in pipelines, but it is not a core data-science/ML library, hence a below-mid relevance score.",success
https://github.com/ActivityWatch/activitywatch,activitywatch,"ActivityWatch is a free, open-source, privacy-focused automated time tracker that records application/window activity, browser activity, and AFK status locally. This repository is a meta-repo bundling ActivityWatch’s core components (server, web UI, watchers, and client libraries) to simplify installation, packaging, and full-suite releases.",16400,time-tracking|productivity|quantified-self|privacy|python|rust|event-logging|data-visualization,4,"This repository primarily provides an automated time-tracking system that collects and stores personal activity events (apps, window titles, browser tabs, AFK) and offers a REST API plus a web UI to query and visualize the data. While it is not an ML library, the locally stored event/time-series data and query/export capabilities can be useful for data science workflows (e.g., personal analytics, feature engineering on behavioral logs, building productivity models). The score is moderate because its main goal is quantified-self/time tracking rather than model training/MLOps, but it can serve as a practical real-world data source and logging platform for analysis.",success
https://github.com/Fission-AI/OpenSpec,OpenSpec,"OpenSpec is a spec-driven development workflow and CLI for working with AI coding assistants, helping humans and assistants agree on requirements (specs, proposals, tasks) before code is written. It provides a structured change/proposal system and integrations (e.g., slash commands/agent instructions) across multiple AI coding tools, without requiring API keys.",16000,ai coding assistants|developer tooling|spec-driven development|requirements management|CLI|TypeScript|software engineering workflow,4,"OpenSpec is primarily a software-engineering workflow tool (spec-driven development) and a Node.js/TypeScript CLI that structures how developers collaborate with AI coding assistants via specs, proposals, and tasks. It is adjacent to ML in that it improves reliability and governance of AI-assisted coding, but it is not a library for model training, inference, data processing, or MLOps pipelines. Data scientists/ML engineers might adopt it to manage AI-assisted development in ML codebases, yet it provides limited direct ML/data workflow functionality and its value is mostly process/tooling rather than ML-specific capability.",success
https://github.com/apitable/apitable,apitable,"APITable is an API-oriented, open-source low-code platform (Airtable alternative) for building collaborative apps on top of a spreadsheet-like database UI. It supports real-time collaboration, a REST-style full-stack API (data + metadata), extensibility via widgets/plugins, and self-hosting via Docker/Docker Compose.",15200,low-code|collaborative-apps|airtable-alternative|api|typescript|nestjs|nextjs|self-hosted,4,"This repository is primarily a low-code collaborative database/spreadsheet platform (Airtable-style) with strong API access and self-hosting support, aimed at building internal tools and collaborative apps rather than ML. It can be indirectly useful in data workflows as a data entry, labeling, lightweight data management, or operational data hub via its APIs and integrations, but it does not provide ML modeling, training, or core data-science libraries. The community adoption appears strong (15.2k GitHub stars), supporting moderate relevance for data-centric product workflows but not specifically ML engineering.",success
https://github.com/botpress/botpress,botpress,"Botpress is an open-source hub for building and deploying GPT/LLM-powered agents and chatbots, centered around Botpress Cloud tooling. This monorepo includes official integrations, developer tools (CLI/SDK/API client), and example bots built “as code.”",14500,LLM agents|chatbots|conversational AI|TypeScript|Node.js|SDK|integrations,4,"This repository primarily provides an agent/chatbot platform ecosystem (integrations + developer tools like the CLI/SDK) for building and deploying GPT/LLM-based assistants, rather than implementing ML model training or data pipelines. It can be useful to ML/LLM practitioners for integrating LLMs into applications, orchestrating tool use, and shipping agent experiences, but it’s not a core data-science library (e.g., no focus on model development, evaluation suites, or dataset tooling). Given its indirect-but-practical relevance for deploying LLM capabilities in products and workflows, it scores as moderately applicable but not central to ML/data engineering.",success
https://github.com/terkelg/awesome-creative-coding,awesome-creative-coding,"A curated “awesome list” of creative coding resources—books, courses, tools/frameworks, learning materials, communities, math references, and inspiration—aimed primarily at beginner to intermediate practitioners in generative art, interaction design, and data visualization.",14300,creative coding|generative art|data visualization|computer graphics|interactive design|webgl|learning resources,4,"This repository is primarily a curated index of creative coding resources (tools, books, courses, and references) focused on generative art, interaction, and visualization rather than an ML library or dataset. It includes some ML-adjacent content (e.g., a dedicated “Machine learning • Computer Vision • AI” section and related creative-ML resources), which can be useful for discovery and education. However, it does not provide ML code, data pipelines, or direct integration with common ML workflows, so its practical value for day-to-day data science is limited, resulting in a below-mid score.",success
https://github.com/markets/awesome-ruby,awesome-ruby,"A categorized, community-maintained “awesome list” of Ruby libraries, tools, frameworks, and software, curated to help developers find reliable Ruby ecosystem resources. It includes sections spanning web development, DevOps, testing, data/ETL, visualization, and more.",14000,ruby|awesome-list|developer-tools|ruby-libraries|web-development|data-processing|machine-learning,4,"This repository is primarily a curated directory of Ruby ecosystem resources rather than an ML/data library itself. It does include categories relevant to data workflows (e.g., Data Processing and ETL, Data Visualization, Machine Learning, NLP, Scientific), which can help practitioners discover tools and learning resources. However, it does not provide direct ML functionality, datasets, or a runnable ML framework—its value is indirect and depends on what linked tools you choose.",success
https://github.com/donnemartin/awesome-aws,awesome-aws,"A curated “awesome list” of Amazon Web Services (AWS) libraries, open-source repositories, guides, blogs, and other AWS-related resources, organized by service/category. It also includes a “Fiery Meter of AWSome” concept and a companion Python module that scans listed repos to help keep star-based rankings accurate.",13900,AWS|cloud|DevOps|infrastructure|serverless|curated-list|cloud-native,4,"This repository is primarily an AWS resource directory (an ""awesome list"") that catalogs tools, SDKs, and learning materials across many AWS services. It is indirectly relevant to ML/data workflows because AWS is commonly used to host data platforms and ML stacks (e.g., S3, EMR, Redshift, Kinesis, SageMaker/ML-related resources), and the list includes categories like analytics/data and machine learning resources. However, it is not itself an ML/data library, dataset, or pipeline framework—it's a curated index—so its direct applicability is moderate rather than high, warranting a 4/10.",success
https://github.com/halfrost/Halfrost-Field,Halfrost-Field,"A personal knowledge-base/blog repository (primarily in Chinese) collecting long-form technical articles and deep dives on topics like Go, iOS, JavaScript, and machine learning notes (e.g., Andrew Ng’s ML course). It serves as the content source for Halfrost’s blog/site and is continuously updated with study notes and framework/source-code analysis.",13300,technical-blog|software-engineering-notes|golang|machine-learning-notes|javascript|ios|computer-science,4,"This repository is mainly a curated collection of technical writings and learning notes that back a personal blog, rather than an ML library or data tooling. It includes a substantial 'Machine Learning' section (notes covering classic ML topics such as regression, SVMs, clustering, dimensionality reduction, etc.), which can be educational for ML learners but does not provide reusable ML code, datasets, pipelines, or MLOps components. Community adoption (stars) is strong, but its primary value for ML/data workflows is indirect and educational, so it scores as moderately relevant rather than a practical ML/data tool.",success
https://github.com/provectus/kafka-ui,kafka-ui,"UI for Apache Kafka is an open-source web application for monitoring and managing Apache Kafka clusters. It provides multi-cluster management, metrics dashboards, topic/consumer group views, message browsing/producing, schema registry support, RBAC/auth options, and extensibility via SerDe/plugins.",11800,apache kafka|data engineering|streaming|observability|devops|web ui|java|spring boot,4,"This repository is primarily a web UI for operating Apache Kafka clusters (monitoring brokers/topics/consumer groups, browsing/producing messages, viewing metrics, managing configs, and integrating with schema registry and auth/RBAC). While it is not an ML library, Kafka is commonly used in data/ML pipelines for streaming ingestion and operational troubleshooting, so this tool can be valuable indirectly for ML/data teams running Kafka-based platforms. The score reflects strong relevance to data infrastructure/operations, but limited direct functionality for modeling, training, or analytics.",success
https://github.com/TheR1D/shell_gpt,shell_gpt,"ShellGPT is a cross-platform command-line tool that uses large language models (by default via OpenAI’s API, e.g., GPT-4) to generate shell commands, code snippets, documentation, and general answers directly from the terminal. It supports piping/redirecting stdin and can be used to analyze inputs like diffs or logs and produce actionable output.",11600,LLM|command-line tool|developer productivity|shell commands|OpenAI API|Python|DevOps,4,"This repository provides a CLI wrapper around LLMs to help users generate commands and text (including analyzing terminal inputs like logs or git diffs) to speed up developer workflows. It is not an ML/data library itself (no model training, data processing framework, or ML algorithms), but it can be useful in data workflows as a general-purpose assistant for tasks like quick analysis, scripting help, and generating snippets for data tooling. The project’s popularity and LLM integration make it moderately relevant as a productivity aid for data scientists/ML engineers, but its primary purpose is general CLI assistance rather than data/ML functionality.",success
https://github.com/GreyDGL/PentestGPT,PentestGPT,"PentestGPT is an AI-powered autonomous penetration testing agentic framework that uses large language models to plan and execute pentesting/CTF-style workflows, with a Docker-first setup and an interactive TUI for running against targets. It supports session persistence, live step-by-step walkthrough/feedback, and multiple security challenge categories (e.g., web, reversing, forensics, pwn, privilege escalation).",10900,cybersecurity|penetration testing|LLM agents|autonomous agents|CTF|Python|Docker,4,"This repository’s primary purpose is cybersecurity automation: an agentic penetration-testing assistant that orchestrates tools and workflows using LLMs, packaged in a Docker-first environment with a CLI/TUI. It is related to ML mainly as an application layer that integrates and routes requests to LLM providers (and even local OpenAI-compatible servers), rather than providing datasets, model training code, or novel ML methods. Data scientists/ML engineers could reuse it as an example of LLM-agent architecture and evaluation/benchmark harness patterns, but it is not directly a data/ML workflow tool, so a below-mid relevance score is appropriate.",success
https://github.com/PipedreamHQ/pipedream,pipedream,"Pipedream is a developer-focused integration and automation platform for building event-driven workflows that connect APIs and services. This repository contains the open-source integration components (sources/triggers and actions), along with related platform code and documentation used to build and run Pipedream workflows.",10900,workflow-automation|api-integrations|serverless|event-driven-architecture|developer-tools|nodejs|python,4,"This repository primarily powers Pipedream’s integration components and workflow automation platform (event sources/triggers, actions, and supporting docs/code). It’s not an ML library, but it can be useful in ML/data workflows as glue infrastructure for moving data between SaaS tools, triggering pipelines, calling model APIs, and shipping results to destinations (e.g., warehouses or storage). Community adoption appears strong (notably high GitHub stars), but the value is mostly indirect for data science compared with dedicated data/ML pipeline or MLOps frameworks, so a mid-low score is appropriate.",success
https://github.com/rybbit-io/rybbit,rybbit,"Rybbit is an open-source, privacy-friendly web and product analytics platform positioned as an alternative to Google Analytics. It provides cookieless analytics plus features like real-time dashboards, advanced filtering, goals/funnels/journeys/retention, and session replays, with support for self-hosting or a hosted service.",10700,web-analytics|product-analytics|privacy|self-hosted|clickhouse|session-replay|dashboarding|open-source,4,"This repository primarily implements a web/product analytics platform (data collection, storage, and interactive dashboards) rather than ML modeling or training. It can be useful in data workflows as an event/behavioral data source and analytics backend (e.g., producing datasets for downstream analysis), but it is not an ML framework, feature engineering library, or MLOps tool. Community interest appears strong (10.7k GitHub stars), which increases its practical relevance, yet its direct ML applicability remains indirect—hence a mid-low score.",success
https://github.com/askmike/gekko,gekko,Gekko is a Bitcoin technical-analysis (TA) trading and backtesting platform written in JavaScript/Node.js that connects to cryptocurrency exchanges and lets users run automated trading strategies and historical backtests. The repository is archived (read-only) and explicitly not maintained anymore.,10200,cryptocurrency|bitcoin|algorithmic-trading|trading-bot|backtesting|technical-analysis|nodejs|javascript,4,"This repository primarily provides an automated crypto trading and backtesting system (strategy execution, exchange connectivity, and historical evaluation), rather than an ML library. It can still be useful in ML/data workflows as infrastructure for generating labeled market/strategy performance data, running experiments over historical price series, and evaluating rule-based strategies (and potentially ML-driven signals if integrated). However, it is archived and unmaintained, and it does not natively focus on model training, feature engineering pipelines, or modern ML integrations, which limits its direct applicability and adoption for ML-specific work.",success
https://github.com/EvanLi/Github-Ranking,Github-Ranking,"Automatically updated (daily) GitHub repository ranking lists based on stars and forks, including Top 100 lists overall and by programming language. It also publishes the rankings as a browsable website via GitHub Pages.",10000,github|analytics|ranking|open-source|data-collection|static-site|python,4,"This repository’s primary purpose is to collect and publish GitHub stars/forks ranking lists (overall and by language) and keep them automatically updated daily. It is data-related in the sense that it builds and maintains a dataset/leaderboard and could be useful for lightweight trend/OSS ecosystem analysis or as a data source for research. However, it is not an ML library, does not provide model training/inference functionality, and its direct applicability to ML workflows is mostly indirect (as an input dataset or monitoring signal), so it scores in the indirect relevance range.",success
https://github.com/aws-amplify/amplify-js,aws-amplify/amplify-js,"AWS Amplify JavaScript is a declarative JS/TS client library for building cloud-enabled web and React Native apps, providing higher-level APIs for auth, API (REST/GraphQL), storage, analytics, push notifications, and more (primarily backed by AWS services). It’s organized as a monorepo of packages published to npm (e.g., `aws-amplify`).",9600,javascript|typescript|aws|cloud-sdk|frontend|react-native|authentication|graphql,4,"This repository primarily provides a frontend/mobile developer SDK that simplifies integrating apps with AWS-backed cloud capabilities like authentication, GraphQL/REST APIs, storage, analytics, and notifications. It is not an ML framework or data-processing library, but it has indirect relevance to ML/data workflows via features such as the Amplify Predictions category (integrations with AWS AI/ML services like Comprehend, Rekognition, Polly, Textract, and Translate) and by enabling apps to consume ML-powered backends. The score reflects that it can be useful for ML-enabled application integration, but it is not a core tool for model training, data engineering, or MLOps.",success
https://github.com/hyperdxio/hyperdx,hyperdx,"HyperDX is an open-source observability platform (part of ClickStack) for searching, correlating, and visualizing production telemetry—logs, traces, metrics, errors, and session replays—backed by ClickHouse and OpenTelemetry. It provides a UI and deployment options (including an all-in-one Docker image) to help engineers debug incidents quickly.",9200,observability|logging|distributed-tracing|apm|clickhouse|opentelemetry|devops|typescript,4,"This repository is primarily an observability/monitoring platform for engineering teams, focusing on collecting and exploring operational telemetry (logs, traces, metrics, errors, and session replays) on ClickHouse with OpenTelemetry support. It can be indirectly useful in ML/data workflows when teams need robust logging/metrics for data pipelines or ML services in production, but it is not designed for model training, feature engineering, experimentation, or MLOps-specific tasks. The score reflects its relevance as general data/telemetry infrastructure rather than a direct ML/data science tool, despite strong applicability to production analytics and debugging.",success
https://github.com/xonsh/xonsh,xonsh,"Xonsh is a Python-powered, full-featured, cross-platform command shell whose language is a superset of Python with additional shell primitives, enabling seamless mixing of Python code with traditional shell commands and pipelines.",9200,command-line shell|python|developer tools|terminal|scripting|cross-platform|plugins,4,"This repository implements Xonsh, a Python-based shell that lets users interleave Python expressions with shell commands, making it a productivity and automation tool rather than an ML library. It can be useful in data/ML workflows for orchestrating experiments, running pipelines, and performing lightweight data manipulation directly in the shell (including convenient imports like JSON and optional integrations/plugins). However, it is not focused on ML algorithms, model training, data engineering at scale, or MLOps features, so its value to ML/data work is indirect and primarily as an enhanced scripting/automation environment.",success
https://github.com/StockSharp/StockSharp,StockSharp,"StockSharp (S#) is an open-source algorithmic/quantitative trading platform and C# library for building trading robots and applications. It provides connectors to many brokers/exchanges (including crypto), plus tooling for strategy design and market-data collection/storage (e.g., Hydra).",9000,algorithmic trading|quantitative finance|trading bots|market data|.NET|C#|crypto exchanges,4,"This repository’s primary purpose is algorithmic trading: building trading strategies/robots and connecting to many exchanges/brokers, along with collecting and exporting market data. It can be useful for data science workflows because it helps acquire, normalize, store, and export financial time-series data and can support research/backtesting setups, but it is not an ML framework and does not center on model training/evaluation. Community adoption appears strong within trading tooling (not specifically ML), so it earns an indirect-relevance score rather than a core ML/data score.",success
https://github.com/evilsocket/pwnagotchi,pwnagotchi,"Pwnagotchi is a Raspberry Pi-focused WiFi auditing/pentesting companion that integrates bettercap and uses deep reinforcement learning (A2C) to adapt its behavior over time to capture WPA handshake/PMKID material more effectively, saving results as PCAPs compatible with tools like hashcat.",8900,wireless-security|wifi|pentesting|bettercap|raspberry-pi|deep-reinforcement-learning|python,4,"This repository’s primary purpose is WiFi security automation (capturing WPA handshakes/PMKIDs via bettercap) on embedded hardware, not data science. It does include a real ML component (deep reinforcement learning with an A2C agent using an LSTM/MLP policy network) and can be educational for understanding applied RL in a non-simulated environment, but it is not a general ML framework nor a typical data/ML workflow dependency. Community adoption appears strongest in the security/hardware hobbyist space rather than the ML/data community, so its ML value is indirect and niche, leading to a score of 4/10.",success
https://github.com/redis/RedisInsight,RedisInsight,"Redis Insight is Redis’s official desktop GUI (Electron/Node.js) for connecting to Redis databases and interacting with data via browsing, CRUD operations, workbench/CLI tooling, profiling, SlowLog analysis, and module-aware features (e.g., RedisJSON, Search/Query, and Time Series). It also supports extensibility via plugins for custom data visualizations.",8000,redis|database-gui|developer-tools|electron|nodejs|typescript|data-visualization|vector-search,4,"This repository contains the source code for Redis Insight, a GUI application for exploring and managing Redis data, running commands, analyzing performance (Profiler/SlowLog), and working with Redis modules. It is not an ML library, but it can support ML/data workflows indirectly because Redis is frequently used as infrastructure for feature stores, caching, and vector similarity search, and the UI explicitly mentions vector similarity search use cases. The score is moderate (4/10) because its primary value is database administration/developer productivity rather than data science algorithms or model training, though it can be a helpful companion tool when Redis is part of a data/AI stack.",success
https://github.com/jagenjo/litegraph.js,litegraph.js,"LiteGraph.js is a JavaScript graph/node engine plus an in-browser visual editor (HTML5 Canvas2D) for building and running node-based graphs similar to Unreal/UDK Blueprints. Graphs can run in the browser or in Node.js, and can be exported as JSON for integration into other applications.",7800,visual programming|node editor|graph editor|javascript|html5 canvas|workflow builder|ui library,4,"This repository provides a general-purpose node-graph engine and a visual node editor for constructing executable graphs in JavaScript (browser/Node.js) and exporting them as JSON. It can support ML/data workflows indirectly (e.g., building visual workflow UIs, pipeline-like graphs, or front-ends for ML tools), but it is not an ML framework, data-processing library, or MLOps tool by itself. Community adoption appears strong for a UI/graph library (thousands of GitHub stars), yet its primary value is in UI/visual workflow construction rather than data science functionality, so it scores as indirectly relevant.",success
https://github.com/timercrack/trader,trader,"A Python-based trading module (交易模块) for quantitative trading workflows, with dependencies such as TA-Lib and MySQL configuration guidance. The repository is oriented around algorithmic/quant trading (stocks, futures) and related infrastructure/components.",7600,algorithmic-trading|quant-finance|python|stocks|futures|technical-analysis|ctp,4,"This repository’s primary purpose is building a trading component for quantitative trading (stocks/futures), rather than providing general-purpose machine learning models or training pipelines. It can be relevant to data/ML workflows indirectly because quant trading systems often ingest market data and may incorporate feature engineering/technical indicators (e.g., via TA-Lib) and data storage (e.g., MySQL). However, based on the repository’s stated focus/topics, it appears more like a trading execution/infrastructure module than an ML-focused library, which limits its direct applicability for typical ML engineering tasks.",success
https://github.com/firerpa/lamda,lamda,"FIRERPA LAMDA is an Android RPA (robotic process automation) agent framework for building mobile automation robots, offering remote device control plus a large set of programmable automation APIs and a Python SDK designed for AI-integrated workflows on rooted Android devices.",7500,android|rpa|mobile-automation|python-sdk|remote-control|adb|mobile-security|reverse-engineering,4,"This repository primarily provides an Android automation/RPA agent framework (with remote control and a Python SDK) aimed at automating tasks and controlling Android devices, including security-analysis-related use cases. It can be useful in ML/data workflows indirectly as a data-collection/automation layer (e.g., automating apps to gather mobile interaction data or drive agentic testing scenarios), but it is not itself an ML framework, model training library, or core data-processing toolkit. Community adoption appears meaningful (thousands of GitHub stars), which raises its practical relevance, but its main value remains in automation infrastructure rather than ML methods—hence a moderate, indirect ML/data score.",success
https://github.com/MycroftAI/mycroft-core,mycroft-core,"Mycroft Core is the main runtime for the Mycroft open-source voice assistant, providing the core services (message bus, skills framework, audio pipeline, and related components) used to run and interact with the assistant. The repository is archived and explicitly marked as no longer actively maintained, with successors recommended by the maintainers.",6600,voice assistant|speech recognition|NLP|Python|conversational AI|IoT|skills framework|open source,4,"This repository implements the core platform for an open-source voice assistant (service orchestration, skill execution, and voice/interaction plumbing), rather than an ML library or dataset. It can be relevant to ML practitioners working on speech/NLP integrations (e.g., swapping STT/TTS backends, building conversational pipelines, prototyping voice UX), but it is not primarily a model-training or data-science workflow tool. Community adoption exists historically (thousands of stars), but the repo is archived (Sep 8, 2024) and no longer actively maintained, which reduces its practical value for current ML/data work.",success
https://github.com/aliasrobotics/cai,cai,"Cybersecurity AI (CAI) is a lightweight, open-source framework for building AI agents that assist with offensive and defensive security automation (e.g., vulnerability discovery, exploitation, reconnaissance, and assessment). It provides an agent-based architecture, integrated security tools, multi-LLM support (via LiteLLM), and safety guardrails against prompt-injection and unsafe command execution.",6600,cybersecurity|agentic-ai|LLM-framework|penetration-testing|bug-bounty|security-automation|python|DevSecOps,4,"This repository is primarily a cybersecurity-focused agent framework that orchestrates LLMs and security tooling to automate/offload parts of pentesting and defensive workflows, rather than a data-science or ML training library. It is relevant to ML workflows mainly as an LLM application framework (multi-model support and agent patterns) and could be used by ML engineers building security agents, evaluations, or tool-using LLM systems. However, it does not center on datasets, feature engineering, model training, or core ML algorithms, and its value for typical data science tasks is indirect, so a mid-low score is appropriate.",success
https://github.com/hatchet-dev/hatchet,hatchet,"Hatchet is a platform for running background tasks at scale, built on Postgres. It provides a durable task queue plus workflow orchestration features (chaining, retries, monitoring/alerting) and a real-time dashboard, with SDKs for languages like Python and TypeScript.",6400,background-jobs|task-queue|workflow-orchestration|distributed-systems|postgresql|devops|golang,4,"This repository primarily provides infrastructure for reliable background task execution and workflow orchestration (queues, workers, retries, monitoring) rather than ML-specific functionality. It can be useful in ML/data workflows as a general-purpose scheduler/orchestrator for batch jobs (e.g., feature pipelines, model training/inference tasks) and integrating task execution into services, but it is not a dedicated MLOps or data-processing framework. Community adoption appears solid based on GitHub stars, yet its direct ML applicability is indirect, so it fits best as supporting infrastructure rather than a core ML/data tool.",success
https://github.com/pixie-io/pixie,pixie,"Pixie is an open-source Kubernetes-native observability platform that uses eBPF to automatically collect telemetry (requests, metrics, profiling) and provides in-cluster storage/querying plus a scriptable query language (PxL) via UI/CLI/APIs.",6300,kubernetes|observability|ebpf|monitoring|distributed-systems|cloud-native|golang,4,"This repository implements Pixie, a Kubernetes observability system focused on auto-telemetry collection (via eBPF), in-cluster querying, and interactive debugging of microservices. It is not an ML library or data-science package, but it can indirectly support ML/data workloads by improving reliability and performance monitoring for Kubernetes-hosted data pipelines and ML services. The project has meaningful adoption signals (e.g., thousands of GitHub stars) and a rich telemetry/query layer, which can be valuable to ML platform teams, but it is not directly used for model training, feature engineering, or core MLOps.",success
https://github.com/aisingapore/TagUI,TagUI,"TagUI is a free, open-source Robotic Process Automation (RPA) tool that lets users write automation “flows” in a simple human-readable language to automate tasks across websites (Chrome/Edge), desktop apps, and the command line on Windows, macOS, and Linux. It supports multiple languages and features such as web automation, image-based UI automation, and OCR-based text targeting.",6200,robotic process automation|rpa|browser automation|web scraping|desktop automation|ocr|workflow automation|low-code scripting,4,"This repository’s primary purpose is RPA—automating repetitive user and business tasks across web, desktop, and command-line environments using the TagUI scripting language. It can support data workflows indirectly (for example, automating data collection from websites or moving data to/from files like CSV/Excel), which is sometimes useful in data science projects. However, it is not an ML/data-native library (no core focus on model training, feature engineering, analytics, or MLOps), so its value for ML is mainly as an automation/scraping utility rather than a core ML tool. Also, the README indicates AI Singapore discontinued maintenance/support (community-supported), which can reduce reliability for ML/data production use compared to dedicated data tooling.",success
https://github.com/donnemartin/dev-setup,dev-setup,"A macOS development environment setup repo that provides clear instructions plus dotfiles and shell scripts to automate installing/configuring common developer tools and apps (e.g., shell, Git, Vim, Homebrew/Cask). It also includes optional setup guidance for Python data analysis and data/infra tooling like Jupyter/IPython, NumPy/Pandas/scikit-learn, Spark/MapReduce, AWS utilities, and popular datastores.",6200,macOS|developer-environment|dotfiles|shell-scripting|homebrew|devops|python-data-science|big-data,4,"This repository’s primary purpose is macOS developer machine setup via dotfiles and automation scripts (Homebrew/Cask and shell scripts), so it is not an ML library or dataset. It is indirectly relevant to ML/data workflows because it includes optional setup sections for Python data analysis tools (e.g., Jupyter/IPython, NumPy, Pandas, scikit-learn) and mentions big-data tooling like Spark. The repo can help data scientists/ML engineers bootstrap a workstation, but it doesn’t provide ML algorithms, training code, data pipelines, or MLOps features, so the value is supportive rather than core—hence a 4/10.",success
https://github.com/openblocks-dev/openblocks,openblocks,"Openblocks is an open-source, Retool-like low-code platform for building internal tools and customer-facing apps. It provides a visual UI builder with 50+ components, reusable modules/queries, JavaScript-based data transformations, RBAC, and native connectors to common databases and APIs (e.g., PostgreSQL, MongoDB, MySQL, Redis, Elasticsearch, REST).",6200,low-code|internal-tools|ui-builder|dashboarding|react|database-connectors|admin-panel|rest-api,4,"This repository is primarily a low-code platform for rapidly building CRUD/admin apps and dashboards by connecting to databases and APIs, rather than an ML library. It can be indirectly useful in data/ML workflows for creating internal data tooling (e.g., dataset exploration, ops dashboards, annotation/review UIs, and monitoring panels) and for integrating with data sources and REST services. However, it does not focus on model training, MLOps, or core data-science algorithms, and its adoption is more aligned with internal-tooling builders than the ML/data community—hence a modest relevance score.",success
https://github.com/apache/camel,apache/camel,"Apache Camel is an open-source integration framework for defining routing and mediation rules (via DSLs like Java, XML, Groovy, and YAML) to connect systems that produce/consume data across many transports and messaging technologies. It provides a large ecosystem of components, data formats, and testing support for building and validating integration routes in Java applications and frameworks like Spring and Quarkus.",6100,enterprise integration|integration framework|message routing|data pipelines|java|apache|middleware|ETL,4,"This repository is primarily an enterprise integration and message-routing framework (Camel routes) used to connect applications, protocols, messaging systems, and data formats. It can be useful in ML/data workflows indirectly as an integration layer to move data between sources/sinks (queues, HTTP endpoints, storage systems) and orchestrate ETL-style flows, but it is not an ML library and does not provide model training/inference capabilities. Because its core purpose is general integration middleware—rather than data science/ML tooling—its value to ML practitioners is situational, mostly for production data movement and system integration, which supports a mid-low relevance score.",success
https://github.com/alexcasalboni/aws-lambda-power-tuning,aws-lambda-power-tuning,"AWS Lambda Power Tuning is an open-source AWS Step Functions state machine that benchmarks a Lambda function across multiple memory (power) settings, then analyzes logs to visualize the cost/performance tradeoff and recommend an optimal configuration (cost, speed, or balanced). It runs in your own AWS account and is deployable via IaC options such as AWS SAM.",6000,aws|aws-lambda|aws-step-functions|serverless|performance-optimization|cost-optimization|observability,4,"This repository provides serverless infrastructure and automation to benchmark AWS Lambda functions across memory configurations and visualize resulting cost and latency, primarily for performance/cost tuning of Lambda workloads. It is not an ML/data library, but it can be indirectly useful to ML/data teams running inference or ETL steps on Lambda by helping reduce latency and optimize cloud cost. Community adoption appears solid (thousands of GitHub stars), but its applicability to ML workflows is infrastructural rather than algorithmic, so a moderate indirect-relevance score fits.",success
https://github.com/0x4m4/hexstrike-ai,hexstrike-ai,"HexStrike AI MCP Agents is a Python-based MCP server/framework that connects MCP-compatible AI agents (e.g., Claude, GPT, Copilot) to autonomously orchestrate 150+ cybersecurity tools for automated penetration testing, vulnerability discovery, and bug-bounty/security research workflows.",5800,cybersecurity|penetration-testing|bug-bounty|MCP|AI-agents|LLM-integration|automation|python,4,"This repository’s primary purpose is offensive-security automation: it provides an MCP server plus multi-agent orchestration to let LLM-based agents select and run a large suite of external security tools and expose related APIs/workflows. It relates to ML mainly through LLM/agent integration (MCP tooling, autonomous agent workflows) rather than classic data-science tasks like dataset handling, model training, evaluation, or MLOps. While it can be useful to ML engineers working specifically on agent tool-use/integration patterns, it is not a general ML/data library and its value to typical data-science workflows is limited, so it scores in the indirect/tangential range.",success
https://github.com/Countly/countly-server,countly-server,"Countly Server is the server-side component of Countly, a self-hosted/managed product analytics platform for collecting and analyzing sessions, views, events, and user behavior across mobile, web, and desktop apps. It also includes features like crash/error reporting, push notifications, remote configuration, dashboards, APIs, and a plugin-based architecture.",5800,product analytics|event tracking|web analytics|mobile analytics|Node.js|MongoDB|self-hosted|customer engagement,4,"This repository provides a full product analytics backend (collection APIs, processing, dashboards, and extensible plugins) primarily for tracking and reporting on user behavior rather than building ML models. It can be relevant to data workflows because it captures large-scale event data and exposes read/write APIs that could feed downstream analytics/BI or ML pipelines, but it does not provide ML training/inference functionality itself. The score reflects indirect relevance: useful as data collection/analytics infrastructure, but not a dedicated ML/data science toolkit.",success
https://github.com/iflytek/astron-rpa,astron-rpa,"AstronRPA is an open-source, enterprise-grade Robotic Process Automation (RPA) desktop application that provides a visual low-code/no-code designer for automating Windows desktop software and browser workflows. It also integrates with an “Astron Agent” platform so agent workflows and RPA workflow nodes can call each other for combined automation + intelligent agent scenarios.",5500,robotic process automation|desktop automation|low-code|workflow orchestration|computer vision|python|tauri|spring-boot,4,"This repository primarily provides an RPA desktop automation suite (visual designer + execution engine) for automating Windows apps and web pages, with many built-in components and enterprise deployment options. While it is not a core ML/data science library, it includes capabilities like image recognition/computer vision components and an AI integration module, and it can be used to automate data collection/ETL-like tasks (e.g., extracting data from UIs, spreadsheets, PDFs) that may support ML workflows. Community adoption is meaningful for an RPA project (5.5k stars), but its main value to ML/data practitioners is indirect—automation/integration rather than model training or data processing at scale—so a mid-low relevance score is appropriate.",success
https://github.com/CryptoSignal/Crypto-Signal,Crypto-Signal,"Crypto-Signal is a command-line cryptocurrency technical analysis (TA) bot that scans many coins across multiple exchanges and computes common indicators (e.g., RSI, MACD, Ichimoku, moving averages). It supports alerting via channels like SMS (Twilio), email, Slack, Telegram, and Discord, and is designed to be extensible for custom strategies.",5400,cryptocurrency|algorithmic-trading|trading-bot|technical-analysis|TA-Lib|Python|CLI|alerts-notifications,4,"The repository’s primary purpose is automated technical analysis and alerting for crypto markets (a trading/TA automation tool rather than an ML library). It can be useful in ML/data workflows indirectly by providing market data processing patterns and a foundation where users could add predictive models, but ML is not a core feature. Community adoption (thousands of stars) improves its practical value, yet its ML-specific educational/integration depth appears limited, supporting a below-mid relevance score.",success
https://github.com/Xtremilicious/projectlearn-project-based-learning,projectlearn-project-based-learning,"ProjectLearn is a curated directory of project tutorials aimed at project-based learning, where learners build full applications from scratch. It organizes tutorials across categories like web, mobile, game development, and AI/ML, and powers the companion site projectlearn.io.",5200,project-based learning|curated list|software engineering education|web development|nextjs|typescript|tailwindcss|machine learning tutorials,4,"This repository’s primary purpose is educational curation: it aggregates and categorizes links to build-from-scratch project tutorials (including some in machine learning, deep learning, and AI), rather than providing ML datasets, models, or reusable ML code. For ML/data workflows, it’s indirectly useful as a learning roadmap and discovery hub, but not a tool or library that plugs into data science pipelines. Community adoption appears solid (about 5.2k stars), yet the value is mainly as a general programming-project index with only partial ML coverage, which fits an indirect relevance score.",success
https://github.com/plotly/falcon,falcon,"Falcon is a free, open-source cross-platform SQL editor/client (built with Electron) that supports connecting to multiple databases and includes inline data visualization capabilities. The repository is archived (read-only) and includes desktop downloads and documentation for configuring database connections.",5100,sql-client|database-tools|data-visualization|electron|react|redux|sequelize|desktop-app,4,"This repository provides a GUI SQL client/editor with inline visualization for querying and exploring databases (e.g., PostgreSQL, MySQL, Redshift, SQLite, Oracle, MS SQL). It can be useful in data workflows for ad-hoc data access and exploratory analysis, but it is not an ML library, pipeline, or modeling tool. Because it is a general analytics/DB utility (and the repo is archived/read-only), its direct value for ML engineering is limited compared to dedicated data/ML frameworks, hence a mid-low score.",success
https://github.com/ThoughtfulDev/EagleEye,EagleEye,"EagleEye is a Python-based OSINT tool that takes one or more photos of a target person (plus a name clue) and attempts to discover that person’s social media profiles (e.g., Instagram, YouTube, Facebook, Twitter) using face recognition and reverse image search, with browser automation via Selenium.",5000,osint|face-recognition|computer-vision|reverse-image-search|selenium|python|social-media,4,"This repository primarily implements an OSINT workflow to identify a person’s social media profiles from images, combining face recognition (via dlib/face_recognition) with reverse image search and Selenium-driven browser automation. It uses ML-based face recognition, but the project is not a general-purpose ML library, training framework, dataset, or reusable data pipeline—it's an application focused on a specific (and potentially misuse-prone) investigative use case. For ML/data workflows, it has some indirect value as a reference implementation of face-matching + automation, but limited applicability for typical data science tasks and limited evidence of broad ML community integration beyond using existing libraries.",success
https://github.com/freqtrade/freqtrade-strategies,freqtrade-strategies,"Community-maintained collection of free buy/sell strategy Python files for the Freqtrade crypto trading bot, including example strategies designed and/or tuned via Hyperopt and intended to be backtested and run in dry-run before live trading.",4800,algorithmic-trading|cryptocurrency|trading-bot|python|quant-trading|technical-analysis|freqtrade,4,"This repository primarily provides ready-to-use trading strategy implementations (signal logic, indicators, ROI/stoploss settings) for the Freqtrade crypto trading bot, rather than a general ML library or dataset. It is somewhat relevant to data/ML workflows because strategies are commonly developed via backtesting and parameter optimization (including Freqtrade’s Hyperopt-based optimization), which involves handling time-series market data and experimentation. However, it does not itself offer reusable ML modeling infrastructure or datasets; its value to ML practitioners is mostly as domain examples/benchmarks for quantitative research and feature/indicator engineering, so a low-to-moderate score is appropriate.",success
https://github.com/jixserver/free-for-dev,free-for-dev,"A curated list of SaaS, PaaS, and IaaS products that offer free tiers useful to developers—especially DevOps and infrastructure-focused practitioners. The repository is primarily a README-driven catalog organized by category, and accepts contributions via pull requests.",4800,developer-resources|devops|cloud-services|free-tier|awesome-list|infrastructure,4,"This repository is a curated directory of free-tier services (SaaS/PaaS/IaaS) aimed mainly at DevOps and infrastructure developers, organized as a categorized README list. It is not an ML library or dataset, but it can still be useful to ML/data practitioners when selecting supporting infrastructure (e.g., hosting, storage, CI/CD, monitoring, APIs, and occasional ""APIs, Data and ML"" entries). Because its relevance is mostly indirect and tooling/infrastructure-oriented rather than core ML/data functionality, it merits a mid-low score rather than a high one.",success
https://github.com/shaxiu/XianyuAutoAgent,XianyuAutoAgent,"An AI customer-service/auto-reply agent system for the Xianyu (闲鱼) marketplace, designed for 24/7 message handling with context-aware conversations, expert-agent routing (e.g., bargaining/tech/support), and automated negotiation strategies. It is configured via prompt templates and environment variables, and can be run locally (Python) or via Docker.",4700,llm|ai-agent|chatbot|customer-support-automation|prompt-engineering|python|docker|e-commerce-automation,4,"This repository primarily automates customer-service interactions on the Xianyu platform using an LLM-driven multi-agent (expert routing) approach with prompt templates and lightweight conversation memory/context management. It is ML-adjacent because it applies LLM APIs and prompt engineering, but it is not a data science library, dataset, training pipeline, or MLOps tooling, and it offers limited direct value for typical ML/data workflows beyond being an applied agent example. Community adoption appears meaningful (thousands of stars), which increases educational value for learning applied LLM-agent patterns, but overall it remains a domain-specific automation bot rather than a general ML/data tool.",success
https://github.com/apache/rocketmq-externals,rocketmq-externals,"Apache RocketMQ community ""external"" projects repository containing integration components and ecosystem add-ons (e.g., connectors, exporters, operators, protocol bridges) that extend RocketMQ beyond the core broker/client codebase.",4600,message broker|Apache RocketMQ|data integration|streaming|connectors|Kubernetes|observability,4,"This repository is a collection of Apache RocketMQ ecosystem extensions (e.g., RocketMQ-Connect, integrations with Flume/Spark, exporters, operators, and protocol bridges) intended to integrate RocketMQ with other systems and deployment/monitoring environments. It is not an ML library, but it can be indirectly useful in ML/data workflows by supporting data ingestion/streaming pipelines and connecting RocketMQ to big-data tools (e.g., Spark/Flume) and operational tooling (e.g., Prometheus exporters, Kubernetes operator). The score reflects moderate, infrastructure-level relevance to data engineering that can support ML pipelines, but limited direct ML functionality, models, or ML-specific APIs.",success
https://github.com/liam-hq/liam,liam,"Liam ERD is an open-source tool that automatically generates interactive, easy-to-read entity-relationship (ER) diagrams from database schemas. It supports quick visualization for public schema files via a shareable URL and provides a CLI setup flow for private projects/CI usage.",4600,database-schema|erd|entity-relationship-diagram|data-visualization|typescript|nodejs|cli|documentation-tool,4,"This repository’s primary purpose is database schema visualization: it reverse-engineers schemas to produce interactive ER diagrams (via web viewer and a CLI). It’s not an ML library, but it can be indirectly useful in data/ML workflows by helping data engineers and ML teams understand and document the structure of operational/analytics databases that feed feature stores, ETL/ELT pipelines, and model training datasets. The community adoption appears solid (thousands of stars), but the tool targets schema documentation rather than modeling, training, or MLOps—hence a moderate indirect-relevance score.",success
https://github.com/0x4D31/awesome-threat-detection,awesome-threat-detection,"A curated “awesome list” of resources for threat detection and threat hunting, including tools, detection rules, datasets, and learning materials (e.g., frameworks, research papers, and blogs). It serves as a reference hub for defenders to discover and compare detection/hunting tooling and content across endpoint, network, email, and SIEM contexts.",4500,cybersecurity|threat detection|threat hunting|blue team|SIEM|incident response|security datasets|detection engineering,4,"This repository is primarily a curated index of threat detection and hunting resources (tools, detection rules, datasets, and references), rather than an ML library or data-processing framework. It is relevant to ML/data workflows mainly insofar as it points to security datasets and “data science” resources that can be used for security analytics, feature engineering, or building detection models. Because it does not itself provide ML code, pipelines, or reusable datasets directly (it aggregates links), its direct applicability to ML engineering is limited, but it still has practical discovery and educational value for security data science use cases.",success
https://github.com/oxnr/awesome-analytics,awesome-analytics,"A curated “awesome list” of analytics platforms, frameworks, and related tools/resources, organized into categories such as general analytics, real-time analytics, website analytics, privacy-focused analytics, dashboards, and more. It serves as a directory for discovering analytics products (open-source and SaaS) rather than a standalone analytics library.",4200,analytics|awesome-list|business-intelligence|product-analytics|web-analytics|data-tools|data-engineering,4,"This repository is primarily a curated directory of analytics tools and resources (an “awesome list”), not an ML library, dataset, or executable data pipeline. It can still be useful to data practitioners by helping them discover analytics/BI/product-analytics platforms that may feed or complement data workflows, but it does not directly provide ML methods, model training utilities, or data science code. Community adoption appears solid for its niche (thousands of stars), but its value for ML engineering is indirect, so a mid-low relevance score is appropriate.",success
https://github.com/gptme/gptme,gptme,"gptme is a personal AI assistant/agent that runs in your terminal (and optionally via a web UI), with local tools to execute code, edit files, use the shell, browse the web, and use vision. It supports multiple LLM providers and aims to be an unconstrained local alternative to tools like ChatGPT with code execution and agent-style workflows.",4100,llm-agent|cli|developer-tools|ai-coding-assistant|web-browsing-automation|python|terminal-ui,4,"This repository primarily provides a general-purpose AI agent (CLI + optional web UI) that can call tools like shell/code execution, file editing, web browsing, and vision, making it a productivity and automation tool rather than an ML library. It can be useful in ML/data workflows indirectly (e.g., automating data tasks, scripting experiments, prototyping code, interacting with local environments), and it supports multiple model providers, but it does not appear to focus on core ML functions like training, evaluation, dataset management, or MLOps pipelines. Community adoption is solid (about 4.1k stars), but its relevance to ML/data work is still secondary to its role as a general coding/knowledge-work agent.",success
https://github.com/michaelgrosner/tribeca,tribeca,"Tribeca is a very low-latency cryptocurrency market-making trading bot/platform built for Node.js/TypeScript, including a web UI and a backtester, with direct connectivity to multiple crypto exchanges and MongoDB-backed persistence. It is designed to react to market data extremely quickly (sub-millisecond order placement/cancellation on modern hardware) and is commonly deployed via Docker.",4100,cryptocurrency|algorithmic-trading|market-making|high-frequency-trading|nodejs|typescript|mongodb|docker,4,"This repository primarily implements a low-latency crypto market-making trading system (execution, order management, exchange connectivity) with a web client and a backtester, rather than ML modeling. It can be indirectly useful for data/ML workflows because it includes backtesting infrastructure and generates/consumes market data streams, which can support research, feature engineering, or strategy evaluation pipelines. However, it does not appear to provide ML algorithms, training workflows, or integrations with common ML frameworks, and its core value is trading infrastructure rather than data science tooling—hence a moderate, indirect relevance score.",success
https://github.com/ndleah/python-mini-project,python-mini-project,"A community-driven collection of beginner-friendly Python mini projects (games, utilities, small apps) intended to help learners practice Python fundamentals and contribute via GitHub. The repo includes contribution guidelines and a template approach for adding new project folders with per-project READMEs.",4000,python|beginner-projects|open-source|learning|data-visualization|data-analysis|mini-projects,4,"This repository is primarily a large grab-bag of beginner Python mini-projects and contribution exercises rather than a focused ML or data-science library. It does include some projects/topics related to data analysis/visualization and even some ML-adjacent items (e.g., object detection, simple regression examples), but these are not the central organizing purpose and are not presented as a cohesive, reusable ML toolkit. Its main value for ML/data practitioners is educational practice and small reference examples rather than direct workflow integration or industry-standard adoption, which supports a lower-to-mid relevance score.",success
https://github.com/deepops-ai/deepops,deepops,"XO (xobserve) is a programmable observability and data-visualization platform for developers, positioned as an alternative to Grafana. It supports building monitoring/logging/tracing experiences with OpenTelemetry integration, customizable charts/datasources, and extensible processing via plugins (including WebAssembly support).",3900,observability|apm|opentelemetry|tracing|prometheus|data-visualization|grafana-alternative|typescript,4,"This repository primarily provides an observability UI/visualization platform (XO/xobserve) for monitoring, logging, and tracing, including native OpenTelemetry support and integrations with common observability backends. It is not an ML library or data-science toolkit, but it can be indirectly useful in ML/MLOps workflows for monitoring ML services, model-serving systems, and operational telemetry. The score reflects its infrastructure/DevOps relevance to ML production environments rather than direct applicability to model training, data processing, or core ML research.",success
https://github.com/grantjenks/python-sortedcontainers,python-sortedcontainers,"Pure-Python, performance-focused sorted collection types for Python, providing SortedList, SortedDict, and SortedSet with efficient (better-than-linear) operations. Designed to be easy to deploy (no C extensions) while remaining fast and well-tested/documented.",3900,python|data-structures|sorted-containers|collections|algorithms|performance|utility-library,4,"This repository provides high-performance sorted data structures (SortedList/SortedDict/SortedSet) implemented in pure Python, primarily for general-purpose programming where ordered collections with fast insert/search are needed. It can be useful in ML/data workflows indirectly (e.g., maintaining ordered windows, ranking/leaderboards, event scheduling, streaming/online algorithms, or certain indexing tasks), but it is not an ML-specific library and does not integrate directly with common ML frameworks. Community adoption is strong for a utility library (thousands of stars), supporting its practical value, but its relevance is infrastructural rather than core to modeling or data pipelines—hence a mid-low score.",success
https://github.com/wmariuss/awesome-devops,awesome-devops,"A curated “awesome list” of DevOps and SRE-related platforms, tools, practices, and learning resources. It organizes links across key infrastructure and software-delivery categories such as cloud platforms, CI/CD, automation/orchestration, observability, security, and more.",3800,DevOps|SRE|awesome-list|CI/CD|cloud|Kubernetes|infrastructure|observability,4,"This repository is primarily a curated directory of DevOps/SRE tools and resources rather than an ML library or dataset. It can still be useful to ML and data teams indirectly because many MLOps and data-platform workflows rely on the same infrastructure foundations (CI/CD, containers/orchestration, monitoring/observability, security, and cloud platforms). However, it does not provide ML-specific code, training utilities, or data assets, and its value to ML/data work is mainly as general infrastructure reference material, which supports a mid-low indirect relevance score.",success
https://github.com/OpenHFT/Chronicle-Queue,Chronicle-Queue,"Chronicle Queue is a broker-less, off-heap Java library for ultra-low-latency persisted messaging (durable queues/topics) that stores data to disk via memory-mapped files. It supports high-throughput appends/reads with multiple writers (locking) and multiple concurrent readers (lock-less) for microsecond-level latencies.",3600,java|messaging|persisted-queue|low-latency|event-streaming|off-heap-memory|high-performance-computing|distributed-systems,4,"This repository provides a high-performance, durable messaging/queueing system focused on ultra-low latency and disk persistence (via memory-mapped files) for JVM applications. It is not an ML library, but it can be indirectly useful in data/ML workflows where you need reliable, high-throughput event ingestion, inter-process/JVM communication, or replayable event logs (e.g., feature/event pipelines). Community adoption appears strong for a specialized infrastructure component (thousands of GitHub stars), but it is not ML-specific and does not integrate directly with common ML frameworks, so a mid-low infrastructure relevance score is appropriate.",success
https://github.com/benbjohnson/thesecretlivesofdata,thesecretlivesofdata,"An interactive visualization project aimed at explaining how data systems work under the hood, with a focus on performance and reliability concepts. It includes web-based visualizations such as an understandable walkthrough of the Raft distributed consensus algorithm (with plans for Apache Kafka).",3600,data visualization|distributed systems|raft|consensus|kafka|javascript|educational,4,"This repository primarily provides interactive visualizations to teach distributed systems concepts (e.g., Raft consensus) rather than ML model training or data science tooling. It can still be valuable to data/ML engineers as educational material because understanding distributed systems is relevant to reliability and performance of data infrastructure. However, it does not offer ML frameworks, datasets, or direct ML workflow integrations, so its usefulness for ML/data work is indirect.",success
https://github.com/fabric8io/kubernetes-client,kubernetes-client,"Fabric8 Kubernetes Client is a Java client library for Kubernetes and OpenShift that provides access to their REST APIs via a fluent DSL. It includes Kubernetes/OpenShift model types, multiple HTTP client backends, extensions (e.g., Knative/Tekton/Istio), and tooling for CRD/Java generation.",3600,kubernetes|openshift|java|devops|cloud-native|kubernetes-operator|client-library,4,"This repository is primarily a Java client SDK for interacting with Kubernetes and OpenShift APIs (CRUD, watch, resource models, and related tooling), aimed at platform/DevOps and application developers building Kubernetes-integrated software. It is not an ML or data-science library, but it can be indirectly valuable for ML/data teams because many ML workloads run on Kubernetes (e.g., deploying training/inference jobs, managing resources, and integrating with MLOps pipelines/operators). The project’s broad Kubernetes focus and ecosystem integrations make it useful infrastructure-wise for MLOps, but it does not provide ML algorithms, data processing, or model tooling itself, which keeps the score in the “indirect relevance” range.",success
https://github.com/Gerapy/Gerapy,Gerapy,"Gerapy is a distributed crawler management framework built around Scrapy and Scrapyd, providing a web UI (Django + Vue.js) to create/manage crawler projects, deploy them to Scrapyd clients, and monitor running jobs.",3500,web scraping|scrapy|scrapyd|distributed systems|crawler management|django|vue.js|docker,4,"This repository primarily provides infrastructure and a web dashboard for managing and deploying distributed web crawlers (Scrapy/Scrapyd), rather than implementing ML algorithms or data science libraries. It can be useful in data workflows as an ingestion layer for collecting raw web data and operationalizing crawlers (deployment, scheduling/monitoring), which often precedes ML/analytics. However, it does not focus on feature engineering, modeling, training, evaluation, or MLOps for models, so its direct applicability to ML is limited, leading to a moderate/indirect relevance score.",success
https://github.com/TracecatHQ/tracecat,tracecat,"Tracecat is an open-source AI automation platform for security, IT, and infrastructure teams, providing workflow automation with a no-code UI plus YAML-based integration templates. It includes built-in case management and lookup tables, and is orchestrated with Temporal for scalable, reliable execution.",3400,workflow-automation|security-automation|it-automation|ai-agents|orchestration|temporal|docker|incident-response,4,"This repository primarily provides an automation/orchestration platform for security and IT response engineering (workflows, integrations, cases, and tables), rather than an ML library or data-science toolkit. It is ML-adjacent because it’s positioned as an “AI automation” platform and can be used to operationalize LLM/agent-driven workflows, but it does not focus on model training, evaluation, or core data processing. Its main value to ML/data practitioners is as infrastructure for automating operational playbooks that may call AI services, which makes it indirectly relevant but not a core ML/data repo.",success
https://github.com/thrasher-corp/gocryptotrader,gocryptotrader,"GoCryptoTrader is a Golang-based cryptocurrency trading bot and framework that provides a unified interface across many exchanges. It includes exchange integrations (REST/WebSocket), portfolio tools, data handling (tickers/order books/OHLCV), and an event-driven backtesting application for strategy testing.",3400,cryptocurrency|algorithmic-trading|trading-bot|golang|exchange-api|backtesting|grpc,4,"This repository is primarily a cryptocurrency trading bot/framework with extensive exchange connectivity (REST/WebSocket), market-data retrieval (including OHLCV/candles), portfolio tooling, and an event-driven backtester. It is not an ML library, but it can support ML/data workflows indirectly by collecting historical/real-time market data and providing a backtesting environment to evaluate strategies that could be ML-driven. The moderate open-source adoption (thousands of stars) and built-in backtesting/data features make it more useful than a general utility repo for quant/data experimentation, but it lacks core ML components (model training, feature engineering pipelines, or ML integrations), so it scores below dedicated data/ML tooling.",success
https://github.com/kirang89/pycrumbs,pycrumbs,"A curated collection of links and references (“bits and bytes”) about Python, organized by topic (e.g., language features, best practices, web, testing, packaging, data analysis/visualization, and more). It serves primarily as a learning/resource index rather than an executable library.",3200,python|curated-resources|learning|reference|data-analysis|data-visualization|deep-learning,4,"This repository is mainly a curated knowledge base of Python resources, with sections that include data-mining, data analysis (e.g., Pandas), data visualization, and deep learning links. It can be useful for ML/data practitioners as a directory of learning materials and tooling pointers, but it is not itself an ML/data library, dataset, pipeline, or framework. Community adoption appears solid based on its star count, yet practical direct integration into ML workflows is limited because it is primarily a README-style resource list rather than code.",success
https://github.com/QiuYannnn/Local-File-Organizer,Local-File-Organizer,"A privacy-preserving, on-device AI file management tool that scans a folder and reorganizes files by understanding their contents (text and images), then renames and sorts them into a structured directory. It uses local LLM/VLM inference via the Nexa SDK (e.g., Llama 3.2 3B for text and LLaVA v1.6 for images) and provides CLI features like dry-run and multiple sorting modes.",3100,local-llm|file-organization|python|cli-tool|document-processing|computer-vision|privacy,4,"This repository is primarily an end-user utility for organizing local files using on-device AI models (LLM for text understanding and VLM for image understanding) to generate categories and filenames. It is related to ML in that it applies inference from pre-trained models (via Nexa SDK) and demonstrates practical multimodal content analysis, but it is not a dataset, ML training framework, or a general-purpose data-processing library. Data/ML practitioners might use it as a workflow helper for managing documents/images or as a reference implementation for local inference pipelines, yet its scope and direct ML engineering value are limited compared to dedicated ML tooling.",success
https://github.com/robcarver17/pysystemtrade,pysystemtrade,"An open-source Python backtesting and live systematic futures trading engine by Rob Carver, implementing the framework from his book ""Systematic Trading"". It supports research/backtesting workflows and automated execution via Interactive Brokers (using ib-insync), with extensive modules for data handling, portfolio/risk, and production trading.",3100,algorithmic-trading|systematic-trading|quant-finance|backtesting|futures|portfolio-risk-management|interactive-brokers|python,4,"pysystemtrade is primarily a systematic futures trading framework (research/backtesting plus live execution) rather than an ML library; its core value is in trading system design, portfolio/risk management, and brokerage integration. It can be useful to data/quant practitioners because it provides a substantial time-series trading research and production codebase (data ingestion, signal/forecast plumbing, evaluation), but it is not centered on model training, feature engineering pipelines, or mainstream ML integrations. Community adoption appears solid for a niche quant-trading project (about 3.1k GitHub stars), supporting a mid-level score rather than a high ML-specific one.",success
https://github.com/yuchenlin/rebiber,rebiber,"Rebiber is a Python tool that normalizes and updates BibTeX entries using official publication metadata (e.g., from DBLP and the ACL Anthology), helping replace outdated/unofficial arXiv-style citations with conference/journal-correct entries. It also supports consistent formatting (DBLP-style), optional abbreviation of venues, deduplication, sorting, and field removal.",3000,bibliography|BibTeX|research-tools|NLP|metadata-normalization|Python|CLI-tool,4,"This repository primarily provides a BibTeX normalization/updating utility for academic citations by fetching/using official bibliographic metadata (not an ML library). It is relevant to ML/data workflows mainly as a research engineering productivity tool for writing papers and maintaining clean citation databases, especially in NLP/ML conferences, but it does not support model training, data processing pipelines, or analytics directly. Community adoption appears solid for its niche (thousands of GitHub stars), which boosts its practical usefulness, but its scope remains adjacent rather than core ML/data infrastructure—hence a 4/10.",success
https://github.com/robusta-dev/robusta,robusta,"Robusta is a Kubernetes-focused alerting and remediation platform that enhances Prometheus/Alertmanager notifications with smart grouping, alert enrichment (e.g., logs and cluster context), optional AI-assisted investigation, and automated remediation workflows. It integrates with popular chat/incident tools (e.g., Slack, Teams, Jira) to reduce alert noise and speed up incident response.",2900,kubernetes|prometheus|alertmanager|observability|devops|incident-response|auto-remediation|ai-ops,4,"This repository primarily targets Kubernetes operations and observability: it improves Prometheus alert notifications via smart grouping, enrichment, routing, and self-healing/auto-remediation playbooks, with optional AI-assisted investigation features. While it is not an ML/data-science library, it can indirectly support ML/data workflows by improving reliability of ML infrastructure running on Kubernetes and integrating with AIOps-style investigation. The ML-related component appears to be optional enrichment rather than core ML functionality, so its direct applicability to model development/training is limited, leading to a below-moderate score.",success
https://github.com/iterativv/NostalgiaForInfinity,NostalgiaForInfinity,"A set of crypto trading strategies for the Freqtrade trading bot, including multiple strategy variants (e.g., NostalgiaForInfinityX series) and accompanying configuration, docs, and tooling for running/backtesting the strategies.",2800,algorithmic-trading|cryptocurrency|freqtrade|trading-bot|python|quantitative-finance|backtesting,4,"This repository primarily provides rule-based/heuristic crypto trading strategies intended to be used with the Freqtrade bot, along with documentation and configurations for running and backtesting. While it can be useful to data practitioners doing quantitative trading research (e.g., as a baseline strategy to evaluate, backtest, and iterate on), it is not an ML library and does not primarily focus on model training or ML-driven signal generation. Its relevance is therefore indirect: it supports experimentation and backtesting workflows that may involve data analysis, but ML is not the core purpose, so it scores a 4/10.",success
https://github.com/Codehagen/Badget,Badget,"Badget is an AI-powered financial management (""Copilot for Money"") web app for tracking accounts, transactions, and budgets in a unified dashboard. It emphasizes household/family multi-user support, automated budgeting, real-time financial health features, and AI-driven insights such as anomaly detection and forecasts.",2700,personal finance|budgeting|web application|Next.js|TypeScript|Prisma|PostgreSQL|AI insights,4,"Badget is primarily a consumer-facing personal finance/budgeting platform built with a modern web stack (Next.js, TypeScript, Prisma, PostgreSQL) and includes AI-driven features like spending analysis, anomaly detection, and forecasting. While it references AI capabilities, it does not appear to be a reusable ML library, dataset, or MLOps tool; its ML components (if present) are embedded as application features rather than general-purpose data-science utilities. It can still be indirectly relevant to ML/data workflows as an example product integrating AI insights into a domain app and potentially as a reference for building analytics/forecast features, but its direct applicability for data scientists is limited compared to dedicated ML/data tooling.",success
https://github.com/circe/circe,circe,"Circe is a JSON library for Scala and Scala.js that provides a JSON AST along with type class-based encoders/decoders, parsing/printing modules, and optional generic derivation to reduce boilerplate.",2500,scala|scala-js|json|serialization|typeclasses|functional-programming|data-encoding,4,"This repository implements a high-performance JSON toolkit for Scala/Scala.js, including encoding/decoding, parsing, and related utilities. It is not an ML library, but it is commonly useful in data/ML workflows for ingesting datasets, reading/writing experiment artifacts, and integrating with JSON-based APIs and services. Its adoption in the Scala ecosystem and clean type-safe abstractions make it a solid supporting dependency for data pipelines, but it provides no ML-specific algorithms or modeling capabilities, so it rates as indirectly relevant.",success
https://github.com/lovoo/goka,goka,"Goka is a stateful stream processing library for Apache Kafka written in Go, designed to simplify building scalable and fault-tolerant microservices. It extends Kafka consumer groups with persisted state tables (group tables) and provides processors, views, and pluggable storage/communication layers.",2500,go|apache-kafka|stream-processing|event-driven-architecture|stateful-processing|microservices|distributed-systems|data-engineering,4,"This repository provides a Go library for building stateful, fault-tolerant stream-processing services on top of Apache Kafka (processors, views, persisted state tables, and optional local storage layers). It is not an ML library, but it can be useful in ML/data workflows as supporting infrastructure for real-time feature computation, online aggregation, data enrichment, and event-driven pipelines feeding training or inference systems. Community adoption appears solid for a Go/Kafka library (on the order of ~2.5k GitHub stars), but its primary focus is general stream processing rather than ML-specific tooling, so it earns an indirect-relevance score.",success
https://github.com/iipc/awesome-web-archiving,awesome-web-archiving,"A curated “awesome list” of resources for getting started with web archiving, including training/documentation, tools and software (acquisition, replay, discovery, utilities), and community/service-provider references. It serves as a practical directory of widely used web-archiving standards, workflows, and ecosystems rather than a single executable tool.",2400,web archiving|awesome-list|digital preservation|WARC|web crawling|data sources|information retrieval,4,"This repository is primarily a curated knowledge base for web archiving (tools, standards like WARC, training, and community resources), not an ML library or dataset. It is indirectly useful for ML/data workflows because web archives (e.g., WARC files, Common Crawl-derived resources, and analysis tooling like Spark-based projects) can be important data sources and processing targets for research. However, it doesn’t provide ML algorithms, model training code, or a turnkey data pipeline itself, so its value is mostly as a discovery/starting point rather than a direct ML dependency.",success
https://github.com/lining808/CS-Ebook,CS-Ebook,"A curated, continuously-updated recommendation list of high-quality, classic computer science and software-related books, organized by topic. It covers CS fundamentals, programming languages, software engineering, math, big data, AI/ML, and career/interview guidance, without hosting download links.",2400,computer science|ebook list|learning resources|software engineering|programming languages|data science|machine learning|deep learning,4,"This repository is primarily a curated reading list (book recommendations) across many CS domains, rather than an ML/data codebase, dataset, or tool. It does include substantial sections on big data and artificial intelligence (machine learning, deep learning, reinforcement learning, NLP), making it educationally useful for ML practitioners looking for study material. However, it has limited direct applicability to ML/data workflows (no training pipelines, libraries, or datasets) and community adoption is best reflected as a popular resource list rather than an ML utility, so it scores as indirectly relevant.",success
https://github.com/ballerine-io/ballerine,ballerine,"Ballerine is an open-source risk management infrastructure and data orchestration platform used to automate risk decisioning across the customer lifecycle (e.g., KYC/KYB onboarding, underwriting, and transaction monitoring). It provides a workflow/rules engine, third-party vendor/plugin integrations, a back-office case management UI for manual review, and data/document collection flows.",2300,risk-decisioning|kyc-kyb|fintech-compliance|workflow-engine|rules-engine|case-management|data-orchestration|typescript-javascript-monorepo,4,"This repository is primarily a fintech risk/compliance workflow platform (KYC/KYB, underwriting, transaction monitoring) with orchestration, rules, plugins, and case-management tooling rather than an ML library. It can be indirectly useful for ML/data workflows because risk systems often integrate data vendors, generate labeled outcomes (decisions/cases), and can serve as an orchestration layer around decision logic, but ML modeling is not the core focus. The repo also notes that the open-source version is undergoing a major rebuild and is not actively supported, which reduces practical ML/data adoption value. Therefore it’s best categorized as indirectly relevant infrastructure rather than a core ML/data tool.",success
https://github.com/cisagov/Malcolm,Malcolm,"Malcolm is a containerized network traffic analysis suite for ingesting and analyzing full packet captures (PCAPs), Zeek logs, and Suricata alerts. It normalizes/enriches/correlates network-security telemetry and provides analysis through OpenSearch Dashboards and Arkime, with scripts to simplify deployment and operations.",2300,network-security|network-traffic-analysis|pcap|incident-response|SIEM|opensearch|zeek|suricata,4,"This repository provides an end-to-end, container-based platform for collecting, parsing, enriching, indexing, and visualizing network telemetry (PCAP, Zeek, Suricata) for security monitoring and incident response. While it is fundamentally a security operations/NTA tool rather than an ML library, it produces and organizes large volumes of structured event data that can be exported or queried for downstream analytics, anomaly detection, or model-building workflows. It has indirect value for data science through its data collection and normalization pipelines and searchable OpenSearch-backed datasets, but it does not focus on ML training/inference, features, or model management—hence a moderate/indirect score.",success
https://github.com/ranaroussi/qtpylib,qtpylib,"QTPyLib (Quantitative Trading Python Library) is an event-driven algorithmic trading framework in Python supporting backtesting plus paper/live trading via Interactive Brokers. It includes components like a market-data “blotter,” broker/algo abstractions, reporting, and integrations (e.g., TA-Lib) for building and monitoring trading strategies.",2300,algorithmic trading|quantitative finance|backtesting|interactive brokers|python|market data|TA-Lib|event-driven architecture,4,"This repository is primarily an algorithmic trading library/framework (backtesting and paper/live execution via Interactive Brokers) rather than a machine learning or data science toolkit. It can be useful in ML/data workflows indirectly because it captures/stores market data for analysis and allows importing ML libraries (e.g., scikit-learn/TensorFlow) into strategies, but it does not provide core ML modeling/training capabilities itself. Community adoption appears solid for its niche (about 2.3k stars), yet its main value is trading infrastructure and strategy execution rather than general-purpose ML/data tooling.",success
https://github.com/shyiko/mysql-binlog-connector-java,mysql-binlog-connector-java,"Java library for reading MySQL binary logs and for tapping into the MySQL replication stream (binlog) via a client API, supporting features like automatic binlog position/GTID resolution, resumable disconnects, checksum support, TLS, and JMX exposure. Note: the repository is explicitly marked as no longer maintained, with a recommendation to migrate to a fork.",2300,mysql|binlog|cdc|database-replication|java|data-engineering|streaming,4,"This repository provides a Java connector/client for consuming MySQL binary log events (including via the replication stream), which is commonly used for change data capture (CDC) and building downstream pipelines. While it is not an ML library, CDC and binlog consumption can be a useful building block for data engineering workflows that feed analytics/feature stores and near-real-time training or inference data. The score is limited because its primary purpose is database replication/binlog parsing (infrastructure), and the project is explicitly marked as unmaintained, reducing practical adoption value for new ML/data projects.",success
https://github.com/Open-Trader/opentrader,opentrader,"OpenTrader is a self-hosted cryptocurrency trading bot with a web UI, supporting 100+ exchanges via CCXT. It includes built-in strategies (e.g., GRID, DCA, RSI), plus paper trading and backtesting for testing strategies on historical data.",2200,cryptocurrency|algorithmic-trading|trading-bot|ccxt|backtesting|paper-trading|typescript|nodejs,4,"This repository’s primary purpose is automated crypto trading (self-hosted bot + UI) with exchange connectivity via CCXT and configurable strategies, plus paper trading and backtesting. It is data-adjacent because it works with market time-series data and includes backtesting infrastructure, which can be useful for quantitative research workflows. However, it does not appear to be primarily an ML framework or modeling toolkit (e.g., no emphasis on model training, feature engineering pipelines, or MLOps), so its direct value for ML/data science is moderate rather than central.",success
https://github.com/moazbuilds/CodeMachine-CLI,CodeMachine-CLI,"CodeMachine is a CLI-native orchestration engine that runs coordinated multi-agent workflows locally to turn high-level specifications into production-ready software. It supports orchestrating multiple CLI AI coding engines (e.g., Codex CLI, Claude Code, Cursor CLI) and provides a spec-to-code workflow with validation and automation steps.",2200,cli|developer-tools|orchestration|workflow-automation|multi-agent-systems|generative-ai|code-generation|automation,4,"This repository primarily provides a developer-focused CLI orchestration runtime for coordinating multiple AI coding agents to generate and validate software from specs, rather than a library for data science/ML modeling or data processing. It is still relevant to ML-adjacent workflows because it can orchestrate LLM-based tools (agent planning, code generation, review) and could be used by ML engineers to bootstrap services and MLOps scaffolding. However, it does not appear to include core ML/data capabilities (datasets, training/evaluation pipelines, model implementations), and its main value is productivity/orchestration in software development rather than data science itself.",success
https://github.com/davepoon/claude-code-subagents-collection,buildwithclaude,"A plugin marketplace and discovery platform for Claude Code that provides curated collections of agents, commands, hooks, skills, and plugins, plus a web UI for browsing and installing them. It also indexes community plugins, MCP servers, and external plugin marketplaces to extend Claude Code workflows.",2100,AI developer tools|Claude Code|agent framework|plugin marketplace|MCP servers|developer productivity|automation,4,"This repository primarily curates and distributes Claude Code extensions (agents, commands, hooks, and plugins) and provides a marketplace/discovery UI rather than implementing ML models, datasets, or training/evaluation tooling. It is somewhat relevant to ML/data workflows because it includes “Data & AI” oriented agents and can help ML engineers automate engineering tasks or integrate tool connections via MCP servers, but its value is indirect and workflow-focused. Community adoption appears solid (about 2.1k GitHub stars), yet it is not a core ML/data library or MLOps platform, so a mid-low score is appropriate.",success
https://github.com/GoogleCloudPlatform/PerfKitBenchmarker,PerfKitBenchmarker,"PerfKit Benchmarker (PKB) is an open-source framework and benchmark suite for measuring and comparing performance across cloud providers using consistent, mostly default configurations. It automates provisioning resources (e.g., VMs), installing benchmark tools, and running workloads via cloud-vendor CLI tooling.",2000,cloud benchmarking|performance testing|cloud infrastructure|DevOps|automation|Python|IaaS,4,"PerfKitBenchmarker primarily benchmarks cloud infrastructure and managed services (compute, storage, networking, databases) by automatically provisioning resources and running standardized workloads. It is not an ML framework or data-processing library, but it can be useful for ML/data teams when sizing and comparing cloud infrastructure for training/inference, data storage, and data pipeline throughput/latency. The score reflects indirect-but-practical relevance to ML/data workflows (infrastructure evaluation and performance characterization), rather than direct ML functionality.",success
https://github.com/nntaoli-project/goex,goex,"A Go (Golang) cryptocurrency exchange REST API SDK/wrapper that unifies and standardizes interfaces across multiple exchanges (notably OKX and Binance). It provides common models and clients for public market data (e.g., tickers) and private trading actions (e.g., creating orders) through a consistent API.",2000,golang|cryptocurrency|trading|exchange-api|rest-api|quant-trading|okx|binance,4,"This repository is primarily a Go SDK that standardizes REST API access to cryptocurrency exchanges (e.g., OKX and Binance) for market data retrieval and trade execution. It can support ML/data workflows indirectly by making it easier to collect historical/real-time crypto market data and to integrate model-driven trading strategies into an execution layer. However, it does not provide ML algorithms, feature engineering, backtesting, or data science tooling itself, so its value is mainly infrastructural and domain-specific rather than core ML.",success
https://github.com/whittlem/pycryptobot,pycryptobot,"PyCryptoBot is a Python-based cryptocurrency trading bot that supports automated trading strategies and technical analysis indicators across multiple exchanges (e.g., Binance, KuCoin, and Coinbase Pro). It also includes tooling such as backtesting, scanning/screening utilities, and optional integrations like a Telegram bot and web UI components.",2000,cryptocurrency-trading|trading-bot|algorithmic-trading|technical-analysis|backtesting|python|telegram-bot|exchange-apis,4,"This repository’s primary purpose is automated crypto trading (strategy execution, technical-analysis-driven signals, and exchange integrations), not machine learning model development. It is still somewhat useful for data/ML workflows because it involves market data ingestion, indicator computation, and includes backtesting/scanning components that can support feature generation and experimentation. However, it does not appear to be an ML framework, MLOps tool, or dataset-centric project, and its value to ML practitioners is largely indirect (as a data source/strategy baseline rather than a modeling toolkit).",success
https://github.com/bellingcat/octosuite,octosuite,"Octosuite is a Python-based, TUI/CLI OSINT framework that uses GitHub’s public API to investigate GitHub users, organizations, and repositories. It supports data collection and searching (e.g., users/repos/topics/issues/commits) with exportable outputs (e.g., CSV) for reproducible analysis workflows.",1900,OSINT|GitHub API|python|terminal-ui|data-collection|investigations|security-research,4,"This repository primarily provides an OSINT/investigation toolkit for gathering and analyzing publicly available GitHub account and repository data via the GitHub API, with a terminal-based interface and CSV export. It can be useful in data workflows for collecting and structuring GitHub metadata/activity for later analysis, but it is not an ML library and does not focus on model training, feature engineering, or MLOps. Community adoption appears moderate (on the order of ~1.9k stars), suggesting practical value, but its relevance to ML is indirect and largely depends on how users repurpose the collected data for downstream analytics or ML tasks.",success
https://github.com/perses/perses,perses,"Perses is a CNCF Sandbox observability dashboard and visualization platform that unifies metrics, traces, logs, and profiling in one UI. It supports Prometheus, Tempo, Loki, and Pyroscope, and emphasizes Dashboard-as-Code, plugins/extensibility, and GitOps-friendly workflows.",1900,observability|monitoring|dashboards|prometheus|grafana-alternative|gitops|kubernetes|golang,4,"This repository primarily provides an observability visualization/dashboard application (and related SDKs/CLI) for metrics, logs, traces, and profiles, rather than an ML or data-science library. It can be indirectly useful to ML/data teams for monitoring ML infrastructure and services (e.g., instrumenting training/serving systems and building operational dashboards), but it does not provide ML modeling, training, feature engineering, or dataset tooling. Its relevance is therefore infrastructure-oriented and situational, leading to an indirect-utility score rather than a core ML/data score.",success
https://github.com/barter-rs/barter-rs,barter-rs,"Barter is an open-source ecosystem of Rust crates for building high-performance, event-driven algorithmic trading systems, supporting live trading, paper trading, and backtesting. It includes a modular trading engine plus components for market data streaming, execution, instruments, and low-level REST/WebSocket integrations.",1808,rust|algorithmic-trading|quantitative-finance|backtesting|event-driven-architecture|websocket|tokio,4,"This repository primarily targets algorithmic trading system development (live/paper trading and backtesting), providing an event-driven engine plus integrations for streaming market data and executing orders. It is relevant to data/ML workflows mainly as infrastructure for collecting time-series market data and running research/backtests, but it does not provide core ML modeling, training, or feature engineering tools. Community traction appears solid for a specialized Rust trading framework (about 1.8k stars), but its direct applicability to mainstream ML engineering is limited compared to dedicated data/ML libraries, so a mid-low score is appropriate.",success
https://github.com/enarjord/passivbot,passivbot,Passivbot is a cryptocurrency perpetual-futures trading bot written in Python and Rust that automates placing/canceling limit orders as a contrarian market-making system. It includes fast backtesting via a shared Rust orchestrator and an evolutionary optimizer to search for better strategy configurations.,1800,cryptocurrency|algorithmic-trading|trading-bot|market-making|backtesting|optimization|python|rust,4,"This repository primarily implements an automated crypto derivatives trading bot (live trading plus backtesting and parameter optimization), not an ML library or dataset. It is somewhat relevant to data/ML workflows because it provides large-scale backtesting and an evolutionary (non-ML) optimization loop that resembles hyperparameter search, which can be useful for quantitative research and experiment automation. However, it does not center on model training/inference, common ML frameworks, or general-purpose data science tooling, so its applicability to typical ML pipelines is limited.",success
https://github.com/keptn/keptn,keptn,"Keptn is a cloud-native, event-based control plane for continuous delivery and automated operations, focused on SLO-driven multi-stage delivery, monitoring, and remediation. This repository contains Keptn v1, which was archived (read-only) after reaching end-of-life in December 2023.",1800,DevOps|CI/CD|Kubernetes|SRE|SLO|continuous-delivery|cloud-native|observability,4,"This repository primarily provides an event-driven DevOps/SRE orchestration platform for automated delivery and operations (e.g., SLO-based quality gates and remediation) rather than an ML or data science library. It can be indirectly useful in ML workflows as infrastructure for deploying and operating ML services (MLOps-adjacent), but it does not provide model training, data processing, or ML-specific tooling as its core focus. Its archival/EOL status further reduces practical value for new ML/data projects, supporting a below-mid relevance score.",success
https://github.com/microsoft/vscode-mssql,vscode-mssql,"Official Microsoft MSSQL (SQL Server) extension for Visual Studio Code, providing a modern SQL development experience including connection management, query execution with results grids, IntelliSense, Object Explorer, schema/table designers, and query plan visualization (with optional AI-assisted features such as Copilot integration).",1800,visual-studio-code-extension|sql-server|azure-sql|database-tools|t-sql|developer-tools|intellisense,4,"This repository powers the VS Code MSSQL extension, primarily aimed at interactive SQL development and database management for SQL Server/Azure SQL (connections, editing, querying, object browsing, schema/table design, and execution plans). It can support data/ML workflows indirectly by making it easier to explore, query, and export data from SQL Server-based systems (often a data source in analytics/ML pipelines), but it is not an ML library or data-processing framework itself. Community adoption is solid for database developers, yet its ML-specific applicability is limited, so it scores as indirectly relevant rather than core to ML/data science.",success
https://github.com/rstudio/blogdown,blogdown,"An R package for creating websites and blogs using R Markdown, typically powered by the Hugo static site generator. It provides workflows/functions (e.g., new_site and serve_site) to build and preview sites with live reloading, supporting rich technical content like code, plots, citations, and math.",1800,r|rmarkdown|hugo|static-site-generator|website-generation|blogging|documentation,4,"blogdown is primarily a website/blog generator for R Markdown (often using Hugo) rather than an ML or data-processing library. It is indirectly relevant to ML/data workflows because it helps data scientists publish analyses, reports, and reproducible tutorials as websites, including embedded code and rendered outputs (plots/tables/widgets). Its adoption in the R data science community is strong, but it does not provide modeling, training, data pipelines, or MLOps functionality, so its ML/data value is mainly for communication and documentation.",success
https://github.com/variety/variety,variety,"Variety is a lightweight MongoDB schema analyzer that scans a collection and reports which keys exist, their observed data types, and how frequently they occur, helping you understand a dataset’s structure and identify outliers/rare fields.",1800,mongodb|schema-analysis|data-profiling|database-tools|javascript|nosql,4,"This repository provides a practical data-profiling utility for MongoDB collections (key frequency and type distribution) to quickly understand and audit semi-structured data. It can be useful in data science workflows as an exploratory step before feature engineering or building ETL/ELT pipelines, especially when inheriting messy MongoDB datasets. However, it is not an ML library or data-processing framework itself, and it does not integrate directly with common ML toolchains beyond helping characterize source data. Therefore it is indirectly relevant to ML/data work rather than a core ML/data tool.",success
https://github.com/ccxt/node-binance-api,node-binance-api,"An asynchronous Node.js SDK for interacting with the Binance API, providing broad REST endpoint coverage plus WebSocket streams for market data and trading. It supports Spot, Margin, Futures/Delivery features and includes conveniences like auto-reconnect WebSockets and configurable request options.",1700,javascript|nodejs|typescript|cryptocurrency|binance-api|trading|websockets,4,"This repository is primarily a Node.js client/SDK for Binance’s REST APIs and WebSocket market-data streams, aimed at building trading and market-data applications rather than ML tooling. It can be useful in data workflows to collect historical/streaming price data (candles, order book, trades) for downstream analysis, labeling, or model training, but it does not provide ML algorithms, feature engineering utilities, or model training/inference functionality itself. Community adoption appears solid for a crypto-exchange SDK (about 1.7k GitHub stars), which helps its integration potential for data collection in quant/ML pipelines. The score reflects indirect-to-moderate relevance: valuable as a data ingestion layer, but not a core ML/data science library.",success
https://github.com/syt123450/giojs,giojs,"Gio.js is an open-source, declarative 3D globe data-visualization library built with Three.js. It helps developers render interactive globe visualizations in modern web applications by adding datasets (e.g., arcs/points) via simple APIs.",1700,data visualization|3d graphics|webgl|three.js|javascript|geospatial|frontend,4,"This repository primarily provides a WebGL/Three.js-based library for building interactive 3D globe data visualizations in the browser, focused on presentation rather than modeling. It can be useful in ML/data workflows as a visualization layer for geospatial or network/flow datasets (e.g., displaying model outputs or aggregated data on a globe), but it does not offer ML algorithms, training, or data-processing pipelines. Its value for data science is therefore indirect: strong for communicating results visually, but not a core ML/data tool, which justifies a mid-low score.",success
https://github.com/OpenNebula/one,one,"OpenNebula is an open-source cloud and edge computing platform for building and managing enterprise clouds, supporting virtualization and orchestration of virtual machines and containerized workloads (e.g., KVM and LXC). It provides the core services and tooling to deploy, operate, and manage on-prem/private cloud infrastructure.",1600,cloud computing|private cloud|edge computing|virtualization|orchestration|KVM|LXC|DevOps,4,"This repository contains the OpenNebula cloud/edge platform used to provision and orchestrate compute resources (VMs/containers) and manage enterprise/private cloud infrastructure. It is not an ML or data-processing library, but it can be indirectly valuable for ML/data workflows by providing the infrastructure layer to run training/inference workloads on self-managed or sovereign clouds. The score is moderate because its primary purpose is cloud infrastructure management rather than ML tooling, though it can underpin MLOps environments and GPU/compute provisioning depending on deployment configuration.",success
https://github.com/c9s/bbgo,bbgo,"BBGO is a modern cryptocurrency trading-bot framework written in Go. It provides exchange integrations, built-in trading strategies, backtesting and parameter optimization tools, technical indicators, and optional web dashboard/notifications for running and developing automated trading systems.",1600,cryptocurrency|algorithmic-trading|trading-bot|backtesting|quantitative-finance|golang|technical-analysis|devops,4,"This repository is primarily a crypto trading-bot framework (strategy execution, exchange APIs, indicators, order execution, and backtesting), not an ML library. It can still be useful for data/ML workflows indirectly because it includes market data handling, indicator computation, and a backtesting/parameter optimization setup that can support data-driven research or feature generation. However, it does not appear focused on model training, MLOps, or integrating common ML frameworks, so its ML-specific direct applicability and adoption in the ML community are limited.",success
https://github.com/lidatong/dataclasses-json,dataclasses-json,"A Python library that adds convenient serialization/deserialization for Python dataclasses to and from JSON (and dicts), via a decorator or mixin. It supports nested dataclasses and common types (e.g., collections, datetime, UUID, Decimal) and offers optional schema-based validation.",1500,python|dataclasses|json-serialization|data-validation|marshmallow|typing,4,"This repository provides utilities to encode/decode Python dataclasses to/from JSON and dictionaries, including support for nested structures and optional schema-based validation, which is broadly useful in many Python applications. In ML/data workflows it’s commonly helpful for configuration objects, experiment metadata, dataset/model I/O wrappers, and API payloads, but it is not a data processing or ML-focused library itself. It has meaningful community adoption (notably ~1.5k GitHub stars), increasing its practical value as a general-purpose building block. The score reflects that it is indirectly relevant and frequently useful around ML systems, rather than being a core ML/data tool.",success
https://github.com/GongRzhe/Office-PowerPoint-MCP-Server,Office-PowerPoint-MCP-Server,"An MCP (Model Context Protocol) server that lets LLM clients create, edit, and manipulate PowerPoint (.pptx) files via Python (python-pptx), including slide/text/shape/image/table/chart operations and template-based styling/design tools.",1400,model-context-protocol|mcp-server|powerpoint|pptx|python|python-pptx|document-automation|data-visualization,4,"This repository’s primary purpose is PowerPoint automation through an MCP server, exposing many tools (e.g., slide management, text formatting, images, tables, and charts) for programmatic presentation generation and editing. It is not an ML/data library, but it can be useful in ML/data workflows for automating reporting deliverables (e.g., turning analysis results into decks with charts/tables) and integrating LLM-driven presentation generation into pipelines. Community adoption appears solid for an MCP tool (about 1.4k stars), but its relevance to ML is indirect rather than core, which is why it scores a 4/10.",success
https://github.com/Roibal/Cryptocurrency-Trading-Bots-Python-Beginner-Advance,Cryptocurrency-Trading-Bots-Python-Beginner-Advance,"A collection of Python scripts and example bots for automated cryptocurrency trading, focused on strategies like Binance triangular arbitrage and beginner/advanced trading-bot implementations. Includes supporting utilities for data collection and portfolio/fee tracking plus links to related tutorials/resources.",1400,cryptocurrency|algorithmic-trading|trading-bot|python|binance|arbitrage|ccxt,4,"This repository’s primary purpose is algorithmic crypto trading (e.g., Binance-focused bots and a triangular arbitrage implementation), plus some scripts for collecting/handling trading-related data. It is not an ML repository (no model training, evaluation, or MLOps focus), but it can be indirectly useful to ML/data workflows as a source of trading automation patterns and potentially as a starting point for building datasets from exchange APIs. The score reflects indirect relevance: helpful for data collection/engineering around market data, but not a core ML/data science library or widely adopted ML tool.",success
https://github.com/ai-for-developers/awesome-ai-coding-tools,awesome-ai-coding-tools,"A curated “awesome list” of AI-powered coding tools for developers, organized into categories like AI code editors/assistants, code completion, coding agents, natural-language-to-code tools, documentation, DevOps, security, and more. It serves as a directory to discover and compare tooling rather than a runnable software package.",1400,developer tools|AI coding assistants|LLMs|code generation|IDE extensions|code review|DevOps,4,"This repository is primarily a curated list of AI coding tools (editors, agents, completions, and related developer utilities) rather than an ML/data library or dataset. It can still be useful to ML/data practitioners indirectly by helping them discover tools that speed up coding in notebooks, pipelines, and MLOps work (e.g., items like Jupyter AI and general LLM-based coding agents). The score is moderate-low because it doesn’t provide ML algorithms, training code, or data assets, and its main value is as a reference catalog for software development tooling rather than data science specifically.",success
https://github.com/clusternet/clusternet,clusternet,"Clusternet is a CNCF Sandbox open-source Kubernetes add-on for multi-cluster management and governance, letting you manage and access many Kubernetes clusters (public/private/hybrid/edge) from a single “hosting/management” cluster. It also supports coordinating application deployments across clusters (including Kubernetes resources, CRDs, and Helm charts) with scheduling and override mechanisms, plus a kubectl plugin/CLI and client-go integration.",1400,kubernetes|multi-cluster-management|cloud-native|devops|container-orchestration|cluster-scheduling|helm,4,"This repository primarily provides Kubernetes multi-cluster management, governance, and cross-cluster application coordination (scheduling, overrides, and deployment distribution) rather than ML or data science functionality. It is indirectly relevant to ML/data workflows because MLOps teams may use multi-cluster Kubernetes control planes to run training/inference workloads across environments (cloud/edge) and standardize deployments. However, it does not include ML frameworks, data processing libraries, or model tooling; its value is infrastructural and workflow-enabling rather than ML-specific, leading to a moderate/indirect score.",success
https://github.com/compose/transporter,compose/transporter,"Transporter is a Go-based tool for syncing and transforming data between persistence engines (databases/files/queues), similar to lightweight ETL. It supports configurable source/sink adaptors, optional JavaScript-based transforms in the pipeline, and (for some adaptors) a tailing mode to keep destinations in sync with ongoing changes.",1400,ETL|data engineering|database migration|data replication|Go|MongoDB|PostgreSQL|Elasticsearch,4,"This repository provides an ETL-like data movement and transformation pipeline for operational data stores (e.g., MongoDB/PostgreSQL and other adaptors) and can be used for migrations or ongoing sync. It can be useful in ML/data workflows indirectly—primarily as infrastructure to move data into/out of systems that may feed analytics or feature generation—but it is not an ML library and does not target model training, evaluation, or MLOps. Community adoption appears moderate (about 1.4k stars), but the repo is archived and read-only (archived Oct 17, 2023), which reduces practical value for new ML/data projects compared to actively maintained pipeline tools.",success
https://github.com/rulego/rulego,rulego,"RuleGo is a lightweight, high-performance embedded rule engine and component-orchestration framework for Go. It uses configurable “rule chains” and reusable components to route, transform, filter, enrich, and distribute messages/events, supporting dynamic updates and integrations (e.g., HTTP/MQTT/Kafka endpoints) for IoT, automation, workflow, and data-integration scenarios.",1400,golang|rule-engine|workflow-orchestration|iot|edge-computing|event-processing|integration-platform|low-code,4,"RuleGo’s primary purpose is a Go-based rule-chain/component orchestration engine for routing and processing events/messages and integrating with external systems and protocols, not an ML library. It can be useful in data/ML systems as an integration and automation layer (e.g., orchestrating data collection, preprocessing, routing to services, or triggering actions), especially in IoT/edge and workflow contexts. However, it does not provide core ML capabilities (model training, feature engineering, inference frameworks) and its adoption is not specifically concentrated in the ML/data community, so its relevance is indirect rather than central.",success
https://github.com/wondertrader/wtpy,wtpy,"wtpy is the Python sub-framework for the WonderTrader quantitative trading system, providing Python interfaces/wrappers to WonderTrader’s C++ core for backtesting, live trading, data components, monitoring services, and related utilities (e.g., analyzers and optimizers).",1400,quantitative-trading|algorithmic-trading|backtesting|python|finance|trading-infrastructure|data-engineering,4,"This repository primarily targets quantitative trading workflows (strategy development, backtesting, live execution, data tooling, and monitoring) by exposing WonderTrader’s C++ trading/backtest engines via Python wrappers. It can support ML/data workflows indirectly (e.g., generating labeled market/strategy datasets, running large-scale backtests for feature/alpha research, and integrating outputs into ML pipelines), but it is not an ML library and does not focus on model training/inference. Community adoption appears meaningful within its niche (about 1.4k GitHub stars), but it’s not broadly adopted in the general ML ecosystem, which keeps the score in the indirect-relevance range.",success
https://github.com/cisagov/LME,LME,"CISA’s Logging Made Easy (LME) is an open-source platform for centralized log collection, threat detection, and real-time alerting aimed at small to medium-sized organizations. It integrates components from Elastic and Wazuh (with alerting via ElastAlert) and provides automated deployment tooling (e.g., Ansible) plus dashboards for visualization.",1300,cybersecurity|SIEM|log-management|threat-detection|Elastic Stack|Wazuh|ElastAlert|Ansible,4,"This repository is primarily a security operations/log management platform (SIEM-like) that centralizes logs and provides detection and alerting, rather than a machine learning or data science library. It can be indirectly useful to ML/data workflows because it helps collect, normalize, and store high-volume security telemetry that could later be used for analytics or anomaly detection models, but ML is not the core focus. Community adoption appears solid for a government-maintained security tool (e.g., ~1.3k stars and active releases), yet it does not provide ML frameworks, model training code, or data-science-first APIs, which keeps the score in the “indirect relevance” range.",success
https://github.com/dbrojas/optlib,optlib,"A Python library for pricing financial options using closed-form models (Black-Scholes/GBS variants) and approximations for products like American, Asian, spread, FX, and commodity options. It also includes implied volatility calculators and an API module to fetch option chains and historical market data via the TDAmeritrade API.",1300,quantitative finance|options pricing|derivatives|python|black-scholes|implied volatility|greeks|market data API,4,"This repository is primarily a quantitative finance library focused on closed-form option pricing formulas and implied-volatility calculations, plus utilities to fetch option chains/historical data from the TDAmeritrade API. While it is not an ML library, it is relevant to data/ML workflows in finance as a source of engineered features (e.g., IV/Greeks) and as a data-access helper for building datasets. Community adoption appears moderate (about 1.3k GitHub stars) but it is not a standard ML/data ecosystem dependency, so it scores as indirectly relevant rather than core.",success
https://github.com/fjb040911/free-sqlite,free-sqlite,"A free, open-source VS Code extension for exploring and querying SQLite database files. It provides a table explorer and data viewer, SQL auto-completion with error output, favorites for frequently used queries, and export of query results to Excel/CSV.",1300,sqlite|vscode-extension|sql|database-tools|typescript|data-exploration|developer-tools,4,"This repository is a VS Code extension focused on interactive SQLite database browsing and SQL query authoring (table explorer, query editor with auto-complete and error logs, favorites, and result export). It is not an ML library, but it can be useful in data workflows because SQLite is commonly used for storing datasets/features and for quick exploratory analysis, and exporting results to CSV/Excel supports downstream ML/data processing. Community adoption appears moderate based on the GitHub star count, but the primary value is as a developer productivity tool rather than a dedicated ML/data science framework, which is why it scores in the indirect-relevance range.",success
https://github.com/bitcoinvsalts/node-binance-trader,node-binance-trader,"Node Binance Trader (NBT) is a Node.js framework for developing crypto trading strategies and managing a portfolio on Binance, including data collection into Postgres, signal generation, auto-trading, and backtesting. The repository is archived and not maintained anymore.",1200,cryptocurrency|trading-bot|binance-api|nodejs|typescript|backtesting|postgresql|algorithmic-trading,4,"This repository is primarily an algorithmic trading and portfolio-management framework for Binance, offering market-data ingestion (candles/order book/trades) into Postgres, strategy signal detection, auto-trading, and backtesting. It can be useful to data/ML practitioners as a data-collection and experimentation scaffold for market microstructure datasets and feature engineering, but it is not an ML library and does not include core model training tooling. Because it’s archived (not maintained) and its ML relevance is indirect (enabling data capture/backtests rather than providing ML workflows), it scores as moderately/indirectly relevant.",success
https://github.com/janarosmonaliev/github-globe,github-globe,"A Three.js-based recreation of the animated globe from GitHub’s homepage, using three-globe with custom lighting/shading and optional data arcs for visualization (e.g., flight routes). Includes a live demo and webpack-based build/dev workflow.",1200,threejs|webgl|3d-graphics|data-visualization|globe-visualization|javascript|webpack,4,"This repository primarily implements an interactive 3D globe visualization in the browser using Three.js/three-globe, focusing on rendering, shading, and displaying arcs/points on a globe. It can be useful in data workflows indirectly as a front-end visualization component for geo/graph-like datasets, but it does not provide ML models, training code, data processing pipelines, or MLOps functionality. Community adoption appears moderate (about 1.2k stars), suggesting some practical value, but its relevance to ML is mainly for presentation rather than analysis—hence a 4/10.",success
https://github.com/michaelchu/optopsy,optopsy,"Optopsy is a Python library for backtesting and computing performance statistics for options trading strategies using options chain datasets. It generates strategy combinations (e.g., long calls/puts, straddles/strangles, vertical spreads) and returns results in Pandas-friendly outputs for analysis.",1200,options|quant-finance|backtesting|algorithmic-trading|python|pandas|statistics,4,"This repository is primarily a quantitative finance backtesting/statistics toolkit for options strategies, producing analytical outputs (typically Pandas DataFrames) from options chain data rather than training ML models. It can support ML/data workflows indirectly by helping generate features, labels, or historical performance summaries for modeling, but ML is not its core purpose and it does not appear to focus on ML frameworks or MLOps. Community adoption is moderate (about 1.2k stars), which supports usefulness, but its domain is specialized to options backtesting rather than general data science.",success
https://github.com/51bitquant/bitquant,bitquant,"A Python cryptocurrency quantitative trading codebase associated with 51bitquant’s tutorial videos, including examples for exchange data crawling, CCXT-based trading (spot/futures), basic backtesting, and technical indicators across multiple exchanges (e.g., Binance/Bybit/Huobi). It appears to be a collection of learning/demo modules and trading-bot components rather than a single packaged library.",1100,cryptocurrency|quantitative trading|trading bot|python|ccxt|backtesting|market data,4,"This repository focuses on cryptocurrency quant trading utilities and educational code (exchange APIs/CCXT usage, data crawling, backtesting folder, and technical indicators), which can support data acquisition and time-series analysis workflows. However, it is not primarily an ML repository (no clear emphasis on model training, feature pipelines for ML, or ML frameworks), and it looks more like scripting/tutorial code than a widely adopted data-science package. It is moderately useful for data work in trading (collecting OHLCV/trades, indicator computation, and simple research/backtests), but only indirectly relevant to ML model development, so a mid-low score is appropriate.",success
https://github.com/chiphuyen/sniffly,sniffly,"Sniffly is a local analytics dashboard for analyzing Claude Code logs, helping users understand usage patterns, inspect message history, and break down errors. It also supports generating opt-in shareable dashboards with configurable privacy options.",1100,ai developer tools|analytics dashboard|claude-code|python|cli|observability|agent tooling,4,"This repository provides a Python-based CLI and dashboard to analyze Claude Code usage logs, offering usage statistics, message history analysis, and error breakdowns. It is relevant to ML/AI practitioners mainly as an operational analytics/observability tool for AI coding-agent workflows rather than a data science or model-training library. While it can support AI/ML engineering productivity and debugging by surfacing patterns and failures, it does not directly provide ML modeling, datasets, training, or core data-processing capabilities, so its value to ML/data workflows is indirect and moderate.",success
https://github.com/cipher387/python-for-OSINT-21-days,python-for-OSINT-21-days,"A beginner-friendly “Python for OSINT” 21-day course repository containing a downloadable PDF course and day-by-day folders with sample Python code for common OSINT and investigation tasks (APIs, scraping, files, automation, visualization, Wayback Machine, etc.). It also includes guidance for running the course environment via GitHub Codespaces.",1100,OSINT|python|web-scraping|API-clients|data-collection|investigation-workflows|education,4,"This repository is primarily an educational OSINT course with a PDF and daily Python examples covering practical data collection tasks like HTTP requests/APIs, scraping, JSON/CSV handling, and basic visualization. It can be useful to data practitioners as a lightweight reference for gathering and cleaning open-source data, but it is not an ML-focused library (no model training, ML frameworks, or MLOps components). Its value for ML/data workflows is indirect—helpful for sourcing and preprocessing data rather than building machine learning systems—so a mid-low score is appropriate.",success
https://github.com/cloudflare/agents-starter,agents-starter,"A starter template for building AI-powered chat agents on Cloudflare’s Agents platform (powered by the `agents` npm package), including a modern React chat UI and an extensible tool system. It supports streaming responses, chat state/history, human-in-the-loop tool confirmations, and advanced task scheduling (one-time, delayed, and cron-based).",1100,ai-agents|cloudflare-workers|durable-objects|typescript|react|chat-ui|tool-calling|llm-applications,4,"This repository is primarily a Cloudflare Workers starter kit for building LLM-powered chat agents with a UI, tool integration, and scheduling—i.e., it’s focused on agent application scaffolding rather than data science or model development. It can still be useful for ML engineers as an application layer to deploy and operate LLM-based agents (including tool calling and provider swapping), and it even cites a “data analysis assistant” as an example use case, but it does not provide datasets, training code, evaluation pipelines, or core ML algorithms. Community adoption appears solid for an app template (about 1.1k GitHub stars), but its value is more in deployment/app engineering than in ML/data workflows, so it scores as indirectly relevant.",success
https://github.com/e2nIEE/pandapower,pandapower,"pandapower is a Python library for convenient power system network modeling, analysis, and optimization using pandas-based data structures and MATPOWER/PYPOWER-compatible formats. It supports power flow and other grid studies with multiple solver backends (e.g., Newton-Raphson and several external solver integrations).",1100,power-systems|power-flow|grid-simulation|energy-systems|python|pandas|optimization|state-estimation,4,"This repository primarily provides a power grid modeling and analysis toolkit (e.g., power flow, short-circuit, state estimation) built around pandas data structures and power-system solvers, rather than an ML framework. It can be useful in data science workflows for generating, cleaning, simulating, and analyzing electrical-grid datasets (including synthetic data for ML tasks like anomaly detection or forecasting), but ML is not its main focus. Community adoption within the power/energy analytics ecosystem appears solid (notably ~1.1k stars and broad usage), supporting moderate indirect relevance to ML/data work. The score reflects strong DS adjacency via simulation + tabular data integration, but limited direct ML tooling.",success
https://github.com/sinall/StrategyEase-Python-SDK,StrategyEase-Python-SDK,"A Python SDK for StrategyEase (策略易), providing a wrapper around its HTTP RESTful API to automate trading actions and manage trading clients. Includes examples, tests, scheduled task tooling, and integrations for multiple Chinese quant platforms (e.g., JoinQuant, RiceQuant, Uqer, Guorn).",1100,python|quantitative-trading|algorithmic-trading|trading-api|fintech|rest-api|automation,4,"This repository is primarily an SDK for automated trading execution via StrategyEase’s REST API, including client management, order placement, and scheduled/batch trading tasks. It is relevant to data/ML workflows mainly as an execution/integration component (e.g., connecting signals from research or ML models to live/simulated trade placement), rather than providing data processing, modeling, or ML algorithms itself. Its usefulness for ML practitioners depends on whether they specifically need StrategyEase as an execution layer; it does not appear to be a broadly adopted general-purpose ML/data library. Therefore, it earns an indirect relevance score rather than a core ML/tooling score.",success
https://github.com/spring-cloud/spring-cloud-stream,spring-cloud-stream,"Spring Cloud Stream is a Spring-based framework for building message-driven, event-driven microservices. It provides opinionated configuration and “binder” implementations to connect Spring Boot applications to messaging systems such as Apache Kafka and RabbitMQ (and includes a Kafka Streams binder for native Kafka Streams types).",1100,java|spring-boot|spring-cloud|event-driven-architecture|messaging|apache-kafka|rabbitmq|microservices,4,"This repository provides infrastructure for event-driven/messaging-based microservices in the Spring ecosystem (binders for brokers like Kafka and RabbitMQ, plus Kafka Streams integration). It is not an ML library, but it can be useful in ML/data platforms for streaming ingestion, event transport, and building real-time data-processing microservices around models (e.g., feature/event pipelines and model serving workflows). The score is moderate because its value to ML/data work is indirect (infrastructure and integration rather than modeling/training), though it can be an important component in production data/ML architectures.",success
https://github.com/Azure/acs-engine,acs-engine,"Azure Container Service Engine (acs-engine) generates Azure Resource Manager (ARM) templates to deploy and customize Docker-enabled container clusters on Microsoft Azure (e.g., Kubernetes, DC/OS, OpenShift, Swarm). The repository is archived and deprecated in favor of Azure/aks-engine.",1000,DevOps|infrastructure-as-code|Azure|ARM-templates|Kubernetes|containers|cluster-provisioning|Go,4,"This repository is primarily an infrastructure/provisioning tool that generates ARM templates for deploying container orchestrator clusters on Azure, and it has been archived (read-only) as of January 11, 2023. It is not an ML or data-science library, but it can indirectly support ML/data workflows by helping teams provision Kubernetes clusters (including GPU-optimized VM sizes) that are often used for training and serving models. Because the repo is deprecated and its primary value is general cluster infrastructure rather than ML-specific functionality, it merits an indirect-relevance score rather than a high ML/data score.",success
https://github.com/Azure/aks-engine,aks-engine,"AKS Engine is a legacy/deprecated tool for deploying and managing self-managed Kubernetes clusters on Microsoft Azure. The repository is archived and read-only (archived Oct 24, 2023), with no further releases planned (Kubernetes 1.24 was the final version to receive updates) and guidance to use AKS or Cluster API Provider Azure instead.",1000,kubernetes|azure|devops|infrastructure-as-code|cluster-provisioning|containers|golang,4,"This repository’s primary purpose is Kubernetes cluster provisioning/management on Azure (a DevOps/infrastructure tool), and it is now deprecated and archived. It can be indirectly valuable for ML/data teams because it helped create/operate Kubernetes environments commonly used to run ML workloads and MLOps platforms, but it does not provide ML/data functionality itself. Given the indirect relevance plus its legacy/archived status and lack of ongoing releases, it merits a low-to-mid infrastructure relevance score rather than a core ML/data score.",success
https://github.com/Rikj000/MoniGoMani,MoniGoMani,"MoniGoMani (MGM) is an experimental Freqtrade framework/strategy for algorithmic crypto trading that uses “weighted signals” and a HyperOpt-driven optimization workflow to tune indicator weights and thresholds for different market regimes (down/side/up trends). The repository includes strategy code, configuration/user_data, documentation, tests, and tooling/scripts to help install and run the framework.",1000,algorithmic trading|crypto trading|freqtrade|python|technical analysis|hyperparameter optimization|quant finance,4,"This repository’s primary purpose is automated crypto trading with Freqtrade, focusing on technical-analysis indicators combined via a weighted-signal mechanism and then tuned via Freqtrade HyperOpt. While it involves optimization and experimentation over time-series market data, it is not a general ML/data-science library and does not center on training predictive models (it’s closer to rule-based/indicator-based strategy tuning). It can still be useful to data/ML practitioners interested in time-series backtesting, parameter search, and systematic strategy evaluation, but community adoption appears more niche than core ML tooling and the repo is archived/read-only.",success
https://github.com/d4t4x/data-selfie,data-selfie,"Data Selfie is a Chrome/Firefox browser extension that tracks your Facebook activity locally (e.g., what you view/interact with and time spent) and lets you inspect/analyze that data via a personal dashboard. It’s positioned as a “monitor your monitoring” privacy tool to help users understand what data can be inferred from their behavior.",1000,browser-extension|privacy|facebook|data-tracking|data-analysis|dashboard|javascript,4,"This repository primarily implements a privacy-focused browser extension that collects and visualizes a user’s Facebook browsing/interaction data and stores it locally. It’s related to data workflows in that it creates a personal behavioral dataset and provides analysis/dashboard capabilities, but it is not an ML library or a general-purpose data-science toolkit. Data scientists could repurpose the collected data for exploratory analysis or experimentation, yet the project’s core value is user privacy awareness rather than reusable ML/data infrastructure or modeling.",success
https://github.com/dbos-inc/dbos-transact-ts,dbos-transact-ts,"DBOS Transact is an open-source TypeScript/Node.js library for Postgres-backed durable execution: it lets you define workflows/steps and durable queues that automatically checkpoint to Postgres and resume after process crashes, without requiring a separate workflow orchestrator.",1000,typescript|nodejs|workflow-orchestration|durable-execution|postgresql|task-queue|background-jobs|opentelemetry,4,"This repository provides infrastructure primitives (durable workflows, steps, and Postgres-backed queues) for building reliable TypeScript/Node.js backends that can recover from failures by resuming from persisted checkpoints. It is not an ML library, but it can be useful in ML/data workflows for reliably running data pipelines, long-running jobs, or AI-agent-like tasks that need retries, exactly-once-ish execution patterns, and observability. The score reflects indirect relevance to ML/data engineering (workflow reliability and orchestration) rather than direct modeling/training functionality, with moderate adoption (~1k GitHub stars) primarily in general backend engineering rather than the ML community.",success
https://github.com/AlgoTrading101/Backtesting.py-AlgoTrading101,Backtesting.py-AlgoTrading101,"A small companion repository (Jupyter notebook + README) that introduces and demonstrates how to use the Backtesting.py Python library to backtest algorithmic trading strategies, linking to an AlgoTrading101 guide.",19,python|jupyter-notebook|algorithmic-trading|backtesting|quantitative-finance|trading-strategies,4,"The repository is primarily an educational/demo resource for backtesting trading strategies in Python using Backtesting.py, rather than a dataset, ML library, or modeling framework. It is relevant to data science workflows because it involves time-series financial data handling, performance evaluation, and systematic experimentation/optimization—common adjacent tasks for quant researchers. However, it does not appear to provide ML-specific components (e.g., feature engineering pipelines, model training/inference, or MLOps integration), so its direct ML utility is limited.",success
https://github.com/sindresorhus/awesome,awesome,"A curated index of ""awesome lists""—high-quality, community-maintained lists of resources across many software and technology topics. It serves as a central directory to discover specialized awesome-* repositories and learning/resources by category.",428000,awesome-lists|curated-resources|developer-resources|open-source|community|learning,3,"This repository is primarily a meta-directory that curates links to ""awesome"" resource lists across many domains, rather than a library, dataset, or ML tool. It can still be useful to ML/data practitioners as a discovery hub for ML-, data-, and big-data-related awesome lists and educational resources (indirect workflow value). Because it doesn’t provide ML functionality, code, datasets, or integrations directly, its applicability to ML/data work is tangential, leading to a low-but-nonzero score.",success
https://github.com/awesome-selfhosted/awesome-selfhosted,awesome-selfhosted,"A curated “awesome list” of free/open-source network services and web applications you can self-host on your own servers. It catalogs software across many categories and provides links, licenses, and platform/stack notes for each entry.",267000,self-hosting|open-source|awesome-list|DevOps|homelab|server-applications|infrastructure,3,"This repository is primarily a curated directory of self-hostable applications and services, organized by category, rather than a codebase for ML or data work. It can still be useful to ML/data practitioners indirectly by helping discover self-hosted infrastructure components (e.g., databases, analytics tools, monitoring, storage, workflow tools) that support data platforms. Because its value is mostly as a general-purpose software index and not an ML/data-specific tool or library, it merits a low-to-tangential relevance score.",success
https://github.com/MunGell/awesome-for-beginners,awesome-for-beginners,"A curated list of beginner-friendly open-source projects and repositories, organized by programming language and tagged with labels like “good first issue” or “first-timers-only” to help newcomers find approachable first contributions.",81400,open source|beginner-friendly|first pull request|good first issue|curated list|community|GitHub,3,"This repository is primarily a curated directory of open-source projects that are welcoming to first-time contributors, rather than a library or tool for building data/ML systems. It can still be useful for ML/data practitioners as a discovery resource to find beginner-friendly issues in data-adjacent projects (and it even includes an “MLOps” section among many language categories). Because it doesn’t provide datasets, ML algorithms, or data tooling itself—and its value is indirect and educational/discovery-oriented—the relevance to ML/data workflows is tangential, leading to a score of 3.",success
https://github.com/strapi/strapi,strapi,"Strapi is a leading open-source headless CMS built with JavaScript/TypeScript for building and managing content APIs. It provides a customizable admin panel, plugin system, and supports REST/GraphQL with multiple databases for self-hosted or cloud deployments.",70900,headless cms|javascript|typescript|nodejs|api|graphql|content management|web development,3,"This repository is the core codebase for Strapi, a headless CMS used to model content types and expose them via REST and/or GraphQL APIs, with an extensible admin UI and plugin ecosystem. It is not an ML/data-science library, but it can support data/ML workflows indirectly as a backend for collecting, managing, labeling, and serving datasets or metadata through APIs. The score is low because its primary purpose is web content management rather than data processing/modeling, though its API-first design and broad adoption can make it useful infrastructure in some ML-adjacent systems.",success
https://github.com/rust-unofficial/awesome-rust,awesome-rust,"A curated “awesome list” of Rust libraries, tools, applications, and learning resources, organized by topic. It serves as a discovery index for the Rust ecosystem rather than a single software package.",54900,rust|awesome-list|curated-resources|developer-tools|rust-libraries|ecosystem-index,3,"This repository is primarily a curated directory of Rust codebases and resources across many domains, not an ML/data-focused toolkit itself. It does include categories relevant to ML/data workflows (e.g., machine learning, data processing, data visualization, MLOps), which can help practitioners discover Rust options for those needs. However, because it is a general ecosystem index (not a library/framework, dataset, or ML pipeline tool), its direct applicability to day-to-day ML engineering is limited, so a low-but-not-zero score is appropriate.",success
https://github.com/pixijs/pixijs,pixijs,"PixiJS is an HTML5 2D rendering/creation engine for building rich, interactive graphics and applications on the web. It provides high-performance WebGL and WebGPU renderers plus features like asset loading, text rendering, input handling, drawing primitives/SVG, masking, filters, and blend modes.",46400,javascript|typescript|webgl|webgpu|2d-rendering|graphics|game-development|data-visualization,3,"This repository is primarily a high-performance 2D graphics/rendering engine for web applications (e.g., interactive visuals, games, creative coding) using WebGL/WebGPU rather than a machine learning or data-science toolkit. It can be useful in ML/data workflows only indirectly—for example, building interactive visualizations, annotation tools, or model demos in the browser—but it does not provide ML algorithms, training, inference, or typical data pipeline functionality. The strong community adoption and solid developer ecosystem help, but its relevance to ML/data tasks remains tangential, so it scores low.",success
https://github.com/gchq/CyberChef,CyberChef,"CyberChef is a browser-based ""Cyber Swiss Army Knife"" for performing a wide range of data transformations and analysis tasks, including encoding/decoding, encryption/decryption, hashing, compression, parsing, and file/byte-level manipulation via drag-and-drop ""recipes"" of operations.",33700,cybersecurity|digital-forensics|data-transformation|cryptography|encoding-decoding|web-application|javascript|reverse-engineering,3,"CyberChef is primarily a cybersecurity/forensics utility for transforming and analyzing arbitrary text/binary data (e.g., decoding, decrypting, hashing, parsing) through a browser-based workflow. It can be useful in data/ML workflows only indirectly—for example, to quickly inspect, decode, or normalize datasets and logs before ingestion or to reverse engineer unknown encodings—but it is not designed for statistical analysis, model training, feature engineering at scale, or MLOps. Community adoption is strong in security and incident response, but limited in core ML/data science contexts, so it scores as tangentially relevant.",success
https://github.com/mxgmn/WaveFunctionCollapse,WaveFunctionCollapse,"Reference implementation of the Wave Function Collapse (WFC) algorithm for procedural bitmap and tilemap generation, producing outputs that are locally similar to a given example image via constraint propagation and entropy-driven collapse.",24500,procedural-generation|wave-function-collapse|constraint-satisfaction|tilemap-generation|image-synthesis|C#|game-development,3,"This repository primarily implements a procedural content generation algorithm (Wave Function Collapse) to synthesize new bitmaps/tilemaps from example inputs using constraint propagation and an entropy-based selection heuristic. It is not an ML library and does not provide model training, statistical learning, or integration with common ML/data tooling, but it is conceptually adjacent to generative methods and can be educational for understanding constraint-based generation and probabilistic sampling. Data scientists might use it for experimentation with generative ideas or as a component in simulation/content pipelines, but it is not directly applicable to typical ML workflows (training, evaluation, deployment).",success
https://github.com/TheAlgorithms/C,TheAlgorithms/C,A community-maintained collection of educational implementations of many classic algorithms and data structures written in C. It covers topics across computer science and applied math (including some ML-related examples) with accompanying documentation and tooling for building/testing.,21600,c|algorithms|data-structures|computer-science-education|numerical-methods|machine-learning-examples,3,"This repository’s primary purpose is educational: it provides reference implementations of a wide range of algorithms and data structures in C, organized by topic (including a small ""machine_learning"" section). While some included algorithms can be relevant to ML/data work (e.g., optimization, statistics, numerical methods), the repo is not an ML framework, data-processing toolkit, or workflow-integrated library. Its main value for ML/data practitioners is conceptual learning and low-level reference code rather than direct, production-ready ML/data science usage, so it scores as tangentially related.",success
https://github.com/yjs/yjs,yjs,"Yjs is a JavaScript CRDT framework that provides shared data types (e.g., Array, Map, Text/XML) for building real-time collaborative applications. It supports offline-first collaboration, conflict-free merging, undo/redo, awareness/cursors, and integrates with multiple network “providers” (e.g., WebSocket/WebRTC) via separate modules.",20794,crdt|real-time-collaboration|collaborative-editing|local-first|offline-first|javascript|distributed-systems,3,"This repository’s primary purpose is real-time, conflict-free collaboration using CRDT-based shared data structures, not machine learning or data science. It can be indirectly useful in ML/data workflows where teams need collaborative annotation, shared notebooks/notes, or synchronized UIs for data labeling and review, but it does not provide ML algorithms, data processing primitives, or integrations with common ML frameworks. Community adoption is strong in collaborative app development, yet its relevance to ML is mostly tangential, so it scores low but not zero.",success
https://github.com/MaaAssistantArknights/MaaAssistantArknights,MaaAssistantArknights,"MAA (MAA Assistant Arknights) is an automation assistant for the game Arknights that uses image recognition to perform daily tasks with one click across multiple clients/regions. It includes features like automated battles with drop recognition/upload, base/roster management assistance, recruitment automation, and provides multiple language/API interfaces for integration.",19200,game automation|computer vision|image recognition|C++|RPA|desktop application|Arknights,3,"This repository is primarily a game automation tool for Arknights, centered on image recognition and UI automation to complete repetitive in-game tasks. While it likely involves computer-vision techniques and could be educational for practical screen/UI recognition and automation patterns, it is not designed as a general ML/data science library or workflow component. Its applicability to ML/data work is mostly indirect (as a reference implementation for vision-driven automation rather than a reusable ML framework), so it scores low but not zero.",success
https://github.com/mikeroyal/Self-Hosting-Guide,Self-Hosting-Guide,"A continuously updated, extensive self-hosting knowledge base and getting-started guide covering how to run and manage applications on your own infrastructure (on‑prem/private servers). It catalogs tools, platforms, and workflows across areas like containers, virtualization, networking, security, cloud, automation, and even LLM/self-hosted AI-related topics.",18200,self-hosting|DevOps|homelab|Docker|Kubernetes|networking|privacy-security|LLMs,3,"This repository is primarily a broad self-hosting reference guide (a curated, continuously updated documentation hub) rather than an ML or data-science library. It can still be indirectly useful to ML/data practitioners by pointing to infrastructure components relevant to ML deployments (e.g., containers, Kubernetes, networking, storage, and sections mentioning LLMs and machine learning), which can support MLOps-style workflows. However, it does not provide datasets, model code, training pipelines, or ML-specific tooling as its main purpose, so its direct applicability to ML/data work is limited compared to dedicated ML/MLOps repositories.",success
https://github.com/mahmoud/awesome-python-applications,awesome-python-applications,"A curated, continuously updated “awesome list” of real-world open-source Python applications, organized by category and generated from structured YAML data. It’s intended as a set of production-grade case studies for learning how successful Python apps are built and shipped.",17700,awesome-list|python|open-source|curated-resources|application-examples|developer-resources|software-architecture,3,"This repository is primarily a curated catalog of open-source Python applications (a reference list), not a library or framework that implements ML/data functionality. It includes an AI/ML section, but ML is not the main focus, and the repo itself doesn’t provide data tooling, models, or ML pipelines—rather it points to external projects. It can still be mildly useful to ML/data practitioners as a discovery/learning resource for production application patterns and for finding a few ML-related apps, but its direct applicability to ML workflows is limited, so a low-to-tangential score is appropriate.",success
https://github.com/hummingbot/hummingbot,hummingbot,"Hummingbot is an open-source framework for creating and running automated (high-frequency) cryptocurrency trading bots across many centralized and decentralized exchanges. It provides configurable strategies, exchange/DEX connectors (including an optional Gateway middleware for AMM DEX access), and Docker-based deployment workflows.",15600,cryptocurrency|algorithmic-trading|trading-bot|quant-finance|python|docker|defi,3,"This repository’s primary purpose is automated crypto trading (strategy execution, exchange/DEX connectivity, and deployment tooling), not machine learning. While data scientists could use it indirectly for market data collection, backtesting-like experimentation, or to integrate ML-based signals into trading strategies, ML is not the core focus and there are no central ML training/inference components. Community adoption appears strong for trading-bot use (15.6k GitHub stars), but it is not widely known as an ML/data platform, so it earns a tangential relevance score.",success
https://github.com/CesiumGS/cesium,cesium,CesiumJS is an open-source JavaScript library for building interactive 3D globes and 2D maps in the browser. It uses WebGL for hardware-accelerated rendering and is designed to visualize dynamic geospatial data and scale to large datasets using open formats.,14700,geospatial|3d-mapping|webgl|javascript|data-visualization|3d-globe|gis,3,"This repository primarily provides a WebGL-based geospatial visualization engine (3D globe and 2D map rendering) for web applications, rather than ML or data-processing tooling. It can support ML/data workflows indirectly by enabling visualization of model outputs (e.g., geospatial predictions, trajectories, 3D/terrain overlays) and exploration of large spatial datasets, but it does not include model training, feature engineering, or common ML pipeline components. Community adoption is strong in GIS and 3D mapping, but its relevance to ML engineering is mostly as a front-end visualization layer, so a low-to-tangential score is appropriate.",success
https://github.com/invertase/react-native-firebase,react-native-firebase,"A feature-rich, modular Firebase implementation for React Native that provides JavaScript wrappers around the native Firebase SDKs for iOS and Android. It offers many Firebase service modules (e.g., Auth, Firestore, Messaging, Analytics) with strong TypeScript support and extensive testing/documentation.",12200,react-native|firebase|mobile-development|android|ios|typescript|monorepo,3,"This repository primarily provides React Native modules for integrating Firebase services into mobile apps, acting as a JS layer over the native Firebase SDKs for iOS and Android. While it includes Firebase components that can support data-centric and analytics workflows (e.g., Analytics, Firestore/Realtime DB, and an ML-related module), it is not an ML/data science library and is mainly used for app development rather than model training, data processing, or MLOps. Its relevance to ML/data work is therefore tangential—useful as an integration surface for data collection/storage or serving results in mobile apps, but not directly for building ML pipelines or doing data science.",success
https://github.com/openreplay/openreplay,openreplay,"OpenReplay is an open-source, self-hostable session replay suite for web applications that lets you watch user sessions and inspect technical context (e.g., network activity, console logs, JS errors, performance metrics) to reproduce bugs and analyze product usage. It also includes related tooling such as cobrowsing/support features and product analytics capabilities.",11600,session replay|product analytics|observability|frontend monitoring|web debugging|self-hosted|user behavior analytics,3,"This repository’s primary purpose is session replay and product analytics for web apps (capturing user interactions plus technical telemetry to debug and improve UX), not machine learning. It can be tangentially useful for data workflows because it generates behavioral/telemetry data that could be exported and analyzed, but it does not provide ML models, training pipelines, or data-science-first tooling. Its strongest value is in engineering observability and product analytics rather than direct ML/data science implementation, so it scores low but not zero.",success
https://github.com/jnv/lists,jnv/lists,"A curated “list of lists” aggregating useful, fun, and “awesome-*” style resource lists hosted on GitHub and elsewhere. The repository is primarily a directory/README that helps people discover other curated collections, and it also provides the list in CSV form.",10900,curation|awesome-lists|resource-directory|github|open-source|knowledge-base,3,"This repository is a meta-curation index (a directory of links to other curated lists), not a software library or dataset-focused ML tool. It can still be mildly helpful to data scientists because it includes links that may point to ML/data-related “awesome” lists or resources, but it doesn’t provide ML code, models, benchmarks, or data processing functionality itself. Community adoption is solid for general discovery (high stars), yet its direct applicability to ML workflows is limited, so a low-but-nonzero score is appropriate.",success
https://github.com/openframeworks/openFrameworks,openFrameworks,"openFrameworks is a community-developed, cross-platform C++ toolkit for creative coding, providing a core framework plus examples, documentation, and add-ons for building interactive graphics, audio, and media applications.",10300,creative coding|C++|graphics|interactive media|computer vision|audio|cross-platform,3,"This repository provides the openFrameworks C++ creative-coding toolkit (core libraries, examples, docs, and add-ons) aimed at building interactive multimedia applications rather than ML/data workflows. It can be used alongside or to prototype sensor/vision-driven and visualization-heavy projects (including computer-vision style use cases), but it does not provide ML training/inference frameworks, data pipelines, or standard DS tooling out of the box. Because its relevance to ML/data is mostly indirect (as a visualization/interactive-app framework), it scores low-to-tangential for data science and machine learning value.",success
https://github.com/ThreeDotsLabs/watermill,watermill,"Watermill is a Go library for building message-driven/event-driven applications using a unified Pub/Sub and routing API. It supports multiple backends (e.g., Kafka, RabbitMQ, SQL/HTTP) and provides tooling for patterns like event sourcing, CQRS, sagas, and RPC over messages.",9400,golang|event-driven-architecture|messaging|pubsub|kafka|rabbitmq|cqrs|microservices,3,"This repository is primarily a Go messaging/event-driven application library (a 'standard library for messages') with Pub/Sub abstractions and routing/middleware patterns, intended for building distributed backend services rather than ML. It can be used in data/ML systems indirectly (e.g., to move events between data services, trigger feature updates, orchestrate pipeline steps, or integrate with queues/brokers), but it does not provide data science algorithms, model training, or ML-specific tooling. Community adoption appears strong for Go backend messaging, yet it is not specifically adopted as an ML/data library, so its value for ML/data workflows is tangential rather than direct.",success
https://github.com/GetStream/Winds,Winds,"Winds is an open-source RSS and podcast application with a React/Redux frontend and a Node.js (Express) backend. It includes features like RSS/podcast recommendations, integrated search, and feed/discovery functionality powered by Stream, with supporting services like Algolia search and MongoDB for storage.",9300,rss-reader|podcast|react|redux|nodejs|express|personalization|activity-feeds,3,"This repository primarily implements a consumer-facing RSS and podcast reader application, including discovery and recommendations, rather than providing reusable ML components or data tooling. While it mentions personalization/machine-learning-powered recommendations via Stream’s API, the repo itself is mainly full-stack web app code and integrations (React/Redux frontend, Node/Express backend, Algolia search, MongoDB). As a result, it has only tangential value to ML/data workflows (e.g., as an example product that consumes recommendation/personalization services) rather than a direct ML/data science toolkit.",success
https://github.com/flowable/flowable-engine,flowable-engine,"Flowable is a compact, efficient workflow and Business Process Management (BPM) platform. It provides a Java-based BPMN 2 process engine that can run embedded or as a standalone service, with rich Java and REST APIs and strong Spring integration.",9000,workflow|BPM|BPMN|process-engine|Java|Spring|REST API|orchestration,3,"This repository is primarily a workflow/BPM engine (BPMN-oriented) for orchestrating human and system activities in enterprise applications, not a machine learning or data science library. It can be tangentially useful in ML/data contexts for orchestrating data/ML pipelines (e.g., triggering jobs, approvals, and service integrations), but it is not designed around data processing, model training, or MLOps tooling. Because its direct applicability to ML/data workflows is limited and it is not adopted mainly by the ML/data community, it scores low-to-tangential on ML/data value.",success
https://github.com/ccxt/binance-trade-bot,binance-trade-bot,An automated cryptocurrency trading bot for the Binance exchange that cycles between a configured set of coins using a ratio-based strategy (typically via a bridge currency like USDT) and includes configuration options plus a backtesting script.,8600,cryptocurrency-trading|trading-bot|binance|algorithmic-trading|python|backtesting|docker,3,"This repository primarily implements an automated Binance crypto trading bot (plus configuration, deployment, and a backtesting script) rather than an ML or data-science library. It can be useful to data/ML practitioners as a practical source of market-data ingestion, backtesting scaffolding, and a baseline rule-based strategy to compare against learned strategies, but it does not provide model training, feature engineering, or MLOps components out of the box. Community adoption appears strong for a trading utility (high GitHub stars/forks), but its direct applicability to ML workflows is still mostly indirect, so it scores as tangential-to-indirect relevance.",success
https://github.com/digoal/blog,blog,"A large, continuously updated collection of technical articles and notes (primarily Markdown) focused on databases—especially PostgreSQL—covering performance tuning, internals, tooling, extensions, operations, and related topics (also including some AI and business notes). It functions as a knowledge base/blog repository rather than a traditional software library.",8338,postgresql|database|database-performance|sql|database-administration|data-engineering|technical-blog,3,"This repository is primarily a written knowledge base/blog (articles and notes) centered on databases—especially PostgreSQL—rather than an ML library, dataset, or training/inference tool. It can still be useful to data/ML practitioners indirectly because database design, SQL, and performance tuning are common dependencies in data engineering and ML data pipelines. However, it does not appear to provide ML-specific code, models, or reusable ML components as its core purpose, so its direct applicability to ML workflows is limited, resulting in a low-but-not-zero score.",success
https://github.com/jackzhenguo/python-small-examples,python-small-examples,"A curated collection of practical, bite-sized Python examples (in Chinese) covering common language features and everyday programming tasks, organized as many small “recipes” with links from the README.",8100,python|programming-examples|python-basics|educational|code-snippets|recipes|utilities,3,"This repository is primarily an educational collection of general-purpose Python mini-examples (operators, built-ins, functions, modules, and common coding patterns), rather than a focused ML or data-science toolkit. While data practitioners may find some examples indirectly useful for scripting and small utilities, it doesn’t provide ML algorithms, modeling workflows, datasets, or integrations with major ML frameworks. Community interest appears solid (thousands of stars), but the adoption is for learning Python broadly, not for data/ML-specific workflows—hence a tangential relevance score.",success
https://github.com/hellerve/programming-talks,programming-talks,"A curated, community-contributed list of recommended programming talks, primarily linking to external videos (often YouTube). The README organizes talks by programming language and broader CS/software “theory” topics (e.g., distributed systems, data science, machine learning).",7300,curated-list|awesome-list|software-engineering|programming-languages|computer-science|tech-talks|learning-resources,3,"This repository is primarily a curated index of links to programming and computer science talks, organized by language and topic, rather than a code library or dataset. It can be useful to ML/data practitioners as an educational resource because it includes sections like “Data Science” and “Machine Learning,” but it does not provide reusable ML tooling, data pipelines, or integrations. Community adoption (as indicated by stars) suggests it’s a popular general learning resource, yet its direct applicability to ML workflows is limited, so a low-but-nonzero score is appropriate.",success
https://github.com/mahmoud/boltons,boltons,"A collection of 230+ BSD-licensed, pure-Python utility modules intended to fill gaps in the Python standard library (e.g., iterutils/remap/backoff, file utilities, caches, queues, dict/multidict structures, and traceback helpers) with no external dependencies.",6800,python|utilities|standard-library|data-structures|json|data-science|statistics,3,"Boltons is primarily a general-purpose Python utility library (iterators, data-structure helpers, caching, file utilities, queues, etc.) rather than an ML or data-specific framework. It can still be useful in ML/data workflows as supporting infrastructure (e.g., iterable transformations, nested structure remapping, lightweight helpers for data handling), but it does not provide core ML capabilities like modeling, training, or data pipeline orchestration. Community adoption is strong for a utility library (thousands of stars and broad usage), yet its relevance to ML is mostly incidental, so it fits best as tangentially related.",success
https://github.com/lballabio/QuantLib,QuantLib,"QuantLib is a free/open-source C++ library providing a comprehensive framework for quantitative finance, including modeling, valuation/pricing, trading, and risk management of financial instruments. It includes extensive examples and testing infrastructure and serves as the core implementation behind multiple language bindings (via separate projects).",6600,quantitative finance|financial engineering|derivatives pricing|risk management|C++|numerical methods|library,3,"This repository is primarily a C++ quantitative finance library focused on instrument pricing, term structures, and risk/analytics rather than machine learning. It can support ML/data workflows indirectly (e.g., generating labels/prices/Greeks for datasets, building simulators for synthetic data, or serving as a benchmark pricer), but it is not an ML framework and does not provide model training, feature engineering, or MLOps components. Community adoption is strong in quant finance (as a pricing library), yet its direct applicability to day-to-day ML engineering is limited, so a low-to-tangential ML/data score is appropriate.",success
https://github.com/muesli/beehive,beehive,"Beehive is a modular event/agent automation system for creating “Bees” (agents) that react to events and trigger actions via pluggable integrations (“Hives”). It can connect services like RSS, email, chat/IRC, Jenkins, and Hue to build automated workflows through configurable chains, templates, filters, and triggers.",6500,automation|event-driven|workflow-orchestration|agents|golang|integrations|DevOps,3,"This repository is primarily an event-driven automation framework (written in Go) for wiring together integrations (“Hives”) and running agents (“Bees”) that react to triggers and execute actions. It is not designed for machine learning, data processing, or model training, and it does not provide ML-centric libraries or datasets. However, it can be tangentially useful in ML/data contexts as general automation glue (e.g., triggering jobs, notifications, or simple workflow steps), which justifies a low-but-nonzero score.",success
https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor,Claude-Code-Usage-Monitor,"A real-time terminal (CLI) monitoring tool for Claude Code usage that tracks token/cost consumption and session limits, and provides analytics plus predictive warnings about hitting plan quotas. It includes a Rich-based UI, plan auto-detection, configurable refresh rates, and an ML-inspired prediction approach (e.g., percentile-based limits) to estimate remaining usage.",6100,cli|terminal-ui|python|developer-tools|usage-monitoring|cost-tracking|anthropic-claude|observability,3,"This repository is primarily a developer productivity/observability CLI for monitoring Claude Code token and cost usage, with analytics and warning/prediction features rather than a library for building ML models. While it mentions ML-based predictions (e.g., percentile-based limit detection) and can be useful for tracking/optimizing LLM usage (a workflow adjacent to ML/AI engineering), it is not a core data-science/ML toolkit and doesn’t provide general-purpose data processing, modeling, or MLOps capabilities. Its value to ML practitioners is mostly operational (budget/usage monitoring) and educational (how to analyze usage patterns) rather than directly enabling model training or data science tasks.",success
https://github.com/Vedenin/useful-java-links,useful-java-links,"A curated, categorized list of useful Java frameworks, libraries, tools, and example projects (including “hello world” examples). It organizes links across many Java domains and includes extra metadata such as licenses and GitHub star information for referenced projects.",6100,java|awesome-list|curated-resources|java-libraries|java-frameworks|developer-tools|big-data|machine-learning-resources,3,"This repository is primarily an “awesome list”-style index of Java frameworks, libraries, and tooling, not a runnable ML/data science library or pipeline. It does include a dedicated section for databases, big data, and machine learning links, which can help ML/data practitioners discover Java ecosystem options. However, its direct applicability to ML workflows is limited because it mainly aggregates links and does not provide datasets, models, training code, or ML-specific utilities, so its value is mostly indirect and educational/discovery-oriented.",success
https://github.com/ZhongFuCheng3y/austin,austin,"A unified message-push platform that supports sending and tracking messages across multiple channels (e.g., email, SMS, WeChat official account/mini-program, Enterprise WeChat, DingTalk, Feishu). It provides a web UI for template management, async/high-concurrency sending, scheduled/crowd-based delivery, and end-to-end delivery tracing/monitoring.",6000,message-push|notification-platform|java|spring-boot|distributed-systems|kafka|flink|docker,3,"This repository is primarily an enterprise notification/message delivery platform (multi-channel sending, scheduling via cron/crowd files, and delivery observability), rather than an ML or data science library. It can be tangentially useful in data/ML contexts for operational notifications (e.g., model training/monitoring alerts) and it references data/streaming components like Kafka/Flink and a data-house module, but those are infrastructure/ops oriented rather than ML-focused. Community adoption appears solid (around 6k stars), yet its direct applicability to ML workflows is limited, so it merits a low-to-tangential score.",success
https://github.com/houbb/sensitive-word,sensitive-word,"A high-performance Java sensitive-word (prohibited/illegal/profanity) detection and filtering library based on a DFA algorithm. It supports common operations like detection, returning matched words, masking/replacement strategies, dynamic dictionary updates, and multiple normalization/conversion options (e.g., simplified/traditional Chinese, full/half-width, pinyin-related handling, and fuzzy matching).",5600,java|nlp|text-processing|content-moderation|string-matching|dfa,3,"This repository is primarily a Java utility for rule-based sensitive word detection/filtering using a DFA, aimed at content moderation and text normalization rather than model training. It can be useful in ML/data workflows as a preprocessing or safety layer (e.g., cleaning datasets, moderating user-generated text, or implementing policy filters), but it does not provide ML models, training pipelines, or data science tooling. Community adoption appears solid for a Java library (thousands of stars), yet its relevance to ML is tangential, so it scores low-to-moderate.",success
https://github.com/chrisleekr/binance-trading-bot,binance-trading-bot,An automated Binance cryptocurrency trading bot that supports multi-symbol monitoring and a trailing buy/sell “grid trading” strategy. It includes persistence (MongoDB) and integrates TradingView technical analysis signals for trade decisions.,5500,cryptocurrency|algorithmic-trading|binance|trading-bot|grid-trading|tradingview|docker|mongodb,3,"This repository is primarily a rules-based crypto trading automation system for Binance, focused on trailing/grid buy-sell execution and operational concerns (multi-symbol monitoring, persistence, deployment). It is only tangentially related to ML/data workflows: while market data and technical-analysis signals are involved, the core design is not model training, feature engineering, experimentation, or MLOps. Data scientists could reuse parts for data collection/backtesting integrations, but ML-specific components and community positioning as an ML tool are limited, justifying a low-to-tangential score.",success
https://github.com/jonaswinkler/paperless-ng,paperless-ng,"Paperless-ng is a document management system for scanning, OCR processing, indexing, and archiving physical documents with a web UI and full-text search. It also supports automated ingestion (e.g., via email), metadata management (tags/correspondents/types), and includes machine-learning-assisted document matching.",5400,document-management|ocr|full-text-search|self-hosted|docker|web-application|python|machine-learning,3,"This repository is primarily a self-hosted document management/OCR and indexing application with a web frontend, not an ML/data science library. It includes an ML-powered feature for document matching/auto-assignment of metadata, but that functionality is embedded as an application feature rather than a reusable ML toolkit. Data/ML practitioners might find it tangentially relevant for document digitization and labeling workflows, but it is not a core ML/data framework or pipeline tool, so the score is low.",success
https://github.com/kubernetes-sigs/headlamp,headlamp,"Headlamp is an easy-to-use, vendor-independent Kubernetes web UI for viewing and managing cluster resources. It supports multi-cluster setups, RBAC-aware controls, in-cluster deployment or a local desktop app, and extensibility via plugins.",5300,kubernetes|kubernetes-dashboard|cloud-native|devops|observability|web-ui|typescript|golang,3,"This repository provides a fully-featured Kubernetes dashboard (web UI/desktop) focused on cluster resource inspection and operations (e.g., viewing resources, logs/exec, editing, multi-cluster, and plugin-based extensibility). It is not an ML/data science library, but it can be tangentially useful for ML/DS teams because many ML workflows run on Kubernetes (e.g., managing training/inference workloads, debugging pods, and operational visibility). The score reflects indirect relevance to ML workflows via Kubernetes operations rather than offering data processing, modeling, or MLOps-specific capabilities out of the box.",success
https://github.com/clientIO/joint,joint,"JointJS is an SVG-based JavaScript/TypeScript diagramming library for building interactive diagram editors and visual UIs (e.g., flowcharts, UML/ERD, org charts, monitoring dashboards), with a graph model, rich interactivity, import/export, and layout capabilities.",5200,javascript|typescript|diagramming|graph-visualization|svg|ui-components|no-code-low-code|data-visualization,3,"This repository is primarily a front-end diagramming/graph visualization library used to build interactive editors and visual interfaces, not an ML or data-processing toolkit. It can be useful in ML/data workflows mainly for presenting or authoring graph-like structures (pipelines, knowledge graphs, model flow diagrams) and building visualization-heavy apps, but it does not provide ML algorithms, training, or data engineering functionality. Community adoption appears strong for diagramming use cases (thousands of GitHub stars), yet its relevance to ML/data work is tangential rather than direct, so it scores low-to-moderate.",success
https://github.com/Openpanel-dev/openpanel,openpanel,"Openpanel is an open-source web and product analytics platform (positioned as an alternative to Mixpanel/Plausible/Google Analytics). It provides event tracking with dashboards, funnels, cohorts, user profiles/session history, A/B testing, alerts, SDKs/APIs, and supports self-hosting.",5100,product analytics|web analytics|event tracking|self-hosted|Next.js|Fastify|ClickHouse|PostgreSQL,3,"This repository is primarily a product/web analytics platform for collecting and analyzing user events (funnels, cohorts, dashboards, alerts) rather than an ML or data-science library. It can be relevant to data workflows indirectly because it captures event data and stores it in databases (notably ClickHouse/PostgreSQL) that a data team could later export/query for modeling or BI. However, it does not appear to focus on ML tasks like feature engineering, model training, MLOps, or statistical/ML tooling, so its direct value to ML practitioners is limited.",success
https://github.com/UfoMiao/zcf,zcf,"ZCF (Zero-Config Code Flow) is a zero-config, one-click setup tool that installs and manages workflows/configuration for AI coding tools like Claude Code and Codex, with an interactive CLI (e.g., via npx) and bilingual support. It focuses on quickly initializing/updating agent workflows and related integrations (e.g., API/provider presets and tooling integrations).",5100,developer-tools|cli|ai-coding|claude|codex|typescript|workflow-automation,3,"This repository is primarily a developer productivity/automation tool: it provides a CLI for zero-config setup and management of AI coding tool workflows (Claude Code and Codex) rather than ML model training, evaluation, or data processing. It is tangentially relevant to ML/data work because it helps engineers integrate and operate LLM-powered coding assistants, which can support ML teams’ development workflows. However, it does not appear to provide core data science functionality (datasets, modeling code, ML pipelines, feature engineering, etc.) or be a widely adopted ML framework, so its direct ML/data applicability is limited, justifying a low-to-mid score.",success
https://github.com/Coder-World04/Complete-System-Design,Complete-System-Design,"A curated, interview-oriented system design learning repository that aggregates core system design topics, templates, and many case-study links (e.g., Instagram, Twitter, URL shortener) along with references to related resources.",4700,system design|software architecture|distributed systems|scalability|tech interview prep|case studies|backend engineering,3,"The repository is primarily a system design study guide/collection of resources and case studies for designing scalable software systems, not an ML/data library. It can be tangentially useful to ML/data practitioners because system design concepts (scaling, caching, databases, queues, distributed systems) are relevant when building data platforms and ML services, and it includes at least some ML-system-design-related pointers. However, it does not provide core ML assets like datasets, model training code, data processing pipelines, or MLOps tooling, so its direct applicability to ML workflows is limited.",success
https://github.com/electerious/Ackee,Ackee,"Ackee is a self-hosted, privacy-focused website analytics tool built on Node.js (with MongoDB) that runs on your own server and provides a minimal UI for traffic insights. It includes event tracking and a fully documented GraphQL API for building custom integrations and tooling on top of the collected analytics.",4600,web-analytics|privacy|self-hosted|nodejs|mongodb|graphql|devops,3,"Ackee’s primary purpose is privacy-preserving web analytics: collecting and presenting website traffic statistics and events via a minimal dashboard, with a GraphQL API for custom consumption. While analytics data can be exported/queried and used downstream for reporting or experimentation, the project is not designed for ML model training, feature engineering, or MLOps workflows. Its relevance to ML/data work is therefore mostly tangential (as a data source/telemetry system rather than an ML tool), which aligns with a low but non-zero score.",success
https://github.com/surveyjs/survey-library,survey-library,"SurveyJS Form Library is an MIT-licensed, client-side JavaScript/TypeScript library for rendering dynamic JSON-based forms/surveys (including multi-page forms, quizzes, and calculators), collecting responses, and integrating with your own backend. It provides UI integrations for React, Angular, Vue, Knockout, and a jQuery wrapper.",4600,javascript|typescript|form-builder|survey-forms|react|angular|vue,3,"This repository primarily provides a web form/survey rendering engine (JSON schema-driven) and UI integrations for major frontend frameworks, intended for building and embedding forms/surveys in applications. While it can support data collection workflows that may feed ML/analytics pipelines (because it helps gather structured survey/form data), it does not provide ML algorithms, data processing/training capabilities, or ML-specific integrations as a core focus. Therefore, it is only tangentially relevant to ML/data science—useful as a data-collection component rather than a modeling or data-engineering tool.",success
https://github.com/phodal/awesome-iot,awesome-iot,"A curated, community-maintained “awesome list” of Internet of Things (IoT) resources, organized by categories such as frameworks, libraries/SDKs, platforms/clouds, protocols (e.g., MQTT/CoAP), hardware, security, analytics, and tools.",4500,internet of things|awesome-list|embedded-systems|iot-platforms|iot-protocols|edge-computing|data-visualization|security,3,"This repository is primarily a curated directory of IoT frameworks, libraries, platforms, protocols, tools, and learning resources rather than a runnable ML/data library or dataset. It has some indirect relevance to data/ML workflows via IoT analytics, edge computing, real-time data, and data visualization resources, which can support data collection and deployment contexts. However, it does not provide ML-specific code, pipelines, benchmarks, or datasets, so its direct applicability to ML engineering is limited despite solid community interest (stars).",success
https://github.com/psviderski/uncloud,uncloud,"Uncloud is a lightweight clustering and container orchestration tool for deploying and managing containerised applications across multiple Docker hosts without the overhead of Kubernetes or Docker Swarm. It sets up a secure WireGuard mesh network and provides service discovery, load balancing/ingress with automatic HTTPS, and a Docker-like CLI for operating apps and infrastructure.",4500,container-orchestration|docker|self-hosted|devops|wireguard|service-discovery|load-balancing|golang,3,"This repository focuses on infrastructure: deploying and operating containerised web/apps across a fleet of Docker hosts using a decentralised design (no central control plane), with built-in WireGuard networking, service discovery, and HTTPS ingress. While it can host ML workloads (e.g., model-serving containers or batch jobs) because it runs containers across machines, it is not built specifically for ML/data pipelines, training, feature stores, or MLOps. Its relevance to ML/data is therefore mostly tangential—useful as general deployment infrastructure, but not an ML/data-focused toolkit.",success
https://github.com/gitbrent/PptxGenJS,PptxGenJS,"PptxGenJS is a JavaScript/TypeScript library for programmatically generating standards-compliant PowerPoint (.pptx) presentations (OOXML). It works in Node.js and in browsers/frameworks (e.g., React/Angular/Vite/Electron) and supports creating slide content like text, shapes, tables, images, and charts, plus features like HTML-table-to-slides export.",4400,javascript|typescript|powerpoint|pptx|ooxml|reporting|data-visualization,3,"This repository’s primary purpose is generating PowerPoint (PPTX/OOXML) presentations from JavaScript across Node and browser environments, enabling automated slide/report creation rather than ML. It can be useful in data workflows for exporting analytics results, dashboards, tables, and charts into slide decks (e.g., automated reporting), but it does not provide ML algorithms, model training, or data-engineering primitives. Community adoption appears solid (4.4k GitHub stars), yet its relevance to ML/data science is mostly tangential as a presentation/reporting output tool rather than a core ML library.",success
https://github.com/ergo-services/ergo,ergo,"Ergo is an actor-based framework for Go that brings Erlang-inspired design patterns (actors, supervision, fault tolerance) with network transparency to build reliable, distributed, event-driven systems. It includes built-in clustering/distributed messaging components and aims for high performance with zero external dependencies.",4300,golang|actor-model|distributed-systems|event-driven-architecture|microservices|fault-tolerance|networking|observability,3,"This repository is primarily a Go framework for building distributed, event-driven systems using the actor model with Erlang-style supervision and network-transparent messaging. While such infrastructure could be used to host ML/data services (e.g., resilient model-serving workers, distributed job orchestration), it does not provide data science/ML-specific functionality (data processing, training, evaluation, MLOps tooling) out of the box. Its relevance to ML/data workflows is therefore tangential—useful as general distributed application infrastructure rather than a dedicated ML/data toolkit.",success
https://github.com/yihong0618/running_page,running_page,"A project to generate a personal “running homepage” that visualizes your running/fitness activities (including map-based displays) and can be auto-updated via GitHub Actions. It syncs activity data from multiple running platforms and builds a static site (now using Vite, previously Gatsby) suitable for GitHub Pages/Vercel deployment.",4300,fitness-data|data-visualization|static-site-generator|github-actions|python|vite|gpx,3,"This repository primarily automates ingestion of personal running activity data (e.g., from services like Strava/Garmin/Nike Run Club/Keep and GPX files) and generates a static website with visual summaries and maps. It is data-related in the sense that it performs ETL-like syncing, storage, and visualization of time-series/geo activity data, but it is not an ML framework and does not focus on modeling, training, or analytics beyond reporting. Data scientists could reuse parts of the ingestion/sync/export pipeline or schemas for personal analytics, but its main value is as an end-user visualization and deployment project rather than a reusable ML/data toolkit.",success
https://github.com/Yooooomi/your_spotify,your_spotify,A self-hosted Spotify tracking dashboard that periodically polls the Spotify Web API and provides a web UI to explore listening statistics and history. It is typically deployed via Docker (server + web client) with MongoDB as the datastore and supports importing past listening history.,4100,self-hosted|spotify|listening-analytics|dashboard|docker|nodejs|mongodb|web-application,3,"This repository is primarily a self-hosted web dashboard for collecting and visualizing Spotify listening data (via periodic polling of the Spotify API) rather than an ML or data-science toolkit. It can be useful to data practitioners as a data collection/ETL-style source for personal listening history and aggregated stats, but it does not provide ML models, feature engineering pipelines, or integrations with common ML frameworks. The community adoption (stars) indicates strong interest in self-hosting and personal analytics, but its direct applicability to ML workflows is limited, so it scores as tangentially related.",success
https://github.com/hygieia/hygieia,hygieia,Hygieia is an open-source DevOps dashboard (originally from Capital One) that aggregates data from CI/CD and related engineering tools via collectors and presents it in configurable dashboard widgets/pipeline views. The repository is archived (read-only) and not actively maintained.,3900,DevOps|CI/CD|engineering-metrics|dashboard|data-aggregation|TypeScript|Angular,3,"This repository provides a DevOps dashboard that collects and visualizes software delivery/engineering metrics from tools like source control, build, and deployment systems rather than performing ML or data science tasks. It can be tangentially useful to ML/data teams for operational visibility (e.g., monitoring MLOps pipelines), but it is not designed as a data processing or model development framework. Additionally, the repo is archived and read-only (archived by Oct 2, 2023), which limits its practical value for modern ML/data workflows compared to actively maintained MLOps tooling.",success
https://github.com/Haehnchen/crypto-trading-bot,crypto-trading-bot,"A JavaScript (Node.js) cryptocurrency trading bot that connects to multiple exchanges (e.g., BitMEX, Binance, Bybit, Coinbase Pro, Bitfinex) using websockets, provides a web UI, and supports features like multi-pair trading, long/short, notifications, and candle/ticker storage in SQLite.",3400,cryptocurrency|algorithmic trading|trading bot|node.js|websockets|technical analysis|sqlite|docker,3,"This repository is primarily an automated crypto trading bot with exchange integrations, a web UI, and technical-indicator-driven trading logic rather than an ML-focused toolkit. It can be useful to data/ML practitioners mainly as a source of market data collection/indicator computation patterns (e.g., storing candles/tickers in SQLite and working with live websocket feeds) and as a baseline system to plug ML-generated signals into. However, it does not appear to provide model training, ML pipelines, or native integration with common ML frameworks, so its direct applicability to ML workflows is limited.",success
https://github.com/milesmcc/shynet,shynet,"Shynet is a self-hosted, privacy-friendly web analytics platform designed to work without cookies and to still function even when JavaScript is unavailable (via a tracking pixel fallback). It’s built with Django and supports tracking multiple sites/users with detailed visitor/session metrics.",3100,web-analytics|privacy|self-hosted|django|devops|docker|kubernetes,3,"This repository provides a self-hosted web analytics application for collecting and viewing website traffic metrics (hits, sessions, referrers, device/browser, approximate location, etc.). While it deals with data collection and reporting, its primary purpose is product analytics/telemetry rather than machine learning, modeling, or data science workflows. It can be tangentially useful to data teams for instrumentation and basic analysis, but it doesn’t offer ML tooling, pipelines, or integrations typical of ML/data engineering stacks, so it rates low on direct ML/data value.",success
https://github.com/mintlify/writer,writer,"Mintlify Writer is an AI-powered documentation writer that generates docstrings/documentation from highlighted code inside IDE/editor integrations (notably VS Code and IntelliJ). The repository includes the extension/plugin code and a server component used to produce documentation in various languages and docstring formats, though the project is noted as no longer being actively updated by the Mintlify team.",3100,developer-tools|documentation|ai-assisted-writing|vscode-extension|intellij-plugin|typescript|productivity,3,"This repository focuses on AI-assisted documentation generation for source code via editor/IDE plugins, which is primarily a developer productivity tool rather than a data/ML library. While it is ""AI powered"" and tagged with ""machine-learning"" on GitHub, it does not provide reusable ML/data science components (e.g., model training, datasets, evaluation, pipelines) that data scientists commonly integrate into workflows. It may be tangentially useful for ML engineers to document ML codebases, but its direct applicability to ML/data tasks is limited, hence a low-to-tangential score.",success
https://github.com/neomjs/neo,neo,"Neo.mjs is an “application engine for the web” focused on high-performance, multi-threaded (off-main-thread) UI runtimes with a persistent scene-graph/component model. It positions itself as an AI-native frontend platform where AI agents can introspect and mutate the running app structure in real time and includes tooling/architecture to support agent-driven development workflows.",3100,web development|frontend runtime|javascript|multithreading|web workers|ui framework|ai-native tooling|enterprise applications,3,"This repository’s primary purpose is building and running high-performance web/enterprise UIs (an application runtime/engine with off-main-thread architecture and persistent UI objects), not building ML models or data pipelines. While it markets “AI-native” development and mentions agent tooling and semantic/code knowledge-base concepts, those features are oriented toward software development workflows rather than data science tasks like training, evaluation, or feature engineering. As a result it’s only tangentially relevant to ML/data work (useful mainly if you’re building AI-enabled frontends/agent-integrated apps), so a 3/10 fits the ‘tangentially related’ category.",success
https://github.com/textlint/textlint,textlint,"textlint is a pluggable linting tool (similar to ESLint) for natural language text. It provides a Node.js CLI and an extensible ecosystem of rules/plugins/formatters to lint and optionally fix issues in Markdown, plain text, and other formats via plugins.",3100,natural language processing|linting|writing-quality|markdown|node.js|cli-tool|typescript,3,"This repository’s primary purpose is text quality linting for human-written documents (e.g., Markdown) using configurable rules and plugins, rather than model training or data science. It is only tangentially useful for ML/data workflows—for example, cleaning/validating documentation, annotation guidelines, or other text artifacts in a data pipeline. It has some NLP-adjacent relevance, but it is not an ML library and does not provide datasets, modeling utilities, or MLOps functionality, so it scores low-to-moderate on ML/data value.",success
https://github.com/tnfe/FFCreator,FFCreator,"FFCreator is a lightweight, flexible short video creation/processing library for Node.js that composes videos from images, video clips, audio, text, and effects. It supports many scene transitions and can convert a large subset of animate.css-style animations into rendered video output via FFmpeg.",3100,node.js|video-processing|ffmpeg|video-rendering|animation|media-compositing|short-video,3,"This repository is primarily a Node.js video composition/rendering toolkit (images/audio/text/effects/transitions to video) rather than an ML or data-science library. It can be useful in ML-adjacent workflows (e.g., generating synthetic training videos, creating automated visualizations, or producing dataset previews and demos), but it does not provide model training, inference, or data processing primitives typical of ML stacks. Community adoption appears solid for its niche (thousands of GitHub stars), yet its direct applicability to day-to-day ML/data engineering is limited, so a low-but-nonzero score is appropriate.",success
https://github.com/tremorlabs/tremor,tremor,"Tremor is a copy-and-paste React component library for building charts, dashboards, and modern web applications. It provides 35+ customizable and accessible UI components built on Tailwind CSS and Radix UI.",3100,react|typescript|ui-components|data-visualization|dashboards|tailwind-css|radix-ui,3,"This repository is primarily a frontend UI toolkit (React components) for building charts and dashboard interfaces, not a data processing or ML library. It can be useful in ML/data workflows indirectly—e.g., for presenting analytics, monitoring metrics, or visualizing model outputs in web apps—but it doesn’t provide ML algorithms, training, MLOps, or data engineering capabilities. Because its value is mostly in visualization/UI (tangential to core ML/data tasks) rather than ML functionality, it merits a low-to-tangential relevance score.",success
https://github.com/bestofjs/bestofjs,bestofjs,"Monorepo for the Best of JS web application, which curates and tracks trends across open-source projects related to the web platform and Node.js (JavaScript/TypeScript, HTML/CSS, and related runtimes). It regularly snapshots GitHub metrics (notably stars) for a curated set of projects and powers the bestofjs.org site for browsing and trend analysis.",3000,web development|javascript|typescript|open source analytics|github stars|trend tracking|node.js|monorepo,3,"This repository powers Best of JS, a web platform that collects and presents popularity/trend signals (e.g., daily GitHub star snapshots) for a curated list of web/Node.js open-source projects. While it involves data collection and trend reporting, its primary purpose is web ecosystem discovery rather than ML modeling, training, or data-science tooling. Data practitioners could reuse parts of the pipeline or dataset concepts for analytics dashboards, but there is little direct ML workflow integration or ML-specific functionality, so it is only tangentially relevant.",success
https://github.com/aws-amplify/amplify-cli,aws-amplify/amplify-cli,"The AWS Amplify CLI (Gen 1) is a command-line toolchain for building and managing serverless backends for web and mobile apps using AWS services. It lets you initialize projects, add/update categories (e.g., auth, API), and provision/sync cloud resources via workflows like init/push/pull that rely on AWS CloudFormation.",2900,aws|amplify|cli|serverless|cloudformation|devops|web-and-mobile-backend,3,"This repository provides a developer-focused CLI for provisioning and managing AWS Amplify (Gen 1) serverless application backends (e.g., auth, APIs, hosting) rather than ML or data science functionality. It can be tangentially useful in ML/data workflows only insofar as teams may use it to deploy supporting infrastructure (APIs, auth, storage) around data/ML applications. Because it is not an ML/data library, does not implement data processing/modeling, and is primarily aimed at application/backend provisioning, its direct value for ML/data work is limited, warranting a low but non-zero score.",success
https://github.com/DormyMo/SpiderKeeper,SpiderKeeper,"SpiderKeeper is a scalable web-based admin UI for managing Scrapy spiders via Scrapyd. It provides a dashboard to deploy Scrapy projects, schedule and control spider runs, view running statistics, and exposes an API (with a Swagger UI).",2800,scrapy|scrapyd|web-crawling|spider-management|dashboard|python|deployment|scheduling,3,"This repository is primarily an operations/admin dashboard for managing and scheduling web crawlers (Scrapy spiders) through Scrapyd, including one-click deployment and run monitoring. It is not an ML library and does not provide modeling, training, or data-science algorithms, but it can be tangentially useful in data workflows because it helps automate and operate data collection via scraping. Its value to ML/data teams is mainly as a scraping management utility rather than a direct ML/data processing tool, which is why it scores low-to-tangential on the ML/data relevance scale.",success
https://github.com/pod4g/hiper,hiper,"Hiper is a CLI-based statistical analysis tool for web performance testing that repeatedly loads a target URL (optionally headless) and reports timing metrics such as DNS, TCP connect, TTFB, DOM ready, and overall load time. It supports configuration via JSON/JS, cache/JavaScript/network toggles, custom user agents, and specifying a Chrome executable path.",2800,performance testing|web performance|benchmarking|command-line tool|node.js|javascript|headless browser|chrome,3,"This repository provides a CLI tool for measuring and summarizing web page performance timings across repeated runs, primarily aimed at web performance testing and benchmarking rather than data science. While it outputs metrics that could be ingested into analytics pipelines and used for statistical comparisons over time, it does not provide ML-specific functionality, datasets, feature engineering, or model training/inference capabilities. Community adoption appears solid for a niche tooling project (thousands of GitHub stars), but its relevance to ML workflows is tangential, so it scores low-to-moderate.",success
https://github.com/princejwesley/Mancy,Mancy,"Mancy is a cross-platform desktop Node.js REPL application built with Electron and React. It provides an enhanced interactive console with features like syntax highlighting, themes, session/history management, autocomplete, and rich output/data visualization helpers.",2600,nodejs|repl|electron|react|javascript|developer-tools|desktop-application|code-editor,3,"This repository primarily provides a GUI-based Node.js REPL (interactive console) for developers, focusing on productivity features like syntax highlighting, autocomplete, session history, and richer output visualization. While it can be used by data/ML practitioners who work in JavaScript (e.g., exploring data structures, running scripts interactively, or quick prototyping), it is not designed as a data science/ML library, framework, or pipeline tool. Its relevance to ML/data workflows is therefore tangential and depends on users doing ML-adjacent work in Node.js rather than being a purpose-built ML/data solution, justifying a score of 3.",success
https://github.com/unsplash/react-trend,react-trend,"A lightweight React component for rendering simple, elegant SVG sparkline “trend” charts with options like gradients, smoothing, and an auto-draw animation. The repository is archived and no longer actively maintained.",2500,react|data-visualization|charts|sparkline|svg|frontend|javascript,3,"This repository provides a small React UI component for drawing sparkline-style trend lines in the browser using SVG, aimed at lightweight visualization rather than analytics or modeling. It can be used to display ML/data outputs (e.g., loss curves, KPI trends) in dashboards, but it does not include data processing, statistical methods, or ML functionality itself. Community adoption is decent for a UI utility (thousands of stars), but its archived/unmaintained status reduces practical value for modern ML/data workflows. Therefore it is only tangentially relevant to ML/data engineering and is scored 3/10.",success
https://github.com/china-testing/python-api-tesing,python-api-tesing,"A Chinese-language collection of Python testing/development resources and example code, including automation/testing topics (e.g., Selenium, Flask examples) plus assorted utilities and downloadable reading lists/books. The README notes the project is gradually migrating to another repository (python_cn_resouce).",2400,python|test-automation|software-testing|qa|selenium|dev-tools|tutorials-and-examples|chinese-resources,3,"This repository is primarily a Chinese resource hub for Python testing development, with folders and scripts spanning testing/automation examples and miscellaneous utilities, plus book/resource indexes. While it includes some data-related or ML-adjacent items (e.g., folders named pandas and opencv_crash_deep_learning, and some scripts processing Excel/image-related data), ML/data science is not its core purpose. It may offer light educational value or small reusable snippets for data handling, but it is not an ML framework, dataset, or MLOps tool and is not positioned as a dedicated ML/data workflow repository.",success
https://github.com/friuns2/Leaked-GPTs,Leaked-GPTs,"A curated list of prompts and instructions intended to extract (""leak"") Custom GPT system prompts and potentially associated files, with the stated aim of bypassing ChatGPT/GPT usage limits or using GPTs without a Plus subscription. The repository primarily contains prompt text and a large list of GPT entries rather than executable ML code.",2400,prompt-engineering|llm-security|prompt-injection|red-teaming|chatgpt|openai-gpts|cybersecurity,3,"This repository is mainly a collection of prompt text focused on extracting hidden instructions from GPTs (prompt injection / jailbreak-style content) rather than a library, dataset, or ML tooling. It can be indirectly useful for ML/LLM practitioners for security testing, red-teaming, and understanding prompt-exfiltration attack patterns, but it does not provide models, training code, or data pipelines. Community adoption appears moderate (roughly 2.4k GitHub stars at the time of review), but its direct applicability to standard data science workflows is limited, so a low-to-tangential score is appropriate.",success
https://github.com/sismics/docs,docs,"Teedy (sismics/docs) is an open-source, lightweight document management system (DMS) for individuals and businesses, providing web and Android clients plus features like OCR, full-text search, metadata, permissions, and workflow automation. It can be deployed via Docker and offers a REST API and webhooks for integrations.",2400,document-management|OCR|full-text-search|self-hosted|Docker|Java|REST-API|PostgreSQL,3,"This repository primarily implements a self-hosted document management system (Teedy) with OCR, indexing, search, metadata, and workflow features, intended for organizing and retrieving documents rather than doing ML. It can be tangentially useful to ML/data workflows as a data source or ingestion/labeling-adjacent system (e.g., OCR’d text extraction, API access, and webhooks to pipe documents into downstream analytics), but it is not an ML framework or data-processing library. Community adoption appears solid for a DMS (thousands of stars), yet its value for ML is indirect, so a low-to-moderate score is appropriate.",success
https://github.com/aolofsson/awesome-opensource-hardware,awesome-opensource-hardware,"A curated “awesome list” of open source hardware-related projects, organized by category (e.g., PDKs, compilers, design/verification tools, and reusable IP/design generators). It serves as a directory to source repositories and resources across the open-source silicon/EDA ecosystem.",2200,open source hardware|EDA|ASIC design|FPGA|RISC-V|PDK|hardware design tools|awesome-list,3,"This repository is primarily a curated index of open-source hardware tooling and reusable hardware designs (e.g., PDKs, compilers, verification tools, and design generators), rather than an ML/data library. It has some tangential relevance to ML workflows because it includes categories and projects related to hardware acceleration and AI-adjacent hardware tooling, which ML engineers might consult when targeting specialized hardware. However, it does not provide datasets, models, training code, or data-processing utilities directly, so its value for day-to-day data science/ML work is limited.",success
https://github.com/astefanutti/kubebox,kubebox,"Kubebox is a terminal UI (TUI) and web console for interacting with Kubernetes clusters, providing an interactive interface for switching contexts/namespaces, viewing logs and events, monitoring container resource usage, and exec-ing into containers. It can be run as a standalone executable, a Docker container, via kubectl, or served from within a Kubernetes/OpenShift cluster.",2200,Kubernetes|DevOps|terminal-ui|web-console|cluster-management|observability|container-logs|resource-monitoring,3,"This repository provides an interactive terminal/web console for Kubernetes operations (context/namespace switching, logs/events viewing, container exec, and resource-usage charts via cAdvisor), so its primary use case is platform operations rather than data science. It can be tangentially useful in ML/data workflows because many ML systems run on Kubernetes and engineers may use it to observe pods running training/inference jobs, but it does not provide ML/data functionality itself (no modeling, data processing, or MLOps pipeline features). Community adoption appears solid for a niche Kubernetes TUI/web console (about 2.2k GitHub stars), which supports a modest relevance score rather than a purely unrelated one.",success
https://github.com/francoispqt/gojay,gojay,"GoJay is a high-performance JSON encoder/decoder for Go that avoids reflection by using small marshal/unmarshal interfaces, and includes a streaming decoding API plus optional faster unsafe paths. It also provides a code generator to generate marshaling/unmarshaling implementations for custom structs.",2100,golang|json|serialization|deserialization|performance|streaming|code-generation,3,"This repository provides a fast JSON encoding/decoding library for Go, emphasizing performance, non-reflective APIs, and stream decoding, with an additional code generator for boilerplate marshaling/unmarshaling. It can be useful in ML/data workflows indirectly because data pipelines and ML services often need efficient JSON ingestion/emission (e.g., model serving endpoints, event streams), but it is not an ML- or data-science-specific library. The adoption signal (stars) indicates it’s a reasonably popular Go JSON utility, yet its value is primarily general backend/performance engineering rather than data science tooling, which is why it scores a 3/10.",success
https://github.com/quarkusio/quarkus-quickstarts,quarkus-quickstarts,"A collection of official Quarkus quickstart/sample projects demonstrating how to build Quarkus applications with various extensions and integrations (e.g., REST, reactive, databases, messaging, cloud services). It serves as reference code and starter templates for common Quarkus use cases and features.",2100,quarkus|java|microservices|cloud-native|rest-api|kubernetes|reactive|messaging,3,"This repository primarily provides Quarkus sample applications across many backend and cloud-native scenarios (REST endpoints, reactive patterns, persistence, messaging, and cloud integrations), intended as starter/reference code for building services. It is not designed for machine learning or data science, but some examples (e.g., Kafka, Elasticsearch, databases) can be tangentially useful for building data-oriented services or ingestion APIs that might sit around ML systems. Given its focus on general application development rather than ML/data tooling, and limited direct applicability to model training/analytics workflows, a low-but-nonzero score is appropriate. It has broad developer utility and strong ecosystem relevance, but not specific ML community adoption as an ML/data repo.",success
https://github.com/F1bonacc1/process-compose,process-compose,"Process Compose is a lightweight, docker-compose-inspired process scheduler/orchestrator for running and managing non-containerized applications from a YAML file. It provides a single-binary CLI/TUI with dependency ordering, restarts/health checks, logging, a REST API, and optional cron/interval scheduling.",2000,DevOps|process-orchestration|scheduler|docker-compose-like|CLI|TUI|Go,3,"This repository is primarily a DevOps utility for orchestrating local/non-containerized processes (dependency management, restarts, logs, TUI/CLI, and an API) using a docker-compose-like YAML configuration. It can be useful in ML/data workflows indirectly—for example, to coordinate local stacks (databases, feature stores, model servers, ETL jobs) during development or CI—but it is not purpose-built for ML, data processing, or MLOps. Adoption appears solid for a general orchestration tool (around ~2k GitHub stars), yet its value to data science is mostly ancillary rather than core.",success
https://github.com/kapicorp/kapitan,kapitan,"Kapitan is a generic, templated configuration management tool for generating and managing infrastructure/app configuration, especially for Kubernetes and Terraform. It supports multiple templating approaches (e.g., Jinja2/Jsonnet) and is commonly used in DevOps/GitOps workflows.",1900,DevOps|configuration-management|Kubernetes|Terraform|GitOps|templating|Python|infrastructure-as-code,3,"Kapitan is primarily an infrastructure/configuration management and templating tool used to generate deployable configuration (not a data/ML library). It can be useful in ML/data workflows indirectly—e.g., to manage Kubernetes manifests for deploying data pipelines, training jobs, or model-serving infrastructure—so it has some tangential relevance for MLOps. However, it does not provide ML algorithms, data processing primitives, or ML-specific tooling, so its direct value to data science/ML work is limited, warranting a low score.",success
https://github.com/jet-admin/jet-bridge,jet-bridge,"Jet Bridge is a self-hosted backend service for Jet Admin that connects to your SQL database and automatically generates a REST API, enabling Jet Admin’s no-code admin/back-office UI to work with your data. It focuses on data privacy (Jet Admin doesn’t directly access your DB) and supports customization/extendability features for building internal tools.",1800,admin-panel|internal-tools|rest-api|sql-database|python|backoffice|dashboard|no-code,3,"This repository provides infrastructure for generating a REST API over SQL databases to power an admin/back-office UI (Jet Admin), and is primarily aimed at internal tools/administration rather than analytics or ML. It can be tangentially useful in data workflows because it connects to many SQL data sources and can expose operational data via an API, but it does not provide ML functionality, model training, feature engineering, or data-science-specific tooling. Its value for ML/data practitioners is mostly indirect (as an internal data access/admin interface component), so it merits a low-to-tangential relevance score.",success
https://github.com/mikeroyal/Apple-Silicon-Guide,Apple-Silicon-Guide,"A curated, documentation-style guide to Apple Silicon (A-series and M-series) covering chip/architecture overviews and practical resources for devices, operating systems, development tools, gaming, virtualization/containers, and related software ecosystems.",1800,apple-silicon|macos|developer-tools|core-ml|metal|virtualization|docker,3,"This repository is primarily a broad Apple Silicon reference/guide (hardware overview plus links and notes about tooling, apps, gaming, virtualization, etc.), not a library or executable ML project. It includes sections relevant to ML practitioners on Apple platforms (notably Core ML and related development topics), which can be useful for setup and ecosystem orientation, but it does not provide datasets, models, training code, or data/ML utilities. Therefore its value to ML/data workflows is tangential and mostly educational/contextual rather than directly actionable as an ML/data tool.",success
https://github.com/sartography/SpiffWorkflow,SpiffWorkflow,"SpiffWorkflow is a pure-Python workflow engine aimed at low-code business process automation, with support for parsing and executing BPMN diagrams and an integrated baseline DMN implementation. It also supports defining workflows directly in Python code or via an internal JSON structure.",1800,python|workflow-engine|business-process-management|BPMN|DMN|process-automation|low-code,3,"SpiffWorkflow is primarily a business process/workflow automation engine (BPMN/DMN execution in Python), not an ML or data-science library. It can be useful adjacent to ML workflows as an orchestration layer (e.g., coordinating human-in-the-loop steps, approvals, and service calls that may include model inference), but it does not provide ML algorithms, model training, or data-processing capabilities itself. Community adoption appears strong for BPMN-in-Python use cases (around 1.8k GitHub stars), yet its relevance to typical data science/ML pipelines is indirect, so a low-but-nonzero score is appropriate.",success
https://github.com/uselotus/lotus,lotus,"Lotus is an open-source pricing and billing engine for SaaS companies, designed to deploy, monitor, and experiment with subscriptions and complex pricing models (including usage-based pricing). It provides a modular control panel that integrates with existing quote-to-cash systems and data sources to support pricing configuration and iteration.",1800,billing|pricing|SaaS|usage-based-pricing|subscriptions|fintech|Django|React,3,"This repository’s primary purpose is pricing and billing infrastructure (subscriptions, usage-based pricing, and related operational tooling), not machine learning or data science. It may be tangentially useful to data/ML teams who need reliable metering/usage ingestion and event-driven infrastructure that can feed analytics or experimentation around pricing, but it does not appear to provide ML models, training pipelines, or DS-focused libraries. Community adoption (based on GitHub stars) suggests general engineering interest, but the direct applicability to ML workflows is limited, so a low-to-tangential score is appropriate.",success
https://github.com/ChHsiching/GitHub-Chinese-Top-Charts,GitHub-Chinese-Top-Charts,"A curated, weekly-updated GitHub Chinese leaderboard that ranks high-star repositories whose Description and README include Chinese. It provides an overall ranking and multiple language-specific sub-rankings to help users discover popular Chinese-documented projects.",1700,curated-list|github-ranking|open-source-discovery|automation-scripts|data-collection|markdown,3,"This repository primarily publishes a weekly-updated leaderboard of popular GitHub projects that include Chinese documentation, organized into an overall chart and language-specific charts. While it involves collecting and presenting repository metadata (stars, updates, language) and may include scripts to generate the rankings, it is not an ML tool, dataset, or framework. It can be tangentially useful to data/ML practitioners for discovering Chinese ML-related repos (e.g., high-star ML projects listed in the charts), but its direct applicability to ML/data workflows is limited, so it scores low-to-moderate.",success
https://github.com/josh-project/josh,josh,"Josh (“Just One Single History”) is a Git history filtering system and proxy that enables fast, incremental, and reversible repository filtering to bridge monorepo and multirepo workflows. It provides features like partial clones of subdirectories, workspace-based composition of virtual repos, and bidirectional sync via josh-proxy.",1700,git|monorepo|devops|source-control|repository-proxy|history-rewrite|rust,3,"This repository is a Git infrastructure tool (josh-proxy and related components) focused on incremental, reversible history filtering and serving filtered “virtual” repositories for monorepo/multirepo workflows. It is not an ML/data library, but it can be tangentially useful to data/ML teams by enabling repo segmentation, caching, and workspace-based dependency boundaries that may improve large-codebase CI/CD and collaboration. Because its primary purpose is version-control infrastructure rather than data processing/modeling, and its adoption is mainly in DevOps/engineering contexts, it merits a low-to-tangential ML/data relevance score.",success
https://github.com/lastbackend/lastbackend,lastbackend,"Last.Backend is an open-source container management platform for deploying, scaling, and managing containerized applications. It provides a REST API and cluster components such as scheduling, service discovery, overlay networking (VxLAN), ingress proxying, and load balancing.",1700,container-orchestration|devops|cloud-infrastructure|kubernetes-alternative|golang|service-discovery|networking|cluster-management,3,"This repository is primarily an infrastructure/DevOps system for orchestrating and managing containerized applications (cluster management, scheduling, networking, ingress, and service discovery), not a data science or machine learning library. It can be tangentially useful in ML contexts by helping run services and workloads in containers, but it does not provide ML-specific capabilities (training, inference tooling, data pipelines, feature stores, etc.). Community adoption appears oriented toward general container platform users rather than the ML/data ecosystem, so its direct applicability to ML workflows is limited.",success
https://github.com/centminmod/my-claude-code-setup,my-claude-code-setup,"A shared starter template for setting up Anthropic Claude Code in a project, including hooks, slash commands, and a CLAUDE.md-based “memory bank” file system to help retain context across sessions. It also includes optional supplemental CLAUDE reference files (e.g., Cloudflare/Convex) and guidance for related tooling/devcontainer workflows.",1600,claude-code|llm-tools|developer-productivity|prompt-engineering|agent-workflows|devcontainers|cli-tooling,3,"This repository is primarily a configuration/template setup for Claude Code projects, providing starter settings, hooks/slash commands, and a CLAUDE.md “memory bank” structure to retain context over multiple sessions. It is related to ML/AI only in the sense that it supports an LLM-based coding assistant workflow, not data science or model training itself. Data/ML practitioners could use it indirectly to streamline AI-assisted development, but it doesn’t provide ML algorithms, datasets, or MLOps/data pipeline functionality. Therefore, its relevance to ML/data workflows is tangential rather than direct.",success
https://github.com/ecmadao/hacknical,hacknical,"Hacknical is a web app that helps GitHub users generate a resume-style profile by analyzing their GitHub activity and data (e.g., contributions, commits, languages, and repositories). It provides GitHub data analysis views intended to help present a stronger technical resume.",1500,web application|resume builder|GitHub analytics|data visualization|React|Koa|Node.js,3,"This repository primarily builds a full-stack website that crawls and visualizes GitHub user activity to generate resume-oriented analytics, using a Koa/Node backend and a React/Redux frontend with charting. It is related to data workflows mainly in the sense of collecting and presenting developer-activity data (basic analytics/visualization), not in implementing machine learning or supporting ML pipelines. Community adoption appears moderate (about 1.5k stars), but its direct usefulness for ML/data science work is limited to lightweight analytics and visualization patterns rather than ML-specific tooling. Hence, it’s tangentially relevant rather than an ML/data-focused library or framework.",success
https://github.com/philogb/jit,jit,"The JavaScript InfoVis Toolkit (JIT) is a JavaScript library for building interactive data visualizations for the web, including visual graph/network layouts and related UI components. This repository contains the development source and build tooling for the toolkit.",1500,javascript|data-visualization|information-visualization|graph-visualization|network-graphs|web-development|frontend,3,"This repository is primarily a front-end JavaScript visualization toolkit for rendering interactive visualizations (not a data processing or machine learning library). It can be useful in ML/data workflows for presenting results (e.g., visualizing graphs, clusters, hierarchies, or exploratory relationships), but it does not provide ML algorithms, model training, feature engineering, or dataset tooling. Because its relevance is mostly in downstream visualization rather than core ML/data work, it merits a tangential score rather than a mid/high ML-focused score.",success
https://github.com/steedos/steedos-platform,steedos-platform,"Steedos Platform is an open-source, AI-native low-code platform for building enterprise applications. It uses a metadata-driven architecture and generative AI to create data models, UIs, and microservices (e.g., text-to-schema, text-to-UI, and text-to-code), with deployment options like Docker and support for REST/GraphQL APIs.",1500,low-code|ai-assisted-development|enterprise-apps|nodejs|react|microservices|metadata-driven|paas,3,"This repository primarily targets enterprise low-code application development (prompt-driven app generation, metadata-driven models, UI/page generation, and microservice logic), rather than ML/data science workflows. While it includes an LLM integration layer and AI features for generating schemas/UIs/code, it is not a framework for model training, data processing, or MLOps, and its core value is in business app development. It may be tangentially useful to ML engineers for building internal tools or AI-enabled business apps on top of their models, but it is not a direct ML/data library—hence a low-to-tangential score.",success
https://github.com/Raathigesh/dazzle,dazzle,"React Dazzle is a React.js library for building customizable, grid-based dashboards with draggable, add/remove/reorderable widgets. It is UI-framework agnostic and provides default components/styles while allowing full override via custom layout and components.",1400,react|dashboard|drag-and-drop|ui-components|data-visualization|javascript|frontend,3,"This repository provides a React UI framework for assembling interactive dashboards (grid layout, widget management, and drag-and-drop via react-dnd), rather than ML or data-processing functionality. It can be used to build interfaces for analytics/ML products (e.g., model monitoring dashboards), but it does not include ML algorithms, data pipelines, or direct integrations with common ML tooling. Community adoption appears moderate (about 1.4k GitHub stars), which supports some practical value, but primarily for frontend/dashboard UI rather than data science workflows.",success
https://github.com/aserg-ufmg/JSCity,JSCity,"JSCity implements the “Code City” metaphor for JavaScript by visualizing source code as a navigable 3D city using three.js. It maps folders/files to districts, and functions to buildings whose height and base size reflect code metrics (e.g., LOC and number of variables).",1400,software visualization|code analysis|javascript|three.js|static analysis|software engineering research|code metrics,3,"This repository is primarily a software visualization and static-analysis tool that turns JavaScript codebases into interactive 3D “cities” based on code metrics (e.g., LOC and number of variables). While it processes structured data derived from source code and could be useful for research/analytics on code, it is not designed for machine learning workflows, model training, or data science pipelines. Its ML relevance is therefore tangential: it can generate/visualize metric data that might be fed into ML studies about software quality, but ML is not the core purpose or main community use case.",success
https://github.com/nealmckee/penumbra,penumbra,"Penumbra is a mathematically balanced color scheme designed in a perceptually uniform color space (Oklab) to provide coherent light/dark themes (including higher-contrast variants) and consistent accent palettes usable across editors/IDEs and terminals; it also includes a TSV with the full palette data for reuse (e.g., visualization).",1400,color theme|developer tooling|ui design|vscode|terminal|data visualization|accessibility,3,"This repository primarily provides a color theme system (light/dark and contrast variants) plus exported palette data (e.g., in a TSV). It is not an ML library, but the palette can be directly useful for data science work in the narrow context of designing readable, consistent data visualizations or plotting styles. Community adoption is decent for a theme (1.4k stars), but its role in ML workflows is indirect, so a low-to-tangential score is appropriate.",success
https://github.com/tailcallhq/tailcall,tailcall,"Tailcall is an open-source, high-performance GraphQL runtime/proxy for building GraphQL backends that can compose and expose upstream services (e.g., REST/HTTP, gRPC) behind a unified GraphQL API. It ships as a CLI/server with multiple distribution options (npm, Homebrew, Docker) and targets cloud-native deployments.",1400,graphql|api-gateway|graphql-proxy|backend|rust|cloud-native|microservices,3,"This repository primarily provides a high-performance GraphQL runtime/proxy for composing APIs and serving GraphQL backends, which is mainly an application/API infrastructure use case rather than an ML or data-science library. It can be indirectly useful in ML/data workflows as a way to expose model-serving or feature services behind a GraphQL API and to integrate heterogeneous upstreams, but it does not provide data processing, modeling, training, or MLOps capabilities itself. Community adoption appears oriented toward GraphQL/backend engineering rather than ML, so its value for ML/data work is tangential.",success
https://github.com/xFFFFF/Gekko-Strategies,Gekko-Strategies,"A collection of trading strategies for the Gekko cryptocurrency trading bot, including backtest results and assorted helper tools/strategy variants contributed by different authors. It serves as a repository of ready-to-use strategy implementations (e.g., RSI/EMA/MACD-style and other indicator-based strategies) for Gekko users.",1400,algorithmic-trading|cryptocurrency|trading-bot|gekko|technical-analysis|backtesting|javascript,3,"This repository primarily provides rule-based algorithmic trading strategies and related tooling for the Gekko trading bot rather than machine-learning models or data-science pipelines. While it may be useful to data/ML practitioners as a source of baseline strategies, feature ideas, or backtesting reference points, it does not appear to focus on ML training, evaluation, or integration with common ML frameworks. Its relevance to ML/data workflows is therefore tangential and mostly indirect (finance/trading context, backtest-centric experimentation), which supports a low-to-moderate score.",success
https://github.com/amonapp/amon,amon,"Amon is a modern server monitoring platform for collecting system and application metrics, visualizing them in dashboards, and triggering alerts/alarms based on health checks and performance data.",1300,server-monitoring|metrics|alerting|dashboard|statsd|python|devops|observability,3,"This repository implements Amon, a server monitoring and alerting platform (dashboards, metrics collection, health checks, and alarms), primarily aimed at DevOps/operations use cases rather than data science. It can be tangentially useful in ML/data workflows for monitoring ML infrastructure (e.g., GPU/CPU/RAM/disk/network utilization, service health, and operational metrics), but it does not provide ML algorithms, data processing pipelines, or model training/evaluation tooling. Community adoption appears moderate (about 1.3k GitHub stars), suggesting it’s known in monitoring circles but not a core ML/data repository. Based on its indirect relevance and operational focus, it earns a 3/10 for ML/data value.",success
https://github.com/manu354/cryptocurrency-arbitrage,cryptocurrency-arbitrage,"A Node.js cryptocurrency arbitrage opportunity calculator that aggregates price data from many exchanges/markets and computes the best buy/sell market pairs per coin, exposing results via a minimal web UI/API. The author notes the full trading-bot code is being kept private, with this public repo focusing on the opportunity-calculation tooling.",1300,cryptocurrency|arbitrage|trading-bot|node.js|websockets|exchange-data|finance,3,"This repository primarily collects JSON price data from multiple crypto markets/exchanges and computes arbitrage spreads between highest/lowest prices, then serves the results to a simple frontend. It is data-centric and could be used as a data collection/feature-generation component for quantitative research, but it is not designed for ML modeling, training, or evaluation, and it does not integrate with common ML/data frameworks. Community interest exists (1.3k stars), yet its core use case is trading/arbitrage utilities rather than machine learning, so it is only tangentially relevant to ML/data workflows.",success
https://github.com/ovh/utask,utask,"µTask is a lightweight, cloud-oriented automation/workflow engine that models and executes business processes declared in YAML. It runs tasks asynchronously, tracks intermediate states, and is designed to be simple to operate (requires PostgreSQL) and extensible via custom Go actions/plugins.",1300,workflow-automation|business-process-management|orchestration|yaml|golang|postgresql|devops,3,"This repository provides a general-purpose workflow/automation engine for orchestrating multi-step business processes defined declaratively in YAML, with async execution and an auditable trail of task state. It is not an ML/data-science library and does not provide modeling, training, or data-processing primitives, but it can be used tangentially to orchestrate ML/data jobs as part of broader automation (e.g., triggering pipelines, approvals, and integrations). Community adoption appears moderate (about 1.3k GitHub stars), but its primary audience is DevOps/process automation rather than ML practitioners, which keeps its ML/data value relatively low.",success
https://github.com/wardbradt/peregrine,peregrine,"A Python library for detecting cryptocurrency arbitrage opportunities across many exchanges and trading pairs. It builds exchange/market graphs (via CCXT) and applies graph algorithms (e.g., Bellman–Ford) to identify profitable cycles and cross-exchange bid/ask spreads; the repository is archived and read-only.",1300,cryptocurrency|arbitrage|algorithmic-trading|python|graph-algorithms|bellman-ford|ccxt|finance,3,"This repository’s primary purpose is crypto market arbitrage detection (cross-exchange and within-exchange), using graph-based methods to find profitable trading paths rather than building or training ML models. It can be tangentially useful to data/ML practitioners as a data source and baseline engine for collecting price graphs, backtesting, or feature generation for trading research, but it is not an ML library and does not provide datasets, model training pipelines, or common ML framework integrations. Community adoption appears moderate (about 1.3k stars), but the project is archived (read-only since Nov 19, 2021), which reduces practical value for current ML/data workflows.",success
https://github.com/TencentBlueKing/bk-sops,bk-sops,"BlueKing SOPS (Standard Operation) is a visual workflow orchestration and task execution system for IT operations, enabling drag-and-drop pipeline design, integration with internal/external systems via APIs, and interactive execution controls (pause/resume/retry/skip). It is a BlueKing SaaS product built with a Python/Django backend and a Vue-based frontend.",1200,workflow-orchestration|DevOps|IT-automation|pipeline-engine|Django|Vue.js|BlueKing,3,"This repository primarily provides a DevOps/IT operations workflow orchestration platform (visual pipeline design, plugin-based integrations, and controlled task execution), rather than a data science or machine learning tool. It can be indirectly useful for ML/data teams as general automation/orchestration infrastructure (e.g., running repeatable operational pipelines), but it is not designed around data processing, model training, or MLOps features. Community adoption appears oriented toward BlueKing/enterprise ops users instead of the ML/data ecosystem, so its direct applicability to ML workflows is limited.",success
https://github.com/cloudposse/atmos,atmos,Atmos is a Terraform orchestration and environment/configuration management CLI that keeps infrastructure configuration DRY using hierarchical stack YAML (imports/inheritance). It natively supports orchestrating Terraform and Helmfile workflows and is designed to run both locally and in CI/CD pipelines.,1200,DevOps|infrastructure as code|Terraform|configuration management|CI/CD|Kubernetes|Helmfile,3,"This repository provides a DevOps-focused orchestration CLI/framework for managing infrastructure configurations and workflows (primarily Terraform, with native support for Helmfile) using DRY, hierarchical stack YAML. It is not an ML/data library and does not provide data science or machine learning functionality directly. It can be tangentially useful to ML teams for provisioning and managing cloud infrastructure for data/ML platforms (e.g., Kubernetes clusters, cloud resources, CI/CD), but its primary audience and feature set are infrastructure/DevOps rather than ML/data workflows, so it rates low-to-tangential for ML/data use.",success
https://github.com/freeCodeCamp/awesome-quincy-larson-emails,awesome-quincy-larson-emails,"An archive of Quincy Larson’s weekly email newsletter, maintained in-repo as a browsable README plus machine-readable exports (e.g., JSON and RSS). Includes helper scripts to generate/convert the archive formats.",1200,newsletter-archive|freecodecamp|open-source|python|json|rss|documentation,3,"This repository primarily serves as a curated archive of a weekly programming newsletter, with content stored as a human-readable README and exports like JSON/RSS plus small conversion scripts. It is not an ML/data library or dataset designed for modeling, but the archived text corpus (emails) could be repurposed for NLP tasks like summarization, topic modeling, or information retrieval. The score is low because it lacks ML tooling, benchmarks, or pipelines, though it has some indirect value as a small-to-medium textual dataset and for data ingestion/format-conversion examples.",success
https://github.com/pro1code1hack/Your-Journey-To-Fluent-Python,Your-Journey-To-Fluent-Python,"An educational repository that serves as a structured book/learning path to become fluent in Python, with chapter-style Markdown lessons (e.g., data types, OOP, testing, concurrency) and a free included PDF. It encourages interactive learning via pull requests for homework/questions and a linked Discord community.",1200,python|programming-education|python-tutorial|software-engineering|object-oriented-programming|testing|concurrency|algorithms,3,"This repository is primarily a Python learning book made up of chapter-based tutorials covering general programming and software-engineering topics (e.g., OOP, SOLID, logging, testing, concurrency), rather than a library or tool for data/ML. While learning Python fundamentals can indirectly benefit data science practitioners, there is no clear focus on ML concepts (modeling, training, evaluation) or common DS tooling (NumPy/Pandas/scikit-learn) visible from the repo’s structure. Community adoption is moderate (about 1.2k stars), but the use case is education for general Python fluency, so its direct applicability to ML/data workflows is limited.",success
https://github.com/react-csv/react-csv,react-csv,"A React library that provides components (CSVLink and CSVDownload) to generate and download CSV files in the browser from arrays, objects, strings, or functions that return data.",1200,react|csv|data-export|frontend|javascript|react-components|web-development,3,"This repository provides React components for exporting data as CSV files from client-side web applications, primarily targeting UI/data export needs rather than ML. It can be tangentially useful in data/ML workflows for exporting datasets, reports, experiment results, or table views from internal tools and dashboards, but it does not provide data processing, analytics, modeling, or ML-specific integration. Community adoption appears moderate (about 1.2k GitHub stars), but its applicability is mainly general frontend utility rather than a data science library.",success
https://github.com/tessera-metrics/tessera,tessera,"Tessera is a dashboard front-end for the Graphite metrics system, providing a Flask-based server with a REST API plus a JavaScript UI for building, rendering, and editing interactive metrics dashboards. It emphasizes separation of queries from presentations and supports transformations/actions for drill-down and on-the-fly query/presentation changes.",1200,monitoring|metrics|graphite|dashboards|observability|python|flask|javascript,3,"This repository is primarily an observability/monitoring dashboard system for Graphite metrics (a web UI plus a Flask/SQL-backed service and REST API), not a machine learning or data science library. It can be useful to ML/data teams indirectly for monitoring training/inference infrastructure metrics, but it does not provide data processing, modeling, or MLOps capabilities specific to ML workflows. Community usage appears established within the Graphite/metrics dashboard niche (e.g., ~1.2k GitHub stars), but its applicability to ML/data work is tangential rather than core, so a low score is appropriate.",success
https://github.com/TritonDataCenter/containerpilot,containerpilot,"ContainerPilot is an init system designed to run inside a container, supervising processes and automating service discovery, health checks, configuration updates, and lifecycle hooks. It integrates with Consul for service registration and coordination across distributed containerized applications.",1100,DevOps|containers|Docker|service-discovery|Consul|process-supervision|orchestration,3,"This repository provides a container init/process supervisor focused on service discovery, health checks, and lifecycle event hooks for containerized applications, typically coordinating through Consul. It is not an ML or data-science library, but it can be used as general infrastructure in ML platforms to manage and orchestrate supporting services around model serving/training components. The score reflects tangential relevance: useful for platform/DevOps work that may support ML systems, but it does not directly provide data processing, modeling, MLOps/model management, or ML-specific functionality.",success
https://github.com/pypa/gh-action-pypi-publish,gh-action-pypi-publish,"A PyPA-maintained GitHub Action for publishing pre-built Python distribution artifacts (e.g., wheels/sdists in dist/) to PyPI or TestPyPI, supporting modern “Trusted Publishing” via OIDC (tokenless authentication). It focuses on secure upload/publishing (not building) and can optionally generate and upload digital attestations in trusted publishing flows.",1100,GitHub Actions|CI/CD|Python packaging|PyPI publishing|DevOps|supply chain security|OIDC|Sigstore attestations,3,"This repository provides a GitHub Action that securely uploads Python package distribution files to PyPI/TestPyPI, with strong support for OIDC-based trusted publishing and optional Sigstore-backed attestations. It is not an ML/data library and does not provide data science functionality, but it can be useful in ML workflows indirectly by automating release/publishing of ML Python packages (libraries, model-serving clients, tooling) to PyPI. The score reflects tangential relevance: valuable CI/CD infrastructure for ML engineers shipping packages, but not directly applicable to model training, data processing, or MLOps pipelines beyond publishing artifacts.",success
https://github.com/vimeo/graph-explorer,graph-explorer,"Graph Explorer is a highly interactive dashboard for Graphite that uses structured (tagged) metrics to enable powerful ad-hoc querying, grouping, aggregation, and dynamic graph generation. It also includes dashboard pages (multiple queries per page) and an alerting system for threshold-based notifications.",1100,monitoring|graphite|metrics|observability|dashboard|alerting|elasticsearch|python,3,"This repository is primarily an observability/monitoring tool for exploring Graphite time-series metrics using a structured tag database, an expressive query language (GEQL), dashboards, and alerting. While it deals with time-series data and can be useful for operational analytics (which sometimes overlaps with data/ML platforms), it is not designed for model training, feature engineering, or ML workflows. Its value to data science is therefore mostly tangential—useful for monitoring data/ML infrastructure metrics, but not a direct ML/data toolkit.",success
https://github.com/byashimov/django-controlcenter,django-controlcenter,"A Django app that provides configurable dashboard pages (with pluggable widgets) for the Django admin, letting you view multiple models and metrics in one place and render charts (e.g., via Chartist.js). It supports composing multiple dashboards and sourcing widget data from Django models or arbitrary external data sources.",1000,django|python|django-admin|dashboard|admin-panel|data-visualization|charting|web-development,3,"This repository is primarily a Django web/admin dashboard framework that helps developers build admin dashboards with widgets and charts, rather than an ML or data-science library. It can be used to display ML-related KPIs (e.g., model performance metrics) inside a Django admin interface if your stack already uses Django, but it does not provide data processing, modeling, training, or MLOps capabilities. Because its value to ML/data workflows is mostly incidental (presentation/UI layer) and not core to ML tasks, it scores as tangentially related.",success
https://github.com/mikeroyal/NixOS-Guide,NixOS-Guide,"A curated, documentation-style guide for learning and using NixOS and the Nix expression language, with practical sections covering setup, desktop apps, developer tooling, and topic-focused resources (e.g., DevOps, Kubernetes, databases, and ML). It serves primarily as an educational/reference hub rather than a software library.",1000,NixOS|Nix|Linux|developer-environment|DevOps|Kubernetes|documentation|guide,3,"This repository is primarily a curated NixOS/Nix reference guide (documentation) covering installation/setup and a wide range of tooling and ecosystem resources, rather than providing ML code, datasets, or reusable ML components. It can be indirectly useful to ML/data practitioners who want reproducible environments (e.g., Nix shells, system configuration) and it includes a machine-learning section, but it does not appear to be an ML framework, MLOps toolkit, or data-processing library. Community interest looks solid for a guide (about 1k stars), yet its direct applicability to day-to-day ML model development is limited compared to dedicated ML/data repositories.",success
https://github.com/opsgenie/kubernetes-event-exporter,kubernetes-event-exporter,"A Kubernetes controller/service that watches Kubernetes Events and exports them to multiple external systems (e.g., Opsgenie, Slack, Elasticsearch, Kafka, AWS/GCP services) using a configurable routing tree with filtering and templated payloads. The repository is archived and deprecated in favor of the actively maintained fork at resmoio/kubernetes-event-exporter.",1000,kubernetes|kubernetes-events|observability|alerting|devops|event-routing|golang|monitoring,3,"This repository provides infrastructure for exporting and routing Kubernetes cluster events to downstream systems for observability and alerting (e.g., Slack, Elasticsearch, Kafka, AWS services). It is only tangentially related to ML/data workflows: it can feed operational events into data stores/streams that could later be analyzed, but it does not offer data science/ML functionality itself. Given its primary DevOps focus and indirect applicability to data/ML, it scores low; additionally, it is archived and deprecated, reducing practical value for new ML/data integrations.",success
https://github.com/jaywcjlove/awesome-mac,awesome-mac,"A curated “Awesome List” collecting premium macOS software across many categories (e.g., developer tools, productivity, design, security), organized in a large categorized README and related docs.",97400,macos|awesome-list|curated-resources|developer-tools|productivity|open-source,2,"This repository is primarily a curated directory of macOS applications and tools, organized by category in a large Awesome List-style README, rather than a codebase or ML library. It can be tangentially useful for ML/data practitioners by helping them discover macOS developer utilities, terminals, editors, or general-purpose tools, but it is not focused on data science or machine learning workflows. Community adoption is very high (large star count), but the relevance to ML/data is indirect, so it earns a low score.",success
https://github.com/Asabeneh/30-Days-Of-JavaScript,30-Days-Of-JavaScript,"A structured, day-by-day JavaScript learning challenge that teaches core language concepts (data types, functions, DOM, async, etc.) through explanations, exercises, and mini-projects, intended to be completed at your own pace over ~30 days.",45800,javascript|programming education|web development|beginner learning|frontend|dom|exercises,2,"This repository is primarily an educational curriculum for learning JavaScript via a 30-day challenge, covering general-purpose JS topics and web fundamentals (including DOM work and mini-projects). It is not an ML/data library, dataset, or workflow tool, though JavaScript skills can be indirectly useful in data/ML contexts (e.g., building dashboards or web UIs). Community adoption is high for learning JS, but there is little direct applicability to typical data science/ML pipelines or frameworks, so it scores low but not zero.",success
https://github.com/makeplane/plane,plane,"Plane is an open-source project management platform positioned as an alternative to Jira/Linear/Monday/ClickUp. It helps teams manage work items (tasks/issues), cycles/sprints, docs/pages, roadmaps, and analytics, with options for cloud or self-hosted deployment.",42900,project management|issue tracking|agile|productivity|self-hosted|web application|Django|React,2,"This repository primarily provides a general-purpose project management and issue-tracking web platform (work items, cycles, docs/pages, analytics) rather than ML/data functionality. While its built-in analytics and the underlying data model could be used to export operational/project data for reporting or downstream data science, that is incidental to its main use case. It is not an ML library, data processing framework, or MLOps tool, and it does not appear targeted at ML/data workflows specifically. Therefore, it is only tangentially relevant to data science/ML use cases, earning a low score.",success
https://github.com/juspay/hyperswitch,hyperswitch,"Hyperswitch is a composable, open-source payments switch/infrastructure stack written in Rust, designed to help businesses integrate and manage payment processing with modular components (e.g., routing, retries, vaulting, and observability). It supports integrating multiple payment methods and payment service providers while aiming for high performance, reliability, and reduced vendor lock-in.",39300,payments|fintech|payment-orchestration|rust|api|microservices|observability|pci-compliance,2,"This repository primarily provides payments infrastructure (a Rust-based payments switch) focused on transaction routing, retries, vaulting, and operational tooling rather than ML or data science. While it includes analytics/observability and “intelligent routing” concepts, the repo’s main value is as backend fintech infrastructure, not as an ML library, data pipeline, or MLOps tool. Data/ML practitioners might only interact with it indirectly (e.g., emitting payment events/logs for downstream analysis), so its direct applicability to ML/data workflows is limited. Therefore, it is tangentially related to data work but not ML-focused, warranting a low score.",success
https://github.com/ant-design/ant-design-pro,ant-design-pro,"Ant Design Pro is an out-of-the-box React + Ant Design boilerplate/scaffolding for building enterprise/admin web applications. It provides ready-made layouts, pages (dashboard, forms, lists, accounts, exceptions), TypeScript support, theming, i18n, mock development, and testing utilities.",37800,web development|React|Ant Design|admin dashboard|TypeScript|Umi|frontend scaffolding,2,"This repository is primarily a front-end scaffolding/template for building enterprise/admin web applications with React and Ant Design, focusing on UI layout, routing, and common admin pages rather than data/ML functionality. It can be tangentially useful in ML/data workflows only insofar as teams might use it to build internal dashboards for monitoring experiments, metrics, or analytics, but it provides no ML libraries, modeling, or data-processing capabilities itself. Community adoption is strong for front-end use, but it is not widely used as an ML/data tool. Therefore, it scores low (2/10) for direct ML/data science value.",success
https://github.com/sorrycc/awesome-javascript,awesome-javascript,"A curated “awesome list” of browser-side JavaScript libraries, tools, and learning resources, organized by category (e.g., package managers, bundlers, testing, frameworks, utilities, data visualization, and more). It serves as a discovery index rather than a runnable software package.",34900,javascript|awesome-list|web-development|front-end|libraries|tooling|learning-resources|data-visualization,2,"This repository is primarily a curated directory of JavaScript libraries and resources for browser-side/web development, not an ML or data-science library itself. It has some indirect relevance because it includes categories like data visualization and even a “Machine Learning” section, which can help practitioners discover JS-based ML or visualization tooling. However, it doesn’t provide datasets, model code, training pipelines, or ML-specific workflows, so its direct applicability to day-to-day ML/data engineering is limited despite strong general popularity.",success
https://github.com/umami-software/umami,umami,"Umami is an open-source, privacy-focused website analytics platform designed as an alternative to Google Analytics (and similar tools like Mixpanel/Amplitude). It provides self-hostable, lightweight traffic and event analytics with a simple dashboard, supporting deployments via Node.js/PostgreSQL or Docker.",34600,web analytics|privacy|self-hosted|TypeScript|Next.js|PostgreSQL|Docker,2,"This repository primarily provides a web analytics application for tracking website traffic and events with a privacy-first approach, intended to replace third-party analytics services. While it produces and stores behavioral/telemetry data that could be exported and analyzed, it is not an ML/data-science library and does not focus on model training, feature engineering, or MLOps workflows. Its value to ML/data work is therefore mostly tangential (data collection/source system rather than an ML tool), which fits a low score of 2.",success
https://github.com/statelyai/xstate,xstate,"XState is an actor-based state management and orchestration library for JavaScript/TypeScript that lets developers model application/workflow logic using event-driven state machines/statecharts and the actor model. It’s used to make complex UI and backend logic more predictable, testable, and debuggable, with integrations across popular frameworks.",29100,javascript|typescript|state-machines|statecharts|actor-model|state-management|react|workflow-orchestration,2,"This repository provides a general-purpose state management and orchestration framework (state machines/statecharts + actor model) primarily aimed at managing complex application logic in JS/TS apps. It is not an ML/data science library, but it can be tangentially useful in ML-adjacent systems for orchestrating workflows (e.g., data processing pipelines, model-serving state, or complex agent/task coordination). Community adoption is high in the broader JS ecosystem, but direct ML/data workflows and integrations are limited, so its value for ML/data work is low but non-zero.",success
https://github.com/arthurspk/guiadevbrasil,guiadevbrasil,"A comprehensive Portuguese-Brazilian programming/tech career guide that curates learning resources, tools, roadmaps, and links across many IT areas (front-end, back-end, DevOps, security, etc.), with community contributions and multiple translations.",15500,developer resources|programming guide|learning roadmap|web development|DevOps|career development|open-source curation,2,"This repository is primarily a curated guide of links and study resources for software development and general IT careers, rather than an ML/data library or tool. While it may contain sections that touch on data-related topics, it does not provide datasets, ML code, reusable ML components, or workflow integrations commonly used by data scientists/ML engineers. Its value for ML/data is therefore mostly tangential and educational at a high level, which aligns with a low score.",success
https://github.com/lint-staged/lint-staged,lint-staged,"Runs configured tasks (e.g., formatters and linters) only on Git staged files, typically via a pre-commit hook, to enforce code quality without running checks across the entire project. It supports glob-based configuration and passes the staged file list to arbitrary shell commands.",14400,git|pre-commit|linting|code-formatting|javascript|nodejs|developer-tooling|ci-cd,2,"lint-staged is a developer workflow utility that runs linters/formatters/tests against only the files staged for commit, commonly used with pre-commit hooks (e.g., via Husky) to keep repositories clean and consistent. It is not an ML/data library and does not provide data processing, modeling, training, or MLOps functionality. It can still be useful in ML/data projects incidentally (e.g., enforcing formatting/linting in Python/JS repos or notebooks-related tooling), but its value is general software engineering rather than data science-specific, hence a low score.",success
https://github.com/FormidableLabs/webpack-dashboard,webpack-dashboard,"A CLI-based dashboard UI for webpack development builds that replaces noisy terminal logs with a real-time, panel-style display. It works by pairing a webpack plugin with a CLI wrapper so you can monitor build status, progress, and related dev-server output in a more readable interface.",14200,webpack|javascript|nodejs|cli|developer-tools|build-tools|frontend-tooling,2,"This repository is primarily a developer-experience tool for frontend build workflows: it provides a terminal dashboard for webpack dev server/build output rather than ML or data functionality. It can be tangentially useful to ML/data practitioners only insofar as they might use webpack in a web app that serves model outputs or dashboards, but it doesn’t provide data processing, ML algorithms, MLOps, or analytics capabilities. Community adoption is strong in general web development, but not specifically in the ML/data ecosystem, so it rates low for direct ML/data value.",success
https://github.com/QwikDev/partytown,partytown,"Partytown is a lazy-loaded library that moves resource-intensive third-party scripts (e.g., analytics) off the browser main thread and into a web worker to improve page performance and Core Web Vitals.",13600,web-performance|javascript|typescript|web-workers|third-party-scripts|analytics|core-web-vitals|lighthouse,2,"This repository is primarily a web performance tool that offloads third-party scripts to a web worker to reduce main-thread work and improve metrics like Lighthouse scores and Core Web Vitals. It is not designed for machine learning or data science tasks, and it does not provide ML algorithms, data processing primitives, or MLOps capabilities. It may be tangentially useful to ML/data teams only insofar as it can improve the performance of data-heavy web apps or analytics instrumentation, but it is not directly applicable to ML workflows.",success
https://github.com/automatisch/automatisch,automatisch,"Automatisch is an open-source, self-hosted Zapier alternative for building workflow automations that connect third-party services (e.g., Slack, Twitter) with low-code/no-code setup. It focuses on letting teams run automation workflows on their own infrastructure to avoid vendor lock-in and keep data in-house.",13500,workflow automation|integration platform|zapier-alternative|self-hosted|low-code|no-code|nodejs,2,"This repository is primarily a workflow automation and app-integration platform (a Zapier-like tool) intended for connecting services and automating business processes, typically via self-hosted deployments. It is not designed for machine learning or data science tasks, and it does not provide ML algorithms, model training, feature engineering, or MLOps capabilities as its core value. It can be tangentially useful in data/ML contexts as general-purpose automation glue (e.g., triggering jobs, moving data between systems), but that utility is incidental rather than ML-focused, hence a low score.",success
https://github.com/hackerkid/Mind-Expanding-Books,Mind-Expanding-Books,"A curated, categorized collection of book recommendations (“Mind Expanding Books”) intended to help readers discover their next book. The repository includes a large README list organized by topics (e.g., business, philosophy, science, fiction) and supports community contributions via guidelines.",13200,book-list|reading-list|curated-list|awesome-list|open-source-community|education|goodreads-links,2,"This repository is primarily a curated reading list and website-oriented catalog of books, organized by subject areas, rather than a software library, dataset, or ML tool. While it can be educational and may include some AI/ML-related books among many categories, it doesn’t provide data pipelines, models, code for ML workflows, or ML-specific integrations. Community adoption is high (many stars), but its direct applicability to day-to-day data science/ML engineering work is limited, so it scores low but not zero.",success
https://github.com/cyrus-and/gdb-dashboard,gdb-dashboard,"A standalone .gdbinit script (built with GDB’s Python API) that adds a modular, terminal-based dashboard to GDB showing key program state (e.g., registers, stack, assembly) to reduce the number of manual inspection commands during debugging.",12100,debugging|gdb|developer-tools|python|terminal-ui|reverse-engineering|syntax-highlighting,2,"This repository provides a modular visual dashboard interface for the GNU Debugger (GDB), delivered as a Python-based .gdbinit configuration script, to improve interactive debugging workflows in the terminal. It is not designed for machine learning or data science tasks, and it does not provide ML/data processing capabilities. It can be tangentially useful to ML engineers when debugging native code (e.g., C/C++/CUDA extensions) used in ML stacks, but that’s an indirect and optional use case rather than the project’s focus. Therefore, it scores low for ML/data value despite being a widely used developer productivity tool.",success
https://github.com/nmap/nmap,nmap,"Nmap (Network Mapper) is an open-source network discovery and security auditing tool for scanning hosts, ports, services, and operating-system fingerprints. This repository is a GitHub mirror of the official Nmap SVN source and includes related utilities such as Ncat, Ndiff, Nping, and Zenmap.",12100,network scanning|cybersecurity|security auditing|network discovery|port scanning|C/C++|Nmap Scripting Engine (NSE),2,"This repository primarily provides Nmap, a widely used network scanner for host discovery, port/service detection, OS fingerprinting, and security auditing. It is not designed for machine learning or data science, but its scan outputs are often consumed as data (e.g., for asset inventory, security analytics, or downstream anomaly detection) in broader security data pipelines. Because its direct purpose is network reconnaissance rather than ML/data processing, and it does not provide ML-focused APIs or modeling components, its value to ML/data workflows is mostly indirect—hence the low score.",success
https://github.com/OffcierCia/DeFi-Developer-Road-Map,DeFi-Developer-Road-Map,"A curated DeFi & blockchain developer roadmap/handbook collecting learning resources, research links, tools, and references for building dApps and smart contracts. It includes a visual roadmap plus categorized sections (e.g., basics, frameworks, security, DeFi topics) and community-contributed translations.",10600,defi|blockchain|ethereum|smart-contracts|dapp-development|security|learning-resources|roadmap,2,"This repository is primarily an educational roadmap and link collection for DeFi/blockchain development (tools, references, and a visual roadmap), not a software library or dataset for ML. It has minimal direct applicability to ML/data workflows, aside from being a general technical learning resource that could be tangentially useful for understanding crypto/DeFi concepts sometimes analyzed in data science. The score reflects low ML relevance despite strong community adoption in its own domain (large star count).",success
https://github.com/faisalman/ua-parser-js,ua-parser-js,"UAParser.js is a JavaScript user-agent parsing and detection library that identifies a client’s browser, OS, CPU, device type/model, and can also detect bots/apps/AI crawlers. It runs in both browsers (client-side) and Node.js (server-side).",10000,javascript|nodejs|user-agent-parsing|browser-detection|device-detection|analytics|client-hints|bot-detection,2,"This repository provides user-agent parsing/detection for web and server environments (browser/OS/device/bot/app identification), primarily for analytics and device targeting rather than ML. It can be tangentially useful in data workflows (e.g., feature engineering from user-agent strings, traffic/bot filtering, or labeling/segmentation for analytics datasets), but it is not an ML or data-processing library. Community adoption appears strong (high stars), yet its direct applicability to model training, MLOps, or core data science tasks is limited, so a low-but-nonzero score is appropriate.",success
https://github.com/DouyinFE/semi-design,semi-design,"Semi Design is an open-source design system and React UI component library maintained by the Douyin/ByteDance front-end team. It provides a large set of production-ready components plus a design-token system (3000+ tokens) and tooling that connects design (e.g., Figma) with code (Design-to-Code / Code-to-Design) for building consistent enterprise web apps.",9700,design system|react|ui component library|typescript|design tokens|figma|accessibility,2,"This repository’s primary purpose is front-end UI: a React component library/design system with extensive design tokens and design-to-code tooling, aimed at building consistent web application interfaces. It is not an ML/data science library and does not provide data processing, modeling, or MLOps functionality. It can be tangentially useful in ML contexts only insofar as it helps build dashboards or internal tools for ML teams, but it is not directly applicable to ML workflows, so it scores low.",success
https://github.com/CreateJS/EaselJS,EaselJS,"EaselJS is a JavaScript library for building high-performance, interactive 2D content using the HTML5 Canvas element. It provides a hierarchical display list, graphics drawing APIs, and a mouse/touch interaction model for things like games, animations, generative art, and data visualization.",8200,javascript|html5-canvas|2d-graphics|animation|interactive-content|data-visualization|web-development,2,"This repository is primarily a 2D rendering and interaction framework for HTML5 Canvas (display list, drawing APIs, sprites, and event handling). It can be used to build custom visualizations (including for data), but it does not provide ML/data-processing functionality, model training, or integration with common ML tooling. As a result, its relevance to ML/data workflows is tangential—useful mainly for front-end visualization rather than data science/ML itself.",success
https://github.com/ajnart/homarr,homarr,"Homarr is a self-hosted, highly customizable dashboard (browser home page) for managing and monitoring a homeserver, with widgets/integrations for common apps and services (e.g., Sonarr/Radarr, Plex/Jellyfin, Docker). This specific repository is the legacy version and was archived on Oct 13, 2025; the project moved to homarr-labs/homarr for v1+.",7000,self-hosted|dashboard|homeserver|docker|devops|web-development|nextjs|typescript,2,"This repository provides a customizable self-hosted dashboard for interacting with and monitoring homeserver applications and containers, rather than tooling for data science or machine learning. It can be tangentially relevant to ML/data workflows only in the sense that a team could surface links/status/metrics for ML services, but it does not offer ML functionality, data processing, or MLOps features itself. Given its primarily homeserver/DevOps dashboard use case (and that it is an archived legacy repo), its direct value to ML/data work is low, hence a score of 2.",success
https://github.com/Tautulli/Tautulli,Tautulli,"Tautulli is a Python-based web application for monitoring, analytics, and notifications for Plex Media Server. It tracks server activity and user watch history, provides library/user statistics and graphs, and supports configurable stream and media-addition notifications.",6300,plex|media-server-monitoring|python|web-application|analytics|notifications|docker,2,"This repository is primarily a monitoring/analytics dashboard for Plex Media Server usage (stream activity, watch history, and library/user statistics) rather than an ML or data science toolkit. While it generates and stores structured usage/telemetry data that could be exported and analyzed externally, it does not focus on machine learning, modeling, data pipelines, or ML-specific integrations. Its value to ML/data workflows is therefore tangential (useful mainly as a source of data), which aligns with a low score.",success
https://github.com/infobyte/faraday,faraday,"Faraday is an open-source vulnerability management platform that aggregates and normalizes security findings from multiple tools, helping teams organize, visualize, and track vulnerabilities in a multiuser workflow. It supports running via Docker/docker-compose, packages, or Python installation and provides dashboards and other views for analysts and managers.",6100,cybersecurity|vulnerability-management|application-security|penetration-testing|DevSecOps|security-automation|docker|python,2,"This repository primarily provides a vulnerability management platform for aggregating, normalizing, and visualizing security scan results, aimed at security operations and pentesting workflows rather than ML. It can indirectly support data/ML use cases if you treat normalized vulnerability data as an analytics dataset, but ML capabilities are not a core focus and it does not provide ML training/inference tooling. Given its tangential relevance to data work (security analytics) but lack of ML-first features or common ML ecosystem integration, a low score is appropriate.",success
https://github.com/fleetdm/fleet,fleet,"Fleet is an open-source device management and security/telemetry platform for managing and querying fleets of endpoints (macOS, Windows, Linux, Chromebooks, and more). It is designed for API-first and GitOps-friendly workflows (APIs, webhooks, YAML) and integrates with common security and IT tools.",5900,device-management|endpoint-security|osquery|mdm|it-operations|security-telemetry|gitops|golang,2,"This repository primarily provides an IT/security endpoint management platform (built around collecting endpoint state/telemetry via osquery and managing devices with MDM and related controls). While it can generate large volumes of structured telemetry that could be exported for analytics, it is not an ML/data-science library, model-training framework, or data pipeline tool. Data/ML teams might use it indirectly as a data source for security analytics or anomaly detection, but ML is not a core focus, so its direct applicability to typical ML workflows is limited.",success
https://github.com/zouhir/jarvis,jarvis,"J.A.R.V.I.S. (Just A Rather Very Intelligent System) is a browser-based dashboard for Webpack that displays build information for both development and production, improving visibility into bundles, chunks, assets, and errors. It includes features like beautified error output, bundle/asset size insights, and quick searching for programming errors.",5400,webpack|javascript|frontend-tooling|build-tooling|developer-dashboard|preact|socket.io|devops,2,"This repository provides a Webpack-focused build dashboard that helps developers inspect and troubleshoot front-end build output (assets, bundles, chunks, and errors) in the browser. It is not designed for machine learning or data science workflows, and it doesn’t provide ML/data processing capabilities, datasets, model tooling, or MLOps integration. It is only tangentially relevant to ML/data work insofar as ML teams might use Webpack in web applications that present model outputs, so the overall ML/data utility is low.",success
https://github.com/camunda/camunda-bpm-platform,camunda-bpm-platform,"Camunda Platform 7 (Community Edition) is an open-source BPMN 2.0 workflow and decision automation platform for the JVM, providing a process engine plus tooling and integrations (e.g., REST API, Spring/Java EE/CDI) for designing, executing, and operating business processes. The repository is archived and read-only, and the project is End of Life (EoL) with Camunda 8 positioned as the successor.",4300,workflow-automation|bpmn|dmn|business-process-management|java|process-engine|rest-api|spring,2,"This repository implements Camunda Platform 7, a Java-based BPMN/DMN process engine and associated components for workflow/process automation, not a data-science or machine-learning toolkit. While it can be used in data/ML-adjacent systems to orchestrate pipelines or business processes that call ML services, it does not provide ML algorithms, training/inference tooling, or core data engineering capabilities. Its primary value to ML/data practitioners is indirect (workflow orchestration/integration), and the repo is archived and read-only, further limiting practical ML-related adoption and evolution.",success
https://github.com/codeceptjs/CodeceptJS,CodeceptJS,"CodeceptJS is an end-to-end (E2E) and acceptance testing framework for Node.js with a BDD-style, scenario-driven syntax that writes tests from a user’s perspective. It is driver-agnostic and can run tests via multiple backends (e.g., Playwright, WebDriver, Puppeteer, TestCafe, Appium/Detox) and includes features like interactive debugging and an HTML reporter.",4200,end-to-end-testing|test-automation|nodejs|javascript|bdd|playwright|selenium-webdriver|ci-cd,2,"This repository’s primary purpose is test automation: it provides a scenario-driven E2E/acceptance testing framework for web/mobile/API applications, integrating with browser/mobile drivers like Playwright, WebDriver, Puppeteer, TestCafe, and Appium/Detox. It is not an ML/data science library and does not directly support model training, data processing, or MLOps workflows. It can be tangentially useful to ML teams only insofar as it helps test ML-powered web products or dashboards in CI, so its direct value for data science/ML work is low, hence a score of 2/10.",success
https://github.com/0wczar/airframe-react,airframe-react,"Airframe React is an open-source (MIT) admin/dashboard/analytics template built with React and Bootstrap 4. It’s a Webpack-based React app (with React Router and customized reactstrap) providing many prebuilt layouts, pages, and UI components for building admin panels, CRMs/CMSs, and similar web apps.",4000,react|bootstrap|admin-dashboard|dashboard-template|webpack|react-router|reactstrap|scss,2,"This repository is primarily a front-end UI/admin dashboard template (React + Bootstrap) meant for building web application interfaces, not ML or data processing. While it could be used to build dashboards that visualize ML metrics or analytics results, it does not provide ML algorithms, data pipelines, model training tools, or integrations typical of ML/data engineering projects. Its value to ML/data workflows is therefore tangential (mostly UI scaffolding), which fits a low score.",success
https://github.com/arxanas/git-branchless,git-branchless,"git-branchless is a Rust-based suite of CLI tools that enhances Git for a “branchless” (but branch-compatible) workflow, with features like high-level undo, commit-graph visualization (smartlog), and tools to repair/restack and manipulate commit graphs. It is designed for high-velocity work and performance in large repositories/monorepos via in-memory operations and optimized commit-graph data structures.",4000,git|version-control|developer-tools|cli|rust|monorepo|commit-graph|productivity,2,"This repository primarily provides Git workflow and history-management tooling (e.g., undoing operations, visualizing commit graphs, restacking/repairing history) rather than any ML or data-science functionality. It can still be tangentially useful to ML/data teams because they often work in large repos/monorepos and benefit from faster rebases and safer history rewriting, but it does not integrate with ML frameworks or address data/ML tasks directly. Community adoption appears solid (about 4k GitHub stars), which suggests it’s a meaningful general developer productivity tool, but its relevance to ML/data workflows remains indirect.",success
https://github.com/camunda/camunda,camunda,"Camunda 8 process orchestration framework, providing a cloud-native workflow engine (Zeebe) plus supporting components for human task management (Tasklist), operations/monitoring (Operate), authentication/authorization (Identity), and process analytics/optimization (Optimize).",4000,workflow-orchestration|business-process-management|bpmn|process-automation|microservices|java|grpc|kubernetes,2,"This repository is primarily a process orchestration and workflow automation platform (Camunda 8) centered on BPMN/DMN execution and operational tooling (Zeebe, Tasklist, Operate, Identity, Optimize). It is not designed for machine learning or data science, but it can be tangentially useful in ML/data workflows as general infrastructure to orchestrate business processes, automate tasks, and export process data for monitoring/analysis. Because ML/data functionality is not a core focus and there is no direct ML framework/pipeline emphasis, it scores low but not zero.",success
https://github.com/frangoteam/FUXA,FUXA,"FUXA is a web-based process visualization platform (SCADA/HMI/Dashboard) for building custom machine/process UIs with real-time data display. It provides a browser-based editor and supports multiple industrial/IoT protocols (e.g., Modbus, Siemens S7, OPC UA, BACnet, MQTT) with a Node.js backend and Angular frontend.",4000,scada|hmi|industrial-iot|dashboard|nodejs|angular|opc-ua|modbus,2,"This repository is primarily an industrial SCADA/HMI web application for real-time process visualization and device connectivity, not an ML or data science library. While it can collect/display time-series tag values and connect to industrial data sources (useful upstream of analytics), it does not provide ML modeling, training, feature engineering, or MLOps capabilities. Therefore its relevance to ML/data workflows is tangential, mainly as a potential data/visualization front-end rather than a core data science tool.",success
https://github.com/fuse-box/fuse-box,fuse-box,FuseBox is a JavaScript/TypeScript bundler and module loader focused on fast builds and a comprehensive programmatic API. It supports typical modern web-dev workflows such as dev server usage and hot module reloading (HMR).,4000,javascript|typescript|bundler|module-loader|web-development|build-tool|hmr|dev-server,2,"This repository is primarily a JavaScript/TypeScript bundler/loader intended for web application build workflows, not for machine learning or data science. It can be tangentially useful to ML/data teams only insofar as they may need to bundle front-end assets for dashboards, demos, or model-serving UIs. It does not provide ML algorithms, data processing utilities, MLOps features, or integrations with common ML frameworks, so its direct applicability to ML/data workflows is limited.",success
https://github.com/TheHive-Project/TheHive,TheHive,"TheHive is a collaborative case management platform for security incident response, investigation tracking, and SOC/CSIRT workflows, with integrations such as Cortex analyzers and MISP synchronization. This public repository is archived and reflects the legacy open-source TheHive (v3/v4), while newer versions are distributed commercially.",3900,cybersecurity|incident-response|case-management|DFIR|SOC|Scala|MISP|Cortex,2,"This repository implements TheHive, a security incident response and investigation/case management platform (legacy OSS versions), not an ML or data-science-focused library. While it may generate and store investigation data (e.g., observables/IOCs) that could be exported for analytics, it does not primarily provide ML models, training pipelines, or data-science tooling. Its relevance to ML/data workflows is therefore tangential (mainly as a data source/integration point), justifying a low score rather than zero.",success
https://github.com/parse-community/parse-dashboard,parse-dashboard,"Parse Dashboard is a standalone web dashboard for administering Parse Server apps. It provides an admin UI for tasks like browsing and managing data, configuring apps, and deploying/running the dashboard (including via CLI, Express middleware, and Docker).",3800,parse-server|admin-dashboard|backend-administration|web-development|nodejs|express|graphql|docker,2,"This repository’s primary purpose is to provide an administrative dashboard for managing Parse Server applications (e.g., data browsing/management, app configuration, and operational deployment). While it can be used to inspect and export application data (which may be part of a data workflow), it is not built for ML/modeling, data processing at scale, or MLOps. As a result, its usefulness to ML/data science is mostly incidental (admin UI over an app database), warranting a low but non-zero score.",success
https://github.com/zeman/perfmap,perfmap,"PerfMap is a bookmarklet and Chrome extension that overlays a front-end performance heatmap on a web page, visualizing when images/resources finish loading using the browser Resource Timing API. It helps identify slow-loading page elements and understand user-perceived loading performance via an interactive legend/timeline.",3800,web-performance|frontend|javascript|browser-extension|bookmarklet|performance-profiling|resource-timing-api,2,"This repository is a front-end web performance visualization tool (bookmarklet/Chrome extension) that uses the Resource Timing API to create a heatmap of resource load timings. It is not designed for machine learning or data science tasks, but it can be tangentially useful to data/ML teams when optimizing performance of web-based ML demos, dashboards, or data-heavy sites. Community adoption appears solid for a niche web-perf utility (thousands of GitHub stars), but it does not integrate with ML/data frameworks or provide ML-focused functionality, hence a low score.",success
https://github.com/fastapi-admin/fastapi-admin,fastapi-admin,"FastAPI Admin is an admin dashboard framework for FastAPI projects, built on TortoiseORM and the Tabler UI. It provides a Django-admin-like interface (with authentication/providers and a ready-to-run example setup using Redis) to quickly manage application data via a web admin panel.",3700,fastapi|python|admin-dashboard|web-development|tortoise-orm|tabler-ui|crud|backend,2,"This repository’s primary purpose is to provide a web-based admin dashboard for FastAPI applications (similar in spirit to Django admin), not ML or data science tooling. It can be tangentially useful in ML/data workflows when you need an internal admin UI to manage datasets, labels, users, or operational metadata in a FastAPI-based service, but it does not provide data processing, model training, MLOps, or analytics functionality. Community adoption appears strong for a FastAPI utility (thousands of stars), but its applicability to ML/data work is indirect, so it fits best in the “tangentially related” range.",success
https://github.com/octodns/octodns,octodns,"octoDNS is a “DNS as code” toolkit for defining DNS zones/records (commonly via YAML) and synchronizing them across multiple DNS providers using a pluggable provider architecture. It supports Git-based workflows (reviewable changes, history) and can validate/plan/sync DNS updates consistently across environments.",3600,DNS|infrastructure as code|DevOps|Python|configuration management|automation|cloud,2,"This repository’s primary purpose is DNS management automation (“DNS as code”) across multiple DNS providers, centered on infrastructure/DevOps workflows rather than data science or machine learning. It has minimal direct applicability to ML/data tasks beyond being a general operational tool that could support ML systems’ infrastructure (e.g., managing service endpoints). Given the lack of ML/data-specific features, libraries, or integrations, it is only tangentially relevant, warranting a low score.",success
https://github.com/rotki/rotki,rotki,"rotki is an open-source, self-hosted portfolio manager focused on privacy, providing crypto (and broader asset) tracking, analytics, and accounting features such as transaction decoding and profit/loss reporting. It stores data locally (encrypted) and supports integrating balances/transactions from multiple chains and exchanges.",3600,cryptocurrency|portfolio-tracking|accounting|tax-reporting|privacy|python|vue.js|self-hosted,2,"This repository is primarily a privacy-focused crypto portfolio tracking and accounting application (transaction ingestion/decoding, analytics dashboards, and PnL/tax-style reports), not a machine learning or data-science library. While it may be useful as a data source for analysts (exporting/structuring transaction history for further analysis), it does not provide ML workflows, model training, or ML-focused integrations as core features. Community adoption appears solid within the crypto-accounting niche, but the direct applicability to ML/data engineering is limited, supporting a low (2/10) score.",success
https://github.com/guildxyz/guild.xyz,guild.xyz,"Open-source web interface for Guild.xyz, a platformless membership management tool for token-curated communities. It provides a Next.js/React frontend with web3 wallet connectivity, UI components, and testing/storybook setup for building and managing Guild experiences.",3500,web3|token-gating|community-management|membership-management|nextjs|react|typescript|frontend,2,"This repository is primarily a web application frontend (React + Next.js) for Guild.xyz, focused on token-gated/community membership management rather than data science or machine learning. While it includes typical product analytics and visualization libraries, it is not designed for ML workflows (no model training, inference pipelines, datasets, or ML tooling). Data/ML relevance is therefore tangential, mainly in the sense that analytics/events could be exported and analyzed elsewhere, which supports a low score.",success
https://github.com/RhinoSecurityLabs/cloudgoat,cloudgoat,"CloudGoat is Rhino Security Labs' ""Vulnerable by Design"" cloud deployment tool that provisions intentionally vulnerable cloud resources (primarily AWS, with Azure support) as capture-the-flag style scenarios for hands-on cloud security training and penetration testing practice.",3400,cloud-security|aws|azure|ctf|security-training|terraform|python|pentesting,2,"CloudGoat's primary purpose is to deploy intentionally vulnerable cloud environments for security training (CTF-style scenarios) and to help users practice cloud penetration testing, using tools like Terraform and a Python-based CLI. It is not designed for machine learning or data science workflows, and it does not provide ML-focused datasets, model training code, or MLOps capabilities. It could be tangentially useful for ML/data practitioners only insofar as it builds general cloud/infra skills or could be used to simulate cloud security situations around data platforms, but that is not its core focus, so the score is low.",success
https://github.com/MauriceNino/dashdot,dashdot,"dash. (dashdot) is a self-hosted, modern server monitoring dashboard designed for smaller VPS/private servers, featuring a glassmorphism UI and Docker-based deployment (AMD64/ARM). It visualizes system metrics like CPU, memory, disk, and network and supports configuration options plus light/dark modes.",3300,server-monitoring|self-hosted|dashboard|docker|nodejs|react|typescript|devops,2,"This repository provides a self-hosted server monitoring dashboard (dash.) focused on visualizing host system metrics for personal/VPS environments, typically deployed via Docker. It is not built for machine learning or data science tasks, and it does not provide ML-specific tooling, datasets, or model-related workflows. It can be tangentially useful to ML/data practitioners only as general infrastructure observability for machines running data workloads, which is why it scores low rather than zero.",success
https://github.com/Smashing/smashing,smashing,"Smashing is a Sinatra-based framework for building and running TV-friendly web dashboards, positioned as the spiritual successor to the unmaintained Dashing project. It provides a Ruby gem/CLI to scaffold dashboard projects and supports dashboard widgets for monitoring and visualization.",3300,ruby|sinatra|dashboard|monitoring|web-development|devops|widgets,2,"This repository is primarily a Ruby/Sinatra dashboard framework (plus widget infrastructure) intended for building monitoring/status dashboards, often displayed on TVs. It is not designed for machine learning or data science tasks such as modeling, training, feature engineering, or data pipelines, though it could be used to display ML metrics (e.g., model performance, pipeline health) as a generic dashboard. Community adoption appears oriented around dashboard/monitoring use rather than ML/data workflows, so its ML/data value is tangential.",success
https://github.com/gautamkrishnar/blog-post-workflow,blog-post-workflow,"A GitHub Action that automatically fetches your latest content (e.g., blog posts, StackOverflow activity, YouTube videos) from RSS-capable sources and updates a GitHub profile/project README between configured markers, committing the changes on a schedule or via manual trigger.",3300,GitHub Actions|automation|README|RSS|DevOps|CI/CD,2,"This repository provides a GitHub Action for automating README updates by pulling entries from RSS feeds (blogs, StackOverflow, YouTube) and writing formatted output into a README. It is not an ML/data-science tool and does not provide datasets, modeling code, or data processing for analytics—its primary value is developer-profile automation. It can be tangentially useful in ML/data contexts only insofar as ML engineers might use it to auto-publish research updates or project posts to a profile README, which is why it scores slightly above completely unrelated.",success
https://github.com/rio-labs/rio,rio,"Rio is a Python-first UI framework for building modern web apps (and local apps) without writing HTML, CSS, or JavaScript. It provides React-style, declarative components and a CLI to scaffold and run projects.",3300,python|web-development|ui-framework|react-style-components|frontend|developer-tools|cli,2,"This repository is primarily a Python UI framework for creating websites and apps with declarative, component-based APIs, focusing on eliminating the need for HTML/CSS/JavaScript. It is not designed for machine learning or data science tasks, and it does not appear to provide ML-centric functionality like data processing, model training, evaluation, or MLOps workflows. Data/ML teams could still use it tangentially as a way to build internal dashboards or lightweight app frontends around ML outputs, but that is an indirect use case rather than the repo’s core purpose. Therefore, it scores low (2/10) as an ML/data resource: useful as general app/UI infrastructure, but not an ML/data tool.",success
https://github.com/unfoldadmin/django-unfold,django-unfold,"Unfold is a modern theme for Django’s built-in admin that upgrades the UI with a Tailwind CSS-based design and adds admin-focused features like configurable sidebar navigation, dark mode, advanced filters, dashboards/tools, UI components, and integrations with common Django admin add-ons.",3100,django|django-admin|admin-dashboard|python|tailwindcss|web-development|ui-theme,2,"This repository is primarily a Django admin UI/theme framework that improves the look-and-feel and usability of Django’s administration interface (e.g., modern styling, navigation, filters, dashboards, and component helpers). It is not designed for machine learning or data science tasks, and it does not provide ML algorithms, data processing utilities, or MLOps functionality. It can still be tangentially useful in data-centric applications by making internal tooling/admin panels nicer for managing datasets, annotations, or model metadata, but that’s an indirect use case rather than an ML-focused feature set. The score reflects minimal direct applicability to ML/data workflows despite being potentially helpful for operational/admin interfaces in data products.",success
https://github.com/deanishe/alfred-workflow,alfred-workflow,"A full-featured Python helper library for building Alfred (v3 and v4) workflows, providing utilities like settings, caching, fuzzy filtering, keychain integration, web requests, background tasks, and JSON feedback generation for Alfred scripts.",3000,python|alfred|macos|workflow-automation|developer-tools|cli-utilities,2,"This repository is primarily a Python utility/library for authoring Alfred 3/4 automation workflows on macOS (e.g., caching, settings, HTTP helper, keychain support, and feedback/serialization for Alfred). It is not designed for machine learning or data science tasks, and it does not provide ML algorithms, data processing pipelines, or integrations with common ML frameworks. Data/ML practitioners could use it only indirectly as general-purpose Python infrastructure (e.g., HTTP requests, caching) when building an Alfred-based launcher for data tools, which is why it scores low but non-zero.",success
https://github.com/msgbyte/tianji,tianji,"Tianji is an all-in-one self-hostable observability/insight hub that combines website analytics, uptime monitoring, and server status tracking as a lightweight alternative to using multiple separate tools (e.g., GA/Umami + uptime monitor + Prometheus-style status). It also includes features oriented around notifications, telemetry, and team/website operations.",3000,website analytics|uptime monitoring|server monitoring|self-hosted|observability|typescript|docker,2,"This repository primarily provides a web operations/observability product (website analytics, uptime checks, and server status dashboards) rather than ML or data science tooling. While it does collect and display event/telemetry data that could be exported and analyzed downstream, it does not appear to include ML models, data processing pipelines for ML, or integrations aimed at training/serving models. As a result, its direct applicability to typical ML/data workflows is limited, earning a low but non-zero score because telemetry/analytics systems can be adjacent to data work.",success
https://github.com/kubernetes-retired/kui,kui,"Kui is a framework that enhances traditional command-line interfaces (notably kubectl) with a fast, graphical UI experience, replacing ASCII-heavy output with interactive visualizations (e.g., sortable tables and clickable resources). It supports building custom graphical CLIs and can be packaged as a desktop app (via Electron) or used in a client-server architecture.",2900,kubernetes|kubectl|cli|electron|cloud-native|devops|visualization|plugin-framework,2,"This repository is primarily a Kubernetes-focused CLI/UI framework that adds interactive visualizations and UX improvements to cloud-native command workflows, rather than providing ML or data science functionality. It may be tangentially useful for ML practitioners only insofar as they operate Kubernetes-based infrastructure (e.g., clusters running data/ML workloads) and want better operational tooling. There is no direct support for model training, data processing, MLOps pipelines, or integration with common ML frameworks, so its applicability to ML/data workflows is limited.",success
https://github.com/apache/cloudstack,apache/cloudstack,"Apache CloudStack is an open-source Infrastructure-as-a-Service (IaaS) cloud computing platform for deploying and managing large-scale virtualized (and container) infrastructure. It provides compute orchestration, networking (NaaS), account management, an API, resource accounting, and a web UI, with support for multiple hypervisors.",2800,cloud computing|IaaS|virtualization|cloud orchestration|DevOps|infrastructure management|Java|networking,2,"This repository is primarily an IaaS cloud management/orchestration platform (Apache CloudStack) used to build and operate private/public/hybrid clouds, not an ML or data-focused library. It can be indirectly useful to ML/data teams as underlying infrastructure for running compute workloads (e.g., provisioning VMs and networking for training/serving clusters), but it does not provide ML algorithms, data processing primitives, or MLOps tooling as its main purpose. Community adoption is strong in cloud/IaaS contexts, but its applicability to ML/data workflows is mostly infrastructural and indirect, hence a low score.",success
https://github.com/mustbeperfect/definitive-opensource,definitive-opensource,"A curated, actively maintained “definitive” directory of consumer-facing open-source applications (desktop, self-hosted, and CLI utilities), with projects organized by category/platform and generated from JSON data via scripts and automation.",2800,open-source|curated-list|awesome-list|self-hosted|desktop-apps|cli-tools|python-scripts,2,"This repository’s primary purpose is to curate and maintain a vetted catalog of consumer-facing open-source apps, with metadata and lists generated from JSON sources and automation. It is not an ML/data-science library, dataset, or MLOps tool, so it has limited direct applicability to typical ML/data workflows. It can still be mildly useful to ML/data practitioners as a general discovery resource (e.g., finding self-hosted tools or AI-related utilities), but that value is incidental rather than core. Community adoption appears solid (≈2.8k stars), yet the project is fundamentally a curated directory rather than a data/ML solution.",success
https://github.com/sorry-cypress/sorry-cypress,sorry-cypress,"Sorry Cypress is an open-source, self-hosted alternative to Cypress Dashboard/Cypress Cloud for recording, parallelizing, and debugging Cypress end-to-end test runs. It provides a web UI and services to store and browse run results, screenshots/videos, and integrates with tools like GitHub and Slack via webhooks.",2800,cypress|test-reporting|ci-cd|devops|docker|kubernetes|typescript|dashboard,2,"This repository’s primary purpose is to provide a self-hosted dashboard and backend services for Cypress E2E test orchestration and reporting (parallelization, artifacts like screenshots/videos, run history, and integrations). It is not aimed at machine learning or data science tasks, but it can be tangentially useful to ML/data teams insofar as they also run web app test suites in CI/CD and need scalable test reporting infrastructure. Because it doesn’t provide ML algorithms, data processing capabilities, or MLOps/model tooling directly, its value for ML/data workflows is limited, hence a low score.",success
https://github.com/viewflow/viewflow,viewflow,"Viewflow is a Django-based low-code component library for building business applications, with reusable BPMN-style workflow primitives plus built-in UI components like CRUD, dashboards, and reporting. It provides a “Core” open-source library and a commercial “PRO” edition, letting teams assemble customizable workflow-driven apps quickly.",2800,python|django|workflow|bpmn|business-process-management|low-code|web-development,2,"This repository primarily provides a reusable workflow and low-code UI/component framework for Django business applications (e.g., BPMN-like workflows, CRUD screens, and reporting dashboards). It is not an ML/data-science library and does not provide model training, data processing, or MLOps functionality. It may be tangentially useful in ML-adjacent products (e.g., building internal workflow apps for model approvals or human-in-the-loop processes), but that’s an indirect use case, so it scores low for direct ML/data value.",success
https://github.com/sindresorhus/alfy,alfy,"Alfy is a Node.js library for building Alfred (macOS) workflows more easily. It provides utilities for Script Filter input/output, caching and config management, fetching remote data with optional caching, packaging/publishing workflows to npm, and automatic update notifications.",2700,alfred-workflows|nodejs|javascript|cli-tools|macos-automation|workflow-automation|developer-tools,2,"This repository is primarily a Node.js helper library for creating Alfred workflows on macOS, focusing on workflow UX (input/output formatting), caching/config, and distribution/update mechanics rather than data/ML functionality. While it can be used to build workflow front-ends that query APIs or run scripts (including ML-related scripts), it does not provide ML algorithms, data processing primitives, or integrations with common ML frameworks. Its relevance to ML/data workflows is therefore tangential—useful only as a general automation/launcher utility around other tools—so a low score is appropriate.",success
https://github.com/t9tio/open-source-jobs,open-source-jobs,"An auto-generated list (and companion website) of open-source projects that offer jobs, intended for people who want to work on open source and get paid. The repository includes the curated/compiled job list data and a web app for browsing it.",2700,open-source|jobs|job-board|career-resources|web-development|nextjs|typescript,2,"This repository’s primary purpose is to curate and publish a directory of open-source projects that are hiring, along with links to job pages. While it may be useful to data/ML practitioners as a career resource (e.g., to find data/ML-friendly open-source employers), it does not provide ML models, datasets, training code, or data tooling. Any ML/data relevance is indirect and primarily informational rather than workflow or tooling oriented, so it scores low.",success
https://github.com/DavidWells/analytics,analytics,"A lightweight, plugin-based analytics abstraction library for tracking page views, custom events, and user identity across multiple analytics providers. It supports browser and server (isomorphic) usage and provides tooling for controlling/queuing events and managing integrations via plugins.",2600,web analytics|javascript|node.js|typescript|plugin architecture|event tracking|marketing analytics,2,"This repository is primarily a JavaScript analytics/event-tracking abstraction layer that standardizes how applications send page, track, and identify events to third-party analytics tools via plugins. While it can generate event data that could later be analyzed, it is not focused on data science or machine learning workflows (no modeling, feature engineering, pipelines, or ML integrations). Its value to ML/data work is mostly indirect—helpful for instrumentation and data collection in product analytics rather than for building or operating ML systems—so it rates low on direct ML/data applicability.",success
https://github.com/babybuddy/babybuddy,babybuddy,"Baby Buddy is a self-hosted web application that helps caregivers track baby-related activities (sleep, feedings, diaper changes, tummy time, etc.) and includes reporting/dashboard features to help understand patterns and better anticipate needs.",2600,python|django|self-hosted|health-tracking|parenting|web-application|dashboard|rest-api,2,"This repository is primarily a Django-based baby activity tracking web app, focused on data entry, dashboards, and reporting for caregivers rather than ML workflows. While it produces structured time-series/event data that could be exported and analyzed externally, it does not appear to provide ML models, feature engineering pipelines, or integrations with common ML tooling. Therefore, its relevance to ML/data science is mostly tangential (useful as a data source, not as an ML/data tool), leading to a low score.",success
https://github.com/gmh5225/awesome-game-security,awesome-game-security,"A curated “awesome list” of resources related to game security and adjacent game-development topics, aggregating links across areas like cheats/anti-cheat, emulators, engines, graphics APIs, networking, and platform security. It primarily serves as a categorized index for learning and reference rather than a standalone software package.",2600,game-security|cheat-development|anti-cheat|reverse-engineering|game-hacking|curated-list|infosec,2,"This repository is mainly a curated directory of links and references about game security (including cheating/anti-cheat, emulators, and related game-dev/security topics), not an ML library or dataset. It may be tangentially useful to ML practitioners only insofar as some security/anti-cheat approaches can involve anomaly detection or classification, but the repo itself does not provide ML code, data, training pipelines, or integrations with ML tooling. Community adoption (stars) indicates popularity in its niche, but direct applicability to ML/data workflows is limited, so it merits a low score.",success
https://github.com/homarr-labs/homarr,homarr,"Homarr is a modern, self-hosted dashboard for organizing and interacting with your services via a drag-and-drop grid UI. It offers 30+ integrations, built-in icon library, authentication/user management (including OIDC/LDAP), and real-time widgets/updates without requiring YAML-based configuration.",2600,self-hosted|dashboard|homelab|devops|docker|kubernetes|typescript|web-application,2,"This repository primarily provides a self-hosted, drag-and-drop web dashboard for homelab and self-hosted service management, focusing on integrations, authentication, and real-time widgets rather than data/ML tasks. It has only tangential relevance to ML/data workflows (e.g., you could add links/widgets to ML services you run, but it is not a data processing, analytics, or MLOps tool). Given its utility orientation and lack of ML/data-specific functionality, a low score is appropriate despite being broadly useful infrastructure for self-hosting.",success
https://github.com/prymitive/karma,karma,"Karma is a web UI/dashboard for Prometheus Alertmanager. It improves alert browsing by providing a dashboard-focused view with alert grouping, filtering, aggregation/deduplication across multiple Alertmanager instances, and built-in silence management.",2600,prometheus|alertmanager|monitoring|observability|devops|go|dashboard|alerting,2,"This repository provides an alert dashboard and management UI for Prometheus Alertmanager, focused on observability/operations workflows (viewing alerts, deduplication/aggregation, and managing silences). It is not an ML or data-science library, and it does not provide modeling, training, or data processing capabilities. It can be tangentially useful in ML production environments (e.g., monitoring ML services and infrastructure), but its primary audience and functionality are DevOps/SRE rather than ML/data practitioners, so it scores low.",success
https://github.com/bhavsec/reconspider,reconspider,"ReconSpider is an OSINT (Open Source Intelligence) reconnaissance framework for scanning targets such as IP addresses, domains/websites, emails, organizations, and more, aggregating results from multiple sources. It correlates findings and can visualize aggregated raw data on a dashboard to support security research and attack-surface enumeration.",2500,OSINT|cybersecurity|reconnaissance|attack-surface-enumeration|information-gathering|Python|CLI-tool,2,"This repository is primarily a cybersecurity/OSINT reconnaissance framework focused on gathering and correlating information about targets (IP, domain, email, organization) from many sources, rather than a machine learning or data science library. While it does aggregate and structure raw OSINT data (which could be exported for downstream analytics), it does not appear to provide ML models, ML training/inference workflows, or standard data-science tooling. As a result, its value to ML/data workflows is tangential—useful mainly as a data-collection utility for security-related datasets—so it scores a 2/10.",success
https://github.com/brndnmtthws/thetagang,thetagang,"ThetaGang is a configurable Interactive Brokers (IBKR) options-trading bot focused on systematically collecting option premium, primarily via a modified “Wheel” strategy. It automates tasks like writing/rolling puts and covered calls, and can optionally add hedging (e.g., VIX call hedges) and simple cash management features.",2400,algorithmic-trading|options-trading|interactive-brokers|trading-bot|python|quant-finance|portfolio-management,2,"This repository is primarily an automated options-trading bot for Interactive Brokers, implementing systematic rules for selling and rolling options (not an ML system). While it may produce trading logs/portfolio data that could be analyzed, the core functionality is execution and strategy automation rather than data science workflows, modeling, or ML tooling. Data scientists could use it tangentially as a data source or for backtesting extensions, but it is not designed as an ML/data library, framework, or MLOps component—hence a low score.",success
https://github.com/arscan/encom-boardroom,encom-boardroom,"An HTML5/WebGL recreation (tribute) of the Tron: Legacy ENCOM boardroom scene, featuring a 3D globe and screen visuals. It can run as a static page, or as a Node.js app that streams real-time activity data from GitHub and Wikipedia into the visualization.",2300,webgl|three.js|javascript|data-visualization|html5|node.js|tron,2,"This repository is primarily a front-end WebGL/Three.js visual experience that recreates a movie-inspired boardroom scene and displays streaming public activity data (GitHub and Wikipedia) for visual effect. While it does ingest and visualize real-time data, it is not aimed at ML/data science workflows (no modeling, training, feature engineering, or analytics tooling). Its main value to ML/data practitioners would be tangential: inspiration for real-time data visualization and UI techniques rather than core data/ML functionality.",success
https://github.com/TailAdmin/free-nextjs-admin-dashboard,free-nextjs-admin-dashboard,"TailAdmin is a free, open-source admin dashboard template built with Next.js and Tailwind CSS. It provides ready-made pages, UI components, and layouts (including charts, tables, auth forms, dark mode) to quickly build an admin panel or back-office dashboard.",2200,next.js|react|typescript|tailwind-css|admin-dashboard|ui-template|web-development,2,"This repository is primarily a frontend admin dashboard template (Next.js + Tailwind CSS) intended for building web admin panels and back-office UIs, not for machine learning or data science tasks. It may be tangentially useful for ML/data teams as a starting point to build internal monitoring or analytics dashboards, but it does not include ML models, data pipelines, MLOps tooling, or data analysis libraries. Because its core purpose is general web UI scaffolding rather than ML/data workflows, the value for data science/ML is low.",success
https://github.com/auctors/free-lunch,free-lunch,"A curated, periodically updated list of free Windows software, online services, and resources for everyday users. The README organizes recommendations by category (e.g., AI, audio, backup, browsers, development, education) and notes caveats around privacy, security, and legality.",2200,awesome-list|windows|software-list|productivity|open-source|privacy|utilities,2,"This repository is primarily a curated directory of free Windows applications and online resources across many categories, rather than a codebase or a data/ML toolkit. It can be tangentially useful for ML/data practitioners by pointing to general-purpose utilities (e.g., editors, terminals, statistical-analysis tools, AI apps), but it does not provide datasets, ML libraries, training pipelines, or MLOps functionality. Given its indirect, list-based utility and lack of ML/data-specific tooling, it fits best in the “tangentially related” range.",success
https://github.com/koding/koding,koding,"Koding is a development platform for orchestrating and managing full-stack, project-specific development environments and related infrastructure, with support for running locally via Docker Compose. It provides tooling and services to spin up, share, update, and manage developer environments from a unified interface.",2200,devops|cloud-development-environments|infrastructure-orchestration|ide|docker-compose|go|coffeescript,2,"This repository is primarily a DevOps/developer-platform project focused on orchestrating and managing development environments and infrastructure, not on data science or machine learning functionality. While such infrastructure tooling can be used alongside ML workflows (e.g., provisioning reproducible dev environments), it does not provide ML algorithms, data processing libraries, MLOps pipelines, or dataset/model utilities. Community adoption appears centered on developer infrastructure rather than the ML/data ecosystem, so its direct applicability to ML/data work is limited.",success
https://github.com/spotify/helios,helios,"Helios is a Docker container orchestration platform for deploying and managing containers across a fleet of servers, providing an HTTP API and CLI plus cluster event history. The repository is archived (read-only) and marked “Sunset,” as Spotify moved to Kubernetes and no longer accepts PRs.",2200,container-orchestration|docker|devops|cluster-management|java|distributed-systems|cli|http-api,2,"This repository implements a (now-sunset) Docker orchestration and deployment platform, aimed at DevOps/infra teams rather than data/ML practitioners. It can be tangentially useful in ML/data contexts only as general-purpose container/fleet deployment infrastructure, but it is not designed for data pipelines, model training, feature stores, or MLOps workflows specifically. The project is also archived/read-only, reducing practical adoption and integration value for modern ML stacks that typically standardize on Kubernetes.",success
https://github.com/sersavan/shadcn-multi-select-component,shadcn-multi-select-component,"A reusable, customizable multi-select UI component built with React + TypeScript, styled with Tailwind CSS and shadcn/ui (Radix-based) primitives. It supports grouped/disabled options, search/filtering, animations, accessibility features, and integration patterns for dashboards and forms (e.g., React Hook Form).",2100,react|typescript|tailwind-css|shadcn-ui|radix-ui|component-library|ui-components|nextjs,2,"This repository provides a frontend multi-select component for React projects using shadcn/ui and Tailwind CSS, focused on UI/UX features like searching, grouping, animations, and accessibility. It is not an ML or data-science library, but it can be used in data-oriented web apps (e.g., analytics dashboards) to filter charts or datasets in the UI. Because its relevance to ML/data workflows is indirect (presentation-layer filtering rather than data processing/modeling), it scores low on ML/data value despite being practically useful in building data product interfaces.",success
https://github.com/Divide-By-0/ideas-for-projects-people-would-use,ideas-for-projects-people-would-use,"A curated list of software project ideas (apps, web apps, and browser extensions) intended to solve real problems people have, with guidance and occasional bounties for building and deploying implementations.",2000,project-ideas|software-engineering|open-source|hackathon|side-projects|startup-ideas,2,"This repository is primarily an idea list for building useful software projects, not a codebase or toolkit for machine learning or data science. While some ideas may incidentally involve data/ML (depending on what builders choose to implement), the repo itself does not provide datasets, ML methods, models, or data engineering utilities. Community interest (stars) reflects popularity of the idea list, but it has limited direct applicability to ML/data workflows, so it merits a low but non-zero score.",success
https://github.com/WeiChiaChang/stacks-cli,stacks-cli,"A Node.js command-line tool that analyzes a given website and reports the technologies (“stack”) it uses, similar in spirit to Wappalyzer but usable from the terminal. It supports interactive usage, direct URL arguments, and Docker-based execution.",2000,CLI|Node.js|JavaScript|web-technology-detection|website-analysis|developer-tools|Docker|wappalyzer,2,"This repository provides a CLI utility to detect and report the technology stack used by a website (e.g., frameworks/services), primarily as a developer convenience tool. It is not designed for ML/data science workflows and does not provide data processing, modeling, or analytics capabilities beyond basic web stack identification. It could be tangentially useful for collecting metadata about websites (e.g., for tech landscape datasets), but that would be an indirect use case with additional work required. Therefore, it scores low for ML/data value.",success
https://github.com/luoxue-victor/workflow,workflow,"A JavaScript/Node.js-based developer workflow platform and monorepo that provides a CLI scaffold (@pkb/cli) to create projects from templates (webpack/rollup/vite/node/lerna/vscode) and manage common engineering tasks via plugins (linting, changelog, mock server, image compression, utilities, etc.). It also includes learning materials (e.g., learn-webpack, learn-rollup) intended to be continuously updated.",2000,javascript|nodejs|cli|scaffolding|monorepo|lerna|frontend-tooling|devops,2,"This repository is primarily a general-purpose engineering workflow/tooling monorepo centered around a Node.js CLI for project scaffolding (webpack/rollup/vite/etc.) and developer productivity plugins (linting, changelog generation, mock tooling, image compression, and assorted utilities). It is not built for machine learning or data science tasks, and it does not provide ML-specific libraries, datasets, model training, or MLOps functionality. It could be tangentially useful to ML teams only insofar as it offers generic JS/Node project setup and automation patterns, which is why it scores low rather than zero.",success
https://github.com/zxh326/kite,kite,"Kite is a modern, lightweight Kubernetes dashboard for managing and monitoring one or more Kubernetes clusters. It provides real-time metrics (via Prometheus), comprehensive resource CRUD/views (including CRDs), live logs, and in-browser terminal access, with a React/TypeScript UI and Go backend.",2000,kubernetes|kubernetes-dashboard|devops|cluster-management|observability|prometheus|golang|react,2,"This repository’s primary purpose is DevOps/operations: it’s a Kubernetes dashboard (Go backend + React/TypeScript UI) for cluster/resource management, monitoring, logs, and terminal access, rather than data science functionality. It can be tangentially useful in ML workflows only insofar as ML teams often deploy training/inference services on Kubernetes and may use such a dashboard to operate those workloads. It is not an ML/data tool, does not provide ML algorithms, data processing, experiment tracking, or MLOps model lifecycle features directly, and its community adoption appears oriented toward Kubernetes UI/ops use cases rather than ML.",success
https://github.com/benvinegar/counterscale,counterscale,"Counterscale is a self-hosted web analytics tracker and dashboard designed to run on Cloudflare (Workers + Analytics Engine), aiming for simple deployment and near-zero operating cost even at high traffic.",1900,web analytics|privacy-friendly analytics|cloudflare workers|serverless|typescript|dashboard|edge computing,2,"This repository provides infrastructure and application code for collecting and visualizing website traffic analytics, deployed primarily on Cloudflare Workers with Workers Analytics Engine (and optional longer-term storage via R2/Arrow). It is not built for machine learning or data science workflows (no modeling, feature engineering, training, or ML integrations), but it can produce basic event/pageview data that could be exported and analyzed externally. The low score reflects its primary focus on web analytics product functionality rather than ML/data tooling, despite some tangential relevance as a data collection source.",success
https://github.com/10bestdesign/jqvmap,jqvmap,"JQVMap is a jQuery-based vector map library for rendering interactive, customizable maps (e.g., world, USA, Europe) in the browser. It provides CSS/JS assets and map data files and supports configuration options like region colors, tooltips, zoom, and click handlers.",1800,javascript|jquery|data-visualization|vector-maps|web-development|frontend|interactive-maps,2,"This repository provides a front-end jQuery plugin for displaying interactive vector maps and styling/handling user interaction (tooltips, clicks, zoom) rather than performing data analysis or machine learning. It can be used to visualize ML/data outputs geographically in a web UI, but it does not include ML algorithms, data processing pipelines, or integrations with common ML tooling. Its primary value for ML/data work is purely presentational (mapping/choropleth-style display), so its relevance is tangential.",success
https://github.com/flatlogic/react-material-admin,react-material-admin,"A free React admin dashboard template built with Material-UI (MUI), providing ready-made pages/components (auth, charts, tables, UI elements) and a responsive layout for building admin panels quickly.",1800,react|material-ui|admin-dashboard|dashboard-template|frontend|web-development|ui-components,2,"This repository is primarily a frontend admin dashboard template for React using Material-UI, intended to accelerate building web admin interfaces rather than performing data science or machine learning. It can be tangentially useful for ML teams only insofar as it could serve as the UI for monitoring models/metrics or displaying charts, but it does not provide ML algorithms, data pipelines, or integrations with common ML tooling. Community adoption exists within web development (e.g., stars/forks), but it is not an ML/data-focused project, so the direct applicability to ML workflows is low.",success
https://github.com/kubewall/kubewall,kubewall,"Kubewall is an open-source, single-binary Kubernetes dashboard for managing multiple clusters from one UI, with real-time resource views (manifests/logs/metrics) and optional AI integrations for troubleshooting and recommendations. It’s designed to run locally or in-cluster and can be installed via Docker/Helm or platform package managers.",1800,Kubernetes|multi-cluster management|DevOps|Kubernetes dashboard|cloud-native|observability|AI integration,2,"This repository’s primary purpose is DevOps infrastructure management: a Kubernetes GUI/dashboard (single-binary) to inspect and operate clusters, with features like real-time monitoring and multi-cluster control. While it includes AI-provider integrations, they are aimed at operational troubleshooting and recommendations rather than building, training, or serving ML models. Data/ML teams might use it indirectly when operating ML workloads on Kubernetes, but it is not an ML/data science tool and has limited direct applicability to typical ML workflows.",success
https://github.com/0PandaDEV/awesome-windows,awesome-windows,"A curated “awesome list” of recommended tools and applications for Windows 10/11, organized by category (e.g., developer utilities, backups, databases, productivity, security, and more) with links and brief descriptions.",1700,windows|awesome-list|software-curation|productivity-tools|developer-tools|system-utilities|windows-10|windows-11,2,"This repository is primarily a curated catalog of Windows apps and tools across many categories, rather than a codebase or library focused on data science/ML. It has limited direct applicability to ML/data workflows, though some listed items (e.g., databases, developer utilities, and a “Local AI” category) could be tangentially useful for practitioners setting up a Windows environment. Community adoption appears decent for a general-purpose awesome list (about 1.7k stars), but it is not an ML/data-specific resource, so the overall ML/data value is low.",success
https://github.com/alozano-77/AWS-SAA-C02-Course,AWS-SAA-C02-Course,"A structured set of personal study notes for the AWS Certified Solutions Architect Associate (SAA-C02) exam, based on Adrian Cantrill’s course. Includes topic-organized sections covering core AWS services (e.g., S3, VPC, EC2, RDS, DynamoDB) and learning aids.",1700,aws|cloud-computing|certification|solutions-architect|devops|infrastructure|study-notes,2,"This repository is primarily an AWS certification study-notes collection (documentation/learning material) rather than a software library or dataset. It can be tangentially useful to ML/data practitioners insofar as it covers cloud infrastructure fundamentals (networking, storage, scaling) that underpin data and ML systems on AWS, but it does not provide ML code, data pipelines, model training tools, or MLOps frameworks. Community interest (stars/forks) reflects its value as exam-prep notes, not direct ML/data applicability. As a result, it scores low but not zero due to indirect relevance to data/ML infrastructure on AWS.",success
https://github.com/kiegroup/jbpm,jbpm,"jBPM is an open-source Business Process Management (BPM) suite/toolkit for building business applications that automate business processes and decisions, supporting BPMN2 workflows, case management, and multiple deployment styles (standalone service or embedded in Java/JEE/Spring Boot applications).",1700,business-process-management|workflow-engine|bpmn2|process-automation|case-management|java|maven,2,"This repository provides the jBPM workflow/process automation engine and related modules (e.g., BPMN2 execution, services, persistence, human tasks) for building BPM/business applications. It is not designed for machine learning or data science tasks, and it does not provide ML algorithms, model training, or core data-processing tooling commonly used in ML workflows. It can be tangentially relevant in data/ML contexts as orchestration infrastructure (e.g., coordinating approval flows, business rules, or operational processes around data products), but that is indirect and not its primary use case.",success
https://github.com/mikeroyal/Windows-11-Guide,Windows-11-Guide,"A comprehensive Windows 10/11 setup and reference guide covering security hardening, encryption, drivers, apps, gaming/graphics, virtualization, and developer tooling like WSL 2 and Windows Terminal. The repo is primarily documentation (README + glossaries) with some helper scripts/files for Windows configuration.",1700,windows-11|windows-10|system-administration|windows-security|powershell|wsl|virtualization|gaming,2,"This repository is mainly a curated Windows 10/11 guide (documentation) listing tools, configuration tips, and resources across security, apps, gaming, virtualization, and WSL. It includes a section on machine learning among many other topics, but it is not an ML library, dataset, or a focused ML workflow/tooling project. Data scientists might benefit indirectly from its Windows/WSL setup guidance for development environments, but it offers limited direct ML/data engineering functionality, so it scores low for ML/data value.",success
https://github.com/aptabase/aptabase,aptabase,"Aptabase is an open-source, privacy-first analytics platform for mobile, desktop, and web apps, positioned as an alternative to Firebase/Google Analytics. It provides a simple dashboard and supports many client SDKs (e.g., Swift, Kotlin/Android, React Native, Flutter, Electron, Tauri) while focusing on minimal data collection and regulatory compliance.",1600,analytics|privacy|self-hosted|app-telemetry|dashboard|electron|react-native|flutter,2,"This repository is primarily an application analytics/telemetry platform (collection and dashboarding of app usage events) rather than a machine learning or data science library. While its event collection and metrics could feed downstream data pipelines or be used to generate datasets for analysis, it does not provide ML modeling, feature engineering, training, or MLOps capabilities out of the box. Therefore, it is only tangentially relevant to ML/data workflows as a data source, not a core ML/data tool.",success
https://github.com/deepakkumar55/ULTIMATE-JAVASCRIPT-PROJECT,ULTIMATE-JAVASCRIPT-PROJECT,"An open-source, community-driven curated list of 500 JavaScript project ideas, organized by category and difficulty (basic to advanced). It’s designed to help developers practice JavaScript, build portfolio projects, and find inspiration across many domains (e.g., data visualization, games, backend/full-stack, PWAs).",1600,javascript|project-ideas|learning-resource|web-development|frontend|full-stack|data-visualization,2,"This repository primarily provides a categorized list of JavaScript project ideas (with links to example repos/live demos in places), aimed at helping developers practice and build projects. It is not an ML/data science toolkit, dataset, pipeline, or framework, and it doesn’t directly support ML workflows. It has some tangential relevance because it includes categories like “AI and Machine Learning Projects” and “Data Visualization,” which can inspire ML-adjacent projects, but the repo itself is mainly an educational idea catalog rather than an ML resource. Therefore, it scores low on direct ML/data usefulness despite being broadly helpful for developer learning.",success
https://github.com/dockpeek/dockpeek,dockpeek,"Dockpeek is a lightweight, self-hosted Docker dashboard that lets you quickly open container web UIs, view live logs, see published ports, and check/update container images. It also supports multi-host Docker management and automatically detects Traefik labels for service URLs.",1600,Docker|DevOps|self-hosted|container-management|dashboard|Traefik|monitoring,2,"This repository provides a DevOps-focused web dashboard for managing Docker containers (web access, logs, ports, Traefik URL detection, multi-host control, and update checks). It is not designed for machine learning or data science tasks, and it does not provide ML-specific functionality (e.g., training, inference, data processing, MLOps pipelines). It could be used tangentially in ML environments to manage containerized services, but its primary value is general container operations rather than ML/data workflows, so it merits a low score.",success
https://github.com/flatlogic/react-dashboard,react-dashboard,"An isomorphic React admin dashboard template/seed project built with React, Bootstrap, React Router, Redux, and GraphQL, including an example Node/Express backend integration and starter features like authentication and CRUD examples to kickstart business web apps.",1600,react|admin-dashboard|dashboard-template|web-development|bootstrap|redux|graphql|nodejs,2,"This repository is primarily a React-based admin dashboard template/seed app (with Bootstrap UI and an example Node/GraphQL backend) intended to jumpstart business web application development. It is not designed for machine learning or data science; it mainly provides frontend UI scaffolding, routing, styling, and basic app features like authentication and CRUD examples. It can be tangentially useful for ML/data teams only as a generic dashboard UI shell for visualizing metrics or model outputs, but it does not include ML libraries, data pipelines, or ML-specific integrations—hence the low score.",success
https://github.com/interactivethings/catalog,catalog,"Catalog is a React-based documentation tool for creating living, interactive style guides using Markdown and React components. The repository is archived and deprecated (read-only) and is no longer maintained.",1600,react|markdown|documentation|style-guide|design-systems|component-library|frontend-tooling,2,"This repository provides a tool to build interactive style guides and documentation sites using React and Markdown, primarily for UI/component documentation workflows rather than data work. It can be tangentially useful to data teams for documenting internal dashboards or visualization components, but it does not provide ML, analytics, or data-processing functionality. The project is also deprecated and archived (read-only), reducing its practical value for new ML/data workflows, hence a low score.",success
https://github.com/kevinschaich/mintable,mintable,"Mintable is an open-source CLI tool that automates personal finance tracking by aggregating account balances and transactions (via Plaid or CSV import) and exporting them to a spreadsheet workflow (e.g., Google Sheets or CSV) for budgeting and analysis. It is designed to be free, ad-free, and to avoid data collection by letting you run it locally and automate updates (e.g., cron/GitHub Actions).",1600,personal-finance|budgeting|plaid-api|google-sheets-api|typescript|nodejs|cli-tool|spreadsheet-automation,2,"This repository is primarily a personal-finance automation tool (CLI) focused on pulling transaction/balance data from banking institutions (often via Plaid) and exporting it into spreadsheets/CSVs for budgeting and analysis. While it involves data ingestion and structured exports that could be used in data workflows, it is not built for machine learning, modeling, or typical data science pipelines. Community adoption appears oriented toward finance tracking rather than ML, and it doesn’t provide ML-specific features, integrations, or educational content around ML.",success
https://github.com/slowlydev/f1-dash,f1-dash,"A real-time Formula 1 telemetry and timing dashboard that visualizes live race data such as the leaderboard, tire compounds, time gaps, laps, and mini sectors. It’s the codebase behind the public site f1-dash.com and is primarily implemented with Next.js/TypeScript plus Rust services.",1600,formula-1|real-time-dashboard|telemetry|typescript|nextjs|rust|web-development,2,"This repository’s primary purpose is building a real-time F1 telemetry/timing web dashboard (UI + supporting services), not an ML or data-science toolkit. While it likely consumes and streams structured live data and could be a useful reference for real-time data ingestion/visualization patterns, it does not provide ML models, training code, feature engineering, or ML-focused integrations. Community adoption appears centered around F1 dashboard use rather than ML workflows, so its value to ML/data work is mostly incidental.",success
https://github.com/volantvm/flint,flint,"Flint is a lightweight KVM/libvirt virtual machine management tool delivered as a single Linux binary with an embedded modern Web UI, CLI, and HTTP API. It focuses on simple VM provisioning and management (including cloud-init/template workflows) without manual XML, and supports managing local or remote libvirt hosts over SSH.",1600,kvm|libvirt|virtualization|vm-management|devops|golang|web-ui|api,2,"This repository is primarily a KVM/libvirt virtualization management tool (Web UI + CLI + API) for developers, sysadmins, and homelabs, not a library or framework for data science. It can be tangentially useful for ML/data workflows only in the sense that it may help provision/manage VM-based infrastructure used to run experiments or services. There is no direct functionality for data processing, model training, MLOps pipelines, or ML-specific integrations, and its community adoption appears centered on virtualization management rather than the ML/data ecosystem.",success
https://github.com/OXOYO/X-Flowchart-Vue,X-Flowchart-Vue,"A visual graph/flowchart editor built with Vue and AntV G6. It provides an interactive canvas with editing tools such as undo/redo, copy/paste, zoom/fit, style controls, and import/export capabilities, and can be used as an installable package (@oxoyo/xfc).",1500,vue|javascript|graph-editor|flowchart|diagramming|antv-g6|visualization|front-end,2,"This repository is primarily a front-end visual flowchart/graph editor (a UI component/library) built on Vue and AntV G6, aimed at interactive diagram creation and editing. It does not provide ML models, data pipelines, training/evaluation utilities, or ML-specific integrations; its relevance to ML/data work is mostly indirect (e.g., potentially visualizing workflows or DAG-like structures in data platforms). Because it is general-purpose diagramming UI rather than a data-science tool, it scores low but not zero due to possible ancillary use in visualizing data/ML workflows.",success
https://github.com/jkbrzt/cointrol,cointrol,"Cointrol is a Bitcoin trading bot for Bitstamp that also provides a real-time web dashboard showing account balances, orders, transactions, and trading sessions. It includes a Python-based trader/server (Django + Tornado) and a single-page webapp that updates in real time via REST and WebSockets.",1500,cryptocurrency|bitcoin|algorithmic-trading|trading-bot|bitstamp|python|django|tornado,2,"This repository is primarily an automated cryptocurrency trading bot plus a real-time dashboard for monitoring a Bitstamp account, implemented with Python (Django/Tornado), Redis pub/sub, and a SPA web client. It is not designed for machine learning or data science, and it does not provide ML models, feature pipelines, training code, or common ML framework integrations. It could be tangentially useful to ML/data practitioners only as a starting point for market-data ingestion/automation or as infrastructure around a trading workflow, which is why it scores low but not zero.",success
https://github.com/AlanChen4/Summer-2024-SWE-Internships,Summer-2024-SWE-Internships,"A curated list of Summer 2024 software engineering internships presented as a table of companies and roles, intended as a job board. The listings were generated/maintained via an automated daily update workflow and the repository is now archived (read-only).",1400,internships|job-board|software-engineering|career-resources|python|github-actions|automation,2,"This repository is primarily a curated (and auto-updated) directory of software engineering internship postings, not an ML or data science library. While it includes automation code (e.g., a custom updater/monitor) that could be conceptually useful for data collection or scraping-style workflows, it is not designed to provide datasets, ML models, or data tooling for ML engineers. Community interest (stars) reflects its usefulness as a career resource rather than adoption in ML/data workflows, so its ML/data value is tangential.",success
https://github.com/TheresAFewConors/Sooty,Sooty,"Sooty is an all-in-one SOC analyst CLI tool (Python-based) that automates common security triage tasks like URL sanitization/decoding, DNS/WhoIs lookups, IP/URL/email reputation checks (via services like VirusTotal, AbuseIPDB, URLScan, etc.), hashing, and basic phishing/email analysis to speed up investigations.",1400,cybersecurity|SOC|incident-response|threat-intelligence|OSINT|phishing-analysis|Python|CLI,2,"This repository is primarily a cybersecurity/SOC workflow automation CLI, focused on investigation utilities (reputation checks, decoders, DNS/WhoIs, hashing, and phishing email triage) rather than machine learning. It can be tangentially useful in data/ML contexts only insofar as it helps collect/enrich indicators (IPs, URLs, domains) that could later be fed into analytics pipelines, but it does not provide ML models, training code, datasets, or MLOps capabilities. Community interest appears decent (about 1.4k GitHub stars), but adoption is within security tooling rather than the ML/data ecosystem. Therefore it scores low for direct ML/data science applicability.",success
https://github.com/m2n037/awesome-mecheng,awesome-mecheng,"A curated “awesome list” of free and useful resources for mechanical engineering students and practitioners, organized by topic (courses, math, programming, mechanics, thermal, manufacturing, FEA, software packages, publications, etc.). It primarily serves as a directory of links and references rather than an executable codebase.",1400,mechanical engineering|education|awesome-list|engineering resources|finite element analysis|CAD/CAM|controls and robotics,2,"This repository is a curated resource list for mechanical engineering (courses, references, tools, and links) rather than a machine learning or data science library. It can be tangentially useful to ML/data workflows only where it points to programming, numerical methods, or robotics/control resources, but it does not provide datasets, ML models, training code, or MLOps tooling. Community adoption (stars/forks) appears solid for an engineering resource list, but its direct applicability to ML/data work is limited, supporting a low score.",success
https://github.com/sighupio/permission-manager,permission-manager,"Permission Manager is a Kubernetes application that simplifies RBAC and user management through a web UI. It lets administrators create users, assign namespaces/permissions using reusable templates, and distribute generated kubeconfig files.",1400,kubernetes|rbac|user-management|devops|platform-engineering|web-ui|security,2,"This repository provides an administrative web application for managing Kubernetes RBAC and cluster users (including templates over roles/bindings and kubeconfig distribution). It can be useful indirectly for ML/data teams because many ML workloads run on Kubernetes and need secure namespace/role access control, but the project itself does not provide ML/data functionality (no modeling, data processing, or MLOps pipeline features). Community adoption is decent for a Kubernetes utility, yet its relevance to data science workflows remains tangential, so a low score is appropriate.",success
https://github.com/CppCon/CppCon2019,CppCon2019,"Official collection of slides, code, and other materials from CppCon 2019. The repository is organized by session type (presentations, posters, lightning talks) and serves as the canonical archive for conference materials.",1300,C++|conference-materials|slides|presentations|sample-code|software-engineering|education,2,"This repository primarily archives CppCon 2019 talk materials (slides, notes, and accompanying code) across many C++ software engineering topics. It is not an ML/data science library or dataset, and it is not directly usable as a component in ML workflows. It has some educational value for ML-adjacent engineers (e.g., performance, concurrency, tooling) and may include a small number of ML-related talks, but ML/data is not the core focus, so the score is low.",success
https://github.com/crocofied/CoreControl,CoreControl,"A self-hosted dashboard for managing server infrastructure: organize servers and their hardware details, maintain quick links to management panels and self-hosted apps, and monitor app availability with built-in uptime tracking. It also includes a networks feature to generate network flowcharts.",1300,self-hosted|server-management|infrastructure-dashboard|uptime-monitoring|Next.js|TypeScript|PostgreSQL|Docker,2,"CoreControl is primarily an infrastructure management dashboard for tracking servers, self-hosted applications, uptime, and network diagrams, built as a web app (Next.js/TypeScript) with an agent component. It does not provide ML models, datasets, data-processing pipelines, or tooling aimed at data science workflows. While it could be tangentially useful to ML practitioners as a general-purpose self-hosted operations dashboard, it is not designed for ML/data tasks and has limited direct applicability in DS/ML pipelines, so it scores low.",success
https://github.com/danielbayerlein/dashboard,dashboard,"A Next.js/React-based web app for creating customizable team dashboards composed of reusable widgets (e.g., Jenkins, JIRA, GitHub, PageSpeed, SonarQube) with theming and optional authentication support.",1300,web development|dashboard|next.js|react|devops|styled-components|widgets,2,"This repository is primarily a customizable team status dashboard application built with Next.js/React and a set of widgets that pull metrics from engineering/DevOps services (e.g., Jenkins, JIRA, GitHub, PageSpeed, SonarQube). It is not designed for machine learning or data science workflows, and it does not provide ML models, data pipelines, or analytics tooling beyond displaying operational metrics. It could be tangentially useful to ML teams only as a general-purpose dashboard for surfacing project/service health, but it lacks direct ML/data engineering integration and community positioning as an ML tool, so it scores low.",success
https://github.com/jazzband/django-analytical,django-analytical,"A Django app that integrates multiple third-party analytics and tracking services by providing a unified interface for injecting the appropriate JavaScript snippets, keeping configuration and identifiers out of templates. It supports many providers (e.g., Google Analytics, Matomo, Mixpanel, Hotjar, Facebook Pixel) and aims for simple setup with optional customization.",1300,django|python|web-analytics|tracking|templates|web-development,2,"This repository is primarily a Django web-development utility for integrating analytics/tracking scripts into server-rendered templates via a common configuration-driven interface, not a data science or machine learning library. While it relates to data collection (website telemetry and event tracking), it does not provide data processing, modeling, experimentation, or MLOps capabilities used directly in ML workflows. Its value to ML/data teams is therefore mostly tangential (helping capture product analytics signals), which fits a low score.",success
https://github.com/WardCunningham/Smallest-Federated-Wiki,Smallest-Federated-Wiki,"A prototype implementation of Ward Cunningham’s Federated Wiki concept, emphasizing federated page sharing between peer servers, drag-and-drop refactoring of pages, and built-in data visualization. The repository is archived and primarily serves as a historical reference rather than the current upstream implementation.",1200,wiki|federated-systems|collaboration|web-application|javascript|nodejs|data-visualization,2,"This repository implements a federated wiki (server + client) focused on collaborative knowledge sharing and UI-driven refactoring, with some built-in data visualization features. It is not designed for machine learning or data science workflows (no ML models, training/inference tooling, datasets, or MLOps integration), so its direct applicability to ML/data work is low. Data scientists might find it tangentially useful as an example of lightweight web-based visualization and collaborative content management, but adoption and integration in ML/data ecosystems appear minimal. Because it is archived and positioned as a historical document rather than the current source, its practical value for modern ML/data workflows is further reduced.",success
https://github.com/apache/apisix-dashboard,apisix-dashboard,"Web-based dashboard for Apache APISIX that provides a frontend UI to manage and operate APISIX resources (e.g., routes, services, upstreams, plugins) more easily than using raw Admin API calls.",1200,api-gateway|api-management|dashboard|devops|apache-apisix|typescript|frontend,2,"This repository is a web dashboard/UI for operating Apache APISIX (an API gateway), focused on configuration and operational management rather than data science functionality. It can be tangentially useful in ML/data platforms that expose model-serving APIs behind an API gateway (e.g., managing routing, auth, rate limits), but it does not provide ML algorithms, data processing, modeling, or MLOps features itself. Community adoption appears solid for an APISIX component (about 1.2k GitHub stars), yet its relevance to ML/data workflows is indirect, so a low score is appropriate. It earns a 2 (rather than 0–1) because API gateway operations are sometimes part of production ML serving infrastructure.",success
https://github.com/bellaj/Blockchain,Blockchain,"A curated repository containing a large compilation of PDFs (scientific papers, whitepapers, surveys, and reports) focused on blockchain technology and cryptocurrencies. It serves primarily as a reading/reference library rather than an executable software project.",1200,blockchain|cryptocurrency|research-papers|whitepapers|distributed-systems|cryptography|literature-review,2,"This repository is mainly a curated collection of documents and academic papers about blockchain and cryptocurrencies, not a codebase or a reusable ML/data library. It can be useful for background research (e.g., for feature ideas, threat models, or understanding crypto-economic mechanisms) but offers little direct integration into ML/data workflows (no datasets, pipelines, models, or tooling). Community adoption appears moderate (about 1.2k stars), but its value to ML practitioners is largely indirect and educational, so a low score is appropriate.",success
https://github.com/benc-uk/kubeview,kubeview,"KubeView is a lightweight Kubernetes cluster visualization tool that renders cluster resources as an interactive graph with derived relationships between objects. It provides a secure read-only view with real-time updates (via Server-Sent Events), plus resource details, events, filtering/search, and pod log viewing for troubleshooting.",1200,kubernetes|cluster-visualization|devops|observability|golang|web-ui|sse|helm,2,"This repository is primarily a DevOps/operations tool for visualizing Kubernetes resources and their relationships, aimed at cluster understanding and troubleshooting rather than data science. It can be indirectly useful in ML workflows because many ML teams run training/inference on Kubernetes and may use KubeView to debug deployments and pods, but it does not provide ML/data functionality (no modeling, datasets, pipelines, or MLOps features focused on ML). Community usage appears solid for a Kubernetes utility, yet its relevance to ML/data work is tangential, so a low score is appropriate.",success
https://github.com/didi/turbo,turbo,"Turbo is a Java-based lightweight workflow/flow engine framework that supports BPMN 2.0. It is designed as an embeddable backend engine for building workflow, approval-flow, low-code orchestration, and process design/execution systems with a relatively small schema footprint and plugin-style extensibility.",1200,workflow-engine|BPMN|Java|process-orchestration|low-code|approval-workflow|backend-framework,2,"This repository provides a lightweight BPMN 2.0-compatible workflow engine (process definition, deployment, execution, rollback, and traceability) intended for general business orchestration and approval flows rather than analytics or modeling. While such an engine could be used to orchestrate data/ML pipelines in principle, it is not purpose-built for data science, MLOps, or ML training/inference workflows, and it does not appear to provide ML-specific integrations. Therefore, its relevance to ML/data work is tangential (infrastructure orchestration utility), leading to a low score.",success
https://github.com/go-workflow/go-workflow,go-workflow,"An ultra-lightweight workflow engine and microservice written in Go, with an architecture loosely similar to Activiti but simplified. It models process definitions using JSON (instead of BPMN) and focuses on workflow state transitions while decoupling user/group and other non-workflow domain data.",1200,workflow-engine|business-process-management|golang|microservices|orchestration|json-configuration|activiti-like,2,"This repository implements a lightweight BPM/workflow engine microservice in Go, providing process definition/execution and task approval/transition mechanics via JSON-defined workflows. It is not designed for machine learning or data science, and it does not provide ML algorithms, data processing primitives, or direct integrations with common ML tooling. However, a workflow/orchestration service can be tangentially useful in ML systems (e.g., orchestrating ETL/training steps), which gives it limited indirect relevance. The score is therefore low because the primary purpose is general workflow management rather than ML/data workflows, despite possible infrastructure reuse.",success
https://github.com/leebyron/testcheck-js,testcheck-js,"TestCheck.js is a generative (property-based) testing library for JavaScript, inspired by QuickCheck. It generates random test cases from value generators and can shrink failing cases to the smallest reproducible example.",1200,property-based testing|generative testing|javascript|testing|quickcheck|test-case generation|shrinking,2,"This repository provides property-based (generative) testing utilities for JavaScript, including value generators and shrinking to minimal failing examples. It is primarily a software testing tool rather than a data science or machine learning library, and it does not integrate directly with common ML/data frameworks. However, its generative testing approach can be tangentially useful for validating data-processing code, feature engineering functions, or model-serving logic, which gives it slight indirect relevance.",success
https://github.com/marcelscruz/dev-resources,dev-resources,"A collaborative “awesome list”-style repository that curates and organizes useful resources for developers (tools, courses, assets, APIs, jobs, and more). It serves as a community-maintained directory of links and references for software development and related topics.",1200,awesome-list|developer-resources|programming|tools|courses|public-apis|infrastructure|design,2,"This repository is primarily a curated directory of general developer resources rather than a software package or data/ML-focused toolkit. While it may include some links that are helpful to data/ML practitioners (e.g., tools, courses, APIs), its main use case is broad software-development resource aggregation. It has notable community adoption (about 1.2k GitHub stars), but it does not provide ML/data functionality, datasets, or ML engineering workflows directly, so its direct value to ML/data work is limited.",success
https://github.com/meodai/poline,poline,"A small JavaScript/TypeScript color palette generator that interpolates between HSL anchor colors in a polar/cartesian coordinate space to produce visually distinct palettes. It supports adjustable point counts, multiple easing/position functions per axis, optional closed loops, hue shifting, and sampling colors along the full path.",1200,color-palette-generator|color-interpolation|generative-art|creative-coding|javascript|typescript|npm-package,2,"This repository is primarily a creative-coding utility for generating color palettes/gradients from anchor colors using custom interpolation and easing functions, aimed at design, visualization, and generative art workflows. It is not an ML/data-science library and does not provide modeling, training, data processing, or ML integrations. It can be tangentially useful for data visualization styling (choosing palettes for plots/dashboards), but that’s peripheral to ML/data workflows, so it merits a low score.",success
https://github.com/nsacyber/WALKOFF,WALKOFF,"WALKOFF is an automation/orchestration framework (SOAR-style) that lets users build and run workflows via an easy drag-and-drop editor, integrating “apps” to automate repetitive operational tasks. It’s designed to be modular and deployable on Windows or Linux, with a RESTful API and Docker-based deployment tooling.",1200,security-orchestration|automation|SOAR|incident-response|workflow-orchestration|docker|python,2,"WALKOFF’s primary purpose is security/operations automation (workflow orchestration and integrations), not data science or machine learning. While it can move and transform data as part of automated workflows and could be used to orchestrate ML-related steps indirectly (e.g., calling external analysis services), it does not provide core ML/data capabilities such as model training, feature engineering, or MLOps tooling. The repository is also archived (read-only), which further limits its value for modern ML/data workflows and community-driven evolution.",success
https://github.com/saniales/golang-crypto-trading-bot,golang-crypto-trading-bot,"A Go (Golang) console-based cryptocurrency trading bot that supports running configurable trading strategies across multiple exchanges, including a simulation (paper trading) mode. It provides exchange integrations (REST/WebSocket where available), strategy bindings per market, and configuration via YAML.",1200,golang|cryptocurrency|algorithmic-trading|trading-bot|exchange-api|backtesting|paper-trading|websockets,2,"This repository is primarily an algorithmic crypto trading bot framework written in Go, focused on executing rule-based trading strategies across supported exchanges with an optional simulation (paper trading) mode. It is not designed for machine learning or data science workflows (no model training, feature engineering, or ML evaluation tooling is central to the project). It can be tangentially useful to ML practitioners only as a potential execution layer or data-collection starting point for market data, but ML integration would require substantial additional work. Therefore it scores low on direct ML/data applicability despite moderate general educational value for trading system architecture.",success
https://github.com/acekyd/made-in-nigeria,made-in-nigeria,"A curated list (“awesome list”) of open-source tools and projects built by Nigerian developers, organized alphabetically with contributor guidelines and a companion website for browsing the collection.",1100,awesome-list|open-source|curated-list|nigerian-developers|community|nextjs|typescript|tailwindcss,2,"This repository’s primary purpose is community curation: it aggregates links to many Nigerian-built tools/projects rather than providing a single ML or data-science library. It can be mildly useful to data/ML practitioners as a discovery directory (you may find data/ML-related projects within the list), but it does not directly provide datasets, ML code, pipelines, or ML tooling itself. Community adoption (stars) indicates popularity as a resource list, not as an ML/data workflow dependency, so its ML/data value is tangential.",success
https://github.com/caoqianming/django-vue-admin,django-vue-admin,"A small-to-medium application development platform with RBAC-based permission control and a separated front-end/back-end architecture: Django + Django REST Framework backend, Vue + ElementUI frontend, plus an optional UniApp + uView mobile client. It includes JWT authentication, Swagger API docs support, and built-in modules like org/user/role management, data dictionary, file library, scheduled tasks, and a (partially included) workflow module.",1100,web development|admin dashboard|RBAC|Django|Django REST Framework|Vue.js|Element UI|JWT authentication,2,"This repository is primarily a full-stack admin/management platform (Django/DRF backend + Vue admin UI) focused on RBAC permissions, authentication, and common enterprise modules (users/roles/org structure, dictionaries, files, scheduling, and workflow). It is not designed for machine learning or data science tasks, and does not provide ML algorithms, model training, data pipelines, or MLOps components. It may be tangentially useful to ML teams only as a generic internal admin console/API foundation (e.g., managing datasets, users, jobs) if adapted, but that is not its core purpose, so it scores low.",success
https://github.com/kottster/kottster,kottster,"Kottster is an instant, self-hosted Node.js admin panel for building custom admin UIs on top of your application database. It provides a CLI to scaffold projects and supports creating CRUD pages, dashboards, and fully custom pages with a focus on security and easy setup.",1100,node.js|admin-panel|low-code|crud|dashboard|typescript|react|developer-tools,2,"This repository is primarily a web/developer productivity tool for generating and running an admin panel for database-backed applications (CRUD pages, dashboards, and custom pages). While it can be used to build internal tools that view or manage data (including datasets used in ML projects), it is not designed for data science or machine learning workflows, and it does not provide ML-specific capabilities such as model training, evaluation, feature engineering, or pipeline orchestration. Its relevance to ML/data work is therefore tangential, mainly as a UI/admin layer around databases that might store ML-related data.",success
https://github.com/pa11y/pa11y-dashboard,pa11y-dashboard,"Pa11y Dashboard is a Node.js web interface for viewing and monitoring website accessibility test results produced by Pa11y/Pa11y Webservice. It provides a UI to manage sites and track accessibility issues over time, backed by MongoDB.",1100,accessibility|a11y|web-testing|monitoring-dashboard|nodejs|mongodb|devops,2,"This repository is primarily an accessibility monitoring dashboard (a web app) for displaying and managing results from Pa11y/Pa11y Webservice, stored in MongoDB. It is not designed for machine learning or data science tasks, and it does not provide ML models, training pipelines, or data-processing utilities aimed at ML workflows. It could be tangentially useful as a source of structured accessibility test data for analytics, but that is incidental rather than a core focus, so a low score is appropriate.",success
https://github.com/stellar-deprecated/kelp,kelp,"Kelp is a free and open-source trading bot focused on the Stellar DEX that also supports integrations with 100+ centralized exchanges. It provides configurable trading strategies (e.g., market making/spread trading), pluggable exchange/strategy modules, and tooling such as a GUI and sample configurations to run bots quickly.",1100,cryptocurrency|algorithmic-trading|trading-bot|stellar|dex|market-making|golang,2,"This repository is primarily an algorithmic trading bot for the Stellar DEX and many centralized exchanges, aimed at automated execution and market-making rather than data science. While it may generate and store trading/accounting data and could be used as a data source for later analysis, it does not provide ML model training, feature engineering, or ML-centric workflows. Community adoption appears oriented toward crypto trading users (and the repo is archived/read-only), so its direct value for ML/data work is limited, justifying a low score.",success
https://github.com/surveyjs/survey-creator,survey-creator,"SurveyJS Creator is an extensible, client-side (JavaScript/TypeScript) drag-and-drop form/survey builder that generates JSON schemas for dynamic forms. It includes a CSS Theme Editor and a GUI for conditional logic/branching, with native integrations for React, Angular, Vue, and Knockout (plus a jQuery wrapper).",1100,form-builder|survey|json-schema|web-development|typescript|react|angular|vue,2,"This repository provides a UI component for building surveys/forms and exporting them as JSON definitions for use in web applications; its primary use case is front-end form authoring, theming, and conditional logic/branching. It is not designed for machine learning, data pipelines, model training, or MLOps, but it can be tangentially useful for data collection (designing questionnaires that feed downstream analytics/ML). Because its relevance to ML/data work is indirect and mostly limited to facilitating structured data capture, it scores low on direct applicability despite being a mature, widely useful web component.",success
https://github.com/xudaolong/CodeVar,CodeVar,"An Alfred workflow (built with JavaScript/Node.js and alfy) that converts Chinese phrases into usable English-style code variable names via the Youdao translation API, outputting multiple naming styles (camelCase, PascalCase, snake_case, CONSTANT_CASE, kebab-case).",1100,alfred-workflow|javascript|nodejs|developer-tools|naming-conventions|translation|productivity,2,"CodeVar is primarily a developer productivity tool: an Alfred workflow that translates Chinese input and generates variable names in different naming conventions. It is not designed for machine learning or data processing, and it doesn’t provide datasets, ML models, or ML workflow integrations. It could be tangentially helpful for data/ML practitioners who write code (e.g., quicker naming/standardization), but its function is general-purpose and not ML-specific, so it scores low.",success
https://github.com/guozhaolong/wfd-vue,wfd-vue,"A Flowable workflow (process) designer UI for Vue, built on the AntV G6 graph visualization/diagramming engine. It provides a configurable canvas/editor for building workflows and supports exporting/saving in formats like JSON and Flowable XML, with a hosted online demo.",1060,vue|javascript|workflow-designer|flowable|diagramming|graph-visualization|antv-g6|bpmn,2,"This repository is primarily a front-end workflow/process diagram designer for Vue applications, using AntV G6 to render and edit workflow graphs and export them (e.g., JSON/Flowable XML). It is not built for machine learning or data science tasks, and it does not provide ML algorithms, datasets, or MLOps/data pipeline functionality. Its relevance to ML/data workflows is mostly tangential (e.g., could be used to design business workflows that might include ML steps), which is why it scores low.",success
https://github.com/EddyVerbruggen/nativescript-plugin-firebase,nativescript-plugin-firebase,"A (now archived) NativeScript plugin that integrates Google Firebase services into NativeScript mobile apps, offering modules like Analytics, Authentication, Firestore/Realtime DB, Cloud Messaging, Crashlytics, Remote Config, Storage, and more.",1000,NativeScript|Firebase|mobile-development|TypeScript|Android|iOS|push-notifications|Cloud-Firestore,2,"This repository is primarily a mobile app development plugin that exposes Firebase capabilities (analytics, auth, databases, messaging, etc.) to NativeScript applications, and it has been archived (read-only) since April 4, 2023. While it includes an ML Kit feature, that support is ancillary to the plugin’s main purpose and does not provide general-purpose ML tooling, training, or data science workflows. It may be tangentially useful to ML-adjacent app teams who need to integrate on-device ML Kit features into a NativeScript app, but it is not a data science/ML engineering library or pipeline tool, hence the low score.",success
https://github.com/MayGo/tockler,tockler,"Tockler is a free, cross-platform desktop time-tracking app that automatically records your computer activity by monitoring active window titles and idle/online state. It provides analytics and visualizations such as interactive timelines plus daily/weekly/monthly statistics, calendars, and charts.",1000,time-tracking|productivity|electron|typescript|react|data-visualization|desktop-application,2,"This repository primarily implements an Electron-based desktop productivity tool for automatically tracking computer usage (active window titles, idle/online state) and visualizing it with timelines and aggregated stats. While it does produce user activity/time-series data and includes visualization tooling (e.g., D3/Victory), it is not designed as a data science/ML library, pipeline, or MLOps component. Data/ML relevance is therefore only tangential (potentially as a personal data source for later analysis), which fits a low score.",success
https://github.com/RicardoValdovinos/vite-react-boilerplate,vite-react-boilerplate,"A production-ready, scalable starter template for building Vite + React applications with a batteries-included developer experience (TypeScript, Tailwind, Storybook, TanStack Router/Query/Table, testing, linting/formatting, and Docker). It’s designed to be a clean starting point (no full demo app), emphasizing type safety, tooling, and project structure.",1000,vite|react|typescript|frontend-boilerplate|tailwind-css|storybook|testing-playwright-vitest|tanstack,2,"This repository is primarily a Vite + React boilerplate focused on frontend application scaffolding and developer tooling (TypeScript, Tailwind CSS, Storybook, TanStack ecosystem, and Playwright/Vitest testing). It is not designed for machine learning or data science workflows, and it doesn’t provide ML-specific functionality such as model training, data processing, or MLOps. It has only tangential relevance to ML/data work in that it could be used to build a UI for dashboards or model-driven web apps, but that is not its core purpose, so it merits a low score.",success
https://github.com/cam-inc/viron,viron,"Viron is an open-source, web-based administration console that generates a fine-tuned GUI from an OpenAPI Specification (OAS) document, enabling you to manage RESTful API servers without building a custom admin frontend. It interprets OAS (YAML/JSON) to construct an admin dashboard for API operations and data management.",1000,openapi|swagger|admin-dashboard|no-code|api-administration|web-console|developer-tools,2,"This repository is primarily a web-based admin console generator driven by OpenAPI Specification documents, aimed at eliminating the need to build custom administration frontends for REST APIs. It is not designed for machine learning or data science tasks (e.g., modeling, training, feature engineering, or MLOps), though it can be tangentially useful in data-adjacent contexts for administering internal data/ML-related service APIs. Because its core purpose is general API administration tooling rather than ML/data workflows, it scores low on direct ML/data applicability.",success
https://github.com/estevanmaito/windmill-dashboard-react,windmill-dashboard-react,"A multi-theme, production-ready React dashboard application focused on accessibility (keyboard navigation, screen-reader friendly) and built with Tailwind CSS. Includes routing, custom UI components (via Windmill React UI), charts (Chart.js), and PWA/offline-first support—intended for you to connect your own data.",1000,react|tailwind-css|dashboard|admin-panel|accessibility|pwa|react-router|chartjs,2,"This repository is primarily a front-end dashboard web application template/application (React + Tailwind CSS) emphasizing accessibility, theming, and common admin UI patterns rather than data science functionality. It can be useful to ML/data teams only indirectly as a UI shell for presenting metrics, charts, or model monitoring dashboards once you supply backend/data integrations. It does not provide ML algorithms, data processing, modeling, or MLOps capabilities out of the box, so its direct applicability to ML/data workflows is limited.",success
https://github.com/imteekay/web-performance-research,web-performance-research,"A curated, continuously updated collection of links and notes for learning and researching web performance. It organizes resources across areas like architecture, browsers, Core Web Vitals, CSS/JS, measurement tooling, and performance budgeting.",1000,web performance|core web vitals|frontend|browser rendering|performance measurement|web development|reference-resources,2,"This repository primarily serves as a curated reading list/knowledge base about web performance (e.g., Core Web Vitals, rendering, measurement tools, and case studies), rather than providing ML code, datasets, or data pipelines. It has limited direct applicability to ML/data workflows, aside from general educational value for performance measurement and experimentation practices. Community interest appears solid (about 1k stars), but it is not aimed at data science or machine learning use cases, so it scores low on ML relevance.",success
https://github.com/maltfield/awesome-lemmy-instances,awesome-lemmy-instances,"A curated comparison table of Lemmy instances to help users choose where to register, focusing on instance policies and configuration differences (e.g., federation status, downvotes, adult content rules), plus activity/uptime and other metadata. The repo includes a CSV dataset and scripts to generate/update the README table from collected instance stats.",1000,lemmy|fediverse|instance-directory|dataset|csv|python|community-migration,2,"This repository primarily maintains a human-facing directory/comparison table of Lemmy instances, backed by a CSV file and scripts that generate the README table and gather/update instance metadata. While the CSV could be used as a small dataset for exploratory analysis (e.g., uptime trends, federation blocking patterns), it is not designed for ML/model training or data engineering workflows. It has limited direct applicability to ML beyond lightweight analysis/visualization, so it rates as tangentially related.",success
https://github.com/wakatime/legacy-python-cli,legacy-python-cli,Deprecated Python-based WakaTime command-line interface used by WakaTime text editor/IDE plugins to send coding activity (heartbeats) and related metadata to the WakaTime service. The repository was archived (read-only) and the README recommends using the newer Go-based wakatime-cli instead.,1000,developer-tools|cli|productivity|time-tracking|python|wakatime|editor-plugins,2,"This repository provides a command-line client for WakaTime, focused on tracking and reporting coding activity from editor/IDE plugins rather than performing data science or ML tasks. It can be tangentially useful in ML/data workflows only as a generic developer productivity/time-tracking utility (e.g., measuring coding time while working on ML projects), but it does not include ML algorithms, data processing pipelines, or MLOps capabilities. Additionally, it is deprecated and archived, further limiting its practical value for modern ML/data tooling.",success
https://github.com/goabstract/Awesome-Design-Tools,Awesome-Design-Tools,"A curated “awesome list” of design tools, apps, and resources (plus companion lists for plugins, conferences, and UI kits), organized by categories like prototyping, accessibility, design systems, handoff, and more. The repo is primarily a community-maintained directory with contribution guidelines and a Node-based site/build setup.",38800,design-resources|awesome-list|ui-ux|prototyping|design-tools|design-systems|front-end,1,"This repository is a curated directory of general design tools and resources (an “awesome list”), not a library or framework for building models or working with datasets. It can be marginally useful to ML practitioners only indirectly (e.g., choosing UI/UX and visualization tools for ML products or dashboards), but it does not provide ML code, data utilities, or integrations with ML frameworks. Community adoption appears strong for design audiences (tens of thousands of stars), but that popularity doesn’t translate into direct ML/data workflow utility, so the score is very low.",success
https://github.com/jondot/awesome-react-native,awesome-react-native,"An “awesome list” that curates React Native libraries, components, tools, tutorials, articles, and other learning resources. It serves as a community-maintained directory for discovering and comparing React Native ecosystem options.",35600,react-native|react|mobile-development|awesome-list|javascript|libraries|developer-resources,1,"This repository is primarily a curated directory of React Native components, tools, and learning material rather than a software library or dataset. It has little direct applicability to ML/data science workflows (no modeling, training, data processing, or MLOps focus), though data/ML practitioners building mobile apps could occasionally find UI or infrastructure-related packages here. Given its purpose as a general mobile development resource list (not ML/data oriented), it scores very low for ML/data value.",success
https://github.com/sudheerj/javascript-interview-questions,javascript-interview-questions,"A large curated collection of JavaScript interview questions (about 1000) covering core JavaScript concepts and popular frameworks/libraries such as React, Angular, and Vue. Intended as a study/reference resource for interview preparation and skill refreshers.",26900,javascript|interview-prep|frontend|react|angular|vue|web-development|learning-resources,1,"This repository is primarily an interview-preparation and learning resource focused on JavaScript and front-end ecosystem topics, not a library/tool for data science or machine learning. It does not provide ML algorithms, datasets, data-processing utilities, or integrations with common ML tooling. Its relevance to ML/data workflows is minimal, aside from general programming fundamentals that could indirectly benefit any engineer, so it scores very low on ML/data value.",success
https://github.com/akveo/ngx-admin,ngx-admin,"Customizable open-source admin dashboard template for Angular, built on the Nebular UI framework. It provides a responsive layout, multiple themes (including a Material-themed branch), an auth module, and many ready-made UI components and example pages to kick-start web app back-office/admin UIs.",25900,angular|admin-dashboard|web-development|typescript|nebular|bootstrap|ui-template,1,"This repository is primarily a front-end admin dashboard template for Angular (UI components, themes, layout, and authentication scaffolding), intended to accelerate building administrative web interfaces. It is not designed for machine learning, data processing, modeling, or MLOps workflows, and it does not provide ML/data libraries, pipelines, or datasets. While a data/ML team could use it as a generic UI shell for internal dashboards, that value is indirect and incidental rather than ML-focused, so it scores very low.",success
https://github.com/unicodeveloper/awesome-nextjs,awesome-nextjs,"A curated “awesome list” of resources for learning and building with Next.js, including community links, essential docs, articles, boilerplates, extensions, apps, books, and videos.",11000,next.js|react|javascript|web-development|frontend|ssr|resources,1,"This repository is primarily a curated directory of Next.js learning and development resources (articles, boilerplates, extensions, and example apps). It is focused on general web development and does not provide datasets, ML models, training code, or data/ML tooling. While a data/ML team might use Next.js for deploying dashboards or model-driven web apps, the repo itself is not geared toward ML/data workflows. Therefore, it has minimal direct value for data science and machine learning beyond incidental educational or deployment context.",success
https://github.com/satnaing/shadcn-admin,shadcn-admin,"A responsive, accessible admin dashboard UI built with Shadcn UI and Vite, featuring light/dark mode, a built-in sidebar, global command search, RTL support, and 10+ dashboard pages.",10800,admin-dashboard|web-development|react|typescript|vite|shadcn-ui|tailwindcss|ui-components,1,"This repository is primarily a frontend admin dashboard UI/template built with Shadcn UI (TailwindCSS + Radix UI) and Vite, aimed at building web app backoffice interfaces rather than data/ML functionality. It does not provide ML models, data processing, training, evaluation, MLOps, or integrations with common ML/data tooling. Its only relevance to ML/data workflows is indirect: teams could use it to build dashboards that display analytics or model monitoring results, but those capabilities would be implemented separately. Therefore it scores very low on direct data science/ML utility despite strong general web UI usefulness.",success
https://github.com/zuiidea/antd-admin,antd-admin,"A React-based admin/dashboard front-end template for enterprise applications, built on Ant Design and UmiJS. It includes common admin features like internationalization, dynamic menu permissions, and mock data for local development.",9800,web development|react|admin dashboard|ant design|umiJS|frontend template|mock data,1,"This repository is primarily a front-end admin/dashboard solution (React + Ant Design + UmiJS) intended for building enterprise web application UIs. It does not provide ML models, data processing utilities, dataset tooling, or integrations with common ML/data frameworks, so it has little direct applicability to data science or machine learning workflows. While it could be used to build an internal UI to monitor ML systems, that use is incidental rather than a core focus, which keeps the score near the minimum.",success
https://github.com/gridstack/gridstack.js,gridstack.js,"Gridstack.js is a mobile-friendly, framework-agnostic TypeScript/JavaScript library for building draggable, resizable, responsive grid layouts—commonly used to create interactive dashboard UIs. It supports features like multi-column layouts, drag-and-drop widget management, saving/restoring layouts, nested grids, and integrations/bindings for frameworks such as Angular (included) plus React and Vue examples.",8600,web development|dashboard layout|drag and drop|responsive UI|TypeScript|UI components|front-end,1,"This repository primarily provides a front-end UI layout engine for building interactive, draggable/resizable dashboard grids in web applications, not an ML or data-processing library. While it can be used to create data/ML dashboards (e.g., arranging charts, metrics, and model monitoring widgets), it does not provide data science functionality like modeling, training, pipelines, or visualization primitives itself. Therefore its relevance to ML/data workflows is incidental and mostly limited to UI composition, leading to a low score.",success
https://github.com/DIYgod/APlayer,APlayer,"APlayer is a lightweight, customizable HTML5 music player UI library for the web. It supports common audio media formats and features like playlists and synchronized lyrics display.",7600,web-development|javascript|html5-audio|music-player|ui-component|frontend-library,1,"DIYgod/APlayer is a front-end JavaScript library for embedding a polished HTML5 music player with features such as playlists and lyrics. Its primary use case is web UI/UX for audio playback rather than data processing, analytics, or model development. While it could appear in data-driven media or dashboard products, it does not provide ML/data functionality, datasets, or integrations with common ML tooling. Therefore it has minimal value for ML/data science workflows beyond very indirect UI embedding needs.",success
https://github.com/homarr-labs/dashboard-icons,dashboard-icons,"A curated collection of 1800+ consistent dashboard/app-directory icons for services and tools, provided in SVG (source) plus auto-generated PNG and WEBP formats with light/dark variants. Icons can be browsed on dashboardicons.com and consumed via direct GitHub/raw links or a jsDelivr CDN URL pattern.",7400,icons|svg|png|webp|dashboards|cdn|homelab,1,"This repository primarily provides a large, curated icon asset library for dashboards and app directories (e.g., Homarr/Homepage/Dashy), distributed in multiple image formats and via CDN-friendly links. It is not designed for machine learning or data workflows, and it contains no ML models, datasets for training, or data/ML utilities beyond general asset organization. It could be tangentially useful only in the sense that ML/data teams might use the icons for UI/UX in internal tools or dashboards, but that is not an ML-specific use case, so it scores very low.",success
https://github.com/brunch/brunch,brunch,"Brunch is a fast front-end web application build tool with a simple declarative configuration and incremental compilation for rapid development. It provides commands to scaffold projects, watch and rebuild on changes (optionally serving via a dev server), and produce production builds with minification.",6800,web development|javascript|build tool|asset pipeline|bundler|frontend tooling|incremental compilation,1,"This repository is a JavaScript-based front-end build tool (asset bundling, watching, and production builds) aimed at general web application development, not machine learning or data processing. While it could be used in ML-adjacent contexts (e.g., building dashboards or UI for ML products), it does not provide ML algorithms, data pipelines, modeling utilities, or integrations with ML frameworks. Because its primary purpose is unrelated to ML/data workflows and its direct applicability to data science is minimal, it earns a score of 1.",success
https://github.com/Gozargah/Marzban,Marzban,"Marzban is a proxy management tool that provides a web-based GUI to manage large numbers of user proxy accounts powered by Xray-core. It offers a built-in Web UI, a REST API backend, multi-node support, and user/traffic/expiry controls for multiple proxy protocols.",6000,proxy-management|xray-core|vpn|networking|web-ui|rest-api|python|react,1,"This repository is primarily a networking/proxy administration platform (GUI + REST API) for managing Xray-based proxy users, nodes, and traffic limits, not a data science or machine learning project. It does not provide ML datasets, model training/inference code, feature engineering, or MLOps components. While it may generate operational logs/traffic statistics that could be analyzed, that is incidental to its core purpose, so its direct value to ML/data workflows is minimal.",success
https://github.com/devias-io/material-kit-react,material-kit-react,"A free React admin dashboard template built with MUI (Material UI) components and Next.js, providing a ready-made UI for common app pages like dashboard, customers, integrations, settings, and authentication screens.",5600,react|nextjs|mui|typescript|admin-dashboard|web-development|dashboard-template|authentication,1,"This repository is primarily a front-end admin dashboard template (React + Next.js) using MUI, focused on UI pages and application scaffolding rather than data/ML functionality. It can be useful indirectly for ML teams to build internal tools (e.g., model monitoring or analytics dashboards), but it does not provide ML algorithms, data processing, training, evaluation, or MLOps capabilities. Community adoption appears strong for a UI template (5.6k stars), but that popularity is in web development rather than ML/data workflows, so the direct ML/data value is minimal.",success
https://github.com/coreui/coreui-free-react-admin-template,coreui-free-react-admin-template,"An open-source CoreUI admin/dashboard template for building responsive React applications, based on Bootstrap 5 and CoreUI components. It provides a ready-made layout (sidebar, header, routes, views, styling) and a preconfigured build setup (Vite) to quickly start an admin panel project.",4900,react|admin-dashboard|bootstrap-5|coreui|vite|web-development|ui-components,1,"This repository is primarily a React + Bootstrap 5 admin dashboard UI template, intended to jump-start web app front-end development (layouts, navigation, components, and styling). It does not provide machine learning models, data processing utilities, MLOps tooling, or data science-focused features beyond generic UI capabilities. While it could be used to build a UI for ML/data products (e.g., monitoring dashboards), it’s not directly applicable to ML/data workflows and has minimal educational value for ML itself, so it scores very low.",success
https://github.com/dillonzq/LoveIt,LoveIt,"LoveIt is a clean, elegant, and feature-rich theme for the Hugo static site generator, primarily aimed at building personal blogs. It adds extensive styling options and shortcodes (e.g., KaTeX math, Mermaid diagrams, ECharts visualizations), along with SEO/performance optimizations and search integrations.",3800,hugo|static-site-generator|blog-theme|web-development|static-sites|documentation|frontend,1,"This repository’s primary purpose is a Hugo theme for building and styling static blogs/websites, focusing on layout, shortcodes, and site features like SEO and search rather than data/ML functionality. While it can embed data visualizations (e.g., via ECharts) and render technical content (e.g., KaTeX), it does not provide ML models, datasets, training pipelines, or data-processing tooling. As a result, it has minimal direct applicability to ML/data science workflows beyond presentation of results in a static site.",success
https://github.com/killop/anything_about_game,anything_about_game,"An “awesome list” style repository that curates and categorizes game development resources (tools, frameworks, engines, libraries, learning links), with a strong emphasis on Unity/C# and related gamedev topics such as shaders, ECS, physics, and assets.",3700,game development|awesome-list|Unity|C#|game engines|ECS|shaders|gamedev-resources,1,"This repository is primarily a curated list of game development resources (engines, libraries, and tooling) rather than code or datasets intended for machine learning. It has little direct applicability to ML/data workflows beyond incidental overlap (e.g., general programming or graphics resources that might be tangentially useful). While it appears popular within the gamedev community (thousands of stars), it does not provide ML-focused utilities, datasets, or model training/inference tooling, so its ML/data value is minimal.",success
https://github.com/Clooos/Bubble-Card,Bubble-Card,"Bubble Card is a minimalist, customizable collection of Lovelace UI cards for Home Assistant, featuring a pop-up interaction pattern and a built-in “Module Store”. It’s distributed as a frontend custom card and can be installed via HACS or manually as a JavaScript resource.",3600,home assistant|lovelace|custom card|hacs|smart home|frontend|javascript,1,"This repository provides UI components (custom Lovelace cards) for Home Assistant dashboards, focusing on presentation and interaction (e.g., pop-up cards) rather than data processing or modeling. It does not implement ML/data-science algorithms, datasets, training pipelines, or MLOps tooling. While it could be used to display sensor data in a smart-home context, that is only tangentially related to ML/data workflows, so its direct ML/data value is minimal.",success
https://github.com/geex-arts/django-jet,django-jet,"Django JET is a modern, responsive UI template/skin for the Django admin that adds usability improvements like a customizable admin dashboard, themes support, and enhanced widgets (e.g., autocompletion). The repository notes that new feature development is frozen and only critical bug fixes are expected going forward.",3600,django|django-admin|admin-template|web-development|python|frontend|dashboard,1,"This repository primarily provides a modern responsive theme and UX enhancements for the Django admin interface (including an optional dashboard app), targeting general web application administration rather than analytics or model development. It does not provide ML/data processing functionality, ML framework integrations, or tools commonly used in data science workflows. At most, it could be used to build admin UIs for managing datasets or ML-related models in a Django app, which is only tangentially related to ML/data work, hence the very low score.",success
https://github.com/vidstack/player,vidstack/player,"Vidstack Player is a set of UI components and hooks for building modern, robust, customizable, and accessible video/audio players for the web. It supports multiple frameworks (e.g., React, Vue, Svelte, Solid, Angular) and can be used to create custom layouts or start from pre-built player layouts.",3300,web-development|video-player|audio-player|typescript|react|web-components|accessibility|hls,1,"This repository primarily provides front-end UI components and hooks for building video/audio players on the web, focusing on customization and accessibility rather than data/ML functionality. It does not provide ML models, training/inference code, datasets, or data science tooling, so it has minimal direct applicability to ML/data workflows. It could be used tangentially in ML-adjacent products (e.g., displaying media in a labeling tool or demo app), but that’s not its core purpose, hence the low score.",success
https://github.com/MetaCubeX/metacubexd,metacubexd,"A web-based dashboard UI for Mihomo (Clash-compatible proxy core) that provides real-time traffic stats, proxy group management (including latency testing), connection tracking, rule viewing/search, and live log streaming in a responsive multi-language interface.",2900,proxy-dashboard|mihomo|clash|web-ui|nuxt|vue|typescript|networking,1,"This repository is primarily a networking/proxy management web dashboard (UI) for controlling and monitoring Mihomo/Clash-compatible proxy setups, focusing on traffic/connection visibility and configuration management. It does not provide machine learning models, datasets, ML utilities, or data-science-focused workflows. While it includes monitoring/statistics features, they are operational networking metrics rather than ML/data tooling, so its relevance to ML/data work is minimal.",success
https://github.com/MicrosoftDX/Vorlonjs,Vorlonjs,"Vorlon.JS is an open-source, extensible, platform-agnostic tool for remotely debugging and testing JavaScript applications. It runs a Node.js server (using socket.io) that provides a browser-based dashboard and connects to target pages via an injected client script.",2900,javascript|remote-debugging|web-development|nodejs|socketio|developer-tools|testing,1,"This repository is primarily a remote debugging and testing tool for JavaScript/web applications (developer tooling), not a library or framework for machine learning or data science. While it could be used incidentally when debugging ML-powered web apps or data-driven dashboards, it does not provide ML/data processing capabilities, integrations, or educational ML content. Community adoption appears oriented toward web developers rather than ML/data practitioners, so its direct value for ML/data workflows is minimal.",success
https://github.com/horizon-ui/horizon-ui-chakra,horizon-ui-chakra,"An open-source admin dashboard/template built with React and Chakra UI, providing pre-built pages and UI components to quickly scaffold modern web app dashboards (e.g., authentication, profile, and example dashboard pages).",2800,react|chakra-ui|admin-dashboard|ui-template|frontend|javascript|dashboard-components,1,"This repository is primarily a frontend admin dashboard template for React + Chakra UI, offering UI layouts, pages, and reusable interface components for building web app dashboards. It is not designed for machine learning, data processing, modeling, or analytics workflows, and it does not provide ML/data tooling or integrations as a primary feature. Data/ML teams could use it only indirectly as a generic UI shell to present metrics or model outputs, which makes its ML/data value minimal. Therefore, it scores very low on direct ML/data applicability despite being broadly useful for web development.",success
https://github.com/FormidableLabs/electron-webpack-dashboard,electron-webpack-dashboard,"An Electron desktop application that provides a GUI dashboard for viewing Webpack build and webpack-dev-server telemetry via the webpack-dashboard plugin, offering cross-platform bundle/build visualization outside the terminal.",2700,electron|webpack|developer-tools|build-tooling|dashboard|javascript,1,"This repository is a desktop GUI for monitoring and visualizing Webpack build information (modules/assets/issues) during JavaScript application development, not a data/ML library. It does not provide ML algorithms, datasets, training/inference workflows, or direct integrations with common ML/data tooling. It could be tangentially useful only in the sense that data/ML teams building Electron/Webpack-based apps might use it as general developer tooling, but it offers little ML-specific value, hence the low score.",success
https://github.com/cruip/tailwind-dashboard-template,tailwind-dashboard-template,"Mosaic Lite is a free, responsive admin dashboard template built with Tailwind CSS and React, intended as a starter UI for SaaS products, admin panels, and modern web apps. It includes pre-built widgets and charts (using Chart.js) and is bootstrapped with Vite.",2700,web development|admin dashboard|tailwind css|react|vite|ui template|chart.js,1,"This repository is primarily a front-end admin dashboard UI template (React + Tailwind CSS) with prebuilt components and charts for building web app interfaces. While it can be used to display analytics or ML metrics on a dashboard, it does not provide data science functionality such as data processing, model training, MLOps tooling, or integrations with ML frameworks. Its relevance to ML/data workflows is therefore minimal and mostly limited to being a potential presentation layer for results, which aligns with a very low score.",success
https://github.com/docsifyjs/awesome-docsify,awesome-docsify,"A curated “awesome list” of resources related to Docsify, including plugins, themes, community resources, and real-world Docsify documentation site showcases.",2600,docsify|documentation|static-site|awesome-list|javascript|plugins|themes,1,"This repository is primarily an “awesome list” that catalogs Docsify-related resources (plugins, themes, and example documentation sites) for building documentation websites. It is not designed for machine learning or data science tasks, and it does not provide ML datasets, models, training code, or data-processing utilities. Its relevance to ML/data workflows is minimal aside from being potentially useful for documenting ML projects.",success
https://github.com/pi-hole/web,pi-hole/web,"Pi-hole’s web-based admin dashboard (built on AdminLTE) used to manage a Pi-hole instance and view/query DNS statistics generated by FTL (FTLDNS), including graphs, query logs, and configuration pages.",2400,networking|dns|ad-blocking|web-dashboard|web-administration|privacy|javascript|self-hosted,1,"This repository provides the Pi-hole web interface for administering Pi-hole and inspecting DNS/query statistics (dashboard graphs, query log, settings pages). While it exposes and visualizes operational/network telemetry that could be exported and analyzed, the project itself is not designed for machine learning, data science workflows, or model development. As a result it has minimal direct applicability to ML/data tasks beyond being a potential data source for downstream analysis, warranting a very low score.",success
https://github.com/unruledboy/WebFrontEndStack,WebFrontEndStack,"A curated, diagram-based overview of the web front-end technology stack, covering browsers, protocols, standards, core concepts, libraries/frameworks, tools, and related ecosystem components. Includes scripts/workflows to build/generate the stack image and update related artifacts (e.g., readme and stargazer counts).",2300,web development|frontend|javascript|web standards|technology stack|learning resource|diagram,1,"This repository primarily documents and visualizes the web front-end technology landscape (browsers, protocols, HTML/CSS/JS, tools, etc.) as an educational/reference diagram rather than providing ML or data functionality. While it includes some Node-based tooling to generate images and update metadata, it does not offer data science workflows, datasets, modeling code, or integrations with ML frameworks. As a result, its value for data science and machine learning use cases is minimal, warranting a very low score.",success
https://github.com/open-source-labs/Reactime,Reactime,"Reactime is a Chrome extension for React applications that provides time-travel debugging by recording state snapshots and letting developers replay/jump through state changes. It also offers performance monitoring/analysis (e.g., render timing and web metrics) and multiple visualization views (component graph/JSON/performance/accessibility trees).",2200,react|chrome-extension|time-travel-debugging|performance-monitoring|developer-tools|typescript|web-development,1,"This repository is primarily a React developer tool (a Chrome extension) focused on time-travel debugging and performance monitoring for React applications, not on data science or machine learning. While it involves capturing and visualizing application state and performance metrics, it does not provide ML algorithms, data processing pipelines, modeling utilities, or integration with common ML tooling. Its relevance to ML/data workflows is minimal beyond generic performance/telemetry concepts, so it scores very low.",success
https://github.com/Boscop/web-view,web-view,"Rust bindings for the lightweight cross-platform webview library, enabling developers to build desktop GUIs using web technologies (HTML/CSS/JS) rendered by the host OS’s native web engine. It supports two-way Rust↔JavaScript communication via an invoke handler and JavaScript bridge, aiming for smaller binaries than Chromium/Electron-based alternatives.",2000,rust|desktop-gui|webview|ffi-bindings|cross-platform|html-js-ui|native-web-engine,1,"This repository is primarily a Rust GUI toolkit/binding for embedding a native webview in desktop applications, focusing on Rust↔JavaScript interaction and cross-platform rendering. It is not designed for machine learning or data science tasks, and it does not provide ML algorithms, data processing utilities, or integrations commonly used in ML workflows. While it could be used to build a desktop UI for ML tools, that is incidental rather than a core purpose, so it scores very low for ML/data relevance.",success
https://github.com/dwainscheeren/dwains-lovelace-dashboard,dwains-lovelace-dashboard,"A Home Assistant custom dashboard (Dwains Dashboard / Dwains Lovelace Dashboard) that auto-generates a responsive UI for desktop, tablet, and mobile with minimal configuration, organizing views by Areas and showing relevant entities per area.",2000,home-assistant|lovelace|smart-home|dashboard|home-automation|hacs|custom-component,1,"This repository provides a self-generating UI/dashboard experience for Home Assistant (a smart-home platform), implemented as a custom component and intended to simplify building a home-automation front-end. It is not designed for machine learning or data science workflows (no ML models, datasets, training/evaluation tooling, or data-processing focus). While it could indirectly display sensor data, that is general smart-home UI functionality rather than an ML/data tool, so it has minimal direct applicability to ML/data work.",success
https://github.com/GSA/datagov-wptheme,datagov-wptheme,"An archived (read-only) WordPress theme repository for Data.gov, containing the legacy WordPress template/theme code and serving as an issue tracker and reference hub for Data.gov’s WordPress-based site (distinct from the CKAN-powered data catalog).",1900,wordpress|php|web-development|theme|government|open-data|datagov,1,"This repository is primarily a legacy WordPress theme used for the Data.gov website’s content pages, and it is archived and marked obsolete. It does not provide ML models, datasets, data-processing pipelines, or tooling commonly used in data science/ML workflows; its main value is web theming and site implementation. Data/ML relevance is therefore minimal beyond very indirect educational value for government open-data web publishing.",success
https://github.com/angulartics/angulartics,angulartics,Vendor-agnostic analytics for AngularJS applications. It provides an AngularJS module/service layer for tracking pageviews and events and supports integrations (plugins) such as Google Analytics and Google Tag Manager.,1900,AngularJS|analytics|web development|JavaScript|event tracking|Google Analytics|Google Tag Manager,1,"This repository is a front-end (AngularJS) analytics instrumentation library for capturing user interactions (pageviews/events) and forwarding them to analytics providers like Google Analytics/Tag Manager. It does not provide machine learning, data processing, feature engineering, modeling, or MLOps functionality, and its primary use case is web tracking rather than data science workflows. It is therefore largely unrelated to ML/data work beyond generating behavioral telemetry that could later be analyzed elsewhere, which supports a very low score.",success
https://github.com/MatteoGabriele/vue-analytics,vue-analytics,"A Vue 2 plugin that integrates Google Analytics (analytics.js) into Vue apps, providing automatic script loading, page/event tracking, batching, opt-out support, Vuex integration, e-commerce tracking, and error/exception tracking. The repository is archived (read-only) and is no longer maintained; it does not support GA4 (gtag.js).",1800,vue.js|vue2|google-analytics|analytics|web-tracking|javascript|frontend-plugin,1,"This repository is a frontend Vue plugin for integrating Google Analytics (analytics.js) tracking into Vue 2 applications (pageviews, events, e-commerce, etc.). It is not designed for data science or machine learning workflows, and it does not provide ML/data processing capabilities beyond collecting web analytics signals. While tracked data could later be analyzed in ML pipelines, this package itself is primarily web instrumentation and is also archived/no longer maintained, limiting its practical value for modern analytics/ML setups.",success
https://github.com/ahmadawais/WPGulp,WPGulp,"WPGulp is an advanced, extensively documented Gulp.js build workflow for WordPress theme and plugin development. It provides a zero-config (but configurable) setup for compiling Sass, bundling/minifying JS, optimizing images, live reloading via BrowserSync, and generating translation (.pot) files.",1800,wordpress|gulp|front-end-build-tools|web-development|sass|browsersync|javascript-tooling,1,"This repository is primarily a web-development automation toolkit: a Gulp-based workflow aimed at streamlining WordPress theme/plugin asset building (Sass->CSS, JS bundling/minification, image optimization, live reload, etc.). It does not provide ML models, data processing utilities, dataset tooling, or integrations commonly used in data science/ML pipelines. Its value to ML/data workflows is limited to general-purpose JavaScript build tooling that could be used in any software project, so it is only tangentially relevant.",success
https://github.com/salimi-my/shadcn-ui-sidebar,shadcn-ui-sidebar,"A responsive, retractable sidebar (mini + wide) for Next.js apps built on top of shadcn/ui, with features like grouped items, collapsible submenus, a scrollable menu, and a mobile sheet menu. Includes a custom shadcn registry entry for easy installation and a demo site.",1800,next.js|react|typescript|shadcn-ui|tailwind-css|zustand|ui-components|admin-dashboard,1,"This repository provides a UI sidebar component/template for Next.js built with shadcn/ui, Tailwind CSS, TypeScript, and Zustand, targeting admin dashboards and SaaS-style navigation. It is not designed for machine learning or data science tasks and does not include data processing, modeling, analytics, or ML integrations. Its relevance to ML/data workflows is limited to being a general-purpose frontend component that could be used in tools that happen to display ML results, but it provides no ML-specific functionality. Therefore it scores near the bottom of the scale as essentially unrelated to ML/data beyond incidental UI utility.",success
https://github.com/Tencent/QMUI_Web,Tencent/QMUI_Web,"QMUI Web is a front-end UI framework aimed at improving Web UI development efficiency by providing a SASS-based design system (mixins/functions/config) plus an integrated workflow for building and maintaining consistent, customizable interfaces.",1700,front-end framework|web UI|Sass/SCSS|design system|gulp|workflow automation|component library,1,"This repository is primarily a web UI/front-end framework focused on SASS utilities, reusable UI components, and a built-in build/workflow toolchain (e.g., gulp-based automation) to speed up interface development. It does not provide machine learning models, data processing utilities, dataset tooling, or ML-specific integrations. While build tooling and general web frameworks can appear in data product UIs, the repo’s core purpose is unrelated to ML/data workflows, so its direct value for data science/ML work is minimal.",success
https://github.com/xushier/HD-Icons,HD-Icons,"A collection of high-definition dashboard icons (1024x1024, losslessly compressed) originally made for Unraid Docker containers, also usable in popular dashboard apps (e.g., Dashy, Homer, Heimdall). It provides icon sets in rounded-rectangle and circular styles, plus SVGs, with guidance for using raw GitHub/CDN links and an icons.json bundle for apps.",1700,icon-pack|dashboard|unraid|docker|ui-assets|svg|self-hosted,1,"This repository primarily provides UI icon assets (PNG/SVG) intended for dashboards and Unraid Docker container presentation, along with instructions for linking/consuming the icons. It does not provide ML models, datasets for ML, data processing utilities, or tooling commonly used in ML/data workflows. Its only minor relevance to ML/data is as generic visual assets that could be used in internal tools or dashboards, but that’s incidental rather than the repo’s purpose, so it scores very low.",success
https://github.com/camunda/camunda-modeler,camunda-modeler,"Camunda Modeler is a desktop application for creating and editing BPMN process diagrams, DMN decision tables, and Forms, powered by bpmn.io. It is intended to be used alongside an IDE to build workflow and decision automation solutions with Camunda.",1600,workflow-automation|bpmn|dmn|forms|desktop-application|electron|diagram-editor|camunda,1,"This repository provides a desktop modeling tool for business process (BPMN), decision (DMN), and form modeling, primarily used in workflow automation and process orchestration contexts. It does not provide machine learning algorithms, datasets, model training, or MLOps capabilities, and its direct applicability to ML/data workflows is minimal. Data/ML practitioners might only encounter it indirectly when integrating ML-driven decisions into business processes, but that is not the tool’s core purpose, so it scores very low for ML/data value.",success
https://github.com/dojo/dojo,dojo,"Dojo 1 core JavaScript toolkit/library providing foundational modules for building web applications, including AMD-style module loading, DOM utilities, events, AJAX/IO, promises, internationalization, and related browser/runtime helpers.",1600,javascript|web-development|frontend|dojo-toolkit|amd-modules|dom|ajax,1,"This repository is the Dojo 1 toolkit core library for general-purpose web application development (module system plus browser utilities like DOM manipulation, events, and network/IO). It is not designed for data science or machine learning tasks, nor does it provide ML-specific algorithms, data processing pipelines, or integrations commonly used in ML workflows. Data/ML teams might only encounter it indirectly when maintaining legacy web UIs, which yields minimal direct applicability to ML/data work, hence a score of 1.",success
https://github.com/jiangxy/react-antd-admin,react-antd-admin,"A general-purpose admin dashboard template built with React and Ant Design, aimed at quickly scaffolding back-office UIs. It includes a configurable layout (sidebar/header/footer, routing, auth/SSO hooks) and a schema-driven CRUD/table module (DBTable) for rapidly building common operations screens.",1600,react|ant-design|admin-dashboard|web-development|react-router|crud|webpack,1,"This repository is primarily a React + Ant Design admin UI starter for building general management backends, with emphasis on configurable navigation/layout and schema-driven CRUD screens. It does not provide ML algorithms, data processing utilities, model training/evaluation, or integrations with common ML/data toolchains (e.g., PyTorch, scikit-learn, Airflow, Spark). While it could be used to build an internal UI for monitoring data/ML systems, that is incidental rather than the core purpose. Therefore, its value for data science and machine learning workflows is minimal, warranting a score of 1.",success
https://github.com/joaomilho/Enterprise,Enterprise,"A satirical “Enterprise™ programming language” project that documents a tongue-in-cheek language specification and provides sample implementations (e.g., in Node.js and Rust). It’s primarily a humor/educational parody of enterprise software development culture rather than a production language/tool.",1600,programming-language|satire|language-specification|javascript|nodejs|rust|parser-interpreter,1,"This repository is a parody programming-language project: it focuses on a humorous language spec and includes example implementations (not an ML library or dataset). It has essentially no direct applicability to machine learning or data-science workflows beyond very general programming/engineering learning value. While it appears to have decent popularity for a joke/spec repo, it doesn’t integrate with ML frameworks, data tooling, or MLOps systems, so its ML/data value is minimal—hence a score of 1.",success
https://github.com/Rafase282/My-FreeCodeCamp-Code,My-FreeCodeCamp-Code,"A public journal-style repository containing Rafael Rodriguez’s solutions and project code from the freeCodeCamp curriculum, organized into directories (algorithms, front-end projects, API projects) and supplemented by a wiki for explanations and learning notes.",1500,javascript|freecodecamp|web-development|frontend|algorithms|learning-notes|html-css,1,"This repository primarily collects freeCodeCamp learning exercises and solutions focused on web development (JavaScript, HTML/CSS) and algorithm scripting, acting as a reference/journal rather than a reusable software package. It does not provide ML models, datasets, data pipelines, or integrations with common ML/data frameworks. Its value for ML/data workflows is minimal beyond general programming practice, so it scores very low on ML/data relevance.",success
https://github.com/cedricp/ddt4all,ddt4all,"DDT4All is a Python/PyQt-based OBD/CAN diagnostic tool that lets users build custom ECU parameter screens and communicate with vehicle ECUs over a CAN network using common OBD-II adapters (e.g., ELM327, Vlinker, VGate, ObdLink, ELS27). It focuses on ECU diagnostics/parameter exploration and CAN ISO-TP network study, with cross-platform support and multiple connection types (USB/Bluetooth/WiFi).",1500,automotive-diagnostics|obd-ii|can-bus|ecu|python|pyqt5|reverse-engineering,1,"This repository is primarily an automotive diagnostics and CAN/OBD communication GUI tool for interacting with vehicle ECUs and creating parameter/diagnostic screens, not a data science or machine learning library. While it can be used to extract vehicle telemetry/diagnostic values that could later be analyzed, it does not provide ML workflows, datasets, feature engineering, modeling, or integration with common ML frameworks. Community adoption appears centered on vehicle diagnostics rather than ML/data, so its ML/data value is minimal beyond being a potential data source.",success
https://github.com/creativetimofficial/notus-nextjs,notus-nextjs,"Notus NextJS is a free, open-source UI kit and admin template built with Next.js and Tailwind CSS. It provides prebuilt presentation pages, an admin dashboard, authentication pages, and a large set of reusable components to speed up web app development.",1500,next.js|tailwind-css|ui-kit|admin-dashboard|web-template|frontend|react,1,"This repository is primarily a frontend UI kit/admin template for building websites and dashboards with Next.js and Tailwind CSS, focused on layout and reusable interface components rather than data or ML functionality. It does not include machine learning models, data processing utilities, notebooks, pipelines, or integrations with common ML/data tooling. It could be used to build a web UI for an ML product, but that is an indirect use case, so its value for ML/data workflows is minimal.",success
https://github.com/flatlogic/angular-material-dashboard,angular-material-dashboard,"A responsive admin dashboard template built with AngularJS and Angular Material, providing a Material Design-based UI for business/admin interfaces. Includes a Gulp-based build workflow, Sass styling, and common dashboard layout/components.",1400,web development|admin dashboard|AngularJS|Angular Material|material design|JavaScript|Gulp,1,"This repository is primarily a front-end admin dashboard template (AngularJS + Angular Material) intended for building business/admin web UIs, not for data science or machine learning. While it could be used as a shell to display analytics/ML outputs (e.g., charts, metrics, model monitoring views), it does not provide ML algorithms, data processing utilities, or integrations with common ML/data tooling. Community adoption appears oriented toward UI/template use cases rather than ML workflows, so its direct value for ML/data work is minimal.",success
https://github.com/KidkArolis/jetpack,jetpack,"Jetpack is a zero-/low-configuration bundling and dev-server tool that wraps Rspack (Webpack-compatible) to provide a smoother frontend developer experience. It ships sensible defaults for JS/CSS/assets, fast builds via SWC, hot reloading, differential modern/legacy bundles, and supports proxying or middleware-based integration with an API server.",1300,frontend|javascript|bundler|rspack|webpack|developer-tools|zero-configuration,1,"This repository primarily provides a convenient wrapper around Rspack for building and serving modern web applications with minimal configuration (bundling, dev server, HMR, and production builds). It is not designed for data science or machine learning tasks, and it does not offer ML-focused functionality (e.g., data processing, model training, evaluation, or MLOps tooling). While ML teams might incidentally use it for building web UIs/dashboards, that’s peripheral to ML workflows, so its direct ML/data value is very low.",success
https://github.com/nextacular/nextacular,nextacular,"Nextacular is an open-source starter kit for building full-stack, multi-tenant SaaS apps with features like authentication, teams/workspaces, billing/subscriptions (Stripe), email handling, and custom domains. It’s built on Next.js with Tailwind CSS and Prisma, and is designed for quick deployment (e.g., to Vercel).",1300,next.js|react|saas-starter-kit|multi-tenancy|tailwind-css|prisma|stripe|vercel,1,"This repository is primarily a web/SaaS application starter kit focused on multi-tenant product scaffolding (auth, billing, teams/workspaces, database integrations) rather than data science or machine learning. While it could host ML-powered features inside a SaaS product (e.g., calling model APIs), it does not provide ML algorithms, data tooling, pipelines, or MLOps components out of the box. Its value to ML/data workflows is therefore minimal and mostly incidental to building a web product wrapper around ML services.",success
https://github.com/seraui/seraui,seraui,"Sera UI is an open-source UI component library for React, Next.js, and other JSX frameworks. It provides reusable, customizable components built with Tailwind CSS (and includes integrations like Framer Motion animations and Lucide icons) to speed up building responsive web UIs.",1300,ui-components|react|nextjs|tailwind-css|typescript|component-library|frontend|design-system,1,"This repository is primarily a frontend UI component library (React/Next.js) focused on building and styling web interfaces using Tailwind CSS and related UI tooling. It does not provide ML/data science functionality (e.g., modeling, data processing, MLOps, analytics) and is not directly applicable to ML workflows beyond being used to build a UI for an ML product. Therefore it has minimal ML/data value, earning a score of 1/10.",success
https://github.com/tiberiuzuld/angular-gridster2,angular-gridster2,"An Angular (v21.x) library for building draggable, resizable, responsive grid-based dashboards (widgets) similar to Gridster, enabling dynamic layout management in Angular applications.",1300,angular|typescript|dashboard-layout|drag-and-drop|resizable-widgets|grid-layout|web-development,1,"This repository is a front-end UI layout component for Angular that provides a Gridster-like grid system for arranging dashboard widgets with drag/resize interactions. Its primary use case is building web application dashboards and configurable widget layouts, not data science or machine learning. While it could be used to present ML outputs (e.g., charts/metrics) in a dashboard UI, it does not provide ML/data processing capabilities, integrations, or workflows, so its direct value for ML/data work is minimal.",success
https://github.com/banq/jdonframework,jdonframework,"JdonFramework is a Java Domain Events framework that supports a pub-sub asynchronous programming model for Domain-Driven Design (DDD). It targets building DDD + CQRS + Event Sourcing applications with reactive, event-driven aggregates and aims to support clean/hexagonal architecture without requiring external message middleware like Kafka or RabbitMQ.",1200,java|ddd|cqrs|event-sourcing|domain-events|pub-sub|reactive|clean-architecture,1,"This repository is primarily a Java framework for Domain-Driven Design, focusing on domain events, pub-sub messaging patterns, and building CQRS/Event Sourcing applications. It is not designed for machine learning or data science tasks (no model training, data processing, or ML tooling focus), though its event-driven architecture could be used in systems that later support ML features. Community usage appears oriented toward application architecture rather than ML/data workflows, so its direct applicability to data science is minimal.",success
https://github.com/shannonhochkins/ha-component-kit,ha-component-kit,"HA Component Kit (HAKit) is a set of React-based packages for building highly customizable, real-time dashboards on top of Home Assistant. It provides ready-made UI components and a core library that wraps the Home Assistant WebSocket API for authentication, state updates, and actions.",1200,home-assistant|smart-home|react|typescript|ui-components|dashboard|websocket,1,"This repository is primarily a front-end developer toolkit for building custom Home Assistant dashboards using React/TypeScript, with real-time updates via the Home Assistant WebSocket API. It does not provide machine learning models, data processing pipelines, analytics tooling, or ML/data engineering components. While Home Assistant data could theoretically be consumed by ML workflows elsewhere, this repo itself is focused on UI and smart-home integration rather than ML/data tasks, so its direct ML/data value is minimal.",success
https://github.com/CreativeIT/material-angular-dashboard,material-angular-dashboard,"A free Angular admin dashboard template built with Google Material Design (dark theme) and TypeScript, providing ready-made UI pages/components plus charting and data-table integrations for building admin panels.",1100,angular|angular-material|admin-dashboard|material-design|typescript|sass|data-visualization|web-development,1,"This repository is primarily a front-end admin dashboard template for Angular using Material Design, aimed at rapidly building web-based admin UIs and layouts rather than performing analytics or modeling. While it includes charting (D3/NVD3) and advanced tables (ag-Grid) that could be used to display ML/data outputs, it does not provide ML algorithms, data processing pipelines, or MLOps functionality. Its relevance to ML/data workflows is therefore minimal and mostly limited to presenting results in a UI, which aligns with a very low score.",success
https://github.com/angulartics/angulartics2,angulartics2,"Vendor-agnostic analytics for Angular applications that provides a unified API and directives/services to track page views and events, with pluggable provider integrations (e.g., Google Analytics) and router-based automatic tracking.",1000,angular|typescript|web-analytics|event-tracking|google-analytics|frontend-library|spa|routing,1,"This repository is a frontend Angular library for instrumenting applications with analytics tracking (page views and events) via a provider-agnostic abstraction and provider plugins. It is primarily used for product/web analytics instrumentation rather than data science or machine learning workflows. While the collected event data could later be used for analytics/ML downstream, the repo itself does not provide ML/data processing functionality, datasets, or modeling capabilities, so its direct value for ML/data work is minimal.",success
